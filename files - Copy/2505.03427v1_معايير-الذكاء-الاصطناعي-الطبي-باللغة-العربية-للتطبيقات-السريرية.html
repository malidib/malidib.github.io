<!DOCTYPE html>
<html lang="ar">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MedArabiQ: تقييم النماذج اللغوية الضخمة في المهام الطبية العربية</title>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        body {
            font-family: 'Times New Roman', serif;
            line-height: 1.6;
            color: #333;
            background-color: #fafafa;
            direction: rtl;
        }
        .container {
            max-width: 900px;
            background-color: white;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
            padding: 40px;
            margin: 20px auto;
        }
        h1 {
            text-align: center;
            font-size: 2.2em;
            margin-bottom: 30px;
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 15px;
        }
        h2 {
            color: #34495e;
            font-size: 1.5em;
            margin-top: 35px;
            margin-bottom: 15px;
            border-right: 4px solid #3498db;
            padding-right: 10px;
            border-left: none;
            padding-left: 0;
        }
        h3 {
            color: #5d6d7e;
            font-size: 1.3em;
            margin-top: 25px;
            margin-bottom: 12px;
        }
        p {
            text-align: justify;
            margin-bottom: 15px;
        }
        .abstract {
            background-color: #f8f9fa;
            border-right: 4px solid #007bff;
            border-left: none;
            padding: 20px;
            margin: 30px 0;
            font-style: italic;
        }
        .keywords {
            background-color: #e9ecef;
            padding: 15px;
            margin: 20px 0;
            border-radius: 5px;
        }
        .equation {
            text-align: center;
            margin: 20px 0;
            padding: 15px;
            background-color: #f8f9fa;
            border-radius: 5px;
        }
        .figure {
            text-align: center;
            margin: 30px 0;
            padding: 20px;
            background-color: #f8f9fa;
            border-radius: 5px;
            border: 1px solid #dee2e6;
        }
        .table {
            margin: 25px 0;
        }
        .reference {
            font-size: 0.9em;
            margin-bottom: 8px;
        }
        .meta-info {
            background-color: #e7f3ff;
            padding: 15px;
            margin-bottom: 30px;
            border-radius: 5px;
            font-size: 0.9em;
            direction: ltr;
            text-align: left;
        }
        code {
            background-color: #f8f9fa;
            padding: 2px 4px;
            border-radius: 3px;
        }
        pre {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
        }
        blockquote {
            border-right: 4px solid #6c757d;
            border-left: none;
            padding-right: 20px;
            font-style: italic;
            color: #6c757d;
        }
        .theorem, .lemma, .proposition, .corollary {
            background-color: #fff3cd;
            border: 1px solid #ffeaa7;
            padding: 15px;
            margin: 20px 0;
            border-radius: 5px;
        }
        .proof {
            border-right: 2px solid #28a745;
            border-left: none;
            padding-right: 15px;
            margin: 15px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="meta-info">
            <strong>ArXiv ID:</strong> 2505.03427v1<br>
            <strong>LaTeX الأصلي:</strong> <code>./nyuad_arxiv_papers/nyuad_papers_comprehensive/source_code/2505.03427v1_extracted/main_arxiv_version.tex</code><br>
            <strong>تاريخ التحويل:</strong> 2025-06-06 13:15:53
        </div>
        <header id="title-block-header">
            <h1 class="title">MedArabiQ: تقييم النماذج اللغوية الضخمة في المهام الطبية العربية</h1>
            <p class="author"><br><br><br><br><br><br>
            جامعة نيويورك أبوظبي، الإمارات العربية المتحدة<br>
            <span class="math inline">\(^\dagger\)</span> مساهمات متساوية
            </p>
            <p class="date">نوفمبر 2024</p>
            <div class="abstract">
                <div class="abstract-title">الملخص</div>
                <p>
النماذج اللغوية الضخمة (LLMs) أظهرت إمكانات كبيرة في تطبيقات الرعاية الصحية المتنوعة. إلا أن فعاليتها في المجال الطبي العربي لا تزال غير مستكشفة بشكل كافٍ بسبب نقص مجموعات البيانات المتخصصة عالية الجودة والمعايير المرجعية المناسبة. في هذه الدراسة، نقدم MedArabiQ، وهو معيار مرجعي جديد يتكون من سبع مهام طبية باللغة العربية، تغطي تخصصات متعددة وتشمل أسئلة اختيار من متعدد، وأسئلة إكمال الفراغ، وأسئلة تفاعلية بين المريض والطبيب. قمنا أولاً ببناء مجموعة البيانات بالاعتماد على اختبارات طبية سابقة ومصادر بيانات عامة متاحة. ثم أجرينا تعديلات مختلفة لتقييم قدرات النماذج اللغوية، بما في ذلك تقنيات الحد من التحيز. أجرينا تقييماً شاملاً باستخدام خمسة من أحدث النماذج اللغوية مفتوحة المصدر والمملوكة، من ضمنها GPT-4o وClaude 3.5-Sonnet وGemini 1.5. تؤكد نتائجنا على الحاجة إلى تطوير معايير مرجعية جديدة عالية الجودة تغطي لغات متعددة لضمان عدالة نشر وتوسيع استخدام النماذج اللغوية في الرعاية الصحية. من خلال إنشاء هذا المعيار وإتاحة مجموعة البيانات، نوفر أساساً للبحوث المستقبلية الهادفة إلى تقييم وتعزيز القدرات متعددة اللغات للنماذج اللغوية من أجل استخدام عادل للذكاء الاصطناعي التوليدي في القطاع الصحي.
                </p>
            </div>
        </header>
        <nav id="TOC" role="doc-toc">
            <ul>
                <li><a href="#sec:intro">المقدمة</a></li>
                <li><a href="#related-work">الأعمال ذات الصلة</a></li>
                <li><a href="#methodology">المنهجية</a>
                    <ul>
                        <li><a href="#tasks-and-datasets">المهام ومجموعات البيانات</a>
                            <ul>
                                <li><a href="#multiple-choice-questions">أسئلة اختيار من متعدد</a></li>
                                <li><a href="#multiple-choice-questions-with-bias">أسئلة اختيار من متعدد مع تحيز</a></li>
                                <li><a href="#fill-in-the-blank-with-choices">إكمال الفراغ مع خيارات</a></li>
                                <li><a href="#fill-in-the-blank-without-choices">إكمال الفراغ بدون خيارات</a></li>
                                <li><a href="#patient-doctor-qa">أسئلة وأجوبة بين المريض والطبيب</a></li>
                                <li><a href="#qa-with-grammatical-error-correction-gec">أسئلة وأجوبة مع تصحيح الأخطاء النحوية</a></li>
                                <li><a href="#qa-with-llm-modifications">أسئلة وأجوبة مع تعديلات النماذج اللغوية</a></li>
                            </ul>
                        </li>
                        <li><a href="#models">النماذج</a></li>
                        <li><a href="#evaluation">التقييم</a></li>
                        <li><a href="#bias-assessment-and-mitigation">تقييم التحيز والحد منه</a></li>
                    </ul>
                </li>
                <li><a href="#experimental-setup">إعداد التجارب</a></li>
                <li><a href="#results">النتائج</a></li>
                <li><a href="#discussion">المناقشة</a></li>
                <li><a href="#ethical-considerations">الاعتبارات الأخلاقية</a></li>
                <li><a href="#limitations-and-future-work">القيود والعمل المستقبلي</a></li>
                <li><a href="#conclusion">الخلاصة</a></li>
                <li><a href="#related-work-1">الأعمال ذات الصلة</a></li>
                <li><a href="#appendix-b">نظرة عامة على مجموعة البيانات</a></li>
                <li><a href="#model-overview">نظرة عامة على النماذج</a></li>
                <li><a href="#prompts-by-task">المحفزات حسب المهمة</a></li>
                <li><a href="#bias-evaluation">تقييم التحيز</a></li>
                <li><a href="#performance-by-bias-category">الأداء حسب فئة التحيز</a></li>
                <li><a href="#performance-by-question-category">الأداء حسب فئة السؤال</a></li>
            </ul>
        </nav>
        <section id="data-and-code-availability" class="level4 unnumbered">
            <h4 class="unnumbered">توفر البيانات والكود البرمجي</h4>
            <p>
في هذا العمل، نقدم مجموعة بيانات معيارية جديدة باسم MedArabiQ ونقيّم أداء أحدث النماذج اللغوية الضخمة. نوفر بياناتنا لضمان إمكانية إعادة التجارب وتحقيق تقييم عادل للنماذج مستقبلاً: <a href="https://github.com/nyuad-cai/MedArabiQ" class="uri">https://github.com/nyuad-cai/MedArabiQ</a>
            </p>
        </section>
        <section id="institutional-review-board-irb" class="level4 unnumbered">
            <h4 class="unnumbered">موافقة لجنة الأخلاقيات (IRB)</h4>
            <p>
هذه الدراسة لا تتضمن مشاركين من البشر، وبالتالي لم تكن هناك حاجة للحصول على موافقة لجنة الأخلاقيات.
            </p>
        </section>
        <section id="sec:intro" class="level1">
            <h1>المقدمة</h1>
            <p>
شهدت السنوات الأخيرة ثورة في معالجة اللغة الطبيعية بفضل ظهور النماذج اللغوية الضخمة (LLMs)، حيث أظهرت أداءً استثنائياً في العديد من المهام مثل الترجمة والكتابة الإبداعية <span class="citation" data-cites="mdpi2023"></span>. ورغم أن هذه النماذج صُممت في البداية لفهم اللغة بشكل عام، فقد تم تقييمها لاحقاً في تطبيقات متخصصة مثل التعليم والبرمجة والفنون والطب، كما تم تكييفها لمهام تخصصية عبر استراتيجيات ضبط دقيقة ومجموعات بيانات متخصصة <span class="citation" data-cites="arxiv2023"></span>.
            </p>
            <p>
أثار استخدام النماذج اللغوية الضخمة في الرعاية الصحية اهتماماً واسعاً نظراً لإمكاناتها في تحسين عمليات التشخيص واتخاذ القرار السريري وجودة رعاية المرضى <span class="citation" data-cites="mdpi2023 sciencedirect2024"></span>. من التطبيقات البارزة أيضاً التعليم الطبي، حيث يمكن لهذه النماذج توليد ملخصات دقيقة ودعم التعلم التفاعلي <span class="citation" data-cites="oup2023"></span>. ولهذا الغرض، تم اقتراح معايير مرجعية لتقييم قدرات النماذج في المعرفة الطبية والاستدلال. ومع ذلك، لا تزال هناك تحديات مثل القضايا الأخلاقية، ومخاطر إنتاج محتوى متحيز أو ضار، وتفاوت الأداء بين اللغات والسياقات الثقافية <span class="citation" data-cites="wiley2024 mdpi2023"></span>.
            </p>
            <p>
تستهدف المعايير المرجعية الحالية مثل GLUE وMedQA اللغة الإنجليزية بالدرجة الأولى، مما يترك فجوة كبيرة في تقييم النماذج اللغوية للمهام الطبية العربية <span class="citation" data-cites="nature2024"></span>. ويعود ذلك إلى عدة أسباب، منها قلة توفر مجموعات بيانات عربية عالية الجودة للتطبيقات السريرية، بالإضافة إلى التعقيد اللغوي للغة العربية وتعدد لهجاتها (الخليج، المغرب العربي، مصر، الشام، وغيرها) إلى جانب العربية الفصحى <span class="citation" data-cites="acl2018"></span>. كما أن أداء النماذج متعددة اللغات التي تتضمن العربية في بيانات تدريبها غالباً ما يكون دون المستوى في السياقات الطبية بسبب نقص الموارد المتخصصة والمعايير المرجعية المناسبة <span class="citation" data-cites="mdpi2023 arxiv2024"></span>. معالجة هذه الفجوات أمر ضروري لتحقيق الاستفادة الكاملة من النماذج اللغوية لصالح المرضى ومقدمي الرعاية الناطقين بالعربية وضمان عدالة الوصول إلى تقنيات الذكاء الاصطناعي في الصحة.
            </p>
            <p>
استجابة لهذه التحديات، تبرز الحاجة إلى أطر عمل لتقييم أداء النماذج اللغوية في المهام السريرية الخاصة بالمجتمعات الناطقة بالعربية. من خلال تطوير معايير تعكس التفاعلات السريرية الواقعية، يمكن ضمان نشر أكثر موثوقية وملاءمة ثقافية للنماذج في أنظمة الرعاية الصحية متعددة اللغات. في هذه الدراسة، نقدم عدة مساهمات رئيسية من خلال تقديم MedArabiQ (انظر الشكل <a href="#fig:overview" data-reference-type="ref" data-reference="fig:overview">[fig:overview]</a>). أولاً، طورنا سبع مجموعات بيانات معيارية لتقييم النماذج في تطبيقات الرعاية الصحية العربية، مع مراعاة التعقيد اللغوي والتحديات التخصصية. ركزنا على مهام طبية حاسمة مثل الإجابة على الأسئلة الطبية، والحوار السريري، واتخاذ القرار الأخلاقي. ثانياً، قمنا بتحليل أداء النماذج متعددة اللغات والنماذج العربية، مع إبراز أثر التغطية اللغوية وشفافية بيانات التدريب على التطبيقات الصحية. أجرينا تقييماً شاملاً لتقديم أساس متين لتطوير حلول الذكاء الاصطناعي في المهام الطبية العربية.
            </p>
            <div class="figure*">
                <p><img src="figures/fig1-arx.png" style="width:92.0%" alt="صورة" /></p>
            </div>
        </section>
        <section id="related-work" class="level1">
            <h1>الأعمال ذات الصلة</h1>
            <p>
تم اقتراح العديد من المعايير المرجعية لتقييم أداء النماذج اللغوية في المهام الطبية، وغالباً ما تركز على اللغة الإنجليزية. على سبيل المثال، قدم <span class="citation" data-cites="GAO2023104286"></span> معيار Dr. Bench، وهو معيار للاستدلال التشخيصي في معالجة اللغة السريرية يركز على فهم النصوص الطبية واستدلال المعرفة الطبية وتوليد التشخيصات. يجمع هذا المعيار بيانات باللغة الإنجليزية من مصادر متنوعة، لكنه يعتمد أساساً على ملاحظات سريرية داخل المستشفيات. لتقييم أداء النماذج في مهام الإجابة على الأسئلة الطبية، تم تضمين عينات من اختبارات المجالس الطبية مثل MedQA، الذي يدعم التقييم متعدد اللغات عبر إدراج أسئلة بالصينية التقليدية والمبسطة والإنجليزية <span class="citation" data-cites="jin2020diseasedoespatienthave"></span>. كما يستخدم معيار MMLU أسئلة من اختبار الترخيص الطبي الأمريكي <span class="citation" data-cites="hendrycks2021measuringmassivemultitasklanguage"></span>، بينما يوسع MedMCQA هذه المعايير إلى إطار تقييم متعدد اللغات <span class="citation" data-cites="pal2022medmcqa"></span>.
            </p>
            <p>
رغم الاهتمام المتزايد بمعالجة اللغة العربية، لا تزال المعايير الطبية العربية محدودة. فقد ترجم <span class="citation" data-cites="achiam2023gpt"></span> معيار MMLU إلى 14 لغة من بينها العربية بمساعدة مترجمين محترفين. يركز AraSTEM على مهمة الإجابة على الأسئلة وله جزء طبي <span class="citation" data-cites="mustapha2024arastemnativearabicmultiple"></span>. كما يقدم AraMed مجموعة بيانات طبية عربية مشروحة <span class="citation" data-cites="alasmari2024"></span>. ومعظم هذه المجموعات تركز على مهمة الإجابة على الأسئلة الطبية وغالباً ما تعاني من قصور آخر، كما هو موضح في الجدول <a href="#table:dataset_comparison" data-reference-type="ref" data-reference="table:dataset_comparison">[table:dataset_comparison]</a>. رغم فائدتها، إلا أنها لا تغطي طيف المهام الطبية العربية بشكل شامل، مما يبرز الحاجة إلى جهود معيارية متخصصة.
            </p>
            <p>
فيما يتعلق بالتقييم، تم اقتراح عدة أطر لتقييم نماذج الذكاء الاصطناعي السريرية. يتكون "نموذج الحوكمة للذكاء الاصطناعي في الرعاية الصحية" من أربعة ركائز رئيسية: العدالة، الشفافية، الموثوقية، والمساءلة <span class="citation" data-cites="Reddy2020491"></span>. كما اقترح <span class="citation" data-cites="dada2024doesbiomedicaltraininglead"></span> إطار تقييم لفهم اللغة السريرية يقيّم النماذج باستخدام بيانات مرضى حقيقية لمهام متنوعة مثل الإجابة على الأسئلة، واستخلاص الفرضيات، وتلخيص المشكلات والاستفسارات. وقدم <span class="citation" data-cites="kanithi2024"></span> إطار "MEDIC" لتقييم النماذج عبر خمس فئات سريرية: الاستدلال الطبي، القضايا الأخلاقية والتحيز، فهم البيانات واللغة، التعلم في السياق، والسلامة السريرية وتقييم المخاطر. رغم التقدم الكبير في هذا المجال، إلا أن معظم التقييمات أجريت على بيانات باللغة الإنجليزية، ولا يوجد معيار واحد لتقييم النماذج العربية في أكثر من مهمة طبية ومقياس أداء واحد. مع وجود أكثر من 380 مليون ناطق أصلي بالعربية <span class="citation" data-cites="Eberhard2024"></span>، كثير منهم أحادي اللغة، من الضروري تلبية احتياجات المرضى الناطقين بالعربية لضمان عدالة النشر.
            </p>
        </section>
        <section id="methodology" class="level1">
            <h1>المنهجية</h1>
            <p>
نستعرض هنا تفاصيل الإطار المنهجي لبناء مجموعات البيانات وتقييم أحدث النماذج اللغوية الضخمة. يقدم الشكل <a href="#fig:overview" data-reference-type="ref" data-reference="fig:overview">[fig:overview]</a> نظرة عامة على MedArabiQ.
            </p>
            <section id="tasks-and-datasets" class="level2">
                <h2>المهام ومجموعات البيانات</h2>
                <p>
لتطوير إطار موثوق لتقييم النماذج اللغوية في تطبيقات الرعاية الصحية العربية، ركزنا على الاستشارات الطبية عن بعد والإجابة على الأسئلة كحالات استخدام رئيسية. تتطلب هذه المهام ليس فقط القدرة على الاستدلال الطبي، بل أيضاً الحوار الطبيعي بين المريض والطبيب. يجب أن يحاكي النموذج دور الطبيب قدر الإمكان، بما في ذلك امتلاك المعرفة الطبية وتوظيفها بشكل مخصص حسب احتياجات المرضى. ومع ذلك، يجب ألا يؤدي التخصيص إلى تحيز أو تمييز في إجابات النموذج بناءً على ملف المريض. في الواقع، ينبغي أن يظهر النموذج مقاومة للمحفزات المتحيزة، ويستجيب بعدالة وموضوعية. استمددنا مجموعات البيانات من مصدرين رئيسيين: <span>اختبارات سابقة وملاحظات من كليات الطب العربية</span>، و<span>مجموعة بيانات AraMed</span> <span class="citation" data-cites="alasmari2024"></span>. اخترنا مصادر بيانات من غير المرجح أن تكون مدرجة في مجموعات تدريب النماذج السابقة.
                </p>
                <section id="multiple-choice-questions" class="level3">
                    <h3>أسئلة اختيار من متعدد</h3>
                    <p>
لتقييم الفهم الطبي للنماذج، أنشأنا مجموعة بيانات معيارية من أزواج أسئلة وأجوبة تغطي مواضيع طبية أساسية ومتقدمة مثل الفسيولوجيا، التشريح، وجراحة الأعصاب. جمعنا اختبارات ورقية وملاحظات محاضرات من مستودع أكاديمي كبير تديره منصات طلابية في كليات الطب الإقليمية. لم تتضمن البيانات أي معلومات تعريفية أو بيانات مرضى حقيقية، وبالتالي لم تكن هناك حاجة لإخفاء الهوية. لم تكن هذه الاختبارات متاحة بصيغ رقمية منظمة، مما تطلب جهداً يدوياً كبيراً لضمان الدقة والوضوح. ونظراً لأن التعليم الطبي العربي غير رقمي إلى حد كبير، فإن هذه الاختبارات ليست متاحة للعامة بشكل منظم. حتى إن وُجدت بعض الأسئلة بشكل فردي على الإنترنت، فإن الجهد الكبير المطلوب لتجميعها وهيكلتها يقلل من احتمال تلوث البيانات. تم اختيار الأسئلة لتعكس تدرج الصعوبة عبر السنوات الأكاديمية، لضمان تقييم أداء النماذج على مستويات مختلفة من الخبرة الطبية. اخترنا عينة عشوائية من 100 سؤال اختيار من متعدد، وقمنا برقمنتها والتحقق منها يدوياً. متوسط طول السؤال يتراوح بين 15 و30 كلمة.
                    </p>
                </section>
                <section id="multiple-choice-questions-with-bias" class="level3">
                    <h3>أسئلة اختيار من متعدد مع تحيز</h3>
                    <p>
تماشياً مع الأعمال الحديثة <span class="citation" data-cites="schmidgall2024addressing"></span>، قمنا بحقن التحيز في مجموعة أسئلة الاختيار من متعدد لتقييم كيفية تعامل النماذج مع السيناريوهات الأخلاقية أو الثقافية الحساسة. استخدمنا فئات تحيز محددة مسبقاً مثل: (1) التحيز التأكيدي، (2) تحيز الحداثة، (3) تحيز التكرار، (4) التحيز الثقافي، (5) تحيز الإجماع الزائف، (6) تحيز الوضع القائم، و(7) تحيز التشخيص الذاتي. من خلال الحقن اليدوي للانحياز، ضمنا ملاءمة الأسئلة للتحديات اللغوية والسريرية الفريدة في السياق العربي. نتج عن ذلك مجموعة بيانات مكونة من 100 عينة.
                    </p>
                </section>
                <section id="fill-in-the-blank-with-choices" class="level3">
                    <h3>إكمال الفراغ مع خيارات</h3>
                    <p>
لتقييم استرجاع المعرفة والتعلم في السياق، أنشأنا يدوياً أسئلة إكمال الفراغ، كل منها مصحوب بمجموعة من الخيارات المحددة مسبقاً. كان على النموذج اختيار الإجابة الأنسب من بين الخيارات. يقيس هذا النهج قدرة النموذج على التعرف على الإجابة الصحيحة ضمن مجموعة محددة، ويقلل من الاعتماد على قدرات التوليد الحرة. تتكون مجموعة البيانات من 100 عينة.
                    </p>
                </section>
                <section id="fill-in-the-blank-without-choices" class="level3">
                    <h3>إكمال الفراغ بدون خيارات</h3>
                    <p>
في هذا الإعداد، تم تقديم أسئلة إكمال الفراغ بدون خيارات محددة، مما يتطلب من النموذج توليد الإجابة بشكل مستقل. يقيس هذا التقييم قدرة النموذج على استرجاع وتوليد المعرفة الطبية الدقيقة دون معلومات إضافية، مع التركيز على الاستدلال وقدرات التوليد اللغوي. تتكون مجموعة البيانات لهذه المهمة أيضاً من 100 عينة.
                    </p>
                </section>
                <section id="patient-doctor-qa" class="level3">
                    <h3>أسئلة وأجوبة بين المريض والطبيب</h3>
                    <p>
تعد AraMed مجموعة بيانات طبية عربية للإجابة على الأسئلة، تم جمعها أصلاً من منصة الطبي، وهي منتدى إلكتروني للنقاشات الطبية بين المرضى والأطباء <span class="citation" data-cites="alasmari2024"></span>. تتكون المجموعة الأصلية من 400 زوج سؤال وجواب، جميعها مصاغة بالعربية الفصحى لضمان الاتساق. اخترنا يدوياً 100 عينة، مع إعطاء الأولوية للأسئلة ذات الصياغة الجيدة والإجابات المفيدة، وتجنبنا الحالات التي كانت الإجابات فيها عامة جداً (مثل "استشر طبيباً" أو "راجع أخصائياً")، مع الاحتفاظ ببعض الأمثلة لتعكس سلوك المستخدمين في الواقع.
                    </p>
                    <p>
حافظنا أيضاً على التوزيع النسبي للفئات الطبية، خاصة في مجالات الصحة الإنجابية والجنسية، والتي غالباً ما تكون ناقصة التمثيل في الأبحاث الطبية العربية رغم أهميتها. ونظراً لحساسية هذه المواضيع، حرصنا على تضمينها لتوفير تقييم أكثر واقعية وتوازناً لقدرة النماذج على التعامل مع استفسارات طبية متنوعة. لضمان التوزيع العادل، اخترنا 100 سؤال، وخصصنا نسبة متساوية لكل تخصص: أمراض القلب، التوليد وأمراض النساء، الجراحة، طب الأطفال، الأعصاب، الأورام، الغدد الصماء، طب الأسنان، الأنف والأذن والحنجرة، الصحة العامة، الأمراض الجلدية، الرعاية الأولية، أمراض الرئة، وعلم النفس.
                    </p>
                    <p>
قمنا أيضاً بإضافة معلومات عن المريض مثل العمر والجنس عند توفرها في السؤال. إذا كانت هذه المعلومات غير معروفة أو غير منطقية (مثلاً عمر غير واقعي)، تم استبعادها. أحياناً كان السؤال يرد من قريب للمريض، فلا تتوفر معلومات عنه. عادةً ما تضاف هذه المعلومات في بداية السؤال أو بعد التحية، بصيغة "أنا رجل/امرأة وعمري [س] سنة". أضفى ذلك واقعية وتخصيصاً على السيناريوهات، مما يجعل المعيار أكثر ملاءمة لتقييم أداء النماذج في الحالات الطبية الواقعية.
                    </p>
                </section>
                <section id="qa-with-grammatical-error-correction-gec" class="level3">
                    <h3>أسئلة وأجوبة مع تصحيح الأخطاء النحوية</h3>
                    <p>
نظراً لاستخدام اللهجات في مجموعة أسئلة وأجوبة المرضى، أنشأنا نسخة إضافية ذات جودة لغوية أعلى. طبقنا سلسلة تصحيح أخطاء نحوية مخصصة للنصوص الطبية العربية. نظراً لتعقيد العربية صرفياً ونحوياً، كان هذا الإجراء ضرورياً. استخدمنا cameltools، وهي مكتبة مفتوحة المصدر لمعالجة اللغة العربية، لتفكيك الكلمات وإزالة التشكيل <span class="citation" data-cites="obeid2020"></span>. ثم استخدمنا نموذج GED قائم على BERT لاكتشاف أخطاء الاتفاق والترتيب والصرف <span class="citation" data-cites="alhafni-etal-2023-advancements"></span>. تم تصحيح الأخطاء تلقائياً باستخدام نموذج GEC مبني على mBART، مدرب على مجموعات QALB-2015 وQALB-2014 وZAEBUC <span class="citation" data-cites="mohit-etal-2014-first rozovskaya-etal-2015-second habash-palfreyman-2022-zaebuc"></span>.
                    </p>
                </section>
                <section id="qa-with-llm-modifications" class="level3">
                    <h3>أسئلة وأجوبة مع تعديلات النماذج اللغوية</h3>
                    <p>
لتقليل احتمالية حفظ النماذج للأسئلة، خاصة أن بعضها قد يكون تدرب على بيانات من الطبي، قمنا بتعديل مجموعة البيانات باستخدام نموذج لغوي ضخم لإعادة صياغة الأسئلة مع الحفاظ على معناها <span class="citation" data-cites="dong2024"></span>. استخدمنا GPT-4o لإعادة صياغة الأسئلة عبر محفز: "أنت مساعد مفيد تعيد صياغة النص مع الحفاظ على معناه." ضمنت هذه الطريقة بقاء المفاهيم الطبية الأساسية مع تقليل الاعتماد على الحفظ.
                    </p>
                    <p>
باختصار، أنشأنا سبع مجموعات بيانات جديدة باستخدام مصدرين رئيسيين (AraMed واختبارات طبية سابقة) عبر تحقق يدوي مكثف لبناء معيار MedArabiQ.
                    </p>
                    <div class="table*">
                        <p><span>tab:benchmark_results</span></p>
                        <p><span id="table:results" label="table:results"></span></p>
                    </div>
                </section>
            </section>
            <section id="models" class="level2">
                <h2>النماذج</h2>
                <p>
غالباً ما تواجه المعايير المرجعية المستخدمة لتقييم النماذج اللغوية تحدي تلوث البيانات، إذ أن العديد من النماذج الحديثة تدربت على مجموعات ضخمة من الإنترنت قد تتضمن أسئلة من المعايير نفسها، مما يؤدي إلى تضخيم نتائج الأداء وجعل التقييم غير عادل <span class="citation" data-cites="deng2024 yihong2024"></span>. معالجة هذه المشكلة ضروري لضمان أن نتائج التقييم تعكس القدرات الحقيقية للنماذج دون تحيز ناتج عن التعرض المسبق للبيانات.
                </p>
                <p>
لتقليل هذه المخاوف، صنفنا النماذج إلى مجموعتين رئيسيتين: نماذج ذات <strong>بيانات تدريب معروفة</strong> ونماذج ذات <strong>بيانات تدريب غير معروفة</strong>. يسمح هذا التمييز بتقييم مخاطر التلوث بشكل أكثر موثوقية للنماذج ذات المصادر الموثقة، مع الاعتراف بأن النماذج غير الشفافة قد يصعب استبعاد تلوثها.
                </p>
                <p>
بالإضافة إلى ذلك، صنفنا النماذج حسب التغطية اللغوية: نماذج <strong>متعددة اللغات بشكل عام</strong> ونماذج <strong>تركز على العربية</strong>. رغم أن العديد من النماذج تتضمن بيانات من لغات عديدة، إلا أن التعرض للغة لا يعني بالضرورة إتقانها <span class="citation" data-cites="bender2021"></span>. على سبيل المثال، من المعروف أن GPT-4 تدرب على لغات متنوعة <span class="citation" data-cites="achiam2023gpt"></span>. من خلال تقييم النماذج متعددة اللغات والنماذج العربية بشكل منفصل، يمكننا تحديد أثر التغطية والتخصص اللغوي على الأداء في المهام الطبية العربية. يوضح الجدول <a href="#table:models" data-reference-type="ref" data-reference="table:models">[table:models]</a> النماذج المختارة.
                </p>
            </section>
            <section id="evaluation" class="level2">
                <h2>التقييم</h2>
                <p>
يتطلب تقييم النماذج اللغوية في تطبيقات الرعاية الصحية العربية إطاراً شاملاً يوازن بين الأداء التقني والملاءمة الواقعية <span class="citation" data-cites="sallam2024"></span>. يقيم إطارنا الاستدلال الطبي، اتخاذ القرار، والإجابة الحوارية على الأسئلة <span class="citation" data-cites="kanithi2024 guo2023"></span>. تم تقييم أسئلة الاختيار من متعدد بناءً على الدقة، بينما تم تقييم الأسئلة المفتوحة مثل إكمال الفراغ وأسئلة المريض-الطبيب باستخدام BERTScore لقياس التقارب الدلالي <span class="citation" data-cites="bert-score"></span>.
                </p>
            </section>
            <section id="bias-assessment-and-mitigation" class="level2">
                <h2>تقييم التحيز والحد منه</h2>
                <p>
لضمان إمكانية نشر النماذج اللغوية في الرعاية الصحية بشكل فعال، من الضروري معالجة احتمالية تكرارها لتحيزات بشرية. من المستحيل تقريباً إزالة التحيز تماماً من النماذج، إذ أن مجموعات البيانات المستخدمة في التدريب تتأثر حكماً بالأحكام البشرية. إدراكاً لهذا التحدي، طورنا إطار تقييم منهجي لقياس مقاومة النماذج للانحيازات المحقونة في أسئلة الاختيار من متعدد، وقياس القابلية للتأثر، واختبار استراتيجيات الحد من التحيز. يستند الإطار إلى منهجيات حديثة <span class="citation" data-cites="schmidgall2024addressing"></span> مع تكييفها للسياق العربي الطبي، بما في ذلك فئات تحيز ملائمة ثقافياً، ومحفزات مصممة للسيناريوهات السريرية، ومقاييس تقييم إضافية.
                </p>
                <p>
أنشأنا إطاراً منهجياً لتقييم مقاومة النماذج للانحيازات المعرفية:
                </p>
                <ol>
                    <li><p><strong>الاختبار الأساسي:</strong> يتم تقييم النماذج باستخدام مجموعة البيانات الأصلية غير المتحيزة لتحديد خط الأساس للأداء.</p></li>
                    <li><p><strong>اختبار التحيز:</strong> يتم اختبار النماذج مع نسخ متحيزة من المحفزات، ونحسب التغير في الدقة لقياس أثر التحيز.</p></li>
                    <li><p><strong>تقييم الحد من التحيز:</strong> يتم اختبار تقنيات الحد من التحيز وقياس أثرها على الدقة، وتشمل:</p>
                        <ul>
                            <li><p><strong>التثقيف حول التحيز:</strong> إضافة تحذيرات في المحفزات تؤكد على الاستدلال القائم على الأدلة (مثلاً: "قيّم كل مريض بشكل فردي دون الاعتماد على الاتجاهات أو الحالات الأخيرة").</p></li>
                            <li><p><strong>مثال واحد توضيحي:</strong> تقديم مثال سلبي واحد يوضح الاستدلال الخاطئ الناتج عن التحيز.</p></li>
                            <li><p><strong>عدة أمثلة توضيحية:</strong> تقديم أمثلة إيجابية وسلبية توضح التعامل الصحيح والخاطئ مع التحيز.</p></li>
                        </ul>
                    </li>
                </ol>
                <p>
يوفر هذا الإطار منهجية منهجية وقابلة للتكرار لتقييم ومعالجة التحيزات المعرفية في النماذج اللغوية، لضمان نشرها في السياقات الصحية بشكل فعال وأخلاقي.
                </p>
                <div class="figure*">
                    <p><img src="figures/fig2-lasr.png" alt="صورة" /></p>
                </div>
                <div class="figure*">
                    <p><img src="figures/samples-arx.png" style="width:97.0%" alt="صورة" /></p>
                </div>
            </section>
        </section>
        <section id="experimental-setup" class="level1">
            <h1>إعداد التجارب</h1>
            <p>
<strong>التقييم.</strong> استخدمنا أسلوب التحفيز الصفري (zero-shot) لجميع النماذج والمهام، مع ضبط درجة الحرارة حسب طبيعة كل معيار بعد مرحلة اختبار أولية. في النماذج المغلقة، تم تعيين درجة الحرارة إلى 0.2 لجميع المهام. في النماذج مفتوحة المصدر، تم تعيينها إلى 0 في المهام المغلقة لضمان إجابات حتمية، و0.4 في المهام المفتوحة. في تقييم BERTScore، استخدمنا نموذج XLM-RoBERTa-Large المدرب على لغات متعددة منها العربية، مما يجعله أكثر ملاءمة من النماذج أحادية اللغة.
            </p>
            <p>
<strong>النماذج المضبوطة بالتعليمات.</strong> استخدمنا نسخاً مضبوطة بالتعليمات من النماذج السابقة نظراً لقدرتها الأفضل على فهم وتنفيذ التعليمات الخاصة بالمهام. أما النسخ الأساسية فقد أظهرت قصوراً كبيراً في اتباع المحفزات حتى مع تحسينها، وهو ما يتفق مع الأدبيات <span class="citation" data-cites="chung2022scaling zhang2023instruction"></span> التي تؤكد أن ضبط التعليمات يحسن الأداء والالتزام بالمحفزات عبر المهام والأحجام المختلفة.
            </p>
            <p>
<strong>محفزات التعليمات.</strong> يعد هندسة المحفزات أمراً محورياً في تقييم النماذج. في تجاربنا، اختبرنا المحفزات بالإنجليزية والعربية، ووجدنا أن المحفزات الإنجليزية كانت أكثر فعالية عموماً، باستثناء مهام AraMed حيث تفوقت المحفزات العربية في النماذج مفتوحة المصدر. بناءً على ذلك، استخدمنا المحفزات الإنجليزية لجميع المهام باستثناء أسئلة المريض-الطبيب، وتصحيح الأخطاء النحوية، وتعديلات النماذج. يوضح الجدول التكميلي <a href="#table:prompts" data-reference-type="ref" data-reference="table:prompts">[table:prompts]</a> المحفزات المستخدمة.
            </p>
            <p>
<strong>معالجة الإجابات.</strong> في مهام الأسئلة والإجابات، والأسئلة مع التحيز، وإكمال الفراغ مع خيارات، تولد النماذج كل من مؤشر الخيار الصحيح والنص الكامل للإجابة. إلا أن بعض النماذج، خاصة مفتوحة المصدر، تظهر تبايناً في التهجئة. لضمان الدقة، قمنا بتقييم أول حرف بعد عبارة "الحرف الصحيح هو:" ومقارنته بالخيارات المتاحة. إذا لم يتطابق الحرف مع خيار صحيح، تعتبر الإجابة غير صالحة. في المهام المفتوحة، يتم تقييم الإجابة الكاملة التي يولدها النموذج.
            </p>
            <div class="figure*">
                <p><img src="figures/bias_figure.png" style="width:95.0%" alt="صورة" /></p>
            </div>
        </section>
        <section id="results" class="level1">
            <h1>النتائج</h1>
            <p>
نستعرض نتائج جميع التجارب على المعايير الستة في الجدول <a href="#table:results" data-reference-type="ref" data-reference="table:results">[table:results]</a>. تظهر النتائج أنه لا يوجد نموذج واحد يتفوق على جميع النماذج في جميع المعايير. في المهام المغلقة (الاختيار من متعدد وإكمال الفراغ مع وبدون خيارات)، تتفوق النماذج المغلقة كما هو متوقع. يحقق Gemini 1.5 Pro أعلى دقة في ثلاث من أصل ست مهام، مع أداء مماثل لـ Claude 3.5 Sonnet في إحداها. في أسئلة الاختيار من متعدد وإكمال الفراغ مع خيارات، يتفوق Gemini بدقة 57.5 و72.7 على التوالي. أما في المهام المفتوحة (أسئلة المريض-الطبيب، التصحيح النحوي، وتعديلات النماذج)، فيتفوق Qwen محققاً 85.2 في أسئلة المريض-الطبيب، بينما يحقق LLaMa أفضل نتيجة في التصحيح النحوي بـ 85.5. ومع ذلك، لا تتفوق النماذج نفسها في جميع أنواع المهام، إذ أن Qwen وLLaMa أداؤهما ضعيف في المهام المغلقة.
            </p>
            <p>
يقارن الشكل <a href="#fig:results_overall" data-reference-type="ref" data-reference="fig:results_overall">[fig:results_overall]</a> (أ) أداء النماذج مفتوحة المصدر والمبنية على واجهات برمجة التطبيقات عبر جميع المهام. يحقق <strong>Gemini 1.5 Pro</strong> <strong>أعلى متوسط أداء</strong>، يليه GPT-4 وClaude 3.5، مما يعزز تفوق النماذج المملوكة في مهام معالجة اللغة. تظهر النماذج مفتوحة المصدر مثل Llama 3.1 وQwen 2.5 أداءً تنافسياً لكن متغيراً، مع تفوق Qwen 2.5 بينها. تشير أشرطة الخطأ إلى أن النماذج المغلقة أكثر استقراراً، بينما تظهر النماذج مفتوحة المصدر تبايناً أكبر بسبب اعتمادها على تدريب عام بدلاً من ضبط تخصصي. تؤكد هذه النتائج تفوق النماذج المملوكة حالياً، مع إمكانية تحسين النماذج مفتوحة المصدر عبر ضبط تخصصي.
            </p>
            <p>
يوضح الشكل <a href="#fig:results_overall" data-reference-type="ref" data-reference="fig:results_overall">[fig:results_overall]</a> (ب) تباين الأداء حسب نوع المهمة، حيث تحقق النماذج المغلقة نتائج عالية في جميع المعايير، خاصة في مهام الأسئلة والأجوبة بما في ذلك التصحيح النحوي وتعديلات النماذج. يشير ذلك إلى قدرة قوية على التعامل مع الاستفسارات الطبية المعقدة، وهو أمر حاسم في التطبيقات الواقعية. ومع ذلك، تظهر مهام إكمال الفراغ والاختيار من متعدد تبايناً أكبر، مع تأخر النماذج مفتوحة المصدر عن المغلقة. تؤكد هذه الفجوات الحاجة إلى ضبط تخصصي للنماذج مفتوحة المصدر لتحسين الدقة في المهام المعرفية. يوضح الشكل <a href="#fig:samples" data-reference-type="ref" data-reference="fig:samples">[fig:samples]</a> أمثلة من إجابات النماذج في المهام المغلقة والمفتوحة.
            </p>
            <p>
يستعرض الشكل <a href="#fig:bias" data-reference-type="ref" data-reference="fig:bias">[fig:bias]</a> أثر التحيز واستراتيجيات الحد منه على أداء النماذج. في الشكل (أ)، نقارن دقة GPT-4o وGemini 1.5 Pro وClaude 3.5 Sonnet-20240620 في الأسئلة الأصلية مقابل الأسئلة المحقونة بالتحيز عبر فئات التحيز المختلفة. تظهر النتائج انخفاضاً عاماً في الدقة عند إدخال التحيز، مع تفاوت الانخفاض حسب نوع التحيز. يظهر Gemini 1.5 Pro مقاومة أعلى خاصة في تحيز الوضع القائم والإجماع الزائف، بينما يظهر Claude 3.5 Sonnet انخفاضاً أكبر في تحيز التشخيص الذاتي والتحيز الثقافي. في الشكل (ب)، يتضح تحسن الدقة مع استراتيجيات مثل التحفيز بعدة أمثلة مقارنة بالأسئلة المتحيزة دون تدخل. يتفوق Gemini 1.5 Pro باستمرار في جميع الاستراتيجيات، مما يعزز متانته في مواجهة التحيز.
            </p>
            <p>
يعرض الشكل (ج) مخطط راداري يلخص أداء النماذج عبر استراتيجيات الحد من التحيز. يظهر Gemini أداءً ثابتاً، بينما يظهر GPT-4o وClaude 3.5 Sonnet تبايناً أكبر عبر الاستراتيجيات مثل التثقيف حول التحيز والتحفيز بمثال واحد. تؤكد هذه النتائج أهمية استراتيجيات الحد من التحيز في تعزيز موثوقية النماذج. يمكن الاطلاع على تفاصيل إضافية حول الأداء حسب فئة التحيز والتخصص الطبي في الأشكال <a href="#fig:bias accuracy1" data-reference-type="ref" data-reference="fig:bias accuracy1">[fig:bias accuracy1]</a> و<a href="#fig:bias accuracy2" data-reference-type="ref" data-reference="fig:bias accuracy2">[fig:bias accuracy2]</a> في الملحق.
            </p>
        </section>
        <section id="discussion" class="level1">
            <h1>المناقشة</h1>
            <p>
تتفق نتائجنا مع أبحاث سابقة في تقييم النماذج الطبية، حيث تتفوق النماذج المغلقة في المهام المنظمة بينما تتقارب النتائج في المهام التوليدية. أظهر <span class="citation" data-cites="chen2025benchmarkinglargelanguagemodels"></span> أن النماذج المملوكة مثل GPT-4 وMed-PaLM 2 تتفوق في مهام الاختيار من متعدد واسترجاع الحقائق بفضل تدريبها على مجموعات بيانات منظمة ودمج المعرفة التخصصية. كما وجد <span class="citation" data-cites="Alonso_2024"></span> أن النماذج المملوكة تحقق دقة أعلى في مهام الأسئلة الطبية بعدة لغات، مما يعزز فكرة أن النماذج المغلقة أكثر رسوخاً في المعرفة الطبية. تدعم نتائجنا هذه الاتجاهات، حيث يتصدر Gemini 1.5 Pro وClaude 3.5 Sonnet في مهام الاختيار من متعدد وإكمال الفراغ، مما يشير إلى أن النماذج المبنية على واجهات برمجة التطبيقات أكثر ملاءمة لدعم القرار السريري والمهام المنظمة.
            </p>
            <p>
يوضح الشكل <a href="#fig:bias" data-reference-type="ref" data-reference="fig:bias">[fig:bias]</a> أيضاً تباين أداء النماذج عند التعرض للانحياز وفعالية استراتيجيات الحد منه لأفضل ثلاثة نماذج (GPT-4o، Gemini 1.5 Pro، وClaude 3.5 Sonnet-20240620). جميع النماذج تشهد انخفاضاً في الدقة عند إدخال التحيز، مع تراجع أكبر في Claude 3.5 Sonnet عبر عدة فئات. أظهرت تقنيات الحد من التحيز مثل التحفيز بعدة أمثلة تحسناً ملحوظاً، خاصة في Gemini 1.5 Pro الذي أظهر أكبر مقاومة. ومع ذلك، لا توجد استراتيجية واحدة فعالة دائماً عبر جميع النماذج والفئات، مما يبرز تعقيد التحيز في معالجة اللغة الطبية والحاجة لمزيد من البحث.
            </p>
            <p>
في المهام التوليدية، لا تعكس مقاييس التقييم التلقائي مثل BERTScore الأداء الفعلي للنماذج بشكل كامل. رغم أن GPT-4 وClaude 3.5 ينتجان إجابات ذات صلة وسياق دقيق كما هو موضح في الشكل 3، إلا أن طول الإجابات يؤدي إلى انخفاض BERTScore مقارنة بالإجابات المرجعية. أشار <span class="citation" data-cites="liu-etal-2025-interactive"></span> سابقاً إلى أن مقاييس مثل ROUGE وBERTScore تعجز عن تقييم النماذج الطبية بدقة بسبب تعقيد التشخيصات وتعدد الخيارات العلاجية. تؤكد نتائجنا هذا القصور، إذ أن النماذج ذات BERTScore المنخفض قد تنتج إجابات عالية الجودة لكنها تعاقب على الإطناب لا على عدم الدقة. يبرز ذلك الحاجة إلى أساليب تقييم أكثر دقة، مثل التقييم البشري أو التقييم الحواري الموجه بالمهام، لتعكس الاستخدام الواقعي في الاستشارات الطبية.
            </p>
        </section>
        <section id="ethical-considerations" class="level1">
            <h1>الاعتبارات الأخلاقية</h1>
            <p>
نظراً لحساسية تطبيقات الرعاية الصحية، تعتبر الاعتبارات الأخلاقية أساسية عند تطوير ونشر النماذج اللغوية الضخمة. تم بناء معيار MedArabiQ بعناية من مصادر تعليمية عامة ومجهولة الهوية، مع الالتزام بمعايير الخصوصية عبر استبعاد أي معلومات تعريفية للمرضى. كما نقر بعدة قضايا أخلاقية مرتبطة بنشر النماذج في السياق السريري، مثل مخاطر المعلومات المضللة، وتضخيم التحيزات (الثقافية، التأكيدية، أو تحيز الوضع القائم)، ومحدودية تفسير النماذج. لمعالجة هذه المخاطر، نؤكد أهمية التحقق الشامل عبر أطر هجينة تجمع بين التقييم التلقائي ومراجعة الخبراء. نوصي بالمراقبة المستمرة، وإشراف الأطباء، ووضع إرشادات تشغيلية واضحة للحد من الأضرار والتحيزات. من خلال توضيح هذه الاعتبارات، نهدف إلى تعزيز تبني مسؤول وشفاف للنماذج، والمساهمة في حلول صحية أكثر أماناً وعدلاً.
            </p>
        </section>
        <section id="limitations-and-future-work" class="level1">
            <h1>القيود والعمل المستقبلي</h1>
            <p>
رغم أن دراستنا تقدم تقييماً شاملاً للنماذج الطبية العربية، إلا أن هناك مجالات تستحق المزيد من البحث. أولاً، هناك احتمال لتلوث البيانات. رغم أن اختبارات الطب السابقة لم تكن متاحة رقمياً وتتطلب جهداً كبيراً لرقمنتها وتنظيفها، لا يمكننا استبعاد التلوث تماماً. ومع ذلك، يمكن تحسين أداء النماذج، مما يبرز أهمية المعايير المرجعية. بالنسبة لـ AraMed، أجرينا تعديلات لاختبار الحفظ المحتمل نظراً لأنها مجموعة بيانات عامة. للتحقق من صلاحية البيانات، أجرينا تقييماً أولياً بالتعاون مع طلاب طب لتقييم الحقائق والملاءمة والوضوح والتعقيد على مقياس من 1 إلى 5. أظهرت النتائج (الملاءمة: 4.99، الحقائق: 4.97، الدقة: 4.88، الوضوح: 4.89) موثوقية وفائدة مبدئية. يتطلب التقييم الموسع مستقبلاً مع توسيع نطاق المعيار.
            </p>
            <p>
اتباعاً للممارسات القياسية في معالجة اللغة الطبية، اعتمدنا على مجموعات بيانات معيارية بدلاً من التفاعلات السريرية الحية لضمان القابلية للتكرار والامتثال الأخلاقي. جدير بالذكر أن مجموعة أسئلة المريض-الطبيب مستمدة من AraMed <span class="citation" data-cites="alasmari2024"></span>، والتي تتضمن استشارات حقيقية من منصة الطبي، مما يضمن الواقعية. رغم أن الاختبار السريري الحي قد يوفر رؤى إضافية، إلا أنه يواجه تحديات خصوصية وتنظيمية كبيرة، خاصة في المنطقة العربية حيث تفرض لوائح مثل GDPR وHIPAA قيوداً صارمة على مشاركة بيانات المرضى <span class="citation" data-cites="theodos2020"></span>. كما أن العديد من المؤسسات الصحية لا تزال تعتمد على السجلات الورقية <span class="citation" data-cites="aljawarneh2024"></span>، مما يصعب جمع البيانات الحية على نطاق واسع. يمكن مستقبلاً استكشاف استراتيجيات تحافظ على الخصوصية لدمج التقييمات السريرية الواقعية بشكل آمن وأخلاقي.
            </p>
            <p>
من القيود الأخرى الحاجة إلى تقنيات أكثر فعالية للحد من التحيز. رغم تقييمنا لقابلية التحيز عبر مهام متعددة، تؤكد النتائج أن الاستراتيجيات الحالية لا تقضي عليه تماماً، خاصة في سياقات اتخاذ القرار السريري الحساس <span class="citation" data-cites="alyafeai2024 omar2024"></span>. يجب أن يركز البحث المستقبلي على تطوير أساليب متخصصة تراعي العوامل اللغوية والثقافية الفريدة للغة العربية الطبية.
            </p>
            <p>
ركزنا في هذه الدراسة على تقييم الأداء الصفري (zero-shot)، لتقديم تقييم غير متحيز لقدرة النماذج على المهام الطبية العربية دون ضبط مسبق <span class="citation" data-cites="kojima2022"></span>. رغم أن ذلك يوفر خط أساس قوي، يمكن مستقبلاً استكشاف ضبط النماذج على مجموعات بيانات طبية عربية لتحسين الفهم التخصصي. يتطلب ذلك مراعاة توفر البيانات، وتكاليف الحوسبة، ومخاطر فقدان التعميم.
            </p>
            <p>
علاوة على ذلك، اعتمدت معاييرنا على العربية الفصحى لضمان الاتساق، إلا أن ذلك لا يعكس التنوع اللهجي المستخدم في التفاعلات الواقعية. يمكن مستقبلاً دمج بيانات لهجية لتعزيز قدرة النماذج على التكيف مع السياقات الصحية العربية المتنوعة. كما أن الدراسة تركز على النصوص فقط، ويمكن توسيع المعايير لدعم الذكاء الاصطناعي متعدد الوسائط مثل الصور الطبية ونتائج المختبرات.
            </p>
            <p>
نخطط مستقبلاً لتوسيع MedArabiQ من حيث العمق والتخصص، عبر تغطية مجالات سريرية إضافية مثل الصحة النفسية، الأمراض المعدية، والأمراض المزمنة، بالتعاون مع أطباء وخبراء لضمان ملاءمة الأسئلة للمعايير السريرية الحديثة. سنصنف الأسئلة حسب نوع الاستدلال السريري، ونقيم تعقيدها، ونجري تقييمات موثوقية بين المقيمين. سيعزز هذا التوسع شمولية وموثوقية المعيار، ويدعم ضبط النماذج العربية ومتعددة اللغات، مما ينعكس إيجاباً على الرعاية الصحية للناطقين بالعربية.
            </p>
        </section>
        <section id="conclusion" class="level1">
            <h1>الخلاصة</h1>
            <p>
في هذا العمل، قدمنا أول معيار منظم لتقييم النماذج اللغوية في الرعاية الصحية العربية، لمعالجة فجوة كبيرة في معالجة اللغة الطبية العربية. يتكون معيارنا من 700 عينة سريرية متنوعة، تغطي التقييمات المعرفية المنظمة والتفاعلات الواقعية بين المريض والطبيب. يتجاوز معيارنا حدود الرعاية الصحية العربية، إذ يضع أساساً لتطوير معايير بلغات طبية أخرى غير مخدومة، مما يساهم في تطوير تطبيقات الذكاء الاصطناعي الطبية عالمياً.
            </p>
            <p>
تكشف نتائجنا عن قيود حرجة في النماذج الحالية، مثل الهلوسة الواقعية في المهام المفتوحة وقابلية التحيز في اتخاذ القرار السريري، مما يعزز الحاجة إلى استراتيجيات فعالة للحد من التحيز. يجب أن يستكشف العمل المستقبلي ضبط النماذج على بيانات طبية عربية، وتوسيع المعايير لتشمل التنوع اللهجي، وتطوير استراتيجيات متخصصة للحد من التحيز في السياق الطبي العربي. من خلال إتاحة معاييرنا، نهدف إلى دعم البحث في معالجة اللغة الطبية العربية، وتوفير أساس لحلول صحية موثوقة وعادلة وفعالة مدعومة بالذكاء الاصطناعي.
            </p>
        </section>
        <section id="related-work-1" class="level1">
            <h1>الأعمال ذات الصلة</h1>
            <p>
توجد عدة مجموعات بيانات طبية عربية، لكنها جميعاً تعاني من قصور ما وغالباً ما تركز على مهمة الإجابة على الأسئلة الطبية. يلخص الجدول <a href="#table:dataset_comparison" data-reference-type="ref" data-reference="table:dataset_comparison">[table:dataset_comparison]</a> هذه المجموعات وقيودها وكيفية تجاوز معيارنا لهذه القيود. باختصار، تتلخص مساهمتنا في أربع نقاط:
            </p>
            <ol>
                <li><p>تقديم مجموعة بيانات تتكون تقريباً بالكامل من بيانات جديدة لم تتعرض لها النماذج من قبل، مما يقلل خطر التلوث.</p></li>
                <li><p>توسيع البيانات من الإجابة التقليدية إلى حالات استخدام متنوعة مثل الاختيار من متعدد وإكمال الفراغ، لاختبار المعرفة والاستدلال الطبي.</p></li>
                <li><p>ضمان جودة البيانات عبر مراجعة بشرية يدوية دقيقة.</p></li>
                <li><p>عكس روح التفاعلات الواقعية بين المريض والطبيب باستخدام بيانات من منصة الطبي.</p></li>
            </ol>
            <div class="table*">
                <p><span> </span> <span id="table:dataset_comparison" label="table:dataset_comparison"></span></p>
            </div>
        </section>
        <section id="appendix-b" class="level1">
            <h1>نظرة عامة على مجموعة البيانات</h1>
            <p>
يلخص الجدول <a href="#table:datasets" data-reference-type="ref" data-reference="table:datasets">[table:datasets]</a> مجموعات البيانات المستخدمة في التقييم، مع توضيح المصدر ومحتوى كل مجموعة.
            </p>
            <div class="table*">
                <p><span>tab:datasets</span></p>
                <p><span id="table:datasets" label="table:datasets"></span></p>
            </div>
        </section>
        <section id="model-overview" class="level1">
            <h1>نظرة عامة على النماذج</h1>
            <p>
تم تصنيف النماذج في الجدول <a href="#table:models" data-reference-type="ref" data-reference="table:models">[table:models]</a> بناءً على شفافية بيانات التدريب، مما يؤثر على احتمال تلوث التقييم، والتغطية اللغوية التي تؤثر على الأداء في العربية.
            </p>
            <div class="table*">
                <p><span>tab:model_summary</span></p>
                <p><span id="table:models" label="table:models"></span></p>
            </div>
        </section>
        <section id="prompts-by-task" class="level1">
            <h1>المحفزات حسب المهمة</h1>
            <p>
تلعب هندسة المحفزات دوراً محورياً في استجابة النموذج. استخدمنا نفس المحفز لكل نموذج، مع تخصيصه حسب فئة المهمة كما هو موضح في الجدول <a href="#table:prompts" data-reference-type="ref" data-reference="table:prompts">[table:prompts]</a>. كان ذلك ضرورياً لضمان واقعية المحفزات وملاءمتها لحالات الاستخدام المختلفة.
            </p>
            <p>مثال 6: طريقة نيوتن-رافسون. المثال الأخير: احسب المشتقة الأولى والأخيرة ثم طبق نيوتن-رافسون.</p>
            <div class="table*">
                <p><span>tab:task_prompts</span></p>
                <p><span id="table:prompts" label="table:prompts"></span></p>
            </div>
        </section>
        <section id="bias-evaluation" class="level1">
            <h1>تقييم التحيز</h1>
            <p>
يقارن الجدول <a href="#table:bias" data-reference-type="ref" data-reference="table:bias">[table:bias]</a> أداء النماذج في أسئلة الاختيار من متعدد والأسئلة المحقونة بالتحيز، مع استراتيجيات الحد من التحيز مثل التثقيف، المثال الواحد، وعدة أمثلة. عموماً، تنخفض الدقة مع التحيز وتتحسن مع استراتيجيات الحد منه. بشكل خاص، أدى التثقيف إلى انخفاض الدقة، بينما حسنت استراتيجيات المثال الواحد وعدة أمثلة الأداء في جميع النماذج، مع أكبر تحسن في Claude 3.5 Sonnet عند استخدام المثال الواحد.
            </p>
            <div class="table*">
                <p><span>tab:bias_evaluation_results</span></p>
                <p><span id="table:bias" label="table:bias"></span></p>
            </div>
        </section>
        <section id="performance-by-bias-category" class="level1">
            <h1>الأداء حسب فئة التحيز</h1>
            <p>
يجمع الشكل <a href="#fig:bias accuracy1" data-reference-type="ref" data-reference="fig:bias accuracy1">[fig:bias accuracy1]</a> أداء النماذج حسب فئة التحيز للأسئلة بدون تحيز، مع تحيز، ومع الحد من التحيز. أظهرت الأسئلة المحقونة بالتحيز التأكيدي والإجماع الزائف أكبر تحسن مع استراتيجيات الحد، خاصة المثال الواحد وعدة أمثلة. كان التثقيف أقل فعالية، وأحياناً أدى لانخفاض الدقة. كانت الأسئلة ذات التحيز الثقافي أكثر مقاومة للاستراتيجيات، مع تحسن طفيف أو معدوم. لم يتحسن أي نموذج باستمرار مع الحد من التحيز عبر جميع الفئات.
            </p>
            <div class="figure*">
                <p><img src="figures/accuracy_by_bias.png" style="width:60.0%" alt="صورة" /></p>
            </div>
        </section>
        <section id="performance-by-question-category" class="level1">
            <h1>الأداء حسب فئة السؤال</h1>
            <p>
يمكن تصنيف الأسئلة حسب التخصص الطبي عند دراسة الأداء مع التحيز واستراتيجيات الحد منه، كما في الشكل <a href="#fig:bias accuracy2" data-reference-type="ref" data-reference="fig:bias accuracy2">[fig:bias accuracy2]</a>. أحياناً حسنت استراتيجيات المثال الواحد وعدة أمثلة الأداء، لكن ليس دائماً. غالباً ما أدى التثقيف إلى انخفاض الدقة أو عدم التغيير. لم تكن التحسينات في الدقة متسقة. كان أبرز تحسن في تخصص الأورام على Gemini عند استخدام عدة أمثلة.
            </p>
            <div class="figure*">
                <p><img src="figures/accuracy_by_bias.png" style="width:70.0%" alt="صورة" /></p>
            </div>
        </section>
        <hr style="margin: 40px 0;">
        <div class="text-muted text-center">
            <small>
                تم تحويل هذه النسخة تلقائياً من LaTeX.<br>
                يتم عرض المعادلات الرياضية باستخدام MathJax.
            </small>
        </div>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>
