<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Xinwei Chen">
  <meta name="author" content="Kun Li">
  <meta name="author" content="Jiangjian Guo">
  <meta name="author" content="Tianyou Song">
  <title>التعرّف على الكيانات المسماة بقليل من الأمثلة في StackOverflow</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>body { direction: rtl; font-size: 22px; }</style>
</head>
<body>
<header>
<h1 class="title">التعرّف على الكيانات المسماة بقليل من الأمثلة في <span class="nodecor">StackOverflow</span></h1>
<p class="author"><span class="nodecor">Xinwei Chen</span></p>
<p class="author"><span class="nodecor">Kun Li</span></p>
<p class="author"><span class="nodecor">Jiangjian Guo</span></p>
<p class="author"><span class="nodecor">Tianyou Song</span></p>
</header>
<p>لايتكس</p>
<h1 id="ملخص">الملخص</h1>
<p>يشكّل المخزون الضخم من الأسئلة في <span class="nodecor">StackOverflow</span> تحدياً لتوسيم البيانات نظراً لمحدودية الأمثلة الموسومة. نعالج هذه الفجوة باستخدام <span class="nodecor">RoBERTa+MAML</span>، وهي طريقة للتعرّف على الكيانات المسماة بقليل من الأمثلة تستفيد من التعلم البيني. تم تقييم نهجنا على مجموعة بيانات <span class="nodecor">StackOverflow NER</span> (27 نوعاً من الكيانات)، وحققنا تحسناً بنحو <span class="nodecor">5%</span> في معيار <span class="nodecor">F1</span> مقارنة بالنموذج الأساسي. علاوة على ذلك، عززنا الأداء أكثر عبر معالجة المصطلحات المتخصصة بالمجال.</p>
<h1 id="مقدمة">مقدمة</h1>
<p>يطرح تنامى محتوى البرمجة على الإنترنت تحديات في فهم واستخراج المعلومات المتعلقة بالبرمجيات. منتدى <span class="nodecor">StackOverflow</span>، كأكبر منتدى للبرمجة، يضم أكثر من <span class="nodecor">15</span> مليون سؤال. لفهم هذا الكم الهائل بفعالية، نحتاج إلى تحديد الكيانات المسماة (<span class="nodecor">NEs</span>). ومع ذلك، يتطلب التعلم المشرف لهدف التعرف على الكيانات المسماة (<span class="nodecor">NER</span>) بيانات موسومة واسعة النطاق، مما يستلزم موارد ضخمة. استجابة لذلك، نقترح التعلم بقليل من الأمثلة لتمكين التعرف الدقيق على الكيانات بأقل قدر من بيانات التوسيم. يمكن تطبيق نهجنا في مهام متعلقة بالبرمجيات مثل استرجاع المعلومات، والإجابة على الأسئلة، وتلخيص المقالات.</p>
<p>يشير <span class="nodecor">mai2018fine</span> إلى التعرّف الدقيق على الكيانات المسماة عبر تصنيفها إلى فئات أكثر تحديداً. وفي بعض الأحيان تكون بنية البيانات الموسومة غير مباشرة، مما يزيد من صعوبة التوسيم. نظراً لارتفاع تكلفة التوسيم اليدوي، يبدو التعلم بقليل من الأمثلة حلاً عملياً. عبر تدريب النماذج على أمثلة موسومة قليلة، نحقق تعرّفاً دقيقاً وفعالاً للكيانات المسماة. في هذه الورقة نقدم دراسة حول التعلم بقليل من الأمثلة في مجال البرمجيات على مجموعة بيانات <span class="nodecor">StackOverflow NER</span> (<span class="nodecor">codener</span>). اقترحنا نموذجاً يستفيد من شبكة انتباه لاستخراج المعلومات من شظايا الكود والنص لتوليد نتائج أولية عند تصنيف <span class="nodecor">20</span> نوعاً من الكيانات المتعلقة بالبرمجيات. تشمل مساهماتنا:</p>
<ul>
<li><p>نقترح إطاراً لعنونة الكيانات المتعلقة بالبرمجيات بقليل من الأمثلة</p></li>
<li><p>نقدّم النتائج الأولى على مجموعة بيانات <span class="nodecor">StackOverflow NER</span></p></li>
</ul>
<h1 id="الأعمال-ذات-الصلة">الأعمال ذات الصلة</h1>
<p>شهد مجال المعرفة البرمجية العديد من الدراسات، من بينها تحسين قياس جودة السؤال في <span class="nodecor">StackOverflow</span> (<span class="nodecor">ravi</span>) واستخراج الأسئلة والأجوبة ذات الصلة في نفس المنتدى (<span class="nodecor">shirani</span>). مع ذلك، تفتقر هذه الأبحاث إلى استخدام تقنيات معالجة اللغة الطبيعية لتحديد الكيانات المسماة في سياق البرمجيات.</p>
<p>أُجريت أعمال عديدة في التعرّف على الكيانات المسماة، حيث عالج (<span class="nodecor">Li19, li2023deception</span>) قضايا استرجاع المعلومات والأونتولوجيا في نطاقات محددة. واقترح (<span class="nodecor">qun</span>) تعلماً بلا أمثلة قابل للنقل بين المجالات للتعرّف على الكيانات. مؤخراً، أصبح التعلم العميق شائعاً في <span class="nodecor">NER</span>، خاصة مع نماذج مدرّبة مسبقاً مثل <span class="nodecor">BERT</span> و<span class="nodecor">RoBERTa</span>. مع ذلك، يظل التعرّف على الكيانات مسعىً يستغرق وقتاً طويلاً ويتطلب خبراء مجال لتوسيم بيانات ضخمة. طُوّرت عدة منهجيات للتعرّف بقليل من الأمثلة، منها خط أنابيب <span class="nodecor">fgner</span> وطرق التوليد التنافسية <span class="nodecor">fewshotner</span> وطرق التعلّم البياني التوليد (<span class="nodecor">pmlr-v202-zeng23c, zeng23acm</span>). ومع ذلك، لم يُطبق التعلم بقليل من الأمثلة حتى الآن في مجال البرمجيات.</p>
<p>هناك أيضاً عمل <span class="nodecor">codener</span> للتعرّف على الكيانات المسماة في مجال البرمجة الحاسوبية. يهدف هذا العمل إلى تمييز الكيانات المسماة في <span class="nodecor">StackOverflow</span>، وقد درّبوا نموذجهم على <span class="nodecor">BERT</span> مع دمج التضمينات السياقية والخاصة بالمجال.</p>
<h4 id="تعلم-الاستدعاء">التعلّم بالاستدعاء:</h4>
<p>يحوّل التعلّم بالاستدعاء المهام التقليدية في معالجة اللغة الطبيعية إلى مشكلات تنبؤية لملء الفجوات. في مهام التعرّف بقليل من الأمثلة، يضيف (<span class="nodecor">fgner</span>, <span class="nodecor">fewshotner</span>) قالباً لاستدعاء الكيان بعد الجملة الأصلية.</p>
<h4 id="التعلم-البياني">التعلّم البيني:</h4>
<p>يوصف التعلّم البيني بأنه "تعلم التعلم". ونظراً لأن تدريب نموذج دقيق يتطلب عادةً بيانات موسومة وفيرة بينما تكون التوسيمات في نطاق البرمجيات محدودة، يتيح التعلم البيني تهيئة أفضل للنموذج ليتكيف سريعاً مع مهام جديدة. طبق (<span class="nodecor">Decomposed</span>) خوارزمية <span class="nodecor">MAML</span> وقدم نموذج <span class="nodecor">MAML-ProtoNet</span> للتعرّف بقليل من الأمثلة.</p>
<h1 id="الطريقة">الطريقة</h1>
<p>بحسب علمنا، لم تُجر دراسات كافية لتطبيق التعلم بقليل من الأمثلة على مجموعة بيانات <span class="nodecor">StackOverflowNER</span>. أجرت مجموعة <span class="nodecor">codener</span> دراسةً منهجية إشرافية على هذه المجموعة، لكنها تواجه قيوداً: أولاً، ضمن مهام المجال، يحتاج التوسيم إلى خبراء ويستغرق وقتاً طويلاً. ثانياً، يستغرق تدريب <span class="nodecor">BERT</span> ضمن النطاق أكثر من شهر على 152 مليون جملة من StackOverflow. نحن نستكشف نموذجين للتعلم بقليل من الأمثلة: أحدهما ضبط دقيق معتمد على الأوامر، والآخر يضيف التعلّم البيني لمهام متخصصة بالمجال.</p>
<h2 id="تصنيف-الكيانات-بعدد-قليل-من-الأمثلة">تصنيف الكيانات بقليل من الأمثلة</h2>
<p>في هذا القسم نعرّف مشكلة تصنيف الكيانات بقليل من الأمثلة: تحديد نوع الكيان في جملة باستخدام عدد محدود من عينات التدريب. المدخل هو تسلسل من رموز النص <span class="math inline">\(\textbf{x}=\{t_{1},t_{2},...,\textbf{m},...,t_{T}\}\)</span>، حيث <span class="math inline">\(m = \{t_{i},...,t_{j}\}\)</span> هو تسلسل كيان مكون من <span class="math inline">\((j-i+1)\)</span> رمزاً، وT هو طول الجملة. المخرج هو تسمية نوع الكيان <span class="math inline">\(y \in Y\)</span>، حيث <span class="math inline">\(Y\)</span> هي مجموعة التسميات <span class="math inline">\(\{y_{1},...,y_{n}\}\)</span>. في إعداد <span class="math inline">\(K\)</span>-shot، تكون هناك <span class="math inline">\(K\)</span> عينات تدريبية لكل فئة.</p>
<h2 id="الضبط-الدقيق-بناء-على-الأوامر">الضبط الدقيق المعتمد على الأوامر</h2>
<p>اعتمدنا إطار العمل المقترح من Huang كنموذج أساسي (<span class="nodecor">fewshotner</span>). يوضّح الشكل العام للضبط الدقيق المعتمد على الأوامر النقاط الأساسية. في هذا الأسلوب نُدخل الجملة مع قالب يتضمن فتحة <span class="math inline">\([MASK]\)</span> لتمثيل التنبؤ المطلوب. بعد المعالجة بواسطة المشفر المدرب مسبقاً <span class="math inline">\(\theta_{0}\)</span> (مثل RoBERTa)، نحصل على التمثيل السياقي <span class="math inline">\(h_{m}\)</span> لرمز <span class="math inline">\([MASK]\)</span>. ثم يقدم رأس النموذج توزيع احتمال عبر المفردات <span class="math inline">\(\mathcal{V}\)</span>، ونستخدم Softmax لحساب احتمالات الكلمات، وبعدها دالة لغوية لتحويل احتمالات الكلمات إلى احتمالات التسميات، ونعتمد دالة خسارة KL لتقليل الفارق بين التنبؤات والهدف.</p>
<h2 id="التعلم-البيني-المستقل-عن-النموذج">التعلّم البيني المستقل عن النموذج</h2>
<p>لتحسين الأداء في المهام المتخصصة بالمجال، ندمج التعلّم البيني المستقل عن النموذج (<span class="nodecor">finn2017model</span>). الفكرة العامة هي تدريب النموذج على مهام متعددة للحصول على تهيئة أولية أفضل للمعاملات، ما يتيح له التعلم بسرعة على مهام جديدة. نطبق خوارزمية <span class="nodecor">MAML</span> عبر مرحلتين: التدريب البيني على <span class="math inline">\(\xi_{train}\)</span> والاختبار البيني على <span class="math inline">\(\xi_{test}\)</span>، مع إعداد <span class="math inline">\(K\)</span>-<span class="nodecor">shot</span>-<span class="math inline">\(N\)</span>-<span class="nodecor">way</span>.</p>
<h3 id="مرحلة-التدريب-الأولى">مرحلة التدريب الأولى</h3>
<p>في هذه المرحلة ندرب النموذج على مجموعة البيانات العامة عبر <span class="nodecor">N</span> مهام. لكل مهمة نأخذ عينة <span class="math inline">\((D_{i}^{sup},D_{i}^{query})\)</span> من <span class="math inline">\(\xi_{train}\)</span> ونحدّث المعاملات داخلياً وفق المعادلة [eqn7]. ثم نقيس الأداء على <span class="math inline">\(D_{i}^{query}\)</span> ونجمع الخسائر عبر المهام لتحديث التهيئة الأولية كما في المعادلتين [eqn8] و[eqn9].</p>
<h3 id="الاختبار-الفوقي">مرحلة الاختبار البيني</h3>
<p>في هذه المرحلة نستخدم المعاملات المحدثة لتحسين النموذج على مجموعة التدريب في <span class="nodecor">StackOverflow</span> ثم نجري التنبؤ على مجموعة الاختبار.</p>
<h1 id="التجربة">التجربة</h1>
<h2 id="مجموعة-البيانات">مجموعة البيانات</h2>
<p>في هذه المهمة نستخدم مجموعة بيانات <span class="nodecor">NER</span> من <span class="nodecor">StackOverflow</span> (المعروفة باسم <span class="nodecor">codener</span>)، التي تضم أكثر من <span class="nodecor">1,237</span> موضوعاً من الأسئلة والأجوبة على مدى <span class="nodecor">10</span> سنوات و<span class="nodecor">27</span> نوعاً من الكيانات. تشمل كيانات الكود: <em>الفئة، المتغير، الكود ضمن السطر، الوظيفة، المكتبة، القيمة، نوع البيانات، والعلامة (HTML/XML)</em>؛ وتشمل كيانات اللغة الطبيعية: <em>التطبيق، عنصر واجهة المستخدم، اللغة، هيكل البيانات، الخوارزمية، نوع الملف، اسم الملف، الإصدار، الجهاز، نظام التشغيل، الموقع الإلكتروني، واسم المستخدم</em>. نخطط أيضاً لاستخدام بيانات إضافية مأخوذة عشوائياً من مستودعات <span class="nodecor">GitHub</span>.</p>
<h2 id="إعدادات-التجربة">إعدادات التجربة</h2>
<p><strong>إعداد خمس لقطات (5-shot).</strong> نجري تجربة التعلّم بخمس لقطات على مجموعة بيانات <span class="nodecor">StackOverflow NER</span> باختيار خمس عينات تدريبية عشوائياً في كل محاولة. أجرينا أيضاً تجربة اختيار الحالات يدوياً لتحسين دقة النموذج.</p>
<p><strong>عينات التدريب الأساسي.</strong> تحتوي مجموعة بيانات <span class="nodecor">Few-NERD</span> على <span class="nodecor">66</span> نوعاً دقيقاً من الكيانات. نجري مرحلة التدريب الأساسي عبر <span class="nodecor">40</span> مهمة، حيث نأخذ لكل مهمة عينة عشوائية من إعداد <span class="nodecor">20</span>-حالة-<span class="nodecor">27</span>-طريقة، ثم نقسمها إلى مجموعة دعم <span class="nodecor">5</span>-حالة-<span class="nodecor">27</span>-طريقة ومجموعة استفسار <span class="nodecor">15</span>-حالة-<span class="nodecor">27</span>-طريقة.</p>
<p><strong>إعدادات المعاملات الفائقة.</strong> نعتمد نموذج <span class="nodecor">RoBERTa-base</span> المدرب مسبقاً. أقصى طول للتسلسل <span class="nodecor">128</span>؛ حجم الدفعة الداخلية للضبط الدقيق <span class="nodecor">8</span>؛ حجم الدفعة الخارجية للتحديث الأساسي <span class="nodecor">32</span>؛ عدد عصور الضبط الدقيق في التدريب الأساسي <span class="nodecor">1</span>؛ عدد عصور الضبط في الاختبار الأساسي <span class="nodecor">10</span>؛ الحد الأقصى لخطوات التعلم الأساسي <span class="nodecor">15</span>؛ معدل التعلم للتعلم الأساسي <span class="nodecor">5e-3</span>؛ معدل التعلم للتحديث الداخلي <span class="nodecor">1e-2</span>. تم التدريب على <span class="nodecor">GPU</span> في <span class="nodecor">Google Colab</span>.</p>
<p><strong>مقاييس التقييم.</strong> استخدمنا معيار <span class="nodecor">Micro-F1</span> و<span class="nodecor">Macro-F1</span>.</p>
<h2 id="النتائج">النتائج</h2>
<p>طبقنا نموذج <span class="nodecor">RoBERTa</span> ونموذج <span class="nodecor">RoBERTa+MAML</span> على مجموعة بيانات التعرّف على الكيانات المسماة من <span class="nodecor">StackOverflow</span>. في التدريب اخترنا عشوائياً خمس عينات لكل فئة. كما يظهر في الجدول [citation-guide]، بلغت درجة <span class="nodecor">Micro-F1</span> لنموذج RoBERTa <span class="nodecor">0.3091</span> ودرجة <span class="nodecor">Macro-F1</span> <span class="nodecor">0.2837</span>.</p>
<p>طبقنا بنفس الطريقة نموذج <span class="nodecor">RoBERTa+MAML</span>، فبلغت درجة <span class="nodecor">Micro-F1</span> <span class="nodecor">0.3578</span> ودرجة <span class="nodecor">Macro-F1</span> <span class="nodecor">0.3197</span>، مما يدل على زيادة ملحوظة باستخدام التعلّم البيني.</p>
<p>كما نرى في الشكلين ([fig:highperform], [fig:lowperform])، تحسّن أداء التعرّف في فئات: هيكل البيانات، عنصر واجهة المستخدم، نظام التشغيل، اسم المستخدم، ونوع البيانات باستخدام RoBERTa+MAML.</p>
<h2 id="دراسة-حالة-لمجموعة-تدريب-من-5-لقطات">دراسة حالة لمجموعة تدريبية من خمس لقطات</h2>
<p>لاحظنا أن درجة <span class="nodecor">F1</span> لعدة فئات مثل نظام التشغيل، المكتبة، اسم الوظيفة، عنوان <span class="nodecor">IP</span>، لوحة المفاتيح، اللغة، اسم المتغير، والخوارزمية كانت أقل من المتوقع. يصعب التعرّف على هذه الفئات عند تطبيق NER بخمس لقطات. بعد فحص مجموعة التدريب العشوائية، وجدنا فيها كيانات مكررة وأخرى غير واضحة.</p>
<p>لتجنب التأثيرات السلبية، اخترنا يدوياً عينات تدريبية ذات معنى وتمثيل أفضل. طبقنا أيضاً نفس النهج على نموذج <span class="nodecor">RoBERTa+MAML</span>. يوضح الجدول أن درجة <span class="nodecor">Micro-F1</span> ارتفعت بنحو 3% ودرجة <span class="nodecor">Macro-F1</span> بنحو 2%.</p>
<p>يوضح هذا المثال أن فئة "المحتوى" كانت غامضة في بيانات التدريب بخمس لقطات ولا تتمتع بتمثيل كافٍ، فقمنا باختيار عينات بديلة يدوياً لتعظيم أداء النموذج. أظهرت النتائج تفوق RoBERTa+MAML مع البيانات المختارة يدوياً على البيانات العشوائية، لذا سنعتمد هذه المجموعة في أعمالنا المستقبلية.</p>
<h2 id="دراسة-حالة-لاستخراج-الأنماط-المعتمدة-على-المعرفة">دراسة حالة لاستخراج الأنماط المعتمدة على المعرفة</h2>
<p>لاحظنا أن هناك فئات يصعب التعرف عليها لكنها تتبع أنماطاً واضحة. مثلاً، جميع امتدادات الملفات الشائعة تُصنَّف ضمن فئة نوع الملف. كما في الجدول [table:maual]، يمكننا استخدام التعبيرات النظامية لاستخراج امتدادات مثل csv، jpg، doc. يشير الجدول [table:extraction] إلى تحسن درجة <span class="nodecor">F1</span> لفئة نوع الملف من <span class="nodecor">0.345</span> إلى <span class="nodecor">0.49</span>، مع دقة <span class="nodecor">0.716</span> واسترجاع <span class="nodecor">0.372</span>. يمكن تطبيق استخراج الأنماط المعتمدة على المعرفة لفئات أخرى لتحسين الدقة الإجمالية ومعيار <span class="nodecor">F1</span>.</p>
<h1 id="الخلاصة-والأعمال-المستقبلية">الخلاصة والأعمال المستقبلية</h1>
<p>ركزنا في دراستنا على التعرّف على الكيانات المسماة في مجال برمجة الحاسوب باستخدام نموذج <span class="nodecor">RoBERTa+MAML</span> في مهمة 5-shot على مجموعة بيانات <span class="nodecor">StackOverflow NER</span>، حيث حققنا تحسينات كبيرة مقارنةً بنموذج RoBERTa الأساسي. بيّنت النتائج أن التعلّم البيني أداة قوية لمهام التعرّف المتخصصة والقليلة العينات، وأن معالجة المصطلحات المتخصصة واستخراج الأنماط المعتمدة على المعرفة يعززان الدقة. نتوقع استفادة المهام المستقبلية في استخراج المعلومات المتعلقة بالبرمجيات والإجابة على الأسئلة من هذه التقنيات. نسعى مستقبلاً إلى توسيع تنوع البيانات واستكشاف تشكيلات مختلفة لمجموعات الدعم والاستفسار لتعزيز فعالية التعلّم البيني.</p>
</body>
</html>