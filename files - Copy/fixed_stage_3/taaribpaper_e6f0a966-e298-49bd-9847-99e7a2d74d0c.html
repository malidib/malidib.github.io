<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Angus Nicolson">
  <meta name="author" content="Lisa Schut">
  <meta name="author" content="J. Alison Noble">
  <meta name="author" content="Yarin Gal">
  <title>شرح القابلية للتفسير: فهم متجهات تنشيط المفهوم</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>body { direction: rtl; font-size: 22px; }</style>
</head>
<body>
<header>
<h1 class="title">شرح القابلية للتفسير: فهم متجهات تنشيط المفهوم</h1>
<p class="author"><span class="nodecor">Angus Nicolson</span></p>
<p class="author"><span class="nodecor">Lisa Schut</span></p>
<p class="author"><span class="nodecor">J. Alison Noble</span></p>
<p class="author"><span class="nodecor">Yarin Gal</span></p>
</header>
<p>latex</p>
<h1 id="ملخص">مُلَخَّص</h1>
<p>تقترح طرق القابلية للتفسير الحديثة استخدام تفسيرات مبنية على المفاهيم لترجمة التمثيلات الداخلية لنماذج التعلم العميق إلى لغة مفهومة للبشر: المفاهيم. يتطلب ذلك فهم المفاهيم الموجودة في فضاء التمثيل لشبكة عصبية. إحدى الطرق الشائعة لاكتشاف المفاهيم هي متجهات تنشيط المفهوم (<span class="nodecor">CAVs</span>)، والتي يتم تعلمها باستخدام مجموعة بيانات استكشافية من أمثلة المفهوم. في هذا العمل، نحقق في ثلاث خصائص لـ <span class="nodecor">CAVs</span>. قد تكون <span class="nodecor">CAVs</span>: (1) غير متسقة بين الطبقات، (2) متشابكة مع مفاهيم مختلفة، و(3) تعتمد على الموقع. توفر كل خاصية تحديات وفرصاً في تفسير النماذج. نقدم أدوات مصممة للكشف عن وجود هذه الخصائص، وتقديم رؤى حول كيفية تأثيرها على التفسيرات المستخرجة، وتقديم توصيات لتقليل تأثيرها. يمكن استخدام فهم هذه الخصائص لصالحنا. على سبيل المثال، نقدم <span class="nodecor">CAVs</span> التي تعتمد على الموقع لاختبار ما إذا كان نموذج ما يتمتع بخاصية الثبات الترجمي بالنسبة لمفهوم وفئة معينة. تتم تجاربنا على <span class="nodecor">ImageNet</span> ومجموعة بيانات تركيبية جديدة، <span class="nodecor">Elements</span>. تم تصميم <span class="nodecor">Elements</span> لالتقاط علاقة حقيقة أرضية معروفة بين المفاهيم والفئات. نطلق هذه المجموعة لتسهيل المزيد من البحث في فهم وتقييم طرق القابلية للتفسير.</p>
<h1 id="sec: Introduction">مُقَدِّمَة</h1>
<p>أصبحت نماذج التعلم العميق شائعة الاستخدام، حيث تحقق أداءً يصل أو يتجاوز خبراء البشر في مجموعة متنوعة من المهام. ومع ذلك، فإن التعقيد الكامن في هذه النماذج يحجب قدرتنا على شرح عملية اتخاذ القرارات لديها. مع تطبيقها في عدد متزايد من المجالات العملية، تزداد الحاجة لفهم كيفية عملها. تتيح هذه الشفافية تصحيح الأخطاء بسهولة أكبر وفهماً أفضل لقيود النموذج.</p>
<p>يمكن أن تأخذ شروحات النماذج أشكالاً متعددة، مثل ميزات الإدخال، النماذج الأولية أو المفاهيم. أظهرت الأعمال الحديثة أن طرق الشرح التي تركز على الميزات منخفضة المستوى يمكن أن تواجه مشاكل. على سبيل المثال، قد تعاني طرق البروز من التحيز التأكيدي ونقص الإخلاص (<span class="nodecor">adebayo2018sanity</span>). حتى عندما تكون مخلصة، فإنها تظهر فقط ’أين’ ركز النموذج في الصورة، وليس ’ماذا’ ركز عليه (<span class="nodecor">achtibat2022where</span>, <span class="nodecor">colin2022what</span>).</p>
<p>لمعالجة هذه المشاكل، توفر الطرق المبنية على المفاهيم شروحات باستخدام مصطلحات عالية المستوى يعرفها البشر. إحدى الطرق الشائعة هي متجهات تنشيط المفهوم (CAVs): تمثيل خطي لمفهوم موجود في فضاء التنشيط لطبقة محددة باستخدام مجموعة بيانات استكشافية لأمثلة المفهوم (<span class="nodecor">kim2018interpretability</span>). ومع ذلك، تواجه الطرق المبنية على المفاهيم أيضاً تحديات، مثل حساسيتها لمجموعة البيانات الاستكشافية المحددة (<span class="nodecor">Ramaswamy2022OverlookedFI</span>, <span class="nodecor">Soni2020AdversarialT</span>).</p>
<p>في هذه الورقة، نركز على فهم ثلاث خصائص لمتجهات المفاهيم:</p>
<ol>
<li><p>قد لا تكون <strong>متسقة</strong> عبر الطبقات،</p></li>
<li><p>يمكن أن تكون <strong>متشابكة</strong> مع مفاهيم أخرى،</p></li>
<li><p>يمكن أن تكون <strong>معتمدة مكانياً</strong>.</p></li>
</ol>
<p>نوفر أدوات لتحليل كل خاصية ونظهر أنها يمكن أن تؤثر على الاختبار باستخدام CAVs (TCAV) (§[sec: layer_stability], §[sec: Entanglement] و §[sec: Spatial]). لتقليل تأثير هذه الآثار، نوصي بـ: إنشاء CAVs لعدة طبقات، التحقق من العلاقات المتوقعة بين المفاهيم ذات الصلة، وتصوير الاعتماد المكاني (§[sec: Recommendations]). لا تعني هذه الخصائص أنه لا ينبغي استخدام CAVs. على العكس، قد نتمكن من استخدام هذه الخصائص لفهم سلوك النموذج بشكل أفضل. على سبيل المثال، نقدم نسخة معدلة من CAVs التي تعتمد مكانياً ويمكن استخدامها لتحديد التغير الترجمي في الشبكات العصبية التلافيفية (CNNs).</p>
<p>لمساعدة في استكشاف هذه الخصائص، أنشأنا مجموعة بيانات تركيبية قابلة للتكوين: العناصر (§[sec:elements]). توفر هذه المجموعة التحكم في العلاقات الحقيقية بين المفاهيم والفئات لفهم سلوك النموذج. باستخدام مجموعة بيانات العناصر، يمكن للباحثين دراسة (1) إخلاص طريقة الشرح المبنية على المفاهيم و(2) التشابك المفاهيمي في الشبكة.</p>
<h1 id="sec: Background">الخلفية: متجهات تنشيط المفهوم</h1>
<p>متجه تنشيط المفهوم (<span class="nodecor">CAV</span>) هو تمثيل متجهي لمفهوم موجود في فضاء التنشيط لطبقة من الشبكة العصبية (<span class="nodecor">NN</span>). فكر في شبكة عصبية يمكن تحليلها إلى دالتين: <span class="math inline">\(g_l(\vx) =\va_l \in \R^{m}\)</span> التي تعين المدخل <span class="math inline">\(\vx \in \R^n\)</span> إلى متجه <span class="math inline">\(\va_l\)</span> في فضاء التنشيط للطبقة <span class="math inline">\(l\)</span>، و<span class="math inline">\(h_l(\va_l)\)</span> التي تعين <span class="math inline">\(\va_l\)</span> إلى المخرج. لإنشاء متجه تنشيط المفهوم لمفهوم <span class="math inline">\(c\)</span> نحتاج إلى مجموعة بيانات استكشافية <span class="math inline">\(\D_c\)</span> تتكون من عينات إيجابية <span class="math inline">\(\X_c^+\)</span> (أمثلة المفهوم)، وعينات سلبية <span class="math inline">\(\X_c^-\)</span> (صور عشوائية ضمن التوزيع). لمجموعتي <span class="math inline">\(\X_c^-\)</span> و <span class="math inline">\(\X_c^+\)</span>، ننشئ مجموعة مقابلة من التنشيطات في الطبقة <span class="math inline">\(l\)</span>: <span class="math display">\[\A_{c,l}^+ = \{ g_l(\vx_i) \quad \forall \vx_i \in \X_c^+\} , \text{ و}  \
    \A_{c,l}^- = \{ g_l(\vx_i) \quad \forall \vx_i \in \X_c^-\},\]</span> نجد متجه تنشيط المفهوم <span class="math inline">\vcl</span> من خلال تدريب مصنف خطي ثنائي للتمييز بين المجموعتين <span class="math inline">\(\A_{c,l}^+\)</span> و <span class="math inline">\(\A_{c,l}^-\)</span>: <span class="math display">\[\label{eq:svm}
    \al \cdot \vcl + b_{c,l}  &gt; 0 \quad \forall \al \in \A_{c,l}^+ , \text{ و } 
    \al \cdot \vcl + b_{c,l}  \leq 0 \quad \forall \al \in \A_{c,l}-,\]</span> حيث <span class="math inline">\vcl</span> هو المتجه العمودي للمستوى الفاصل بين التنشيطات <span class="math inline">\(\A_{c,l}^+\)</span> و <span class="math inline">\(\A_{c,l}^-\)</span>، و<span class="math inline">\(b_{c,l}\)</span> هو الجزء المقطوع.</p>
<p>لتحليل حساسية النموذج لـ <span class="math inline">\vcl</span>، يقدم كيم وآخرون (<span class="nodecor">kim2018interpretability</span>) اختباراً باستخدام متجهات تنشيط المفهوم (<span class="nodecor">TCAV</span>)، والذي يحدد حساسية المفهوم النموذجية عبر فئة كاملة. ليكن <span class="math inline">\(\X_k\)</span> مجموعة من المدخلات التي تنتمي إلى الفئة <span class="math inline">\(k\)</span>. يعرف مقياس <span class="nodecor">TCAV</span> كما يلي <span class="math display">\[\operatorname{TCAV}_{c, k, l}=\frac{\left|\left\{\vx \in \X_{k}: S_{c, k, l}(\vx)&gt;0\right\}\right|}{\left|\X_{k}\right|},\]</span> حيث المشتقة الاتجاهية للمفهوم، <span class="math inline">\(S_{c, k, l}\)</span>، معرفة كما يلي <span class="math display">\[S_{c, k, l}(\vx) =\lim _{\epsilon \rightarrow 0} \frac{h_{l, k}\left(g_{l}(\vx)+\epsilon \vv_{c, l}\right)-h_{l, k}\left(g_{l}(\vx)\right)}{\epsilon}
        =\nabla h_{l, k}\left(g_{l}(\vx)\right) \cdot \vcl\]</span> حيث <span class="math inline">\(\nabla h_{l, k}\)</span> هو المشتق الجزئي لمخرج الشبكة العصبية للفئة <span class="math inline">\(k\)</span> إلى التنشيط. يقيس مقياس <span class="nodecor">TCAV</span> نسبة المدخلات للفئة <span class="math inline">\(k\)</span> التي يتأثر تنشيطها في الطبقة <span class="math inline">\(l\)</span> بشكل إيجابي بالمفهوم <span class="math inline">\(c\)</span>. يستخدم اختبار إحصائي لمقارنة مقاييس متجهات تنشيط المفهوم بالمتجهات العشوائية لتحديد أهمية المفهوم (انظر الملحق [app: CAV]).</p>
<h1 id="sec: CAV properties">فرضيات المتجهات المفاهيمية الموجهة</h1>
<p>لكي نستخدم طرق التفسير المبنية على المتجهات المفاهيمية الموجهة في الممارسة العملية، من المهم فهم كيفية عملها. لذلك، ندرس ثلاث خصائص للمتجهات المفاهيمية الموجهة وتأثيراتها على نتائج متجهات تنشيط المفهوم. نركز على هذه الفرضيات لأنها توفر رؤية حول تمثيلات الشبكة وعن المعنى المشفر بواسطة متجهات المفهوم.</p>
<p>نصوغ كل خاصية من خلال فرضية صفرية، والتي نقدم دليلاً لرفضها لاحقاً في الورقة. في النص التالي، نستخدم التنسيق <code>concept</code> للدلالة على مفهوم.</p>
<h2 id="الاتساق">الاتساق</h2>
<p>بشكل عام، نريد فهم سلوك <em>النموذج</em>. ومع ذلك، تفسر متجهات تنشيط المفهوم (CAVs) ما إذا كان النموذج حساساً لمفهوم في طبقة محددة. في الواقع، قد يكون تحليل جميع الطبقات غير عملي حسابياً، وليس من الواضح أي الطبقات يجب اختيارها. لذلك، تستكشف فرضيتنا الأولى العلاقة بين متجهات المفهوم المنشطة الموجودة في طبقات مختلفة. تذكر أن درجات TCAV تعتمد على المشتقة الاتجاهية: <em>كيف يتغير مخرج النموذج عند إجراء تغيير متناهي الصغر على التنشيطات في اتجاه متجه المفهوم المنشط</em>. من خلال تعديل التنشيطات في اتجاه متجه المفهوم المنشط، نستكشف ما إذا كان بإمكان متجهين مفهوميَين منشطين موجودين في طبقات مختلفة أن يكون لهما نفس التأثير على مخرجات النموذج. نشير إلى هذه الخاصية باسم <em>الاتساق</em>.</p>
<p>افترض أن لدينا دالة <span class="math inline">\(f(\cdot)\)</span> ترسم التنشيطات من الطبقة <span class="math inline">\(l_1\)</span> إلى التنشيطات في الطبقة <span class="math inline">\(l_2\)</span>، حيث <span class="math inline">\(l_1&lt;l_2\)</span>. المتجهات المفاهيمية، <span class="math inline">\(\vclo\)</span> و <span class="math inline">\(\vclt\)</span> متسقة إذا ولكل مدخل <span class="math inline">\(\vx\)</span> والتنشيطات المقابلة <span class="math inline">\(\va_{l_1}\)</span> و <span class="math inline">\(\va_{l_2}\)</span>، <span class="math inline">\(f(\va_{l_1} + \vclo) = \va_{l_2} + \vclt\)</span>.</p>
<p>إذا كان متجهان مفهوميَان منشطان متسقين، فإن لهما نفس التأثير اللاحق على النموذج عندما يتم تعديل التنشيطات في اتجاههما، أي، على الرغم من أنهما في طبقات مختلفة، فإن لهما تأثيراً مكافئاً على مخرجات النموذج وبالتالي يعطيهما النموذج نفس المعنى. فرضيتنا الأولى هي:</p>
<p><em><strong>الفرضية الصفرية 1 (NH1)</strong>: تمثيلات المتجه المفهومي متسقة عبر الطبقات</em></p>
<h2 id="متجهات-المفاهيم-المتشابكه">متجهات المفاهيم المتشابكة</h2>
<p>قد ترتبط المفاهيم المختلفة ببعضها البعض. على سبيل المثال، ضع في اعتبارك المفهومين 'السماء' و 'اللون الأزرق' – أحد الجوانب الأساسية لتعريف السماء هو أنها غالباً ما تكون زرقاء. في هذه الفقرة، نوضح كيفية اكتشاف هذه الارتباطات باستخدام متجهات المفاهيم المنشطة وآثارها على نتائج تحليل المفاهيم المنشطة.</p>
<p>لنأخذ في الاعتبار المعنى الذي يتم ترميزه بواسطة متجه المفهوم. نقوم بتسمية متجه المفهوم باستخدام التسمية المقابلة لمجموعة البيانات الاستكشافية. على سبيل المثال، قد يتم تسمية متجه المفهوم بـ <span class="nodecor">striped</span> أو <span class="nodecor">red</span>. هذا يفترض ضمنياً أن التسمية هي وصف كامل ودقيق للمعلومات التي يتم ترميزها بواسطة المتجه. في الواقع، قد يمثل متجه المفهوم عدة مفاهيم – على سبيل المثال، استمراراً في المثال أعلاه، قد يرمز المتجه إلى <span class="nodecor">striped</span> و <span class="nodecor">red</span> في نفس الوقت. نشير إلى هذه الظاهرة باسم “تشابك المفاهيم”. من الناحية الرياضية، نصوغ هذا على النحو التالي. متجه المفهوم <span class="math inline">\(\vcl\)</span> أكثر تشابهاً مع التنشيطات المقابلة للصور التي تحتوي على المفهوم من التنشيطات للصور التي لا تحتوي على المفهوم، أي أنه يلبي <span class="math display">\[\va_{c,l}^+ \cdot \vcl &gt; \va_{c,l}^- \cdot \vcl \quad \forall \va_{c,l}^+ \in \A_{c,l}^+, \va_{c,l}^- \in \A_{c,l}^-.\]</span></p>
<p>لنفترض أن لدينا المفاهيم <span class="math inline">\(c_1\)</span> و <span class="math inline">\(c_2\)</span>، مع مجموعات البيانات الاستكشافية <span class="math inline">\(\D_{c_1}\)</span> و <span class="math inline">\(\D_{c_2}\)</span>، على التوالي. لكل مجموعة بيانات استكشافية، نجد مجموعات التنشيط: <span class="math inline">\(\A_{c_1,l} = \{A_{c_1,l}^+ \cup  A_{c_1,l}^- \}\)</span> و <span class="math inline">\(\A_{c_2,l} = \{ \A_{c_2,l}^+ \cup  \A_{c_2,l}^- \}\)</span>.</p>
<p>متجه المفهوم لمفهوم ما متشابك مع مفهوم آخر إذا وفقط إذا <span class="math display">\[\label{eqn: entangled definition}
        \begin{aligned}
            &amp;\textcolor{blue}{\va_{c_2,l}^+} \cdot \textcolor{red}{\vv_{c_1,l}} &gt; \textcolor{blue}{\va_{c_2,l}^-} \cdot \textcolor{red}{\vv_{c_1,l}}
            &amp;\forall \textcolor{blue}{\va_{c_2,l}^+} \in \textcolor{blue}{\A_{c_2,l}^+} , \textcolor{blue}{\va_{c_2,l}^-} \in \textcolor{blue}{\A_{c_2,l}^-} 
        \end{aligned}\]</span></p>
<p>فرضيتنا الثانية تستكشف تشابك المفاهيم:</p>
<p><em><strong>الفرضية الصفرية 2 (NH2)</strong>: يمثل متجه المفهوم المفهوم المقابل فقط لتسميته في مجموعة البيانات الاستكشافية الخاصة به</em></p>
<h2 id="الاعتماد-المكاني">الاعتماد المكاني</h2>
<p>في هذا القسم، نستكشف تأثير الاعتماد المكاني على المفاهيم. لنفترض أن <span class="math inline">\(\D_{c, \mu_1}\)</span> و <span class="math inline">\(\D_{c,\mu_2}\)</span> تمثلان مجموعتي بيانات تحتويان على نفس المفهوم ولكن في مواقع مختلفة <span class="math inline">\(\mu_1 \neq \mu_2\)</span>. على سبيل المثال، قد تحتوي <span class="math inline">\(\D_{c, \mu_1}\)</span> على أمثلة للمفهوم <span class="nodecor">striped on the left</span> في الصورة، و <span class="math inline">\(\D_{c,\mu_2}\)</span> على أمثلة للمفهوم <span class="nodecor">striped on the right</span> في الصورة. كما في السابق، نقوم ببناء تمثيلات كامنة <span class="math inline">\(\A_{c,l,\mu_1}\)</span> و <span class="math inline">\(\A_{c,l,\mu_2}\)</span> لمجموعتي البيانات <span class="math inline">\(\D_{c, \mu_1}\)</span> و <span class="math inline">\(\D_{c, \mu_2}\)</span> على التوالي. ليكن <span class="math inline">\(\vcl\)</span> هو متجه المفهوم الذي تم العثور عليه باستخدام مجموعة البيانات الاستكشافية <span class="math inline">\(\D_{c, \mu_1}\)</span>.</p>
<p>ليكن <span class="math inline">\(\va_{l, i}\)</span> هي التنشيطات المقابلة للمدخل <span class="math inline">\(\vx_i\)</span> في الطبقة <span class="math inline">\(l\)</span>، وليكن <span class="math inline">\(\mu_{c,i}\)</span> هو موقع المفهوم <span class="math inline">\(c\)</span> في <span class="math inline">\(\vx_i\)</span>. تمتلك الطبقة تمثيلاً مكانياً معتمداً لمفهوم إذا وفقط إذا <span class="math display">\[\exists \phi: \forall \vx_i \in \mathbb{X}_c^+, \phi(\va_{l, i}) = \mu_{c,i}\]</span></p>
<p>قد يكون الاعتماد المكاني للتنشيط في شبكة عصبية ناتجاً عن تصميم الهندسة، إجراء التدريب و/أو مجموعة بيانات التدريب. في الشبكات العصبية التلافيفية، هو نتيجة طبيعية لمجال الاستقبال لمرشحات التلافيف التي تحتوي على مناطق مختلفة من المدخل. إذا كانت الشبكة العصبية تمتلك تنشيطات مكانياً معتمدة وكانت مجموعة البيانات الاستكشافية تمتلك اعتماداً مكانياً، فقد يكون من الممكن إنشاء متجه مفهوم مع اعتماد مكاني.</p>
<p>متجه المفهوم <span class="math inline">\(\vv_{c,l}\)</span> معتمد مكانياً بالنسبة للمواقع إذا وفقط إذا <span class="math display">\[\label{eqn: concept vector spatial dependence}
    \begin{aligned}
        &amp;\textcolor{red}{\va_{c,l,\mu_1}^+} \cdot \vv_{c,l} &gt; \textcolor{blue}{\va_{c,l,\mu_2}^+} \cdot \vv_{c,l}
        &amp;\forall \textcolor{red}{\va_{c,l,\mu_1}^+} \in \textcolor{red}{\A_{c,l,\mu_1}^+}, \textcolor{blue}{\va_{c,l,\mu_2}^+} \in \textcolor{blue}{\A_{c,l,\mu_2}^+}.
    \end{aligned}\]</span></p>
<p><em><strong>الفرضية الصفرية 3 (NH3)</strong>: لا يمكن أن تكون متجهات تنشيط المفهوم معتمدة مكانياً</em></p>
<h1 id="العناصر-مجموعة-بيانات-اصطناعية-قابلة-للتهيئة">العناصر: مجموعة بيانات اصطناعية قابلة للتهيئة</h1>
<p>لاستكشاف هذه الفرضيات، نقدم مجموعة بيانات اصطناعية جديدة: العناصر. في هذه المجموعة، يمكننا التحكم في: (1) مجموعة البيانات التدريبية وتعريفات الفئات، مما يتيح لنا التأثير على خصائص النموذج، مثل ارتباط المفاهيم في فضاء التضمين، و(2) مجموعة البيانات الاختبارية، مما يتيح لنا اختبار خصائص متجه المفهوم، مثل الاعتماد المكاني لمتجه المفهوم. سنقوم بمزيد من التفصيل حول هذه المزايا في الملحق [app: Elements].</p>
<p>كل صورة تحتوي على <span class="math inline">\(n\)</span> عناصر، حيث يتم تعريف العنصر بسبع خصائص: اللون، السطوع، الحجم، الشكل، النسيج، تحول النسيج، والإحداثيات داخل الصورة. يمكن تهيئة المجموعة بتغيير التوليفة المسموح بها للخصائص لكل عنصر. يتم إعطاء النطاقات والتكوينات المستخدمة لكل خاصية في الملحق [app: Elements].</p>
<h1 id="sec: related work">الأعمال ذات الصلة</h1>
<h4 id="الارتباط-والتشابك-بين-المفاهيم">الارتباط والتشابك بين المفاهيم</h4>
<p>يناقش تشين وآخرون (<span class="nodecor">Chen2020ConceptWF</span>) كيف يمكن أن تكون متجهات المفاهيم مرتبطة، مما يجعل من الصعب إنشاء متجه يمثل مفهوماً واحداً فقط. بينما يركز عملهم على فك الارتباط بين المفاهيم <em>أثناء التدريب</em>, نحن نركز على تحليل تأثير المفاهيم المرتبطة <em>بعد التدريب</em> ونظهر كيف يمكن أن تؤدي إلى تفسيرات مضللة (§[sec: Entanglement]). يستخدم فونغ وفيدالدي (<span class="nodecor">fong2018net2vec</span>) تشابه الجيب التام لإظهار أن التشابه بين المفاهيم يختلف بناءً على طريقة إنشاء المتجه. في عملنا، نستخدم أيضاً تشابه الجيب التام لمقارنة متجهات المفاهيم. الاختلاف يكمن في تركيزنا على تحليل متجهات المفاهيم والرؤى التي تقدمها حول مجموعة البيانات والنموذج.</p>
<h4 id="الاعتماد-المكاني-1">الاعتماد المكاني</h4>
<p>يصف بيسكيوني وباورز (<span class="nodecor">Biscione2021Invariant</span>) كيف أن الشبكات العصبية التلافيفية ليست مترجمة بشكل طبيعي ولكن يمكن أن تتعلم أن تكون كذلك (تحت ظروف معينة على مجموعة البيانات). هذا الاكتشاف يتحدى الافتراض الشائع بأن الشبكات العصبية التلافيفية تمتلك ترجمة طبيعية. من خلال <em>متجهات التحليل العنقودي المعتمدة مكانياً</em>، نظهر الترجمة بالنسبة لمفهوم وفئة محددة، بدلاً من ذلك بشكل عام، مما يوفر معلومات أكثر تفصيلاً عن النموذج.</p>
<h4 id="ما-هي-تمثيلات-المفاهيم-التي-ينطبق-عليها-تحليلنا">ما هي تمثيلات المفاهيم التي ينطبق عليها تحليلنا؟</h4>
<p>تمثل معظم طرق التفسير المبنية على المفاهيم المفاهيم كـ <em>متجهات</em> في فضاء التنشيط لشبكة عصبية مدربة (<span class="nodecor">kim2018interpretability, fong2018net2vec, bolei2018ibd, ghorbani2019automating, zhang2020invertible, ramaswamy2022elude, fel2023craft</span>). ومع ذلك، تستخدم بعض الطرق المبنية على المفاهيم تمثيلات مختلفة: الخلايا العصبية الفردية (<span class="nodecor">bau2017network</span>)، مناطق فضاء التنشيط (<span class="nodecor">crabbe2022</span>) أو المفاهيم غير الخطية (<span class="nodecor">bai2022concept, li2023emergent</span>). يركز عملنا على خصائص متجهات المفاهيم.</p>
<h4 id="كيف-يكون-عملنا-ذا-صلة-عمليا">كيف يكون عملنا ذا صلة عملياً؟</h4>
<p>لتقديم رؤية حول متى قد تكون الخصائص المختلفة ذات صلة، قمنا بمراجعة أوراق الرؤية الحاسوبية التي تستخدم متجهات التحليل العنقودي في (1) التطبيقات ذات الأهمية العالية للتصوير الطبي (بما في ذلك سرطان الجلد، وآفات الجلد، وسرطان الثدي، وعلم الأنسجة (<span class="nodecor">Yan2023SkinCancer, Furbock2022Breast, Pfau2020Robust</span>))، و(2) بحوث الرؤية الحاسوبية على النماذج المدربة بمجموعات بيانات معروفة (<span class="nodecor">Krizhevsky2009CIFAR, Tsung2014COCO, Wah2011CUB,Zhou2017Places, Sagawa2020Waterbirds, Deng2009ImageNet</span>). يمكن العثور على جدول ملخص في الملحق [app: related work]. وجدنا أن الأوراق التالية كان يمكن أن تستفيد من تقييم: الاتساق (<span class="nodecor">Yan2023SkinCancer, Ramaswamy2022OverlookedFI, Furbock2022Breast, Yuksekgonul2023Post, Ghosh2023Dividing, Lucieri2020Oninterp</span>)، التشابك (<span class="nodecor">Yan2023SkinCancer, Ramaswamy2022OverlookedFI, Furbock2022Breast، Yuksekgonul2023Post, Ghosh2023Dividing, Graziani2020Concept, McGrath_2022, Lucieri2020Oninterp, Pfau2020Robust</span>)، والاعتماد المكاني (<span class="nodecor">Yan2023SkinCancer, Ramaswamy2022OverlookedFI, Furbock2022Breast, Yuksekgonul2023Post, Ghosh2023Dividing, McGrath_2022, Lucieri2020Oninterp, Pfau2020Robust</span>). نقدم مثالاً مفصلاً، باستخدام تطبيق تشخيص سرطان الجلد (<span class="nodecor">Yan2023SkinCancer</span>)، في § [sec: Recommendations] والملحق [app: Example UseCase].</p>
<h4 id="مجموعات-البيانات">مجموعات البيانات</h4>
<p>بينما تم تقديم العديد من مجموعات البيانات لتقييم طرق التفسير، فإنها تختلف عن مجموعتنا في بعض الطرق الرئيسية. هناك ثلاثة جوانب نهتم بها:</p>
<ol>
<li><p>هل يتم تمثيل المفهوم في الشبكة؟</p></li>
<li><p>هل يتم استخدام المفهوم لتنبؤ الشبكة؟</p></li>
<li><p>كيف تمثل الشبكة المفاهيم المرتبطة؟</p></li>
</ol>
<p>تسمح مجموعات البيانات الحالية فقط بالاطلاع على (1)، بينما تسمح مجموعتنا لنا بتحليل (2) و(3) أيضاً. تقوم طريقة تقييم التفسير (<span class="nodecor">yang2019</span>) بإدراج الأشياء في صور المشاهد. بينما تستفيد من استخدام الصور الحقيقية والمفاهيم المعقدة (الكلب أو غرفة النوم)، فإنها تقدم أيضاً تحديات. أحد العيوب هو أن الاعتماد على الصور الحقيقية يجعل من الصعب إنشاء علاقة الحقيقة الأساسية بين المفاهيم وتنبؤات الفئة أو معرفة التشابهات بين المفاهيم. ونتيجة لذلك، لا تعطينا رؤية في (2) أو (3). مجموعة البيانات الاصطناعية في يه وآخرون (<span class="nodecor">yeh2020completeness</span>) هي الأقرب إلى مجموعتنا ولكن تم تصميمها لاكتشاف المفهوم، حيث تتميز الصور بأن كل جسم يتوافق مع مفهوم واحد (الشكل). في مجموعتنا، يحتوي كل جسم على مفاهيم متعددة، مما يسمح لنا بإنشاء ارتباطات بينها. نركز على دقة التفسير من خلال التأكد من أن المفاهيم يجب استخدامها بشكل صحيح من قبل النموذج لتحقيق دقة عالية. لذا، بالنسبة لنموذج دقيق، لدينا فهم حقيقي لكيفية استخدام كل مفهوم. يمكن العثور على مراجعة أدبية موسعة في الملحق [app: related work].</p>
<h1 id="النتائج-استكشاف-خصائص-متجه-المفهوم">النتائج: استكشاف خصائص متجهات تنشيط المفهوم</h1>
<p>نستكشف الفرضيات حول الاتساق (NH1)، التشابك (NH2)، والاعتماد المكاني (NH3) في § [sec: layer_stability]، § [sec: Entanglement] و § [sec: Spatial]، على التوالي. نقوم بإجراء التجارب باستخدام متجهات المفهوم المشروطة على مجموعات بيانات العناصر وImageNet. يمكن العثور على تفاصيل التنفيذ في الملحق [app: implementation].</p>
<h2 id="sec: layer_stability">اتساق المتجهات المفاهيمية عبر الطبقات</h2>
<h3 id="النظرية">النظرية</h3>
<p>نبدأ بفحص NH1، والذي ينص على أن المتجهات المفاهيمية متسقة عبر الطبقات، أي أن <span class="math inline">\(f(\va_{l_1} + \vv_{c, l_2}) = \va_{l_2} + \vv_{c, l_2}\)</span>. لنفترض أن <span class="math inline">\(\hat{\_va}_{l_1}\)</span> و <span class="math inline">\(\hat{\va}_{l_2}\)</span> هما اضطرابات خطية للتنشيطات في الطبقتين <span class="math inline">\(l_1\)</span> و <span class="math inline">\(l_2\)</span> على التوالي: <span class="math display">\[\begin{aligned}
    \hat{\va}_{l_1} &amp;= \va_{l_1} + \vclo \\
    \hat{\va}_{l_2} &amp;= \va_{l_2} + \vclt = f(\va_{l_1}) + \vclt\end{aligned}\]</span> نريد أن نفحص إذا كان <span class="math inline">\(\vclo\)</span> و <span class="math inline">\(\vclt\)</span> لهما نفس التأثير على التنشيطات (وبالتالي على النموذج)، أي إذا كان: <span class="math display">\[\label{eqn: consistent cavs}
    \begin{aligned}
        f(\hat{\va}_{l_1}) &amp;= \hat{\_va}_{l_2} \\
        f(\va_{l_1} + \vclo) &amp;= f(\va_{l_1}) + \vclt.
    \end{aligned}\]</span> لنفترض أننا وجدنا <span class="math inline">\(\vclo\)</span> ونود أن نجد <span class="math inline">\(\vclt\)</span> الذي يلبي المعادلة [eqn: consistent cavs]. إذا كانت <span class="math inline">\(f\)</span> تحافظ على جمع المتجهات، كما في طبقة خطية، فإنه يصح أن: <span class="math display">\[\begin{aligned}
        f(\va_{l_1}) + f(\vclo) &amp;= f(\va_{l_1}) + \vclt \\
        \vclt &amp;= f(\vclo).
    \end{aligned}\]</span> وبالتالي، من الممكن أن يكون لدينا ناقلات متسقة عبر الطبقات إذا كانت <span class="math inline">\(f\)</span> تحافظ على جمع المتجهات و <span class="math inline">\(\vclt = f(\vclo)\)</span>. بدلاً من ذلك، إذا لم تحافظ <span class="math inline">\(f\)</span> على جمع المتجهات، لا يمكننا تبسيط المعادلة [eqn: consistent cavs] ولأي <span class="math inline">\(\vv_{c, l_1}\)</span>: <span class="math display">\[\label{eqn: consistency vcl2}
    \vv_{c, l_2} = f(\va_{l_1} + \vv_{c, l_1}) - f(\va_{l_1}).\]</span> إذا كان <span class="math inline">\(\vclt\)</span> يعتمد على <span class="math inline">\(\va_{l_1}\)</span>، فلا يوجد <span class="math inline">\(\vclt\)</span> بحيث تكون المعادلة [eqn: consistent cavs] صحيحة لجميع <span class="math inline">\(\va_{l_1}\)</span>. بمعنى آخر، لا يوجد ناقل في الطبقة <span class="math inline">\(l_2\)</span> له نفس التأثير على التنشيطات كالناقل في الطبقة <span class="math inline">\(l_1\)</span> لجميع المدخلات إلى النموذج.</p>
<!-- باقي النص يبقى كما هو مع تطبيق التصحيحات الواردة أعلاه -->
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>بافتراض أن النموذج يستخدم كل مفهوم بشكل صحيح<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>قد تظل CAVs الفردية معتمدة مكانياً، ولكن هذا يُلغى عبر تشغيلات التدريب. انظر الملحق [app: Individual Spatial Norms] للتفاصيل.<a href="#fnref2">↩</a></p></li>
</ol>
</section>
</body>
</html>