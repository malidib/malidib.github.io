<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Gengming Zhang, Hao Cao, Kewei Hu, Yaoqiang Pan, Yuqin Deng, Hongjun Wang, Hanwen Kang">
  <title>تقدير نقاط القطع الدقيقة لحصاد الليتشي الآلي من خلال التعلم الهندسي الواعي</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>body { direction: rtl; font-size: 22px; }</style>
</head>
<body>
<header>
<h1 class="title">تقدير نقاط القطع الدقيقة لحصاد الليتشي الآلي من خلال التعلم الهندسي الواعي</h1>
<p class="author"><span class="nodecor">Gengming Zhang</span>, <span class="nodecor">Hao Cao</span>, <span class="nodecor">Kewei Hu</span>, <span class="nodecor">Yaoqiang Pan</span>, <span class="nodecor">Yuqin Deng</span>,<br />
<span class="nodecor">Hongjun Wang</span>, <span class="nodecor">Hanwen Kang</span></p>
</header>
<h1 id="ملخص">مُلَخَّص</h1>
<p>يُعَدُّ تحديد نقاط قطف الليتشي بدقة في بيئات البساتين غير المُنظَّمة واستنباط مواقعها الإحداثية أمراً حاسماً لنجاح روبوتات قطف الليتشي. ومع ذلك، غالباً ما تواجه طرق الكشف عن الأجسام المعتمدة على الصور ثنائية الأبعاد (2D) صعوبات بسبب الهياكل الهندسية المعقدة للفروع والأوراق والثمار، مما يؤدي إلى أخطاء في تحديد مواقع القطف. في هذه الدراسة، نقترح نموذج شبكة <span class="nodecor">Fcaf3d-lychee</span> المصمم خصيصاً للكشف عن نقاط قطف الليتشي بدقة. يتم الحصول على بيانات سحابة النقاط الخاصة بنقاط قطف الليتشي في البيئات الطبيعية باستخدام كاميرا <span class="nodecor">Microsoft’s Azure Kinect DK</span> بآلية قياس زمن الطيران (<span class="nodecor">TOF</span>) عبر التصوير متعدد الزوايا. نعزز نموذج الكشف ثلاثي الأبعاد الخالي من المراسي والكامل التلافيفي (<span class="nodecor">Fcaf3d</span>) بوحدة الضغط والإثارة (<span class="nodecor">SE</span>)، والتي تستلهم آليات الانتباه البصري البشري لتعزيز استخراج الميزات الخاصة بنقاط القطف. تم تقييم النموذج على مجموعة اختبار لمنطقة القطف، محققاً قيمة <span class="nodecor"><span class="math inline">\(F_{1}\)</span></span> بلغت <span class="nodecor">88.57%</span>، متفوقاً بشكل ملحوظ على النماذج الحالية. يضمن الكشف ثلاثي الأبعاد لمواقع نقاط القطف في بساتين الليتشي الحقيقية دقة عالية حتى في ظروف التغطية الكثيفة. تبلغ أخطاء تحديد المواقع ضمن <span class="nodecor">±1.5 cm</span> في جميع المحاور، مما يبرهن على قوة وعمومية النموذج.</p>
<h1 id="مقدمة">مُقَدِّمَة</h1>
<p>الزراعة الدقيقة أو الزراعة الذكية هي مفهوم حديث لإدارة المزرعة الشاملة، ويستخدم مجموعة متنوعة من التقنيات من الاستشعار عن بعد وجمع البيانات القريبة إلى الأتمتة والروبوتات. في هذه الدراسة نركز على حصاد الليتشي الطازج، الذي يمثل تحدياً ليس فقط من ناحية التصميم الميكانيكي للروبوت، بل أيضاً من حيث نظام الرؤية وخوارزميات التنقل وآليات التحكم ونظام التلاعب (<span class="nodecor">r65</span>). وفي هذه الدراسة، يتمحور اهتمامنا حول اكتشاف نقاط القطف في بيانات السحابة النقطية لتعزيز قدرات القطف الذاتي لروبوتات المحصول.</p>
<p>يمكن قطف الفواكه الفردية مثل التفاح والبرتقال مباشرة، بينما تتطلب الفواكه العنقودية مثل الليتشي والعنب قطف العنقود بكامله. ولحصاد الليتشي، يجب أولاً تحديد نقطة القطع الرئيسية للفرع الحامل للفاكهة (MFBB) ثم قطع الفرع بدقة لمنع تلف الثمار (<span class="nodecor">r2</span>). إذا كانت منطقة العمل خاليةً من العوائق وسهلةَ الوصول، فلا تمثل إزالة الثمار صعوبة كبيرة (<span class="nodecor">r63</span>). ومع ذلك، فإن الحقل غير منظم، وقد تختلف عناقيد الليتشي في الحجم والشكل وتظهر على ارتفاعات ومواقع متعددة، علاوة على ذلك، قد تتعرض نقاط القطف للازدحام الشديد أو يكون موقع الهدف غير واضح بما فيه الكفاية، وتُصعّب الأهداف الصغيرة عملية الكشف، مما يؤثر سلباً على الدقة. لذلك، أصبح تحديد نقاط قطف عناقيد الليتشي بدقة وبتركيز انتقائي محوراً رئيسياً في الأبحاث. ويتطلب ذلك أساساً تقنيتين رئيسيتين: (1) بيانات سحابة نقطية ثلاثية الأبعاد (3D) تتحمل الازدحام، و(2) نموذج كشف ثلاثي الأبعاد مبني على الشبكات التلافيفية قادر على التحديد الدقيق.</p>
<p>خلال السنوات الأخيرة، توسعت تطبيقات الرؤية الحاسوبية في تحديد نقاط القطف (<span class="nodecor">r3,r42,r4</span>)، حيث تُستخدم خصائص الهدف—كاللون والشكل والنسيج—لاكتشاف الليتشي عبر معالجة الصور (التصفية، التجزئة، المعالجة المورفولوجية) وخوارزميات التعلم الآلي (<span class="nodecor">r5,r43,r6,r7,r44</span>). ومع تقدم التعلم العميق، لا سيما الشبكات التلافيفية (CNN)، تحولت العديد من الدراسات إلى أساليب الكشف ثنائية الأبعاد المعتمدة على التعلم مثل YOLO (<span class="nodecor">r11,r12,r45,r46,r47</span>) وسلاسل RCNN (<span class="nodecor">r50</span>). ورغم النتائج المشجعة، لا تزال التقلبات الضوئية والازدحام الناتج عن الأوراق والفروع عائقاً كبيراً.</p>
<p>تتميز بيانات السحابة النقطية ثلاثية الأبعاد بقدرتها على تمثيل الأشكال الهندسية بدقة وتوفير معلومات العمق مباشرة، كما تدعم إعادة البناء ثلاثي الأبعاد متانة الكشف ودقته. ومع تطور الشبكات العصبية التلافيفية ثلاثية الأبعاد، استُخدمت أساليب قائمة على السحابة النقطية في حصاد الفاكهة وكشف نقاط القطف (<span class="nodecor">r51,r16,r52,r53,r14,r54,r66,r57</span>). ورغم النتائج الجيدة، لا تزال هناك فجوات في تحديد نقاط قطف الليتشي بشكل مباشر.</p>
<p>في هذا العمل، نقترح نموذجاً متكاملاً يتضمن دمج بيانات سحابة النقاط متعددة الزوايا من كاميرا TOF مع نموذج Fcaf3d-lychee لاكتشاف نقاط قطف الليتشي وتحديد مواقعها بدقة في بيئة البستان الطبيعية، مع اختبار ميداني. يدمج النهج بيانات الاستشعار المرئي متعدد الزوايا ثم يكتشف الموقع الدقيق لنقطة القطف عبر خوارزمية الكشف ثلاثية الأبعاد. تظهر النتائج تفوُّق هذه الدراسة على نماذج الكشف التقليدية للسحابة النقطية ثلاثية الأبعاد، ويمكن تلخيص المساهمات الرئيسية في هذه الورقة كما يلي:</p>
<ul>
<li><p>اقتراح نموذج Fcaf3d-lychee للكشف عن نقاط قطف الليتشي، مما يسهم بشكل كبير في تحسين دقة تحديد المواقع.</p></li>
<li><p>استخدام كاميرا TOF لخياطة البيانات النقطية متعددة الزوايا، مما يعالج مشكلة الازدحام أحادي الزاوية وقلة المعلومات الحسية.</p></li>
<li><p>عرض قدرات روبوت قطف الليتشي المجهز بنموذج Fcaf3d-lychee على التعرف وتحديد مواقع نقاط القطف في بيئات البستان الطبيعية.</p></li>
</ul>
<p>يُنظّم باقي هيكل هذه الورقة كما يلي. يستعرض القسم [section: review] الأعمال ذات الصلة. يقدم القسم [section: method] نظرة عامة على النظام والمنهجية. تُعرض نتائج التجارب ومناقشتها في القسم [section: experiment]، ثم الخاتمة في القسم [section: conclusion].</p>
<h1 id="section: review">الأعمال ذات الصلة</h1>
<h2 id="مراجعة-عن-الكشف-عن-الأهداف-ثنائية-الأبعاد-المبنية-على-الصور-في-الليتشي">مراجعة حول الكشف عن الأهداف ثنائية الأبعاد المبنية على الصور في الليتشي</h2>
<p>حالياً، يغطي مجال تطبيق الروبوتات تقنيات أساسية ومتنوعة (<span class="nodecor">r17</span>). وفي تطوير روبوتات الحصاد الذكية، تشكل خوارزميات الرؤية عاملاً حاسماً في الأداء. تشمل مهمتا الرؤية الرئيسيتان تحديد موقع الثمرة واستخراج نقطة القطع، مع تحديات مثل تشوه اللون الناتج عن الإضاءة الطبيعية المتغيرة وتداخل أعضاء النبات وتشوهات داخل الفئة للثمار (<span class="nodecor">r18</span>). سعت خوارزميات الرؤية الآلية إلى تحسين الكفاءة والدقة والذكاء والتفاعل عن بعد خلال عمليات الحصاد (<span class="nodecor">r19</span>). تصنّف الأساليب بين تحليل الميزة الفردية ودمج الميزات المتعددة والتعرف على الأنماط (<span class="nodecor">r20</span>, <span class="nodecor">r21</span>). (<span class="nodecor">r24</span>) اقترح مصنفاً يعتمد على تحليل التمييز الخطي المحسن (LDA) لمعالجة معدل النجاح المنخفض في التعرف على الليتشي الأخضر نتيجة تداخل الخلفية. تقوم طريقة LDA باستخراج ميزات التحويل الصوري، ويُقدّم مفهوم “الهامش الأقصى” في خوارزمية SVM لتحديد العتبة المناسبة، ثم يتم دمج ذلك في مصنف متعدد LDA عبر Adaboost. أظهرت التجارب دقة <span class="nodecor">80.4%</span> لليتشي غير الناضج، ويمكن استخدام الخوارزمية أيضاً في تصنيف نضج الفاكهة. غير أن هذه الأساليب المعتمدة على الصور تتطلب إضاءة مناسبة ومعالجة إضافية للتعامل مع الموضع ثلاثي الأبعاد، مما يضعف من كفاءة عملية القطف وقوتها.</p>
<h2 id="مراجعة-على-طرق-الكشف-عن-الأهداف-ثنائية-الأبعاد-لثمره-الليتشي-باستخدام-التعلم-العميق">مراجعة حول طرق الكشف ثنائية الأبعاد لثمرة الليتشي باستخدام التعلم العميق</h2>
<p>اعتمدت بعض الأبحاث تقنيات الرؤية المجسمة وتقنيات معالجة الصور التقليدية، بينما قدم التطور في التعلم العميق حلولاً متقدمة لتمييز الفواكه في بيئات البساتين المعقدة (<span class="nodecor">r25</span>). على سبيل المثال، اقترح (<span class="nodecor">r26</span>) خوارزمية للكشف عن ثمار الليتشي وسيقانها في البيئات الليلية، باستخدام YOLOv3 وU-Net تحت شدات ضوء صناعية مختلفة، محققاً دقة كشف متوسطة قدرها <span class="nodecor">99.57%</span> وتجزئة MIoU بلغت <span class="nodecor">84.33%</span>. ومع ذلك، تعتمد الطريقة أولاً على YOLOv3 ثم منطقة ROI لتمييز السيقان، ما يقلل من الفاعلية في التنفيذ. (<span class="nodecor">r28</span>) حسّن هيكل YOLOv5s لسيناريوهات الاحتجاب الخلفي والفواكه المتداخلة أثناء قطف التفاح، لكنه يقتصر على الفواكه الفردية ولا يغطّي سيناريوهات حصاد الليتشي. ورغم التقدم الكبير في تحديد نقاط القطف عبر الصور ثنائية الأبعاد، لم تتناول معظم الدراسات الكشف المباشر عن نقاط قطف الفرع الأم.</p>
<h2 id="مراجعة-على-طرق-الكشف-عن-الأهداف-ثلاثية-الأبعاد-باستخدام-التعلم-العميق-للفواكه">مراجعة حول طرق الكشف ثلاثية الأبعاد باستخدام التعلم العميق للفواكه</h2>
<p>على الرغم من التقدم الملحوظ في الكشف ثنائي الأبعاد، يفتقر هذا النمط إلى التوزيع المكاني التفصيلي. توفر السحب النقطية ثلاثية الأبعاد تمثيلاً شمولياً لتوزيع الأجسام في المشاهد المعقدة، مما أدّى إلى ظهور أساليب جديدة للكشف. (<span class="nodecor">r33</span>) اقترح استراتيجية لتحديد نقاط القطف بدقة لعناقيد العنب الصناعية عبر دمج البيانات القريبة والبعيدة من السحب النقطية، محققاً نجاحاً بنحو <span class="nodecor">95%</span> من <span class="nodecor">100</span> عينة ودقة <span class="nodecor">95%</span>. كذلك، (<span class="nodecor">r36</span>) اقترح طريقة لمعالجة أعضاء شجرة الرمان وعد الفواكه عبر دمج الميزات واستخدام SVM، إذ يتم أولاً الحصول على السحابة النقطية ثلاثية الأبعاد ثم استخراج ميزات اللون والشكل للتصنيف، وقد أظهرت التجارب قدرة عالية على اكتشاف معظم الثمار على الشجرة. ومع ذلك، لم تُدرس طرق الكشف المباشر للسحب النقطية الخاصة بنقاط القطف.</p>
<p>يبني عملنا على نموذج Fcaf3d، حيث استُحدث نموذج Fcaf3d-lychee لتحديد نقاط قطف الليتشي مباشرة من تدفق السحب النقطية لكاميرا العمق، مسرعاً وفاعلاً عملية الاكتشاف وتوفير الإحداثيات ثلاثية الأبعاد بدقة.</p>
<h1 id="section: method">المواد والطرق</h1>
<h2 id="نظرة-عامة-على-النظام">نظرة عامة على النظام</h2>
<p>بينما يوضح الشكل [fig:graph1] عملية اكتشاف نقطة قطف الليتشي المقترحة، تنقسم إلى مرحلتين: الحصول على السحابة النقطية وعملية الخياطة متعدد الزوايا، ثم نموذج <span class="nodecor">Fcaf3d-lychee</span> لتحديد الموقع بدقة. أولا، يتجول الروبوت القاطف المزوّد بخريطة البستان بشكل مستقل للحصول على تقدير أولي لموقع الهدف من تدفق السحابة النقطية. بعدها، ينتقل الروبوت لجمع سحابة نقطية حول الهدف من ثلاث زوايا قريبة، ثُم يقوم بعملية الخياطة والتنقية. تُغذى السحابة المعالجة إلى نموذج <span class="nodecor">Fcaf3d-lychee</span> لاكتشاف النقطة بدقة، ويعقب ذلك توجيه الخاطف لأداء حركة القطف.</p>
<h2 id="نموذج-الرؤية-اليد-عين-وطريقة-المعايرة-المغلقة">نموذج الرؤية يد-عين وطريقة المعايرة المغلقة</h2>
<p>يحمل حساس الكاميرا على ذراع روبوت Aubo بست درجات حرية ويجمع البيانات، التي تحوّل في النهاية إحداثيات نقطة القطف ثلاثية الأبعاد بدقة إلى نظام إحداثيات قاعدة الذراع. قبل ذلك، أُجريت معايرة الكاميرا ومعايرة اليد-عين. الأولى تمت بواسطة طريقة Zhang الكلاسيكية (<span class="nodecor">r59</span>). في دراساتنا السابقة، اقترح (<span class="nodecor">r60</span>) طريقة معايرة يد-عين مغلقة الحلقة لتحديد العلاقة الإحداثية بين نهاية الذراع وحساس الكاميرا. وتُحسب مصفوفة اليد-عين كما في المعادلة (1). <span class="math display">\[\begin{gathered}
    \widehat{{_{C}^{F}}T} =\frac{1}{N_c} \sum_{i=1}^{N_C} {({_{B}^{C}}T{^{(i)}}{_{R}^{B}}T{_{F}^{R}}T{^{(i)}})^{-1}}\end{gathered}\]</span> حيث <span class="math inline">\(_R^BT\)</span> مصفوفة التحويل الثابتة بين {R} و{B}، و<span class="math inline">\(_B^CT^{(i)}\)</span> بين {C} و{B} للوضع i، و<span class="math inline">\(_F^RT^{(i)}\)</span> بين {F} و{R} للوضع i. يمثل <span class="math inline">\(N_c\)</span> عدد الوضعيات المختلفة، وهنا <span class="nodecor">16</span>. عند تحريك الذراع إلى المواقع المختارة (<span class="nodecor">r64</span>)، تُحوّل الميزات المحلية لكل نقطة إلى نظام الإحداثيات الأساسي لتشكيل الميزة العالمية.</p>
<h2 id="اكتساب-سحابه-النقاط">اكتساب سحابة النقاط</h2>
<h3 id="التصفية">التصفية</h3>
<p>تتأثر دقة السحابات النقطية الخام المجمعة من نظام الرؤية متعدد الزوايا بعوامل عدة كالتغيرات الضوئية والاهتزازات وأخطاء المعايرة وأخطاء الأجهزة. تولّد هذه العوامل ضوضاء وانتشار نقاط خارج الهيكل الرئيسي. للتعامل معها دمجنا مرشحاً إحصائياً ومرشحاً لونه لتنقية الشوائب المنعزلة والنقاط شديدة الاختلاف، وتوفير حالة أولية صالحة لخياطة السحابات لاحقاً.</p>
<p>كما اقترح (<span class="nodecor">r62</span>) في إعادة بناء <span class="nodecor">3D</span> لأشجار الفاكهة، نطبق مرشحاً لونه بسيطاً على السحابة النقطية للحد من عدد الأوراق الخضراء الممزقة وإعداد بيئة أولية مناسبة للكشف اللاحق. <span class="math display">\[\begin{gathered}
\left\{
\begin{aligned}
    R_s &amp; &gt; &amp; \sigma_1 \\
    G_s &amp; \leq &amp; \sigma_2
\end{aligned}
\right.\end{gathered}\]</span> حيث <span class="math inline">\(R_s\)</span> و <span class="math inline">\(G_s\)</span> قنوات الأحمر والأخضر لكل نقطة. إذا تحقق الشرط، تُزَال النقطة من السحابة.</p>
<p>أما المرشح الإحصائي، فيبحث لكل نقطة عن جيرانها، ويحسب متوسط المسافات <span class="math inline">\(\mu\)</span> والانحراف المعياري <span class="math inline">\(\sigma\)</span>، ويستبعد النقاط خارج الفترة <span class="math display">\[\left[ 
    \mu-\alpha_v\times\sigma,\ \mu+\alpha_v\times\sigma
\right]\]</span> حيث <span class="math inline">\(\alpha_v<3\)</span>.</p>
<h3 id="الخياطة">الخياطة</h3>
<p>وفقاً لمعايرة اليد-عين، تُحوّل كل مجموعة من السحب النقطية الثلاث إلى نظام إحداثيات قاعدة الذراع، مما يوفر توجيهاً أولياً جيداً لخياطة السحابات التالية.</p>
<p>لنفترض أن عدد نقااط السحابة في الزوايا A وB وC هو <span class="nodecor"><span class="math inline">\(n_1\)</span></span>، <span class="nodecor"><span class="math inline">\(n_2\)</span></span> و <span class="nodecor"><span class="math inline">\(n_3\)</span></span> على التوالي، وأن إحداثياتها في النظام الأساسي هي <span class="nodecor"><span class="math inline">\({^R}P_A^{(k)}\)</span></span>، <span class="nodecor"><span class="math inline">\({^R}P_B^{(k)}\)</span></span> و <span class="nodecor"><span class="math inline">\({^R}P_C^{(k)}\)</span></span>، بينما إحداثياتها في نظام الكاميرا هي <span class="nodecor"><span class="math inline">\({^{CA}}P^{(k)}\)</span></span>، <span class="nodecor"><span class="math inline">\({^{CB}}P^{(k)}\)</span></span> و <span class="nodecor"><span class="math inline">\({^{CC}}P^{(k)}\)</span></span> على التوالي. بتطبيق التحويل <span class="nodecor"><span class="math inline">\(_{C}^{R}T\)</span></span>، كما استُنتج في القسم III-B، نحصل على:</p>
<p><span class="math display">\[\left[
\begin{array}{c}
    {^R}P_A^{(1)} \\
    {^R}P_A^{(2)} \\
    \vdots \\
    {^R}P_A^{(\textnormal{$n_1$})} 
\end{array}
\right]
= \ 
^{\ R}_{CA}T
\left[
\begin{array}{c}
    ^{CA}P^{(1)} \\
    ^{CA}P^{(2)} \\
    \vdots \\
    ^{CA}P^{(\textnormal{$n_1$})} 
\end{array}
\right],\quad
^{\ R}_{CA}T
= 
^{\ R}_{CB}T
=
^{\ R}_{CC}T
=
\widehat{{_{C}^{F}}T}\]</span></p>
<p>وبالتالي تتجمّع السحابة النقطية الموحدة <span class="nodecor"><span class="math inline">\(P_s\)</span></span> كما يلي: <span class="math display">\setlength{\arraycolsep}{1.8pt}
    P_s
=
\left[
\begin{array}{c|c|c}
    \Bigl[{^R}P_A^{(1)},\dots,{^R}P_A^{(n_1)}\Bigr] &
    \Bigl[{^R}P_B^{(1)},\dots,{^R}P_B^{(n_2)}\Bigr] &
    \Bigl[{^R}P_C^{(1)},\dots,{^R}P_C^{(n_3)}\Bigr]
\end{array}
\right]^T\]</span></p>
<!-- ... باقي النص كما هو ... -->
</body>
</html>