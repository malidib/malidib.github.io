<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Xinwei Chen">
  <meta name="author" content="Kun Li">
  <meta name="author" content="Jiangjian Guo">
  <meta name="author" content="Tianyou Song">
  <title>التعرّف على الكيانات الاسمية بعدد قليل من الأمثلة في StackOverflow</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>body { direction: rtl; font-size: 22px; }</style>
</head>
<body>
<header>
<h1 class="title">التعرّف على الكيانات الاسمية بعدد قليل من الأمثلة في <span class="nodecor">StackOverflow</span></h1>
<p class="author"><span class="nodecor">Xinwei Chen</span></p>
<p class="author"><span class="nodecor">Kun Li</span></p>
<p class="author"><span class="nodecor">Jiangjian Guo</span></p>
<p class="author"><span class="nodecor">Tianyou Song</span></p>
</header>
<p>لايتكس</p>
<h1 id="ملخص">مُلخّص</h1>
<p>يشكّل مخزون <span class="nodecor">StackOverflow</span> الضخم من الأسئلة تحدياً للتوسيم نظراً لمحدودية الأمثلة الموسومة. نعالج هذه الفجوة باستخدام <span class="nodecor">RoBERTa+MAML</span>، وهي طريقة للتعرّف على الكيانات الاسمية بعدد قليل من الأمثلة تستفيد من التعلم البيني. تم تقييم نهجنا على مجموعة بيانات <span class="nodecor">StackOverflow NER</span> (27 نوعاً من الكيانات)، وحققنا تحسناً بنحو <span class="nodecor">5%</span> في نقاط <span class="nodecor">F1</span> مقارنة بالنموذج الأساسي. علاوةً على ذلك، عزّزنا الأداء بشكل إضافي عبر معالجة العبارات المتخصصة بالمجال.</p>
<h1 id="مقدمة">مقدمة</h1>
<p>يطرح تنامى محتوى البرمجة على الإنترنت تحديات في فهم واستخراج المعلومات المتعلقة بالبرمجيات. منتدى <span class="nodecor">StackOverflow</span>، كأكبر منتدى للبرمجة، يضم أكثر من <span class="nodecor">15</span> مليون سؤال. لفهم هذا الكم الهائل بفعالية، يتطلب الأمر تحديد الكيانات المسماة (<span class="nodecor">NEs</span>). ومع ذلك، يحتاج التعلم الخاضع للإشراف الكامل للتعرّف على الكيانات المسماة (<span class="nodecor">NER</span>) بيانات موسومة واسعة النطاق، وهو ما يتطلب موارد عالية. استجابةً لذلك، نقترح التعلم بعدد قليل من الأمثلة لتمكين التعرّف الدقيق على الكيانات مع أقل قدر من بيانات التوسيم. يمكن أن يُطبق نهجنا في المهام المتعلقة بالبرمجيات مثل استرجاع المعلومات، والإجابة على الأسئلة، وتلخيص المقالات.</p>
<p>يشير <span class="nodecor">mai2018fine</span> إلى التعرّف الدقيق على الكيانات المسماة عبر تصنيفها إلى فئات أكثر تحديداً. وفي بعض الأحيان تكون بنية البيانات الموسومة غير مباشرة، مما يزيد من صعوبة التوسيم. نظراً للتكلفة العالية للتوسيم اليدوي، يبدو التعلم بعدد قليل من الأمثلة حلاً عملياً. عبر تدريب النماذج على أمثلة موسومة قليلة، نحقق تعرفاً دقيقاً وفعالاً للكيانات المسماة. في هذه الورقة نقدم دراسة حول التعلم بعدد قليل من الأمثلة في مجال البرمجيات على مجموعة بيانات <span class="nodecor">StackOverflow NER</span> (<span class="nodecor">codener</span>). اقترحنا نموذجاً يستفيد من شبكة انتباه لاستخراج المعلومات من شظايا الكود والنص لتوليد نتائج أولية عند تحديد <span class="nodecor">20</span> نوعاً من الكيانات المتعلقة بالبرمجيات. تشمل مساهماتنا:</p>
<ul>
<li><p>نقترح وحدة لشرح تسمية الكيانات المتعلقة بالبرمجيات باستخدام عدد قليل من الأمثلة</p></li>
<li><p>نولد النتائج الأولى على مجموعة بيانات <span class="nodecor">StackOverflow NER</span></p></li>
</ul>
<h1 id="الأعمال-ذات-الصلة">الأعمال ذات الصلة</h1>
<p>شهدت قاعدة المعرفة البرمجية العديد من الدراسات. من الأمثلة: تحسين قياس جودة السؤال في StackOverflow (<span class="nodecor">ravi</span>)، واستخراج الأسئلة والأجوبة ذات الصلة في StackOverflow (<span class="nodecor">shirani</span>). مع ذلك، تفتقر هذه الأبحاث إلى استخدام تقنيات معالجة اللغة الطبيعية لتحديد الكيانات المسماة في سياق البرمجيات.</p>
<p>أُجريت أعمال كثيرة في التعرّف على الكيانات المسماة، حيث عالج (<span class="nodecor">Li19, li2023deception</span>) قضايا استرجاع المعلومات والأونتولوجيا في نطاقات محددة. واقترح (<span class="nodecor">qun</span>) تعلماً بدون أمثلة قابل للنقل بين المجالات للتعرّف على الكيانات. مؤخراً، أصبح التعلم العميق شائعاً في <span class="nodecor">NER</span>، خاصة مع نماذج مدربة مسبقاً مثل BERT (<span class="nodecor">bert</span>) وRoBERTa (<span class="nodecor">roberta</span>). على الرغم من ذلك، يظل التعرّف على الكيانات مهمة تستغرق وقتاً طويلاً وتتطلب خبراء مجال لتوسيم بيانات ضخمة. طُوّرت عدة منهجيات للتعرّف الدقيق بعدد قليل من الأمثلة، منها خط أنابيب <span class="nodecor">fgner</span> وطرق التوليد التناقضي <span class="nodecor">fewshotner</span> وطرق التعلّم بياني التوليد (<span class="nodecor">pmlr-v202-zeng23c, zeng23acm</span>). ومع ذلك، لم يتم حتى الآن العمل على التعرّف على الكيانات المسماة الدقيقة بعدد قليل من الأمثلة في مجال البرمجيات.</p>
<p>هناك أيضاً عمل <span class="nodecor">codener</span> للتعرّف على الكيانات المسماة في مجال البرمجة الحاسوبية. يهدف هذا العمل إلى تمييز الكيانات المسماة في <span class="nodecor">StackOverflow</span>، وقد درّبوا نموذجهم على BERT مع دمج التضمينات السياقية وتضمينات المجال الخاصة.</p>
<h4 id="تعلم-الاستدعاء">تعلم الاستدعاء:</h4>
<p>يحول تعلم الاستدعاء المهام التقليدية في معالجة اللغة الطبيعية إلى مشكلات تنبؤية للفتحات غير المملوءة. في مهام التعرّف بعدد قليل من الأمثلة، يضيف (<span class="nodecor">fgner</span>, <span class="nodecor">fewshotner</span>) قالباً لاستدعاء الكيان بعد الجملة الأصلية.</p>
<h4 id="التعلم-البياني">التعلم البيني:</h4>
<p>يوصف التعلم البيني بأنه "تعلم التعلم". ونظراً لأن تدريب نموذج دقيق يتطلب عادةً بيانات موسومة وفيرة، بينما تكون التوسيمات في نطاق البرمجيات محدودة، يتيح التعلم البيني تهيئة أفضل للنموذج ليتكيف سريعاً مع مهمات جديدة. طبق (<span class="nodecor">Decomposed</span>) خوارزمية <span class="nodecor">MAML</span> وقدم نموذج <span class="nodecor">MAML-ProtoNet</span> للتعرّف بعدد قليل من الأمثلة.</p>
<h1 id="الطريقة">الطريقة</h1>
<p>بحسب علمنا، لم تُجرَ دراسات كافية لتطبيق التعلم بعدد قليل من الأمثلة على مجموعة بيانات <span class="nodecor">StackOverflowNER</span>. أجرت مجموعة <span class="nodecor">codener</span> دراسةً منهجية إشرافية على هذه المجموعة، لكنها تواجه قيوداً: أولاً، ضمن مهام المجال، يحتاج التوسيم إلى خبراء ويستغرق وقتاً طويلاً. ثانياً، يستغرق تدريب BERT داخل النطاق أكثر من شهر على 152 مليون جملة من StackOverflow. نحن نستكشف نموذجين للتعلم بعدد قليل من الأمثلة: أحدهما ضبط دقيق مستند إلى الأوامر، والآخر يضيف التعلم البيني للمهام المتخصصة بالمجال.</p>
<h2 id="تصنيف-الكيانات-بعدد-قليل-من-الأمثلة">تصنيف الكيانات بعدد قليل من الأمثلة</h2>
<p>في هذا القسم، نعرّف مشكلة تصنيف الكيانات بعدد قليل من الأمثلة: تحديد نوع الكيان في جملة باستخدام عدد محدود من عينات التدريب. المدخلات هي تسلسل من رموز النص <span class="math inline">\(\textbf{x}=\{t_{1},t_{2},...,\textbf{m},...,t_{T}\}\)</span>، حيث <span class="math inline">\(m = \{t_{i},...,t_{j}\}\)</span> هو تسلسل كيان مكون من <span class="math inline">\((j-i+1)\)</span> رمزاً، وT هو الطول الكلي للجملة. المخرجات هي تسمية نوع الكيان <span class="math inline">\(y \in Y\)</span>، حيث <span class="math inline">\(Y\)</span> هي مجموعة التسميات <span class="math inline">\(\{y_{1},...,y_{n}\}\)</span>. في التعلم ب <span class="math inline">\(K\)</span>-مثال، يكون هناك <span class="math inline">\(K\)</span> عينات تدريبية لكل فئة.</p>
<h2 id="الضبط-الدقيق-بناء-على-الأوامر">الضبط الدقيق المستند إلى الأوامر</h2>
<p>اعتمدنا إطار العمل المقترح من Huang كنموذج أساسي (<span class="nodecor">fewshotner</span>). يوضح الإطار العام للضبط الدقيق المستند إلى الأوامر في الشكل المشار إليه. في هذا الأسلوب، نُدخل الجملة مع قالب يتضمن فتحة <span class="math inline">\([MASK]\)</span> لتمثيل التنبؤ المطلوب. بعد المعالجة بواسطة مشفّر النموذج المدرب مسبقاً <span class="math inline">\(\theta_{0}\)</span> (مثل RoBERTa)، نحصل على التمثيل السياقي <span class="math inline">\(h_{m}\)</span> لرمز <span class="math inline">\([MASK]\)</span>. ثم يقدّم رأس النموذج توزيع احتمال عبر المفردات <span class="math inline">\(\mathcal{V}\)</span>، ونستخدم Softmax لحساب احتمالات الكلمات، ثم معيار لغوي لتحويل احتمالات الكلمات إلى احتمالات التسميات، ونعتمد التباين KL دالة خسارة لتقليل الفارق بين التنبؤات والهدف.</p>
<h2 id="التعلم-البيني-المستقل-عن-النموذج">التعلم البيني المستقل عن النموذج</h2>
<p>لتحسين الأداء في المهام المتخصصة بالمجال، ندمج التعلم البيني المستقل عن النموذج (<span class="nodecor">finn2017model</span>). الفكرة العامة هي تدريب النموذج على مهام متعددة للحصول على تهيئة أفضل للمعاملات، ما يتيح له التعلم بسرعة على مهام جديدة. نطبق خوارزمية <span class="nodecor">MAML</span> عبر مرحلتين: التدريب البيني على <span class="math inline">\(\xi_{train}\)</span> والاختبار البيني على <span class="math inline">\(\xi_{test}\)</span>، مع إعداد <span class="math inline">\(K\)</span>-<span class="nodecor">shot</span>-<span class="math inline">\(N\)</span>-<span class="nodecor">way</span>.</p>
<h3 id="مرحلة-التدريب-الأولى">مرحلة التدريب الأولى</h3>
<p>في هذه المرحلة، ندرب النموذج على مجموعة البيانات العامة عبر <span class="nodecor">N</span> مهام. لكل مهمة، نأخذ عينة <span class="math inline">\((D_{i}^{sup} , D_{i}^{query})\)</span> من <span class="math inline">\(\xi_{train}\)</span> ونحدث المعاملات داخلياً بحسب المعادلة [eqn7]. ثم نقيس الأداء على <span class="math inline">\(D_{i}^{query}\)</span> ونجمع الخسائر عبر المهام لتحديث التهيئة العامة كما في المعادلتين [eqn8] و[eqn9].</p>
<h3 id="الاختبار-الفوقي">مرحلة الاختبار البيني</h3>
<p>في هذه المرحلة، نستخدم المعاملات المحدثة لتحسين النموذج على مجموعة تدريب <span class="nodecor">StackOverflow</span> ثم نجري التنبؤ على مجموعة الاختبار.</p>
<h1 id="التجربة">التجربة</h1>
<h2 id="مجموعة-البيانات">مجموعة البيانات</h2>
<p>في هذه المهمة، نستخدم مجموعة بيانات <span class="nodecor">NER</span> من <span class="nodecor">StackOverflow</span> (المعروفة باسم <span class="nodecor">codener</span>)، التي تضم أكثر من <span class="nodecor">1,237</span> موضوعاً من الأسئلة والأجوبة على مدى <span class="nodecor">10</span> سنوات و<span class="nodecor">27</span> نوعاً من الكيانات. تشمل كيانات الكود: <em>الفئة، المتغير، الكود ضمن السطر، الوظيفة، المكتبة، القيمة، نوع البيانات، والعلامة (HTML/XML)</em>. وتشمل كيانات اللغة الطبيعية: <em>التطبيق، عنصر واجهة المستخدم، اللغة، هيكل البيانات، الخوارزمية، نوع الملف، اسم الملف، الإصدار، الجهاز، نظام التشغيل، الموقع الإلكتروني، واسم المستخدم</em>. نخطط أيضاً لاستخدام بيانات إضافية مأخوذة عشوائياً من مستودعات <span class="nodecor">GitHub</span>.</p>
<h2 id="إعدادات-التجربة">إعدادات التجربة</h2>
<p><strong>أخذ عينات لقليل اللقطات.</strong> نجري تجربة التعلم بخمس حالات (<span class="nodecor">5</span>-shot) على مجموعة بيانات <span class="nodecor">StackOverflow NER</span> باختيار خمس عينات تدريبية عشوائياً في كل تجربة. أجرينا كذلك تجربة اختيار خمس حالات يدوياً لتحسين دقة النموذج.</p>
<p><strong>عينات التدريب الأساسي.</strong> تحتوي مجموعة بيانات <span class="nodecor">Few-NERD</span> على <span class="nodecor">66</span> نوعاً دقيقاً من الكيانات. نقوم بمرحلة التدريب الأساسي عبر <span class="nodecor">40</span> مهمة، حيث نأخذ لكل مهمة عينة عشوائية من إعداد <span class="nodecor">20</span>-حالة-<span class="nodecor">27</span>-طريقة، ثم نقسمها إلى مجموعة دعم <span class="nodecor">5</span>-حالة-<span class="nodecor">27</span>-طريقة واستفسار <span class="nodecor">15</span>-حالة-<span class="nodecor">27</span>-طريقة.</p>
<p><strong>إعدادات المعاملات الفائقة.</strong> نعتمد نموذج <span class="nodecor">RoBERTa-base</span> المدرب مسبقاً. أقصى طول للتسلسل <span class="nodecor">128</span>؛ حجم الدفعة الداخلية للضبط الدقيق <span class="nodecor">8</span>؛ حجم الدفعة الخارجية للتحديث الأساسي <span class="nodecor">32</span>؛ عدد عصور الضبط الدقيق في التدريب الأساسي <span class="nodecor">1</span>؛ عدد عصور الضبط في الاختبار الأساسي <span class="nodecor">10</span>؛ الحد الأقصى لخطوات التعلم الأساسي <span class="nodecor">15</span>؛ معدل التعلم للتعلم الأساسي <span class="nodecor">5e-3</span>؛ معدل التعلم للتحديث الداخلي <span class="nodecor">1e-2</span>. تم التدريب على <span class="nodecor">GPU</span> في <span class="nodecor">Google Colab</span>.</p>
<p><strong>مقاييس التقييم.</strong> استخدمنا مقاييس <span class="nodecor">Micro-F1</span> و<span class="nodecor">Macro-F1</span>.</p>
<h2 id="النتائج">النتائج</h2>
<p>طبقنا نموذج RoBERTa ونموذج RoBERTa+MAML على مجموعة بيانات التعرّف على الكيانات المسماة من <span class="nodecor">StackOverflow</span>. في التدريب، اخترنا عشوائياً خمس عينات لكل فئة من مجموعة البيانات. كما يظهر في الجدول [citation-guide]، بلغت درجة <span class="nodecor">Micro-F1</span> لنموذج RoBERTa <span class="nodecor">0.3091</span> ودرجة <span class="nodecor">Macro-F1</span> <span class="nodecor">0.2837</span>.</p>
<p>طبقنا بنفس الطريقة نموذج <span class="nodecor">RoBERTa+MAML</span>، فبلغت درجة <span class="nodecor">Micro-F1</span> <span class="nodecor">0.3578</span> ودرجة <span class="nodecor">Macro-F1</span> <span class="nodecor">0.3197</span>، ما يدل على زيادة ملحوظة باستخدام التعلم البيني.</p>
<p>كما نرى في الشكلين ([fig:highperform], [fig:lowperform])، تُحسن <em>هيكل البيانات، عنصر واجهة المستخدم، نظام التشغيل، اسم المستخدم</em> و<em>نوع البيانات</em> أداء التعرّف باستخدام RoBERTa+MAML.</p>
<h2 id="دراسة-حالة-لمجموعة-تدريب-من-5-لقطات">دراسة حالة لمجموعة تدريب من 5 لقطات</h2>
<p>لاحظنا أن درجة <span class="nodecor">F1</span> لعدة فئات مثل نظام التشغيل، وفئة المكتبة، واسم الوظيفة، وعنوان <span class="nodecor">IP</span>، ولوحة المفاتيح، واللغة، واسم المتغير، والخوارزمية كانت أقل من المتوقع. يصعب التعرّف على هذه الفئات عند تطبيق NER بخمس لقطات. بعد فحص مجموعة التدريب العشوائية، وجدنا فيها كيانات مكررة وأخرى غير واضحة التمثيل.</p>
<p>لتجنب التأثيرات السلبية، اخترنا يدوياً عينات تدريبية ذات معنى وتمثيلية أفضل. طبقنا أيضاً نفس النهج على نموذج <span class="nodecor">RoBERTa+MAML</span>. كما يوضح الجدول، ارتفعت درجة <span class="nodecor">Micro-F1</span> بنحو 3% ودرجة <span class="nodecor">Macro-F1</span> بنحو 2%.</p>
<p>يوضح هذا المثال أن فئة "المحتوى" غامضة ضمن بيانات التدريب بخمس لقطات ولا تتمتع بتمثيل كافٍ، فقررنا اختيار عينات بديلة يدوياً لتعظيم أداء النموذج. أظهرت النتائج تفوق RoBERTa+MAML مع البيانات المختارة يدوياً على البيانات العشوائية، لذا سنعتمد هذه البيانات في أعمالنا المستقبلية.</p>
<h2 id="دراسة-حالة-لاستخراج-الأنماط-المعتمدة-على-المعرفة">دراسة حالة لاستخراج الأنماط المعتمدة على المعرفة</h2>
<p>لاحظنا أن هناك فئات يصعب التعرف عليها لكنها تتبع أنماطاً واضحة. مثلاً، جميع امتدادات الملفات الشائعة تصنف ضمن فئة نوع الملف. كما في الجدول [table:maual]، يمكننا استخدام التعبيرات النظامية لاستخراج امتدادات مثل csv، jpg، doc. يشير الجدول [table:extraction] إلى تحسن درجة <span class="nodecor">F1</span> لفئة نوع الملف من <span class="nodecor">0.345</span> إلى <span class="nodecor">0.49</span>، مع دقة <span class="nodecor">0.716</span> واسترجاع <span class="nodecor">0.372</span>. يمكن تطبيق استخراج الأنماط المعتمدة على المعرفة لفئات أخرى لتحسين الدقة الإجمالية ودرجة <span class="nodecor">F1</span>.</p>
<h1 id="الخلاصة-والأعمال-المستقبلية">الخلاصة والأعمال المستقبلية</h1>
<p>ركزنا في دراستنا على التعرّف على الكيانات المسماة ضمن مجال برمجة الحاسوب باستخدام نموذج <span class="nodecor">RoBERTa+MAML</span> في مهمة 5-shot على مجموعة بيانات StackOverflow NER، حيث حققنا تحسينات كبيرة مقارنةً بنموذج RoBERTa الأساسي. بَيّنت النتائج أن التعلم البيني أداة قوية لمهام التعرف المتخصصة والقليلة العينات، وأن معالجة العبارات المتخصصة واستخراج الأنماط المعتمدة على المعرفة يعززان الدقة. نتوقع استفادة المهام المستقبلية في استخراج المعلومات المتعلّقة بالبرمجيات والإجابة على الأسئلة من هذه التقنيات. نسعى مستقبلاً إلى توسيع تنوع البيانات واستكشاف تشكيلات مختلفة لمجموعات الدعم والاستفسار لتعزيز فعالية التعلم البيني.</p>
</body>
</html>