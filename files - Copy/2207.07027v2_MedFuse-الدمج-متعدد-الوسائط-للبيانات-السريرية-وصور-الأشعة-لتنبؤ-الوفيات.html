<!DOCTYPE html>
<html lang="ar">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MedFuse - الدمج متعدد الوسائط للبيانات السريرية وصور الأشعة لتنبؤ الوفيات</title>
    <!-- MathJax for LaTeX math rendering -->
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true,
                packages: {'[+]': ['ams', 'amssymb', 'amsmath', 'amsthm', 'newcommand', 'boldsymbol']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            }
        };
    </script>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        body {
            font-family: 'Times New Roman', serif;
            line-height: 1.6;
            color: #333;
            background-color: #fafafa;
            direction: rtl;
        }
        .container {
            max-width: 900px;
            background-color: white;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
            padding: 40px;
            margin: 20px auto;
        }
        h1 {
            text-align: center;
            font-size: 2.2em;
            margin-bottom: 30px;
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 15px;
        }
        h2 {
            color: #34495e;
            font-size: 1.5em;
            margin-top: 35px;
            margin-bottom: 15px;
            border-right: 4px solid #3498db;
            padding-right: 10px;
            border-left: none;
            padding-left: 0;
        }
        h3 {
            color: #5d6d7e;
            font-size: 1.3em;
            margin-top: 25px;
            margin-bottom: 12px;
        }
        p {
            text-align: justify;
            margin-bottom: 15px;
        }
        .abstract {
            background-color: #f8f9fa;
            border-right: 4px solid #007bff;
            border-left: none;
            padding: 20px;
            margin: 30px 0;
            font-style: italic;
        }
        .keywords {
            background-color: #e9ecef;
            padding: 15px;
            margin: 20px 0;
            border-radius: 5px;
        }
        .equation {
            text-align: center;
            margin: 20px 0;
            padding: 15px;
            background-color: #f8f9fa;
            border-radius: 5px;
        }
        .figure {
            text-align: center;
            margin: 30px 0;
            padding: 20px;
            background-color: #f8f9fa;
            border-radius: 5px;
            border: 1px solid #dee2e6;
        }
        .table {
            margin: 25px 0;
        }
        .reference {
            font-size: 0.9em;
            margin-bottom: 8px;
        }
        .meta-info {
            background-color: #e7f3ff;
            padding: 15px;
            margin-bottom: 30px;
            border-radius: 5px;
            font-size: 0.9em;
        }
        code {
            background-color: #f8f9fa;
            padding: 2px 4px;
            border-radius: 3px;
        }
        pre {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
        }
        blockquote {
            border-right: 4px solid #6c757d;
            border-left: none;
            padding-right: 20px;
            font-style: italic;
            color: #6c757d;
        }
        .theorem, .lemma, .proposition, .corollary {
            background-color: #fff3cd;
            border: 1px solid #ffeaa7;
            padding: 15px;
            margin: 20px 0;
            border-radius: 5px;
        }
        .proof {
            border-right: 2px solid #28a745;
            border-left: none;
            padding-right: 15px;
            margin: 15px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="meta-info">
            <strong>معرّف ArXiv:</strong> 2207.07027v2<br>
            <strong>LaTeX الأصلي:</strong> <code>./nyuad_arxiv_papers/nyuad_papers_comprehensive/source_code/2207.07027v2_extracted/main.tex</code><br>
            <strong>تم التحويل:</strong> 2025-06-06 13:13:48
        </div>
        <header id="title-block-header">
<h1 class="title">MedFuse - الدمج متعدد الوسائط للبيانات السريرية وصور الأشعة لتنبؤ الوفيات</h1>
<p class="author"><a href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a><br />
قسم الهندسة<br />
جامعة نيويورك أبوظبي<br />
أبوظبي، الإمارات العربية المتحدة<br />
قسم الأشعة<br />
كلية الطب بجامعة نيويورك جروسمان<br />
نيويورك، الولايات المتحدة الأمريكية<br />
قسم الهندسة<br />
جامعة نيويورك أبوظبي<br />
أبوظبي، الإمارات العربية المتحدة</p>
<div class="abstract">
<div class="abstract-title">الملخص</div>
<p>تهدف تقنيات الدمج متعدد الوسائط إلى تكامل المعلومات المستخلصة من مصادر بيانات مختلفة. بخلاف مجموعات البيانات الطبيعية، مثل تطبيقات الصوت والصورة، حيث تتكون العينات عادة من وسائط "مقترنة"، غالبًا ما يتم جمع البيانات في الرعاية الصحية بشكل غير متزامن. لذا، فإن اشتراط توفر جميع الوسائط لكل عينة ليس واقعيًا في المهام السريرية، ويحد بشكل كبير من حجم مجموعة البيانات أثناء التدريب. في هذا البحث، نقترح <code>MedFuse</code>، وهو وحدة دمج قائمة على LSTM بسيطة من الناحية المفاهيمية وواعدة في الأداء، قادرة على التعامل مع المدخلات أحادية أو متعددة الوسائط. نقوم بتقييم طريقة الدمج هذه ونقدم نتائج معيارية جديدة لتنبؤ الوفيات داخل المستشفى وتصنيف الأنماط المرضية، باستخدام بيانات زمنية سريرية من مجموعة بيانات MIMIC-IV وصور الأشعة السينية للصدر من MIMIC-CXR. بالمقارنة مع استراتيجيات الدمج متعدد الوسائط الأكثر تعقيدًا، يوفر <code>MedFuse</code> تحسنًا كبيرًا في الأداء على مجموعة الاختبار المقترنة بالكامل، كما يبقى قويًا عند اختبار العينات التي تفتقد صور الأشعة السينية للصدر. نطرح الشيفرة البرمجية الخاصة بنا لتعزيز إمكانية إعادة إنتاج النتائج وتمكين تقييم النماذج المنافسة مستقبلاً.</p>
</div>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#introduction">المقدمة</a>
<ul>
<li><a
href="#generalizable-insights-about-machine-learning-in-the-context-of-healthcare">رؤى عامة حول تعلم الآلة في سياق الرعاية الصحية</a></li>
</ul></li>
<li><a href="#related-work">الأعمال ذات الصلة</a>
<ul>
<li><a href="#multi-modal-learning">التعلم متعدد الوسائط</a></li>
<li><a href="#multi-modal-fusion-with-medical-images">دمج الوسائط المتعددة مع الصور الطبية</a></li>
<li><a
href="#multi-modal-fusion-with-clinical-data-and-medical-images">دمج الوسائط المتعددة بين البيانات السريرية والصور الطبية</a></li>
</ul></li>
<li><a href="#sec:method">المنهجية</a>
<ul>
<li><a href="#encoders">المشفّرات الخاصة بكل وسيط</a></li>
<li><a href="#fusion">وحدة <code>MedFuse</code></a></li>
</ul></li>
<li><a href="#sec:exp">التجارب</a>
<ul>
<li><a href="#datasets-and-benchmark-tasks">مجموعات البيانات والمهام المعيارية</a>
<ul>
<li><a
href="#pre-processing-of-clinical-time-series-data">معالجة البيانات الزمنية السريرية</a></li>
<li><a href="#data-splits">تقسيمات البيانات</a></li>
</ul></li>
<li><a href="#training-strategy-with-the-medfuse-module">استراتيجية التدريب مع وحدة <code>MedFuse</code></a></li>
<li><a href="#baseline-models">النماذج الأساسية</a></li>
<li><a href="#model-training-and-selection">تدريب النماذج واختيارها</a></li>
</ul></li>
<li><a href="#sec:res">النتائج</a>
<ul>
<li><a
href="#performance-results-in-the-uni-modal-multi-modal-settings">نتائج الأداء في الإعدادات أحادية ومتعددة الوسائط</a></li>
<li><a href="#performance-results-in-the-paired-setting">نتائج الأداء في الإعداد المقترن</a></li>
<li><a
href="#performance-results-in-the-partially-paired-setting">نتائج الأداء في الإعداد المقترن جزئياً</a></li>
<li><a href="#phenotype-wise-analysis">تحليل حسب الأنماط المرضية</a></li>
<li><a href="#in-hospital-mortality-age-wise-analysis">تحليل الوفيات داخل المستشفى حسب الفئة العمرية</a></li>
</ul></li>
<li><a href="#discussion">المناقشة</a></li>
<li><a href="#appendix-a"></a>
<ul>
<li><a href="#image-aug">تحسينات الصور</a></li>
<li><a href="#hyperparameter">نتائج البحث عن القيم الفائقة</a></li>
<li><a href="#unimodalpercentagetraining">نسبة العينات أحادية الوسيط ضمن مجموعة التدريب</a></li>
<li><a href="#unimodalpercPAIRED">نسبة العينات أحادية الوسيط ضمن مجموعة الاختبار المقترنة</a></li>
<li><a href="#missingtoken">الوسيط المفقود مع الدمج المبكر والمشترك</a></li>
<li><a href="#unimodalpercPARTIAL">نسبة العينات أحادية الوسيط ضمن مجموعة الاختبار المقترنة جزئياً</a></li>
<li><a href="#ensemble">تجميع النماذج أحادية ومتعددة الوسائط</a></li>
</ul></li>
</ul>
</nav>
<section id="introduction" class="level1">
<h1>المقدمة</h1>
<p>يدرك الإنسان العالم من حوله من خلال بيانات متعددة الوسائط <span class="citation" data-cites="ngiam2011multimodal"></span>. حتى الآن، تعتمد معظم النماذج الناجحة في تعلم البيانات الإدراكية في الرعاية الصحية على وسيط واحد فقط <span class="citation" data-cites="Huang2020_survey"></span>. لقد تم استكشاف التعلم متعدد الوسائط على نطاق واسع في سياق تطبيقات الصوت والصورة <span class="citation" data-cites="vaezi20mmtm"></span> ومجموعات بيانات الصور الطبيعية <span class="citation" data-cites="zellers2021merlot zsd"></span>، إلا أن تطبيقاته في الرعاية الصحية ما تزال محدودة. الهدف الرئيسي من الدمج متعدد الوسائط هو استغلال المعلومات ذات الصلة من وسائط مختلفة لتحسين الأداء في المهام اللاحقة <span class="citation" data-cites="baltruvsaitis2018multimodal"></span>. يمكن تصنيف استراتيجيات الدمج إلى دمج مبكر أو مشترك أو متأخر <span class="citation" data-cites="Huang2020_survey"></span>. ويُعد الدمج المشترك الأكثر وعدًا، إذ يركز على نمذجة التفاعلات بين تمثيلات الوسائط المدخلة.</p>
<p>نبرز هنا تحديين رئيسيين يواجهان الدمج المشترك متعدد الوسائط في الرعاية الصحية. أولاً، تفترض العديد من الأساليب الحديثة توفر جميع الوسائط لكل عينة أثناء التدريب أو الاستدلال أو كليهما <span class="citation" data-cites="daft"></span>. رغم أن بعض الدراسات السريرية تتبع هذا الافتراض <span class="citation" data-cites="Huang2020_survey"></span>، إلا أن الحصول على بيانات مقترنة غير عملي لأن الممارسة السريرية اليومية تنتج بيانات غير متجانسة وبكثافة متفاوتة. فعلى سبيل المثال، تُجمع البيانات الفسيولوجية بشكل أكثر تكرارًا من صور الأشعة السينية للصدر في وحدات العناية المركزة. هاتان الوسيطتان هما محور دراستنا لما لهما من أهمية في مهام التنبؤ السريري <span class="citation" data-cites="benchhmark Lohan2019"></span>. كما أن تطوير نموذج دمج موحد لهاتين الوسيطتين يطرح تحديات إضافية، منها: (1) اختلاف أبعاد المدخلات بشكل كبير، (2) الحاجة إلى مستخلصات ميزات خاصة بكل وسيط بسبب اختلاف المعلومات والضجيج <span class="citation" data-cites="nagrani2021attention"></span>، و(3) عدم التزامن الزمني بين الوسيطتين، مما يصعب اقترانهما. بناءً على هذه التحديات، هدفنا الأساسي هو اقتراح بنية دمج قادرة على التعامل مع البيانات المقترنة جزئيًا لتحقيق أداء جيد في مهام التنبؤ.</p>
<p>التحدي الثاني هو غياب معايير عامة متعددة الوسائط متاحة علنًا في المجال السريري. لذا، تعتمد معظم الدراسات على وسيط بيانات واحد <span class="citation" data-cites="benchhmark"></span>، أو على مجموعات بيانات متعددة الوسائط خاصة <span class="citation" data-cites="Huang2020_survey"></span>. هنا، هدفنا الثانوي هو تقديم نتائج معيارية جديدة لمهمتين سريريتين شائعتين باستخدام مجموعتي بيانات MIMIC-IV <span class="citation" data-cites="mimic4"></span> وMIMIC-CXR <span class="citation" data-cites="mimiccxrjpg"></span> المتاحتين للجمهور، مع توفير الشيفرة البرمجية لضمان إعادة الإنتاج. نقارن منهجيتنا مع الدمج المبكر والمشترك التقليدي، بالإضافة إلى أحدث الأساليب مفتوحة المصدر <span class="citation" data-cites="vaezi20mmtm daft"></span>. باختصار، نقدم المساهمات التالية:</p>
<ul>
<li><p>نقترح <code>MedFuse</code>، وهو نهج دمج متعدد الوسائط قائم على LSTM <span class="citation" data-cites="hochreiter1997long"></span>. في حين أن الاستراتيجيات التقليدية للدمج المشترك تعتمد على دمج تمثيلات الميزات من عدة وسائط في تمثيل واحد، ثم معالجته في المهام اللاحقة، فإننا نتعامل مع التمثيلات متعددة الوسائط كسلسلة من التمثيلات أحادية الوسيط (أو رموز)، بحيث يقوم نموذج الدمج بتجميع هذه التمثيلات عبر آلية التكرار في LSTM. نفترض بنية تسلسلية للاستفادة من التحيز الاستقرائي في LSTM ولمعالجة تسلسلات مدخلات بطول متغير في حال غياب وسيط ما. وحدة الدمج غير مرتبطة بهندسة مستخلصات الميزات الخاصة بكل وسيط، ويمكنها التعامل مع البيانات المفقودة أثناء التدريب والاستدلال.</p></li>
<li><p>لتقييم النهج المقترح، قمنا بربط مجموعتي بيانات واقعيتين مفتوحتين: MIMIC-IV <span class="citation" data-cites="mimic4"></span> التي تحتوي على بيانات زمنية سريرية من وحدات العناية المركزة، وMIMIC-CXR <span class="citation" data-cites="mimiccxrjpg"></span> التي تحتوي على صور أشعة سينية للصدر. قمنا بمعالجة البيانات وقدمنا نتائج معيارية جديدة لمهمتين: تنبؤ الوفيات داخل المستشفى وتصنيف الأنماط المرضية <span class="citation" data-cites="benchhmark"></span>. أظهرت النتائج أن أداء النموذج يبقى قويًا في العينات أحادية الوسيط ويتحسن في العينات متعددة الوسائط المقترنة. يحقق النموذج نتائج متقدمة دون افتراض وجود ترابط بين الوسائط.</p></li>
<li><p>نظرًا لغياب معايير تعلم متعدد الوسائط في الرعاية الصحية، نطرح شيفرة معالجة البيانات والنتائج المعيارية لضمان إعادة الإنتاج وتمكين تقييم النماذج المنافسة مستقبلاً. الشيفرة متاحة على: <a href="https://github.com/nyuad-cai/MedFuse" class="uri">https://github.com/nyuad-cai/MedFuse</a>. نظرة عامة على العمل المقترح موضحة في الشكل <a href="#fig:overview-of-work" data-reference-type="ref" data-reference="fig:overview-of-work">1</a>.</p></li>
</ul>
<figure>
<img src="mlhc-submission-files 2022/figures/overview_updated.png"
id="fig:overview-of-work" style="width:70.0%"
alt="نظرة عامة على العمل المقترح. نقوم أولاً باستخراج وربط مجموعات البيانات من MIMIC-IV وMIMIC-CXR بناءً على تعريف المهمة (أي تنبؤ الوفيات داخل المستشفى أو تصنيف الأنماط المرضية). يتم تلخيص تقسيمات بيانات التدريب والتحقق والاختبار لكل مهمة، كما يتم عرض انتشار العلامات الإيجابية والسلبية لتنبؤ الوفيات داخل المستشفى. يتضمن تصنيف الأنماط المرضية 25 علامة كما هو موضح في الجدول [tab:phenotype_wise]." />
<figcaption aria-hidden="true"><strong>نظرة عامة على العمل المقترح.</strong> نقوم أولاً باستخراج وربط مجموعات البيانات من MIMIC-IV وMIMIC-CXR بناءً على تعريف المهمة (أي تنبؤ الوفيات داخل المستشفى أو تصنيف الأنماط المرضية). يتم تلخيص تقسيمات بيانات التدريب والتحقق والاختبار لكل مهمة، كما يتم عرض انتشار العلامات الإيجابية والسلبية لتنبؤ الوفيات داخل المستشفى. يتضمن تصنيف الأنماط المرضية 25 علامة كما هو موضح في الجدول <a href="#tab:phenotype_wise" data-reference-type="ref" data-reference="tab:phenotype_wise">[tab:phenotype_wise]</a>.</figcaption>
</figure>
<p><span id="fig:overview-of-work"
label="fig:overview-of-work"></span></p>
<section
id="generalizable-insights-about-machine-learning-in-the-context-of-healthcare"
class="level2 unnumbered">
<h2 class="unnumbered">رؤى عامة حول تعلم الآلة في سياق الرعاية الصحية</h2>
<p>عادةً ما تركز تقنيات الدمج متعدد الوسائط الحديثة على مصادر معلومات متزامنة باستخدام مجموعات بيانات طبيعية مثل الصوت والصورة والنص. في الرعاية الصحية، غالبًا ما تكون البيانات متفرقة وغير متجانسة، وبالتالي لا تكون الوسائط مقترنة دائمًا. يتغلب عملنا على تحدي البيانات المفقودة من خلال اقتراح نهج دمج مرن لا يعتمد على نوع المشفّر الخاص بكل وسيط. لذا يمكن تطبيقه على أنواع أخرى من البيانات، وليس فقط صور الأشعة السينية للصدر والبيانات الزمنية السريرية. كما يبرز أهمية معالجة سلسلة من التمثيلات أحادية الوسيط مقارنة باستراتيجية الدمج التقليدية في الدمج المشترك. بشكل عام، يبرز العمل إمكانيات الدمج متعدد الوسائط في الرعاية الصحية لتحسين الأداء في المهام السريرية.</p>
</section>
</section>
<section id="related-work" class="level1">
<h1>الأعمال ذات الصلة</h1>
<p>تنتج الممارسة السريرية الروتينية كميات كبيرة من البيانات من مصادر مختلفة (أي وسائط متعددة)، بما في ذلك الصور الطبية، ونتائج التحاليل المخبرية، وقياسات العلامات الحيوية، والملاحظات السريرية <span class="citation" data-cites="asri2015big"></span>. مكّنت التطورات في التعلم العميق من بناء نماذج تنبؤية باستخدام مجموعات فرعية من هذه الوسائط، وغالبًا ما تكون بيانات زمنية سريرية <span class="citation" data-cites="shickel2017deep"></span> أو صور طبية <span class="citation" data-cites="litjens2017survey"></span>. هنا نقدم لمحة عن الأعمال ذات الصلة في دمج الوسائط المتعددة في الرعاية الصحية باستخدام البيانات التصويرية وغير التصويرية.</p>
<section id="multi-modal-learning" class="level2">
<h2>التعلم متعدد الوسائط</h2>
<p>تم استكشاف التعلم متعدد الوسائط على نطاق واسع لتعلم تمثيلات مشتركة لعدة وسائط <span class="citation" data-cites="baltruvsaitis2018multimodal"></span>. تشمل المهام أمثلة مثل الربط البصري <span class="citation" data-cites="chen2021endtoend"></span>، ربط اللغة من خلال الإشارات البصرية <span class="citation" data-cites="zhang2021explainable"></span>، التعرف على الأفعال <span class="citation" data-cites="chen2015utd"></span>، تصنيف الفيديو <span class="citation" data-cites="nagrani2021attention"></span>، توليد وصف للصور <span class="citation" data-cites="yu2019multimodal"></span>، أو الإجابة على الأسئلة البصرية <span class="citation" data-cites="zellers2021merlot"></span>. بما أن دراسات تعلم الآلة غالبًا ما تدرس مجموعات مختلفة من وسائط الصوت والصورة والنص، فإن العديد من الأساليب الحالية تفترض وجود معلومات بنيوية مشتركة بين الوسائط. هذا الافتراض لا ينطبق دائمًا على البيانات غير المتجانسة في الرعاية الصحية، لذا يجب مراعاة خصوصية البيانات الطبية عند تطوير تقنيات التعلم متعدد الوسائط.</p>
</section>
<section id="multi-modal-fusion-with-medical-images" class="level2">
<h2>دمج الوسائط المتعددة مع الصور الطبية</h2>
<p>هناك اهتمام متزايد بتطوير تقنيات دمج الصور الطبية متعددة الوسائط <span class="citation" data-cites="imaging_fusion"></span>. غالبًا ما تمثل الصور وجهات نظر مختلفة لنفس العضو أو الآفة، يتم الحصول عليها باستخدام جهاز أو أكثر، وتشارك نفس مجموعة العلامات. تركز الأساليب المقترحة بشكل رئيسي على الدمج على مستوى البكسل لوجهات النظر التكميلية للحصول على تمثيل مركب موحد للصور الخام <span class="citation" data-cites="img_fusion JAMES20144"></span>. كما تم اقتراح طرق دمج على مستوى الميزات أو التنبؤ لتحسين التصنيف <span class="citation" data-cites="Therapy_Response Breast_Cancer cancersubtypes"></span> أو أداء التقسيم <span class="citation" data-cites="imaging_fusion"></span>. وبما أن التقارير النصية هي نتاج طبيعي لفحوصات الأشعة، فقد تم استخدامها كوسائط إضافية في مهام مثل الإجابة على الأسئلة البصرية <span class="citation" data-cites="imag_reports Sharma2021"></span>، توليد التقارير <span class="citation" data-cites="radiology"></span>، أو التصنيف الفوري للصور <span class="citation" data-cites="gzsl MVSE"></span>.</p>
</section>
<section id="multi-modal-fusion-with-clinical-data-and-medical-images"
class="level2">
<h2>دمج الوسائط المتعددة بين البيانات السريرية والصور الطبية</h2>
<p>درست عدة أبحاث دمج الصور الطبية مع البيانات السريرية المستخرجة من السجلات الصحية الإلكترونية للمرضى في تطبيقات متنوعة <span class="citation" data-cites="Huang2020_survey"></span>. على سبيل المثال، هناك أعمال تتعلق بتنبؤ عودة السرطان <span class="citation" data-cites="cancer_recurrence"></span>، اكتشاف الآفات <span class="citation" data-cites="cancers_diag"></span>، أو تنبؤ البقاء على قيد الحياة <span class="citation" data-cites="cancer_survival"></span>. وتشمل مهام أخرى اكتشاف الانصمام الرئوي <span class="citation" data-cites="Huang2020"></span>، تنبؤ تطور مرض الزهايمر <span class="citation" data-cites="MildInt"></span>، تشخيص الأمراض العصبية <span class="citation" data-cites="9534148"></span>، أو تشخيص خلل التنسج العنقي <span class="citation" data-cites="cervical"></span>. رغم أن هذه الدراسات تبرز أثر استخدام وسائط متعددة على الأداء، إلا أن العديد منها يفترض اقتران الصور مع الميزات السريرية المختارة.</p>
<p>ركزت بعض الدراسات تحديدًا على دمج البيانات السريرية مع صور الأشعة السينية للصدر. على سبيل المثال، أظهر دمج الوسيطتين أثرًا إيجابيًا في مهام التنبؤ لدى مرضى كوفيد-19 <span class="citation" data-cites="Shamout2021 Jiao2021"></span>. تقوم بعض الدراسات بتحسين تمثيل كامن مشترك بعد تجميع الميزات المشفرة لكل وسيط <span class="citation" data-cites="Cardiomegaly_ehr_cxr Jiao2021"></span>، بينما تجمع دراسات أخرى التنبؤات المحسوبة من كل وسيط عبر المتوسط المرجح (أي الدمج المتأخر) <span class="citation" data-cites="Shamout2021 Jiao2021"></span>. رغم أن الدمج المتأخر يتيح التنبؤ حتى في العينات غير المكتملة، إلا أنه يتطلب أن تشترك الوسيطتان في نفس العلامات، وهو أمر غير متاح دائمًا. العمل الأقرب إلى بحثنا هو ما قدمه <span class="citation" data-cites="hayat2021dynamic"></span>، حيث اقترحوا نهج تدريب ديناميكي للبيانات الزمنية السريرية وصور الأشعة السينية للصدر المقترنة جزئيًا في مهمة تصنيف الأنماط المرضية. إلا أن طريقتهم غير قابلة للتوسع لأنها تتطلب مصنفًا إضافيًا لكل تركيبة ممكنة من الوسائط المدخلة.</p>
<div class="figure*">
<p><embed
src="mlhc-submission-files 2022/figures/MedFuse_final.pdf" /></p>
</div>
</section>
</section>
<section id="sec:method" class="level1">
<h1>المنهجية</h1>
<p>نعرّف نهجًا من مرحلتين: (1) تعلم نماذج إدراكية خاصة بكل وسيط لاستخلاص الميزات الكامنة (انظر القسم <a href="#encoders" data-reference-type="ref" data-reference="encoders">3.1</a>)، و(2) دمج هذه الميزات عبر وحدة دمج متعددة الوسائط مشتركة، <code>MedFuse</code> (انظر القسم <a href="#fusion" data-reference-type="ref" data-reference="fusion">3.2</a>). تظهر البنية الكلية في الشكل <a href="#fig:main_fig" data-reference-type="ref" data-reference="fig:main_fig">[fig:main_fig]</a>. نركز هنا على وسيطين فقط: البيانات الزمنية السريرية (ehr) وصور الأشعة السينية للصدر (cxr) عند شرح المنهجية.</p>
<section id="encoders" class="level2">
<h2>المشفّرات الخاصة بكل وسيط</h2>
<p>أحد مصادر عدم التجانس الرئيسية في الرعاية الصحية هو اختلاف أبعاد وسائط الإدخال، مما يصعّب تطوير مشفّر موحد لجميع الوسائط. كما تختلف مساحة الأهداف، إذ لا نفترض أن جميع الوسائط يجب أن تشترك في نفس مجموعة العلامات. لذا، نعرّف مشفّرات خاصة بكل وسيط كما يلي.</p>
<p>بالنسبة لعينة معينة، لنفترض أن <span class="math inline">\(\mathbf{x}_{ehr}\in \mathbb{R}^{t\times d}\)</span> تمثل البيانات الزمنية السريرية المرتبطة بعلامات حقيقية <span class="math inline">\(\textbf{y}_{ehr}\)</span>، حيث <span class="math inline">\(t\)</span> هو عدد الخطوات الزمنية و<span class="math inline">\(d\)</span> هو عدد الميزات المستخرجة من المتغيرات السريرية. نطبق المشفّر <span class="math inline">\(f_{ehr}\)</span> كشبكة LSTM مكونة من طبقتين مع طبقة إسقاط. نحسب تمثيلًا كامنًا <span class="math inline">\(\mathbf{v}_{ehr} \in \mathbb{R}^m\)</span> يمثل الحالة المخفية الأخيرة من LSTM، حيث <span class="math inline">\(m=256\)</span>. ثم نطبق مصنفًا <span class="math inline">\(g_{ehr}\)</span> لحساب التنبؤات: <span class="math inline">\(\hat{\mathbf{y}}_{ehr} = g_{ehr}(\mathbf{v}_{ehr})\)</span>. لتحسين المشفّر، نستخدم دالة الخسارة التالية: <span class="math display">\[\mathbb{L}_{ehr}(\mathbf{y}_{ehr}, \mathbf{\hat{y}}_{ehr}) = BCE(\mathbf{y}_{ehr}, \mathbf{\hat{y}}_{ehr}),\]</span> حيث <span class="math inline">\(BCE\)</span> هي خسارة الانتروبيا الثنائية.</p>
<p>لنفرض أن <span class="math inline">\(\mathbf{x}_{cxr} \in \mathbb{R}^{w\times h \times c}\)</span> تمثل صورة الأشعة السينية للصدر لنفس العينة مع العلامات الحقيقية <span class="math inline">\(\textbf{y}_{cxr}\)</span>، حيث <span class="math inline">\(w\)</span> هو العرض، <span class="math inline">\(h\)</span> هو الارتفاع، و<span class="math inline">\(c\)</span> هو عدد القنوات. في جميع تجاربنا، <span class="math inline">\(h=224\)</span>، <span class="math inline">\(w=224\)</span>، و<span class="math inline">\(c=3\)</span>، حيث نكرر كل صورة عبر ثلاث قنوات. نطبق المشفّر <span class="math inline">\(f_{cxr}\)</span> كشبكة ResNet-34 <span class="citation" data-cites="he2016deep"></span> لحساب <span class="math inline">\(\mathbf{v}_{cxr} \in \mathbb{R}^n\)</span>، وهو تمثيل الميزات بعد طبقة التجميع المتوسط في الشبكة الالتفافية حيث <span class="math inline">\(n=512\)</span>. بالمثل، نطبق مصنفًا <span class="math inline">\(g_{cxr}\)</span> لحساب التنبؤات: <span class="math inline">\(\hat{\mathbf{y}}_{cxr} = g_{cxr}(\mathbf{v}_{cxr})\)</span> ونستخدم دالة الخسارة التالية لتحسين المشفّر: <span class="math display">\[\mathbb{L}_{cxr}(\mathbf{y}_{cxr}, \mathbf{\hat{y}}_{cxr}) = BCE(\mathbf{y}_{cxr}, \mathbf{\hat{y}}_{cxr}).\]</span></p>
<p>يمكن بالتالي تدريب المشفّرات بشكل مستقل باستخدام العلامات والخسائر الخاصة بكل وسيط.</p>
</section>
<section id="fusion" class="level2">
<h2>وحدة <code>MedFuse</code></h2>
<p>لدمج الوسائط، نستبعد أولاً المصنفات <span class="math inline">\(g_{ehr}\)</span> و<span class="math inline">\(g_{cxr}\)</span> ونحتفظ بالمشفّرات المدربة مسبقًا <span class="math inline">\(f_{ehr}\)</span> و<span class="math inline">\(f_{cxr}\)</span>. وبما أن أبعاد الفضاء الكامن للوسيطين مختلفة، نستخدم طبقة إسقاط <span class="math inline">\(\mathbf{\phi}\)</span> لإسقاط <span class="math inline">\(\mathbf{v}_{cxr}\)</span> إلى نفس أبعاد <span class="math inline">\(\mathbf{v}_{ehr}\)</span>: <span class="math display">\[\mathbf{v}_{cxr}^* =  {\phi(\mathbf{v}_{cxr})}\]</span> بحيث <span class="math inline">\(\mathbf{v_{cxr}^*}\in \mathbb{R}^m\)</span>. بعد ذلك، ننشئ تسلسلًا من تمثيلات الميزات أحادية الوسيط للعينة: <span class="math display">\[\mathbf{v}_{fusion} = [\mathbf{v}_{ehr}, \mathbf{v}_{cxr}^*].\]</span> نحدد شبكة دمج متعددة الوسائط <span class="math inline">\(f_{fusion}\)</span> كطبقة LSTM واحدة بمدخل 256 وبُعد مخفي 512، تقوم بتجميع التسلسل متعدد الوسائط عبر التكرار. الدافع لاستخدام LSTM مزدوج: أولاً، يتبع منطق اتخاذ القرار السريري، حيث يقوم الأطباء بفحص كل وسيط على حدة. هذا يسمح لوحدة LSTM بالتعلم أولاً من <span class="math inline">\(\mathbf{v}_{ehr}\)</span> ثم تحديث حالتها الداخلية باستخدام <span class="math inline">\(\mathbf{v}_{cxr}^*\)</span>. ثانيًا، يمكنها التعامل مع تسلسلات مدخلات بعدد متغير من الوسائط، وبالتالي تتعامل تلقائيًا مع الوسائط المفقودة. في حال غياب صورة الأشعة السينية أثناء التدريب أو الاستدلال، تعالج الشبكة تسلسلًا مكونًا من عنصر واحد فقط <span class="math inline">\([\mathbf{v}_{ehr}]\)</span>.</p>
<p>تتم معالجة الحالة المخفية الأخيرة <span class="math inline">\(\textbf{h}_{fusion}\)</span> من <span class="math inline">\(f_{fusion}\)</span> عبر مصنف <span class="math inline">\(g_{fusion}\)</span> لحساب التنبؤات النهائية: <span class="math inline">\(\mathbf{\hat{y}}_{fusion}=g_{fusion}(\mathbf{h}_{fusion})\)</span>. نقوم بتدريب المشفّرات <span class="math inline">\(f_{ehr}\)</span> و<span class="math inline">\(f_{cxr}\)</span> وطبقة الإسقاط <span class="math inline">\(\phi\)</span> ووحدة الدمج <span class="math inline">\(f_{fusion}\)</span> والمصنف <span class="math inline">\(g_{fusion}\)</span> معًا عبر تحسين دالة الخسارة التالية: <span class="math display">\[\mathbb{L}_{fusion}(\mathbf{y}_{fusion}, \mathbf{\hat{y}}_{fusion}) = BCE(\mathbf{y}_{fusion}, \mathbf{\hat{y}}_{fusion}),\]</span> حيث <span class="math inline">\(\textbf{y}_{fusion}=\textbf{y}_{ehr}\)</span>، إذ نفترض أن البيانات الزمنية السريرية هي الوسيط الأساسي المرتبط بمهمة التنبؤ، وهي متوفرة دائمًا أثناء التدريب والاستدلال. جميع المصنفات <span class="math inline">\(g_{ehr}\)</span> و<span class="math inline">\(g_{cxr}\)</span> و<span class="math inline">\(g_{fusion}\)</span> تتكون من طبقة خطية واحدة متبوعة بتفعيل سيجمويد.</p>
</section>
</section>
<section id="sec:exp" class="level1">
<h1>التجارب</h1>
<section id="datasets-and-benchmark-tasks" class="level2">
<h2>مجموعات البيانات والمهام المعيارية</h2>
<p>في تجاربنا، استخرجنا البيانات الزمنية السريرية من MIMIC-IV <span class="citation" data-cites="mimic4"></span> مع صور الأشعة السينية للصدر المرتبطة بها من MIMIC-CXR <span class="citation" data-cites="mimiccxrjpg"></span>. نوضح هنا المهمتين ونقدم تفاصيل إضافية:</p>
<ul>
<li><p><strong>تصنيف الأنماط المرضية:</strong> الهدف من هذه المهمة متعددة العلامات هو التنبؤ بما إذا كان قد تم تشخيص 25 حالة مرضية مزمنة أو مختلطة أو حادة للمريض خلال إقامته في وحدة العناية المركزة. لكل عينة، تحتوي <span class="math inline">\(\mathbf{x}_{ehr}\)</span> على بيانات زمنية سريرية تم جمعها خلال كامل فترة الإقامة، و<span class="math inline">\(\mathbf{y}_{ehr}\)</span> هي متجه ثنائي من 25 علامة. نربط كل عينة بآخر صورة أشعة سينية تم جمعها خلال نفس الإقامة. تحتوي MIMIC-III على رموز ICD-9، بينما تحتوي MIMIC-IV على رموز ICD-9 وICD-10. في الورقة المعيارية الأصلية <span class="citation" data-cites="benchhmark"></span>، تم تعريف العلامات الـ25 باستخدام برنامج التصنيف السريري لـICD-9 <span class="citation" data-cites="ccs_9"></span>. قمنا بتحويل جميع رموز ICD-10 إلى ICD-9 وفقًا لإرشادات مراكز الرعاية الطبية والخدمات الطبية<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>، ثم ربطناها بفئات CCS. نقيم هذه المهمة باستخدام منحنى المساحة تحت منحنى الاستقبال (AUROC) ومنحنى المساحة تحت منحنى الاسترجاع (AUPRC).</p></li>
<li><p><strong>تنبؤ الوفيات داخل المستشفى:</strong> الهدف من هذه المهمة الثنائية هو التنبؤ بحدوث الوفاة داخل المستشفى بعد أول 48 ساعة في وحدة العناية المركزة. لكل عينة، تحتوي <span class="math inline">\(\mathbf{x}_{ehr}\)</span> على بيانات زمنية سريرية تم جمعها خلال أول 48 ساعة، و<span class="math inline">\(\mathbf{y}_{ehr}\)</span> هي علامة ثنائية تشير إلى الوفاة. نستبعد الإقامات التي تقل عن 48 ساعة. نربط كل عينة بآخر صورة أشعة سينية تم جمعها خلال الإقامة. نقيم هذه المهمة باستخدام AUROC وAUPRC.</p></li>
</ul>
<section id="pre-processing-of-clinical-time-series-data"
class="level3">
<h3>معالجة البيانات الزمنية السريرية</h3>
<p>قمنا بتعديل خط أنابيب استخراج البيانات ومعالجتها <span class="citation" data-cites="benchhmark"></span>، الذي كان مطبقًا أصلاً في TensorFlow <span class="citation" data-cites="tensorflow2015"></span>، وقدمنا نسخة جديدة لـMIMIC-IV باستخدام Pytorch <span class="citation" data-cites="NEURIPS2019_9015"></span>. لضمان المقارنة العادلة وإبراز فعالية التعلم متعدد الوسائط، استخدمنا نفس مجموعة المتغيرات السريرية البالغ عددها 17. من بينها خمسة متغيرات فئوية (معدل إعادة تعبئة الشعيرات الدموية، مقياس غلاسكو لفتح العين، الاستجابة الحركية، الاستجابة اللفظية، والمجموع الكلي)، و12 متغيرًا مستمرًا (ضغط الدم الانبساطي، نسبة الأكسجين المستنشق، الجلوكوز، معدل ضربات القلب، الطول، ضغط الدم المتوسط، تشبع الأكسجين، معدل التنفس، ضغط الدم الانقباضي، درجة الحرارة، الوزن، وpH). لجميع المهام، قمنا بأخذ عينات منتظمة كل ساعتين، وتقطيع وتوحيد المتغيرات السريرية للحصول على مدخلات <span class="math inline">\(f_{ehr}\)</span> كما في الأعمال السابقة <span class="citation" data-cites="benchhmark"></span>. بعد المعالجة والترميز الأحادي للميزات الفئوية، نحصل على تمثيل متجه بحجم 76 في كل خطوة زمنية، بحيث <span class="math inline">\(\mathbf{x}_{ehr}\in\mathbb{R}^{t\times76}\)</span> و<span class="math inline">\(t\)</span> يعتمد على العينة والمهمة.</p>
</section>
<section id="data-splits" class="level3">
<h3>تقسيمات البيانات</h3>
<p>باستخدام معرف المريض للبيانات الزمنية السريرية، قمنا بتقسيم البيانات عشوائيًا إلى 70% للتدريب، 10% للتحقق، و20% للاختبار، كما هو موضح في الشكل <a href="#fig:overview-of-work" data-reference-type="ref" data-reference="fig:overview-of-work">1</a>. نبلغ عن النتائج النهائية على مجموعات الاختبار ونحسب فترات الثقة 95% عبر طريقة bootstrap مع 1000 تكرار <span class="citation" data-cites="efron1994introduction"></span>. نرمز للبيانات الزمنية السريرية بـ<span class="math inline">\(\mathbf{EHR}\)</span> ولصور الأشعة السينية بـ<span class="math inline">\(\mathbf{CXR}\)</span>. <span class="math inline">\((\mathbf{EHR}+\mathbf{CXR})_\mathbf{PARTIAL}\)</span> تحتوي على عينات مقترنة وجزئياً مقترنة (أي عينات تفتقد صورة الأشعة السينية). <span class="math inline">\((\mathbf{EHR}+\mathbf{CXR})_\mathbf{PAIRED}\)</span> تحتوي فقط على العينات التي تتوفر فيها الوسيطتان. على سبيل المثال، مجموعة التدريب <span class="math inline">\((\mathbf{EHR}+\mathbf{CXR})_\mathbf{PARTIAL}\)</span> لمهمة تصنيف الأنماط المرضية تحتوي على 7756 عينة مرتبطة بصور أشعة سينية من أصل 42628 عينة.</p>
<p>استخرجنا من MIMIC-CXR صور الأشعة السينية وقسمناها بناءً على تقسيم عشوائي للمرضى. ثم نقلنا الصور من مجموعة التدريب إلى التحقق أو الاختبار إذا كانت مرتبطة بمرضى في تلك المجموعات. نتج عن ذلك 325188 صورة في التدريب، 15282 في التحقق، و36625 في الاختبار. نعرّف <span class="math inline">\(\mathbf{y}_{cxr}\)</span> كمتجه من 14 علامة ثنائية مستخرجة من تقارير الأشعة عبر CheXpert <span class="citation" data-cites="irvin2019chexpert"></span>. نرمز لهذه المجموعة أحادية الوسيط بـ<span class="math inline">\(\mathbf{CXR}_{\mathbf{UNI}}\)</span> وهي ثابتة عبر جميع المهام. نستخدم أيضًا <span class="math inline">\(\mathbf{CXR}_{\mathbf{PAIRED}}\)</span> التي تشمل فقط الصور ضمن <span class="math inline">\((\mathbf{EHR}+\mathbf{CXR})_\mathbf{PAIRED}\)</span>، و<span class="math inline">\(\mathbf{EHR}_{\mathbf{PARTIAL}}\)</span> التي تشمل فقط البيانات الزمنية ضمن <span class="math inline">\((\mathbf{EHR}+\mathbf{CXR})_\mathbf{PARTIAL}\)</span>.</p>
</section>
</section>
<section id="training-strategy-with-the-medfuse-module" class="level2">
<h2>استراتيجية التدريب مع وحدة <code>MedFuse</code></h2>
<p>تتكون استراتيجية التدريب من خطوتين: تدريب مسبق لمشفّرات الوسائط، ثم تحسين مشترك للمشفّرات ووحدة الدمج. أثناء التدريب المسبق، ندرب مشفّر الصور باستخدام مجموعة التدريب أحادية الوسيط <span class="math inline">\(\mathbf{CXR}_{\mathbf{UNI}}\)</span> مع العلامات الشعاعية الـ14. كما ندرب مشفّر البيانات الزمنية السريرية لكل مهمة بشكل مستقل باستخدام <span class="math inline">\(\mathbf{EHR}_{\mathbf{PARTIAL}}\)</span>، حيث أن لكل مهمة مدخلاتها وعلاماتها الخاصة. بعد التدريب المسبق، نستبعد المصنفات أحادية الوسيط ونحسن المشفّرات وطبقة الإسقاط و<code>MedFuse</code> باستخدام <span class="math inline">\((\mathbf{EHR+CXR})_{\mathbf{PARTIAL}}\)</span>. نقارن هذه الاستراتيجية مع تحسين وحدة الدمج مع مستخلصات ميزات عشوائية التهيئة.</p>
<figure>
<embed src="mlhc-submission-files 2022/figures/early_joint.pdf"
id="fig:baselines" style="width:100.0%" />
<figcaption aria-hidden="true"><strong>بنية نماذج الدمج المبكر والمشترك.</strong> في الدمج المبكر (يسار)، يتم تدريب المشفّرات مسبقًا ثم تثبيتها وتحسين طبقة الإسقاط ووحدة التصنيف. في الدمج المشترك (يمين)، يتم تهيئة المشفّرات ووحدة التصنيف عشوائيًا وتدريبها من البداية.</figcaption>
</figure>
</section>
<section id="baseline-models" class="level2">
<h2>النماذج الأساسية</h2>
<p>نقارن أداء نهجنا متعدد الوسائط المقترح مع عدة نماذج أساسية:</p>
<ul>
<li><p><strong>الدمج المبكر:</strong> يعتمد الدمج المبكر التقليدي المستخدم في الأعمال الحديثة <span class="citation" data-cites="Huang2020_survey"></span> (انظر الشكل <a href="#fig:baselines" data-reference-type="ref" data-reference="fig:baselines">2</a> (يسار)) على توفر بيانات مقترنة أثناء التدريب والاستدلال. ندرب نسختين: في الأولى، ندرب الشبكات الخاصة بكل وسيط بشكل مستقل: <span class="math inline">\(f_{cxr}\)</span> و<span class="math inline">\(g_{cxr}\)</span> مع <span class="math inline">\(\mathbf{CXR}_\mathbf{PAIRED}\)</span>، و<span class="math inline">\(f_{ehr}\)</span> و<span class="math inline">\(g_{ehr}\)</span> مع <span class="math inline">\(\mathbf{EHR}_\mathbf{PAIRED}\)</span>. ثم نثبت المشفّرات، ندمج تمثيلاتهما الكامنة، ونحسن طبقة إسقاط وشبكة تصنيف باستخدام <span class="math inline">\((\mathbf{EHR}+\mathbf{CXR})_\mathbf{PAIRED}\)</span>. في النسخة الثانية، نستخدم <span class="math inline">\((\mathbf{EHR}+\mathbf{CXR})_\mathbf{PARTIAL}\)</span> للتحسين، ونستبدل الوسيط المفقود بمتجه قابل للتعلم كما في <span class="citation" data-cites="kyono2021miracle"></span>.</p></li>
<li><p><strong>الدمج المشترك:</strong> في هذا الإعداد، ندرب شبكة من البداية تشمل المشفّرات الخاصة بكل وسيط وشبكة تصنيف تطبق على التمثيلات المدمجة (انظر الشكل <a href="#fig:baselines" data-reference-type="ref" data-reference="fig:baselines">2</a> (يمين)). ندرب نسختين: الأولى باستخدام <span class="math inline">\((\mathbf{EHR}+\mathbf{CXR})_\mathbf{PAIRED}\)</span>، والثانية باستخدام <span class="math inline">\((\mathbf{EHR}+\mathbf{CXR})_\mathbf{PARTIAL}\)</span> مع متجه قابل للتعلم للوسيط المفقود.</p></li>
<li><p><strong>وحدة النقل متعددة الوسائط (MMTM):</strong> تم اقتراحها في <span class="citation" data-cites="vaezi20mmtm"></span> وتفترض بيانات مقترنة. نطبق وحدة MMTM بعد أول طبقة LSTM في البيانات الزمنية، وبعد الطبقة الثالثة أو الرابعة في ResNet. ندرب الشبكة من البداية باستخدام <span class="math inline">\((\mathbf{EHR}+\mathbf{CXR})_\mathbf{PAIRED}\)</span> ونتبع استراتيجية التدريب الأصلية.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p></li>
<li><p><strong>تحويل الخريطة المميزة الديناميكي (DAFT):</strong> يتطلب أيضًا بيانات مقترنة، ويستخدم وحدة DAFT <span class="citation" data-cites="daft"></span> لإعادة تحجيم وتحويل التمثيلات بعد أول طبقة LSTM باستخدام تمثيل الأشعة السينية المحسوب من ResNet. ندرب باستخدام <span class="math inline">\((\mathbf{EHR}+\mathbf{CXR})_\mathbf{PAIRED}\)</span> ونتبع استراتيجية التدريب الأصلية.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p></li>
</ul>
<p>نقارن أيضًا مع شبكة LSTM ثنائية الطبقات مدربة فقط على البيانات الزمنية السريرية، ومع طريقة <span class="citation" data-cites="hayat2021dynamic"></span> (Unified) المدربة باستخدام <span class="math inline">\((\mathbf{EHR}+\mathbf{CXR})_\mathbf{PARTIAL}\)</span>.</p>
<div class="table*">
<p><span id="tab:univsmulti" label="tab:univsmulti"></span></p>
</div>
</section>
<section id="model-training-and-selection" class="level2">
<h2>تدريب النماذج واختيارها</h2>
<p>قمنا بضبط القيم الفائقة عبر 10 تكرارات لكل نموذج من النماذج المقترحة والأساسية. في كل تكرار، نختار معدل تعلم عشوائيًا بين <span class="math inline">\(10^{-5}\)</span> و<span class="math inline">\(10^{-3}\)</span>، ثم نختار النموذج ومعدل التعلم الذي يحقق أفضل AUROC على مجموعة التحقق. بالنسبة للنماذج ذات الخيارات المعمارية (MMTM وDAFT)، نختار البنية التي تحقق أفضل أداء على التحقق ونبلغ عن نتائجها على الاختبار. استخدمنا خوارزمية Adam <span class="citation" data-cites="kingma2014adam"></span> في جميع التجارب بحجم دفعة 16. حددنا الحد الأقصى لعدد العصور بـ50 واستخدمنا الإيقاف المبكر إذا لم يتحسن AUROC للتحقق خلال 15 عصرًا. طبقنا أيضًا تحسينات الصور كما هو موضح في الملحق <a href="#image-aug" data-reference-type="ref" data-reference="image-aug">7.1</a>.</p>
<p>مع أفضل معدل تعلم تم اختياره، قمنا بتغيير نسبة العينات أحادية الوسيط في مجموعة التدريب <span class="math inline">\((\mathbf{EHR+CXR})_{\mathbf{PARTIAL}}\)</span>، وحسّنا <code>MedFuse</code> وفقًا لذلك وقيّمناه على مجموعة التحقق. اخترنا أفضل نموذج بناءً على أفضل أداء AUROC على مجموعة التحقق <span class="math inline">\((\mathbf{EHR+CXR})_{\mathbf{PARTIAL}}\)</span>، وبلغنا عن نتائجه على مجموعة الاختبار. نرمز لهذا النموذج بـ<code>MedFuse</code> (OPTIMAL).</p>
<div class="table*">
<p><span id="tab:paired_res" label="tab:paired_res"></span></p>
</div>
</section>
</section>
<section id="sec:res" class="level1">
<h1>النتائج</h1>
<p>في هذا القسم، نعرض نتائج عدة تجارب لتوضيح فعالية النهج المقترح. تم تلخيص معدلات التعلم التي حققت أفضل النتائج في الملحق <a href="#hyperparameter" data-reference-type="ref" data-reference="hyperparameter">7.2</a> لجميع النماذج. تظهر نتائج التحقق عند تغيير نسبة العينات أحادية الوسيط أثناء التدريب في الملحق <a href="#unimodalpercentagetraining" data-reference-type="ref" data-reference="unimodalpercentagetraining">7.3</a>. النسب المثلى هي 10% لتنبؤ الوفيات و20% لتصنيف الأنماط المرضية.</p>
<section id="performance-results-in-the-uni-modal-multi-modal-settings"
class="level2">
<h2>نتائج الأداء في الإعدادات أحادية ومتعددة الوسائط</h2>
<p>في الجدول <a href="#tab:univsmulti" data-reference-type="ref" data-reference="tab:univsmulti">[tab:univsmulti]</a>، نقارن النهج المقترح مع LSTM أحادي الوسيط. كما هو متوقع، نلاحظ أولاً أن أداء LSTM أحادي الوسيط يتحسن على مجموعة اختبار <span class="math inline">\(\mathbf{EHR}_{\mathbf{PAIRED}}\)</span> من حيث AUROC وAUPRC لكلا المهمتين عند استخدام مجموعة التدريب الأكبر <span class="math inline">\(\mathbf{EHR}_{\mathbf{PARTIAL}}\)</span>. يحقق النهج المقترح باستخدام <code>MedFuse</code> أفضل أداء على مجموعة الاختبار المقترنة عند استخدام صور الأشعة السينية كوسيط مساعد أثناء التدريب والاستدلال (0.770 AUROC و0.481 AUPRC لتصنيف الأنماط المرضية، و0.865 AUROC و0.594 AUPRC لتنبؤ الوفيات). نلاحظ اتجاهات مشابهة ولكن أقل وضوحًا في مجموعة الاختبار الأكبر المقترنة جزئيًا، ربما بسبب أن 18.8% و26.2% فقط من العينات مقترنة في مجموعات اختبار التصنيف وتنبؤ الوفيات على التوالي.</p>
</section>
<section id="performance-results-in-the-paired-setting" class="level2">
<h2>نتائج الأداء في الإعداد المقترن</h2>
<p>نظرًا لأن النماذج الأساسية صممت أصلاً للمدخلات المقترنة، قمنا بتقييم جميع النماذج على مجموعة اختبار (<span class="math inline">\(\mathbf{EHR+CXR})_{\mathbf{PAIRED}}\)</span> كما هو موضح في الجدول <a href="#tab:paired_res" data-reference-type="ref" data-reference="tab:paired_res">[tab:paired_res]</a>. أولاً، نلاحظ أن الدمج المبكر والمشترك يقدمان أداءً متقاربًا في كلا المهمتين عند التدريب على (<span class="math inline">\(\mathbf{EHR+CXR})_{\mathbf{PAIRED}}\)</span>، مع تفوق طفيف للدمج المبكر في AUROC. كما نلاحظ أن تدريب الدمج المبكر باستخدام (<span class="math inline">\(\mathbf{EHR+CXR})_{\mathbf{PARTIAL}}\)</span> يؤدي إلى انخفاض في AUROC وAUPRC في كلا المهمتين، بينما يتحسن الدمج المشترك فقط في التصنيف. ثانيًا، نلاحظ أن نهج Unified <span class="citation" data-cites="hayat2021dynamic"></span> يحقق أفضل أداء بين النماذج الأساسية (0.765 AUROC و0.461 AUPRC للتصنيف، و0.835 AUROC و0.495 AUPRC لتنبؤ الوفيات). ثالثًا، يحقق النهج المقترح <code>MedFuse</code> (OPTIMAL) أفضل أداء في كلا المهمتين (0.770 AUROC و0.481 AUPRC للتصنيف، و0.865 AUROC و0.594 AUPRC لتنبؤ الوفيات). أجرينا أيضًا دراسة حذف عشوائي للوسيط الشعاعي في مجموعة الاختبار المقترنة، والنتائج في الملحق <a href="#unimodalpercPAIRED" data-reference-type="ref" data-reference="unimodalpercPAIRED">7.4</a>. كما قارنا بين استبدال الوسيط المفقود بأصفار أو متجه قابل للتعلم في الدمج المبكر والمشترك، والنتائج في الملحق <a href="#missingtoken" data-reference-type="ref" data-reference="missingtoken">7.5</a>. كلا الطريقتين تقدمان أداءً متقاربًا.</p>
<div class="table*">
<p><span id="tab:partialresults" label="tab:partialresults"></span></p>
</div>
<p><embed src="figures/bar_aurocs.pdf" /> <embed
src="figures/bar_auprcs.pdf" /></p>
</section>
<section id="performance-results-in-the-partially-paired-setting"
class="level2">
<h2>نتائج الأداء في الإعداد المقترن جزئياً</h2>
<p>في الجدول <a href="#tab:partialresults" data-reference-type="ref" data-reference="tab:partialresults">[tab:partialresults]</a>، نقيم النهج المقترح <code>MedFuse</code> بالإضافة إلى الدمج المبكر والمشترك على مجموعة الاختبار المقترنة جزئيًا. بالمقارنة مع الدمج المبكر، يحقق النهج المقترح أداءً أفضل في تصنيف الأنماط المرضية (0.758 مقابل 0.748 AUROC و0.418 مقابل 0.394 AUPRC). ويقدم أداءً مقاربًا في تنبؤ الوفيات، رغم تفوق الدمج المبكر في AUPRC. يتفوق نهجنا على الدمج المشترك في تنبؤ الوفيات (0.861 مقابل 0.841 AUROC و0.501 مقابل 0.482 AUPRC)، ويقدم أداءً مقاربًا في التصنيف. بشكل عام، يحقق <code>MedFuse</code> (OPTIMAL) المدرب مع عينات مقترنة و10% فقط من العينات أحادية الوسيط لتنبؤ الوفيات و20% للتصنيف أفضل أداء (0.768 AUROC و0.429 AUPRC للتصنيف، و0.874 AUROC و0.567 AUPRC لتنبؤ الوفيات). أجرينا أيضًا دراسة حذف عشوائي لنسبة العينات أحادية الوسيط في الإعداد المقترن جزئيًا، والنتائج في الملحق <a href="#unimodalpercPARTIAL" data-reference-type="ref" data-reference="unimodalpercPARTIAL">7.6</a>.</p>
<p>كما قارنا أداء <code>MedFuse</code> مع تجميع من نموذجين: (1) <code>MedFuse</code> للعينات المقترنة، و(2) LSTM أحادي الوسيط للعينات التي تفتقد الأشعة السينية. النتائج متقاربة، كما هو موضح في الملحق <a href="#ensemble" data-reference-type="ref" data-reference="ensemble">7.7</a>، مما يشير إلى أن تجميع نماذج قوية قد يكون أفضل لبعض المهام مثل التصنيف، لكنه يتطلب تدريب نموذجين.</p>
<div class="table*">
<p><span id="tab:phenotype_wise" label="tab:phenotype_wise"></span></p>
</div>
<div class="table*">
<p><span id="tab:age_analysis" label="tab:age_analysis"></span></p>
</div>
</section>
<section id="phenotype-wise-analysis" class="level2">
<h2>تحليل حسب الأنماط المرضية</h2>
<p>في الشكل <a href="#fig:types_bar" data-reference-type="ref" data-reference="fig:types_bar">[fig:types_bar]</a>، نعرض نتائج AUROC (يسار) وAUPRC (يمين) عبر فئات الأنماط المرضية: الحادة، المختلطة، والمزمنة. أنواع العلامات وانتشارها موضحة في الجدول <a href="#tab:phenotype_wise" data-reference-type="ref" data-reference="tab:phenotype_wise">[tab:phenotype_wise]</a>. نلاحظ أن نهجنا يحسن الأداء بشكل ملحوظ في الحالات المختلطة والمزمنة، والتي يصعب عادة التنبؤ بها عبر البيانات الزمنية فقط <span class="citation" data-cites="benchhmark"></span>. على وجه الخصوص، في الحالات المختلطة، يرتفع AUROC من 0.749 إلى 0.800 وAUPRC من 0.458 إلى 0.565. في الحالات المزمنة، يرتفع AUROC من 0.717 إلى 0.745 وAUPRC من 0.487 إلى 0.512. أما في الحالات الحادة، فالتحسن أقل وضوحًا (AUROC من 0.761 إلى 0.772 وAUPRC من 0.432 إلى 0.433). في الجدول <a href="#tab:phenotype_wise" data-reference-type="ref" data-reference="tab:phenotype_wise">[tab:phenotype_wise]</a>، نبلغ عن الأداء عبر جميع العلامات الـ25 لمجموعة الاختبار المقترنة باستخدام البيانات أحادية ومتعددة الوسائط. نلاحظ تحسنًا في عدة أنماط مرتبطة بالصدر مثل الالتهاب الرئوي والتهاب غشاء الجنب، والتي يتم تقييمها سريريًا غالبًا عبر التصوير الشعاعي <span class="citation" data-cites="long2017emergency"></span>. هذا يبرز أهمية استخدام صور الأشعة السينية كمصدر معلومات إضافي مع البيانات الزمنية السريرية.</p>
</section>
<section id="in-hospital-mortality-age-wise-analysis" class="level2">
<h2>تحليل الوفيات داخل المستشفى حسب الفئة العمرية</h2>
<p>قمنا بتقييم أداء النهج عبر الفئات العمرية المختلفة، كما هو موضح في الجدول <a href="#tab:age_analysis" data-reference-type="ref" data-reference="tab:age_analysis">[tab:age_analysis]</a>، وقارنّاه مع LSTM أحادي الوسيط. نلاحظ أن AUROC وAUPRC يتحسنان في الفئات 40-60، 60-80، وأكثر من 80 عامًا، بينما ينخفض AUROC للفئة 18-40 عامًا. يحتاج هذا الأخير لمزيد من الدراسة مع مجموعة بيانات أكبر، إذ تحتوي مجموعة الاختبار على 11 عينة إيجابية فقط للفئة الأصغر. كما توجد فروق في نسب التحسن، فمثلاً يرتفع AUPRC بنسبة 24% للفئة 40-60 عامًا، مقابل 1.3% للفئة 60-80 عامًا.</p>
</section>
</section>
<section id="discussion" class="level1">
<h1>المناقشة</h1>
<p>في هذا البحث، قدمنا نهج دمج متعدد الوسائط باسم <code>MedFuse</code> ونتائج معيارية جديدة لدمج البيانات الزمنية السريرية وصور الأشعة السينية للصدر المقترنة جزئيًا. قمنا بتقييمه في مهمتين معياريتين شائعتين: تنبؤ الوفيات داخل المستشفى وتصنيف الأنماط المرضية، باستخدام مجموعتي بيانات MIMIC-IV وMIMIC-CXR المتاحتين للجمهور.</p>
<p>لدراستنا عدة نقاط قوة. أولاً، النهج المقترح بسيط وسهل التطبيق. أظهرت النتائج أن النهج يتفوق على LSTM أحادي الوسيط، إذ يستفيد من صور الأشعة السينية كمصدر إضافي عند توفرها. كما يتفوق على عدة نماذج أساسية، ويوفر تحليل الأنماط المرضية والفئات العمرية رؤى حول مواضع التحسن. نستنتج أن الطريقة المقترحة هي الخيار الأفضل لأنها (1) تتعامل تلقائيًا مع البيانات المفقودة (أي العينات المقترنة جزئيًا)، و(2) أن الجمع بين البنية واستراتيجية التدريب يوفر مكاسب في الأداء. لا يبدو أن حجم مجموعة التدريب المقترنة جزئيًا مرتبط بتحسن الأداء، كما هو موضح في نتائج التحقق في الملحق <a href="#unimodalpercentagetraining" data-reference-type="ref" data-reference="unimodalpercentagetraining">7.3</a>. تبرز النتائج بشكل عام إمكانيات الدمج متعدد الوسائط في تحسين أداء النماذج السريرية. كما أن التعلم متعدد الوسائط يتماشى مع عملية اتخاذ القرار السريري، حيث يأخذ الأطباء في الاعتبار مصادر متعددة للمعلومات عند تقييم المريض.</p>
<p>علاوة على ذلك، بخلاف الأساليب التقليدية التي تفترض مدخلات مقترنة، فإن طريقتنا أكثر مرونة إذ يمكنها معالجة العينات التي تفتقد صور الأشعة السينية. هناك اهتمام متزايد بتعلم التفاعلات بين الوسائط أثناء التدريب وإعادة بناء الوسائط المفقودة <span class="citation" data-cites="ngiam2011multimodal 9534148 missing sylvain2021cmim missing"></span>. بخلاف مجموعات البيانات الطبيعية، فإن افتراض وجود ترابط عالٍ بين الوسائط ليس أمرًا بديهيًا في الرعاية الصحية، خاصة عندما لا تشترك الوسائط في نفس العلامات، وهذا مجال للبحث المستقبلي. الصعوبة تنبع من الطبيعة المتفرقة وغير المتزامنة للبيانات الطبية، أي أنه من الصعب استخدام تقرير خزعة جلدية لإعادة بناء ميزات أمراض الصدر <span class="citation" data-cites="hayat2021dynamic"></span>. كما أن بعض الأعمال الحالية تفترض توفر جميع الوسائط أثناء التدريب <span class="citation" data-cites="sylvain2021cmim"></span>.</p>
<p>ميزة أخرى هي أن النهج يمكن توسيعه بسهولة لأكثر من وسيطين دون تعديل دالة الخسارة، بخلاف الأعمال السابقة التي تزداد تعقيدها مع زيادة عدد الوسائط <span class="citation" data-cites="hayat2021dynamic"></span>. إلا أن ذلك يتطلب تقييمًا مستقبليًا. كما لا نفترض أي ترابط بين الوسائط من حيث المعلومات أو العلامات.</p>
<p>بالإضافة إلى ذلك، قدمنا نتائج معيارية جديدة لمهمتين شائعتين غالبًا ما يتم تقييمهما باستخدام البيانات الزمنية فقط <span class="citation" data-cites="benchhmark"></span>. من خلال إتاحة مجموعتي بيانات MIMIC-IV وMIMIC-CXR <span class="citation" data-cites="mimic4 mimiccxrjpg"></span>، يمكن للباحثين الاستفادة من خط أنابيب معالجة البيانات مفتوح المصدر وتقديم نتائج جديدة للمقارنة المباشرة.</p>
<section id="limitations." class="level4">
<h4>القيود</h4>
<p>للدراسة بعض القيود. أولاً، ركزنا على دمج البيانات الزمنية السريرية وصور الأشعة السينية من مصدر واحد، وقيمنا العمل على مهمتين فقط بسبب محدودية الموارد. العمل الأصلي <span class="citation" data-cites="benchhmark"></span> يشمل مهمتين إضافيتين (تنبؤ فك التثبيت وتنبؤ مدة الإقامة)، نخطط لتقييم طريقتنا عليهما مستقبلاً. يجب أيضًا دراسة مهمة تنبؤ الوفيات في سياق استبعاد صور الأشعة السينية المأخوذة بعد أول 48 ساعة. لم نجري تجارب على حالات غياب البيانات الزمنية مع توفر الأشعة السينية، وهذا يتطلب تعريف مهام معيارية جديدة حيث تكون الأشعة السينية هي الوسيط الأساسي. كما أن النموذج الحالي يفتقر للتفسيرية، إذ ركزنا على الدمج فقط. نخطط لاحقًا لإدخال طبقات انتباه <span class="citation" data-cites="vaswani2017attention"></span> على مستوى المدخلات لتقييم أهمية الميزات داخل كل وسيط، وداخل وحدة الدمج لتقييم أهمية كل وسيط. كما يمكن أن يستفيد العمل من تحليل على مستوى العينة، إلا أن ذلك يتطلب خبرة سريرية تربط بين تحليل الصور والبيانات الزمنية، وهو ما نفتقده حاليًا. لتحقيق الاستفادة الكاملة من التعلم متعدد الوسائط، هناك حاجة لمزيد من الفهم للأسس السريرية للدمج. بشكل عام، تبرز الدراسة أهمية مواصلة استكشاف إمكانيات التعلم متعدد الوسائط في الرعاية الصحية مع تزايد تنوع وكمية البيانات الطبية.</p>
</section>
<section id="acknowledgements." class="level4">
<h4>الشكر والتقدير</h4>
<p>تم دعم هذا العمل جزئيًا من قبل مركز الذكاء الاصطناعي والروبوتات بجامعة نيويورك أبوظبي، الممول من تمكين ضمن جائزة معهد أبحاث جامعة نيويورك أبوظبي CG010. كما نشكر فريق الحوسبة عالية الأداء (HPC) في جامعة نيويورك أبوظبي على دعمهم.</p>
</section>
</section>
<section id="appendix-a" class="level1">
<h1>الملحق</h1>
<section id="image-aug" class="level2">
<h2>تحسينات الصور</h2>
<p>بالنسبة لصور الأشعة السينية، طبقنا سلسلة من التحويلات أثناء التدريب المسبق والتحسين في جميع التجارب. قمنا بتغيير حجم كل صورة إلى <span class="math inline">\(256 \times 256\)</span> بكسل، وتطبيق قلب أفقي عشوائي، وتحويلات عشوائية مثل التدوير والتحجيم والقص والترجمة. ثم أخذنا اقتصاصًا عشوائيًا للحصول على صورة بحجم <span class="math inline">\(224 \times 224\)</span> بكسل. أثناء التحقق والاختبار، قمنا بتغيير الحجم إلى <span class="math inline">\(256 \times 256\)</span> وتطبيق اقتصاص مركزي إلى <span class="math inline">\(224 \times 224\)</span> بكسل.</p>
</section>
<section id="hyperparameter" class="level2">
<h2>نتائج البحث عن القيم الفائقة</h2>
<p>نتائج ضبط القيم الفائقة موضحة في الجدول <a href="#tab:learning_rates" data-reference-type="ref" data-reference="tab:learning_rates">[tab:learning_rates]</a>. نلخص معدلات التعلم التي حققت أفضل أداء لكل نموذج.</p>
<p><span id="tab:learning_rates" label="tab:learning_rates"></span></p>
</section>
<section id="unimodalpercentagetraining" class="level2">
<h2>نسبة العينات أحادية الوسيط ضمن مجموعة التدريب</h2>
<p>أجرينا تجارب بتغيير نسبة العينات أحادية الوسيط أثناء التحسين. أفضل نتائج AUROC لكلا المهمتين على مجموعة التحقق موضحة في الشكل <a href="#fig:data_ratio" data-reference-type="ref" data-reference="fig:data_ratio">3</a>. بالنسبة لتنبؤ الوفيات (بالأحمر)، نلاحظ أن نسبة صغيرة (10%) تحقق أفضل أداء. بالنسبة للتصنيف (بالأزرق)، نلاحظ اتجاهًا مشابهًا حيث تحقق أفضل AUROC عند 20%. نثبت النسبة التي تحقق أفضل AUROC في جميع التجارب، ما لم يُذكر خلاف ذلك. هذا يبرز أن أفضل مكاسب <code>MedFuse</code> تتحقق حتى مع نسبة صغيرة من العينات أحادية الوسيط.</p>
<figure>
<embed src="figures/aurocs.pdf" id="fig:data_ratio" />
<figcaption aria-hidden="true"><strong>الأداء على مجموعة التحقق عند تغيير نسبة العينات أحادية الوسيط.</strong> يوضح الرسم منحنى AUROC لمجموعة التحقق لنسب مختلفة من العينات أحادية الوسيط.</figcaption>
</figure>
</section>
<section id="unimodalpercPAIRED" class="level2">
<h2>نسبة العينات أحادية الوسيط ضمن مجموعة الاختبار المقترنة</h2>
<p>أجرينا دراسة حذف عشوائي للوسيط الشعاعي في مجموعة الاختبار المقترنة. النتائج في الشكل <a href="#fig:data_ratio_paired" data-reference-type="ref" data-reference="fig:data_ratio_paired">4</a>. نلاحظ أنه مع زيادة نسبة الحذف، ينخفض AUROC في كلا المهمتين.</p>
<figure>
<embed src="figures/aurocs_paired_ratio.pdf"
id="fig:data_ratio_paired" />
<figcaption aria-hidden="true"><strong>الأداء على مجموعة الاختبار عند حذف وسيط CXR عشوائيًا.</strong> يوضح الرسم منحنى AUROC لمجموعة الاختبار المقترنة لنسب مختلفة من حذف وسيط CXR.</figcaption>
</figure>
</section>
<section id="missingtoken" class="level2">
<h2>الوسيط المفقود مع الدمج المبكر والمشترك</h2>
<p>أجرينا تجارب أولية لمقارنة المتجه القابل للتعلم مع تعويض الأصفار للوسيط المفقود. النتائج في الجدول <a href="#tab:missing-modality" data-reference-type="ref" data-reference="tab:missing-modality">[tab:missing-modality]</a>. نلاحظ أن النتائج متقاربة دون فروق واضحة.</p>
<div class="table*">
<p><span id="tab:missing-modality"
label="tab:missing-modality"></span></p>
</div>
</section>
<section id="unimodalpercPARTIAL" class="level2">
<h2>نسبة العينات أحادية الوسيط ضمن مجموعة الاختبار المقترنة جزئياً</h2>
<p>أجرينا دراسة حذف عشوائي لنسبة العينات أحادية الوسيط في مجموعة الاختبار المقترنة جزئيًا. النتائج في الشكل <a href="#fig:data_ratio_pairtial_testset" data-reference-type="ref" data-reference="fig:data_ratio_pairtial_testset">5</a>. عند تضمين 0% من العينات أحادية الوسيط، يكون ذلك مكافئًا لمجموعة الاختبار المقترنة بالكامل. نلاحظ زيادة في AUROC في مهمة تنبؤ الوفيات مع زيادة النسبة، بينما يبقى AUROC أكثر استقرارًا في التصنيف. كما نلاحظ أن عرض فترات الثقة ينخفض مع زيادة النسبة في كلا المهمتين.</p>
<figure>
<embed src="figures/aurocs_nonpaired_ratio.pdf"
id="fig:data_ratio_pairtial_testset" />
<figcaption aria-hidden="true"><strong>الأداء على مجموعة الاختبار عند تغيير نسبة العينات أحادية الوسيط.</strong> يوضح الرسم منحنى AUROC لمجموعة الاختبار الجزئية لنسب مختلفة من العينات أحادية الوسيط.</figcaption>
</figure>
</section>
<section id="ensemble" class="level2">
<h2>تجميع النماذج أحادية ومتعددة الوسائط</h2>
<p>أجرينا تجربة لمقارنة أداء <code>MedFuse</code> مع تجميع من نموذجين: نموذج EHR فقط للعينات غير المرتبطة بصورة أشعة سينية باستخدام LSTM، ونموذج مقترن للعينات المقترنة باستخدام <code>MedFuse</code>. النتائج في الجدول <a href="#tab:medfuse_unimodal" data-reference-type="ref" data-reference="tab:medfuse_unimodal">[tab:medfuse_unimodal]</a>. نلاحظ أن التجميع يتفوق قليلاً على <code>MedFuse</code> في التصنيف فقط، ما يشير إلى أن تجميع نماذج قوية قد يكون أفضل لبعض المهام مثل التصنيف، لكنه يتطلب تدريب نموذجين.</p>
<div class="table*">
<p><span id="tab:medfuse_unimodal"
label="tab:medfuse_unimodal"></span></p>
</div>
</section>
</section>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>يعمل حالياً في G42 للرعاية الصحية.<a
href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>مراكز الرعاية الطبية والخدمات الطبية، <a
href="https://www.cms.gov/Medicare/Coding/ICD10/2018-ICD-10-CM-and-GEMs"
class="uri">https://www.cms.gov/Medicare/Coding/ICD10/2018-ICD-10-CM-and-GEMs</a><a
href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>https://github.com/haamoon/mmtm<a
href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>https://github.com/ai-med/DAFT/<a
href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
    </div>
    <hr style="margin: 40px 0;">
    <div class="text-muted text-center">
        <small>
            تم تحويل هذا الإصدار من LaTeX إلى HTML تلقائيًا.<br>
            تم عرض المعادلات الرياضية باستخدام MathJax.
        </small>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>
