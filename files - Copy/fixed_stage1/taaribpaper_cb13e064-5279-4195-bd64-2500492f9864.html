<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Erlend Frayling">
  <meta name="author" content="Jake Lever">
  <meta name="author" content="Graham McDonald">
  <title>استراتيجيات التوليد بدون أمثلة وبأمثلة قليلة للسجلات الطبية الاصطناعية</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>body { direction: rtl; font-size: 22px; }</style>
</head>
<body>
<header>
<h1 class="title">استراتيجيات التوليد بدون أمثلة وبأمثلة قليلة للسجلات الطبية الاصطناعية</h1>
<p class="author"><span class="nodecor">Erlend Frayling</span></p>
<p class="author"><span class="nodecor">Jake Lever</span></p>
<p class="author"><span class="nodecor">Graham McDonald</span></p>
</header>
<h1 id="ملخص">مُلخّص</h1>
<p>تُعد تحديات الوصول إلى بيانات المرضى التاريخية للبحث السريري، مع الالتزام بلوائح الخصوصية، عقبة كبيرة في العلوم الطبية. يتمثل أحد النهج المبتكرة للتغلب على هذه المشكلة في استخدام السجلات الطبية الاصطناعية التي تعكس بيانات المرضى الحقيقية دون المساس بخصوصية الأفراد. يوفر إنشاء هذه المجموعات البيانية الاصطناعية، وخاصة دون استخدام بيانات المرضى الفعلية لتدريب النماذج اللغوية الكبيرة، حلاً جديدًا نظرًا لأن الحصول على معلومات المرضى الحساسة لتدريب النماذج يُعد تحديًا أيضًا. تقيم هذه الدراسة قدرة نموذج اللغة الكبير <span class="nodecor">Llama 2</span> على إنشاء سجلات طبية اصطناعية تعكس بدقة معلومات المرضى الحقيقيين، باستخدام استراتيجيات التوجيه بدون أمثلة وبأمثلة قليلة للمقارنة مع منهجيات التدريب المعتمدة على بيانات المرضى الحساسة. نركز على توليد السرديات الاصطناعية لقسم تاريخ الحالة المرضية الحالي، باستخدام بيانات من مجموعة <span class="nodecor">MIMIC-IV</span> للمقارنة. في هذا العمل، نقدم تقنية توجيه جديدة تستفيد من نهج سلسلة الأفكار، مما يعزز قدرة النموذج على توليد سرديات طبية أكثر دقة وملاءمة سياقية دون تدريب مسبق. تشير نتائجنا إلى أن هذا النهج الموجه بسلسلة الأفكار يتيح للنموذج بدون أمثلة تحقيق نتائج تضاهي تلك الخاصة بالنماذج المدربة، استنادًا إلى تقييم مقاييس <span class="nodecor">Rouge</span>.</p>
<h1 id="sec: introduction">مُقدّمة</h1>
<p><span class="nodecor">Clinical research</span> أمر ضروري لتحسين فهم الأمراض، وتطوير علاجات جديدة وأكثر فعالية، وتحسين رعاية المرضى. الوصول إلى السجلات الطبية السريرية، مثل ملاحظات خروج المستشفى والسجلات الصحية الإلكترونية (<span class="nodecor">EHRs</span>) (<span class="nodecor">hoerbst2010electronic, coorevits2013electronic</span>) يمكن أن يساعد هذا البحث في تحديد أنماط الأعراض وآثار الأدوية الجانبية. الحصول على هذه السجلات يمثل تحديًا، بسبب المعلومات الشخصية الحساسة التي تحتوي عليها (<span class="nodecor">nurmi2019privacy</span>). هذه التحديات تبطئ في نهاية المطاف تقدم الاكتشافات الطبية الجديدة التي (<span class="nodecor">could benefit patient health</span>) (<span class="nodecor">cowie2017electronic</span>).</p>
<p><span class="nodecor">Developing approaches that can</span> تخفيف مخاوف الخصوصية في مجال البحث السريري أمر مرغوب فيه لتمكين وصول أسهل إلى <span class="nodecor">EHRs</span> بحيث يمكن إجراء البحوث بحرية أكبر، مما يؤدي إلى اكتشافات أسرع في المجالات الصحية. أحد النهج التي يمكن أن تخفف التحديات الناشئة عن المعلومات الحساسة للمرضى هو توليد سجلات مرضى اصطناعية لها نفس التوزيع الإحصائي للمصطلحات كما في السجلات الطبية الحقيقية ولكنها، في الواقع، مزيفة. يمكن بعد ذلك استخدام هذه السجلات الطبية الاصطناعية كبديل لـ <span class="nodecor">EHRs</span> الحقيقية حيث تمنع حواجز خصوصية المرضى الوصول إلى البيانات الحقيقية (<span class="nodecor">iveSynthetic</span>).</p>
<p>تم استكشاف عدة أعمال لتوليد نص <span class="nodecor">EHR</span> اصطناعي باستخدام <span class="nodecor">Large Language Models</span> المعتمدة على المحولات (<span class="nodecor">LLMs</span>)، على سبيل المثال (<span class="nodecor">melamudTowards,iveGeneration</span>). على وجه الخصوص، أظهرت الأعمال التي قام بها <span class="nodecor">Ive <span class="nodecor">et al</span>.</span> (<span class="nodecor">iveGeneration</span>) أن النص السريري الاصطناعي يمكن استخدامه لزيادة بيانات <span class="nodecor">EHR</span> الحقيقية وتحسين فعالية <span class="nodecor">LLMs</span> في المهام اللاحقة (<span class="nodecor">iveSynthetic</span>). <span class="nodecor">However, to prepare these models to produce synthetic EHRs, they first need to be trained on real EHR data, which brings us back to the initial issue of accessing private EHR information.</span></p>
<p>أكثر <span class="nodecor">recently, a number of LLMs, that are pre-trained using large volumes of data and that leverage prompt inputs to discern the nature of the generative task, e.g.</span> (<span class="nodecor">brownGpt3, touvronLlama2</span>), قد <span class="nodecor">been</span> أظهرت أنها فعالة <span class="nodecor">for a</span> مجموعة واسعة من المهام. هذه النماذج لا تتطلب التعديل الدقيق. يمكن أن يؤدي استخدام مثل هذه <span class="nodecor">LLMs</span> لتوليد بيانات <span class="nodecor">EHR</span> الاصطناعية إلى إزالة الحاجة إلى جمع بيانات <span class="nodecor">EHR</span> الحقيقية التي يصعب الوصول إليها للتعديل الدقيق.</p>
<p>في هذا العمل، نقيم قدرات <span class="nodecor">Llama 2 LLM</span>، مع مجموعة متنوعة من استراتيجيات التعلم، بما في ذلك التعديل الدقيق، والتعلم بعدد قليل من الأمثلة وإعدادات التعلم بدون أمثلة، لتوليد نص <span class="nodecor">EHR</span> السريري الاصطناعي. على وجه الخصوص، ننشر النماذج التي تم تقييمها لتوليد سرد تاريخ الأمراض الحالي من نص شكوى رئيسية قصير يلخص المشكلة الطبية الرئيسية. نقارن السرد المولّد بـ <span class="nodecor">EHRs</span> الحقيقية من مجموعة بيانات <span class="nodecor">MIMIC-IV</span> (<span class="nodecor">mimicFour</span>). علاوة على ذلك، نقترح استراتيجية توجيه سلسلة الأفكار (<span class="nodecor">CoT</span>) التي يمكن استخدامها لتوجيه <span class="nodecor">LLM</span> في توليد محتوى <span class="nodecor">EHR</span> مع مراعاة الهيكل والمحتوى المحدد لـ <span class="nodecor">EHRs</span>. تظهر تجاربنا أن هذه الطريقة <span class="nodecor">CoT</span> يمكن أن تحسن استراتيجيات التعلم بدون أمثلة وبعدد قليل من الأمثلة مع <span class="nodecor">Llama 2</span> لتكون تنافسية مع نموذج <span class="nodecor">GPT-2</span> المعدل بدقة، وبالتالي تقليل الحاجة إلى الوصول إلى بيانات <span class="nodecor">EHR</span> الحقيقية، التي تحتوي على بيانات حساسة للمرضى، عند إجراء البحوث السريرية.</p>
<h1 id="sec:background">الأعمال ذات الصلة</h1>
<p>تستخدم غالبية الأعمال المتعلقة بتوليد النصوص السريرية هندسة التعلم العميق المبنية على المحولات في مهام نمذجة اللغة السببية مع نماذج اللغة التلقائية العكسية (<span class="nodecor">vaswaniAttention</span>, <span class="nodecor">radford2018Gpt</span>, <span class="nodecor">scholkopf2021toward</span>). اقترح أمين نجاد وآخرون توليد ملخصات خروج المرضى من بيانات سجلات الصحة الإلكترونية المنظمة باستخدام <span class="nodecor">GPT-2</span> (<span class="nodecor">radford2019language</span>) وأظهروا أنه يمكن استخدامها لتدريب نماذج أكثر فعالية للتعرف على الكيانات المسماة (<span class="nodecor">amin2020exploring</span>). بالمثل، أظهر لو وآخرون أن النص السريري الاصطناعي يمكن استخدامه لزيادة مجموعة بيانات التدريب الحقيقية لسجلات الصحة الإلكترونية لتحسين الأداء في مهام التنبؤ بإعادة القبول (<span class="nodecor">lu2021textual</span>). كما استقصت أعمال أخرى استخدام النص الاصطناعي المولّد في المهام اللاحقة، مثل عمل ميلامود وآخرين الذين أظهروا أن السجلات الاصطناعية يمكن استخدامها في مهام الاستدلال اللغوي الطبيعي (<span class="nodecor">melamudTowards</span>). درب لي وآخرون عدة نماذج تلقائية عكسية لتوليد أقسام تاريخ الحالة الحالية من ملخصات خروج سجلات الصحة الإلكترونية وقاموا بتعليق السجلات الاصطناعية يدويًا لذكر الكيانات. أظهر لي وآخرون أنه يمكن تدريب نموذج تعرف الكيانات المسماة أكثر فعالية باستخدام البيانات الاصطناعية المعلقة لزيادة مجموعة البيانات التدريبية الحقيقية. كما توجد كمية كبيرة من الأعمال في ملخص سجلات الصحة الإلكترونية باستخدام نماذج التسلسل إلى التسلسل، على سبيل المثال (<span class="nodecor">RaffelT5</span>, <span class="nodecor">gaoSummarizing</span>, <span class="nodecor">palNerual</span>, <span class="nodecor">hartman2022day</span>). ومع ذلك، على عكس عمل (<span class="nodecor">RaffelT5</span>, <span class="nodecor">gaoSummarizing</span>, <span class="nodecor">palNerual</span>, <span class="nodecor">hartman2022day</span>)، نركز في هذا العمل حصريًا على المهمة التلقائية العكسية لتوليد البيانات السريرية الاصطناعية.</p>
<p>تستخدم معظم الأعمال المتعلقة بتوليد النصوص السريرية مجموعات بيانات السوق الطبية المعلوماتية للعناية المركزة (<span class="nodecor">MIMIC</span>). <span class="nodecor">MIMIC-III</span> (<span class="nodecor">johnsonMimic3</span>) هي قاعدة بيانات كبيرة ومُتاحة للعامة تحتوي على بيانات سريرية مفصلة للمرضى المقبولين في وحدات العناية المركزة. تم إصدار <span class="nodecor">MIMIC-IV</span> (<span class="nodecor">mimicFour</span>) مؤخرًا. يحتوي <span class="nodecor">MIMIC-IV</span> على العديد من السجلات أكثر من <span class="nodecor">MIMIC-III</span>، ولذلك نستخدم مجموعة بيانات <span class="nodecor">MIMIC-IV</span> لتجاربنا. ومع ذلك، بسبب حداثته، كان هناك عمل أقل يستخدم <span class="nodecor">MIMIC-IV</span> لمهام توليد النص مقارنة بـ <span class="nodecor">MIMIC III</span>. تحتوي كلتا المجموعتين على مجموعة متنوعة من البيانات المنظمة وغير المنظمة، بما في ذلك الديموغرافيا السكانية للمرضى، نتائج المختبرات، الإجراءات وملاحظات الطاقم الطبي المكتوبة. تقيم معظم الأعمال المذكورة أعلاه (<span class="nodecor">amin2020exploring</span>, <span class="nodecor">lu2021textual</span>, <span class="nodecor">melamudTowards</span>) جودة النص السريري المولّد مباشرة باستخدام مقاييس تقيس التداخل المصطلحي، مثل درجة <span class="nodecor">ROUGE</span> ودرجة <span class="nodecor">BLEU</span> (<span class="nodecor">linRouge</span>, <span class="nodecor">papineniBleu</span>)، على الرغم من أن الأخيرة تُستخدم عادة لتقييم أداء نموذج الترجمة الآلية - لذلك، في هذا العمل، نستخدم عائلة مقاييس <span class="nodecor">ROUGE</span> لتقييم جودة سجلاتنا الاصطناعية المولدة مقارنة بالأمثلة المعيارية.</p>
<h1 id="sec: method">توليد سجل الصحة الإلكتروني باستخدام نماذج اللغة الكبيرة</h1>
<p>كما وُصف في <span class="nodecor">Section</span> [sec:background]، لتوليد نص صناعي، يتم تدريب نموذج لغوي تلقائي الارتداد على مجموعة بيانات من النصوص الحقيقية. طبيعة النماذج التلقائية الارتداد تجعلها مثالية لمهام نمذجة اللغة السببية حيث يقوم نموذج اللغة بنمذجة توزيع المصطلحات في مجموعة البيانات بحيث يمكنه التنبؤ بالرمز التالي الذي يجب أن يأتي بناءً على تسلسل سابق من الرموز ومجموعة من رموز المفردات. تظهر المعادلة [eqn: nexttokenpred] كيفية حساب احتمال الرمز التالي في تسلسل بناءً على تسلسل أولي من الرموز المنفصلة، حيث <span class="math inline">\( W_{0}\)</span> هو تسلسل كلمات السياق الأولى، <span class="math inline">\( W_{t}\)</span> هو الرمز التالي المحتمل، و <span class="math inline">\( w_{1:0} = \emptyset \)</span> يشير إلى الكلمة الأولى من تسلسل البداية. <span class="math display">\[P(w_{1:T} \mid W_{0}) = \prod_{t=1}^{T} P(w_{t} \mid w_{1:t-1}, W_{0}) \text{ with } w_{1:0} = \emptyset
    \label{eqn: nexttokenpred}\]</span> في مهمتنا، ننمذج جزأين من النص غير المنظم من سجل الصحة الإلكتروني في مهمة نمذجة اللغة السببية. هذه هي:</p>
<ol>
<li><p>الشكوى الرئيسية (CC) - وصف قصير وأساسي للمشكلة الطبية الرئيسية للمريض المقبول.</p></li>
<li><p>تاريخ الحالة المرضية الحالي (HPI) - شرح أطول حول كيفية وصول المريض إلى المستشفى لعلاج مرضه، بما في ذلك أسباب الأمراض، وملاحظات المريض، وملاحظات أخرى من طاقم المستشفى.</p></li>
</ol>
<p>الهدف من مهمتنا، إذن، هو نمذجة العلاقة بين الشكوى الرئيسية وتاريخ الحالة المرضية الحالي باستخدام نماذج اللغة الكبيرة، بحيث يمكن لنموذج اللغة الكبير أن ينتج تاريخ الحالة المرضية الحالي عند تقديم شكوى رئيسية. بهذه الطريقة، يمكن تحفيز النموذج لتوليد تواريخ الحالات المرضية الحالية التي قد تهم الباحثين، أو للاستخدام في المهام اللاحقة كما استُخدم في الأعمال السابقة (<span class="nodecor">melamudTowards</span>, <span class="nodecor">amin2020exploring</span>, <span class="nodecor">lu2021textual</span>). بينما يمكن تحقيق هذه المهمة عادة بتحسين نموذج توليدي على مقاطع نصية منسقة تحتوي على شكاوى رئيسية وتواريخ الحالات المرضية الحالية، نحن نركز على تطوير استراتيجيات التحفيز لاستخدام نماذج اللغة الكبيرة بدون تحسين في إعداد الصفر والقليل من الأمثلة، لإزالة الحاجة إلى الوصول إلى بيانات المرضى الحساسة للتحسين، معتمدين بدلًا من ذلك على المعرفة البارامترية للنموذج المدرب مسبقًا لتوليد تواريخ الحالات المرضية الحالية الصناعية.</p>
<h2 id="sec: inContext">استراتيجيات التحفيز</h2>
<p>فيما تبقى من هذا القسم، نصف الاستراتيجيات المختلفة التي نستخدمها لتوليد أقسام المؤشر الصحي الشخصي من نص القسم المقدم للشكوى الرئيسية. نصف أيضًا الاستراتيجيات التعليمية المختلفة التي نستخدمها لتحفيز نماذج اللغة الكبيرة، بما في ذلك التحفيز بدون أمثلة والتحفيز بعدد قليل من الأمثلة. نقوم بتصميم التحفيزات لهندسة نموذج اللغة الكبيرة لاما ٢، والتي تستخدم مكون <em>System Prompt</em> لتزويد النموذج بمعلومات سياقية إضافية حول طبيعة المهمة التوليدية للنموذج (<span class="nodecor">touvronLlama2</span>). نستخدم هذا التحفيز النظامي لاقتراح استراتيجية تحفيز سلسلة الأفكار المصممة خصيصًا لتوليد نصوص طبية اصطناعية.</p>
<h3 id="إستراتيجية-التوجيه-المباشر">استراتيجية التوجيه المباشر</h3>
<p>أولًا، نقترح نص توجيه يتضمن أسماء كلا القسمين من سجلات الصحة الإلكترونية التي نهتم بها. يُقدم النص إلى النموذج كجملة مدخلة واحدة (حيث يُستبدل <em>X</em> بشكوى رئيسية حقيقية):</p>
<blockquote>
<p>الشكوى الرئيسية هي: {X}. تاريخ الحالة المرضية الحالي هو:</p>
</blockquote>
<p>يوفر هذا النمط سياقًا حول نوع المعلومات المقدمة، وهي الشكوى الرئيسية، ويحث النموذج على بدء توليد تاريخ حالة مرضية حالية مناسبة للشكوى الرئيسية المقدمة. تستند طبيعة هذا التنسيق المختصر إلى حقيقة أن بيانات السجلات السريرية مقيدة وقد لا يكون من الممكن تزويد النموذج بمعلومات إضافية حول سجلات الصحة الإلكترونية في بيئة مغلقة وحساسة. يُشار إلى هذه الاستراتيجية بالتوجيه المباشر في القسم [sec:results].</p>
<h3 id="طريقة-سلسلة-التفكير">طريقة سلسلة التفكير</h3>
<p>ثانيًا، نقترح استراتيجية توجيه أكثر تعقيدًا تعتمد على نموذج سلسلة التفكير. يمكن لنموذج سلسلة التفكير أن يوجه نموذج اللغة الكبير بشكل صريح من خلال عدة خطوات من التفكير أثناء أداء مهمة (<span class="nodecor">wei2022chain</span>). نقترح تعليم النموذج لتوليد أجزاء أخرى من سجلات الصحة الإلكترونية لرمز الشكوى الرئيسية المعطى، <em>قبل</em> تعليم النموذج لتوليد تاريخ المرض الحالي. على وجه التحديد، نعلم النموذج أولًا لتوليد جنس المريض لرمز الشكوى الرئيسية المقدمة، يليه عرق المريض، وأخيرًا تاريخ المرض الحالي. من خلال ذلك، نفترض أن النموذج يجب أن يستخدم إجاباته الإضافية حول هذه المفاهيم البسيطة لتوليد تاريخ مرض حالي أكثر واقعية.</p>
<p>نستخدم هذه العملية في سلسلة التفكير مع مكون موجه النظام لنموذج اللغة الكبير لاما ٢ (النموذج المختار للتوجيه). تم تدريب نموذج لاما ٢ لاستخدام <em>موجه النظام</em> الذي يتم إدراجه قبل موجه المستخدم. يستخدم موجه النظام لإعلام النموذج بمهمته العامة ووظيفته. في هذه الحالة، نعدل موجه النظام الأصلي المقترح في (<span class="nodecor">touvronLlama2</span>) وبدلًا من ذلك نعلم النموذج لتوليد بيانات سريرية ولإخراج كل مكون من تعليمات سلسلة التفكير كـ JSON. يوضح الشكل [fig:cotStruct] كيفية تنظيم موجه سلسلة التفكير وكيف يشير إلى هيكل سجل الصحة الإلكتروني، باستخدام موجه النظام قبل النظر في رمز الشكوى الرئيسية المحدد لتوليد تاريخ المرض الحالي. يتم تقديم موجه النظام للنموذج مع رمز خاص <span class="math inline">\(&lt;&lt;SYS&gt;&gt; \)</span>، ويشار إلى هذه الاستراتيجية التوجيهية باسم [سلسلة التفكير] في القسم [sec:results].</p>
<h2 id="sec: learnStrats">استراتيجيات التعلم</h2>
<p>نحن ننفذ كل استراتيجيات التحفيز لدينا مع ثلاث استراتيجيات تعلم مساعدة، أي كيفية تمرير الأمر إلى النموذج. أولًا، نستخدم التحفيز بدون أمثلة، حيث يتم تمرير الأمر دون أي معلومات سياقية أخرى. ثانيًا، نمرر أمثلة عن ما يُتوقع أن يكون عليه الإخراج، أي التعلم بأمثلة قليلة، والذي أظهر تحسين أداء نماذج التعلم في السياق (<span class="nodecor">brownGpt3</span>). نقترح استخدام التعلم بأمثلة قليلة بطريقتين، أولًا بأخذ عينات عشوائية من الأمثلة لاستخدامها مع أمر معين، وثانيًا بتزويد النموذج بأمثلة مشابهة للأمر الرئيسي.</p>
<h1 id="sec: experiment">التجارب</h1>
<p>في هذا القسم نصف التجارب التي نقوم بها للإجابة على الأسئلة البحثية الثلاثة التالية:</p>
<p><span><strong>RQ1</strong>: هل يمكن لنموذج اللغة الكبير تحقيق نفس الأداء في توليد المؤشرات الصحية الشخصية باستخدام استراتيجيات التلميح مقارنة بنماذج اللغة الكبيرة المعدلة؟</span></p>
<p><span><strong>RQ2</strong>: هل استراتيجية التلميح المقترحة من قبلنا تحسن أداء توليد النصوص بناءً على التلميحات مع نماذج اللغة الكبيرة؟</span></p>
<p><span><strong>RQ3</strong>: كيف تؤدي استراتيجيات التلميح لدينا في الإعدادات بدون أمثلة وبأمثلة قليلة؟</span></p>
<h2 id="الإعداد-التجريبي">الإعداد التجريبي</h2>
<h3 id="sec: dataset">مجموعة البيانات</h3>
<p>استخدمنا مجموعة بيانات MIMIC-IV (<span class="nodecor">mimicFour</span>) لإنشاء مجموعة بيانات من الشكاوى الرئيسية مع سجلات تاريخ الحالة الحالية المقابلة، حيث قمنا باستخراج <span class="nodecor">7000</span> ملخص خروج للمرضى الذين تضمنت سجلاتهم كلاً من شكوى رئيسية وأيضًا قسم تاريخ الحالة الحالية. تم تقسيم مجموعة البيانات لدينا إلى مجموعة تدريب ومجموعة اختبار تتكون من <span class="nodecor">6000</span> عينة تدريبية، تُستخدم لتدريب النماذج الأساسية التي يُستخدم فيها التحسين الدقيق، و <span class="nodecor">1000</span> عينة اختبار لتقييم الـ HPIs المنتجة. لكل عينة، قمنا أيضًا باستخراج جنس وعرق المرضى المقابلين لكل زوج CC-HPI.</p>
<h3 id="النماذج-والتقييم">النماذج والتقييم</h3>
<p>للإجابة على أسئلتنا البحثية، نقوم بنشر ثلاثة نماذج معمارية قائمة على <span class="nodecor">transformer</span>، وهي <span class="nodecor">GPT-2</span>، <span class="nodecor">BioGPT</span> (<span class="nodecor">luo2022biogpt</span>) و <span class="nodecor">LLaMA-2 13B</span> (<span class="nodecor">Llama</span>). يوفر الجدول [tab: modelInfo] نظرة عامة على استراتيجيات التعلم والنماذج التي نستخدمها. بشكل ملحوظ، نستخدم <span class="nodecor">GPT-2</span> كنموذج أساسي بسبب استخدامه الواسع كنموذج للتحسين الدقيق في العديد من مهام التوليد المختلفة. نختار <span class="nodecor">BioGPT</span> بسبب تدريبه المسبق في المجال الطبي الحيوي، والذي قد يحسن الأداء في المجال السريري، نتيجة لتشابه البيانات السريرية مع البيانات الطبية الحيوية. أخيرًا، نستخدم نموذج <span class="nodecor">Llama LLM</span> في كل من إعداد التدريب الدقيق وللاستراتيجيات التوجيهية الخاصة بنا مع كل استراتيجية تعلم مساعدة.</p>
<p>أولًا، نقوم بتدريب كل نموذج بدقة على مجموعة بيانات <span class="nodecor">CC-HPI</span> الموصوفة في القسم [sec: dataset]، مع دمج نصوص <span class="nodecor">CC</span> و <span class="nodecor">HPI</span> التدريبية مع إضافة رمز خاص، &lt;|sep|&gt;. بالنسبة لنموذج <span class="nodecor">Llama</span>، نقوم بتحميل النموذج مع تقنية الكَمّية <span class="nodecor">4-bit</span> (<span class="nodecor">dettersQLoRA</span>) ونستخدم <span class="nodecor">Low Rank Adaptation</span> (<span class="nodecor">HuLoRA</span>) لتدريب النموذج بكفاءة على مهمة التوليد بسبب حجمه الكبير. لكل نموذج، نقوم بـ <span class="nodecor">20</span> تشغيلًا لضبط المعلمات الفائقة باستخدام <span class="nodecor">Optuna</span> (<span class="nodecor">akiba2019optuna</span>)، بحثًا عن معدل التعلم، تآكل الوزن، وعدد العصور. نحسن من أجل خسارة التقييم ونستخدم أفضل تكوين للمعلمات الفائقة لتدريب نموذج نهائي يُستخدم في التقييم.</p>
<p>ثانيًا، نستخدم نموذج <span class="nodecor">Llama 2</span> مع استراتيجيات التوجيه الخاصة بنا الموصوفة في القسم [sec: inContext]. في هذه الحالات، نستخدم النموذج المكمم بـ <span class="nodecor">4-bit</span>، بدون أي تدريب دقيق. للتعلم بعدد قليل من الأمثلة، نستخدم أمثلة مستخرجة من مجموعة البيانات التدريبية القوية المكونة من <span class="nodecor">6000</span> عينة كما هو موصوف في القسم [sec: inContext]: أولًا عشوائيًا، وثانيًا باستخدام مسترجع <span class="nodecor">ColBERT-PRF</span> للعثور على أمثلة مماثلة (<span class="nodecor">wang2023colbert</span>). نقوم بإنشاء فهرس كثيف لـ <span class="nodecor">CCs</span> في مجموعة البيانات التدريبية، ولكل <span class="nodecor">CC</span> في مجموعة البيانات الاختبارية نسترجع أعلى اثنين من <span class="nodecor">CCs</span> ذات الصلة من مجموعة البيانات التدريبية مع <span class="nodecor">HPIs</span> المرتبطة بها لاستخدامها كأمثلة مماثلة. لمطالبنا المباشرة ومطالب <span class="nodecor">CoT</span>، نقوم بعد ذلك ببناء مجموعات بيانات بدون أمثلة، بعدد قليل من الأمثلة (عشوائي)، وبعدد قليل من الأمثلة (مماثل)، مع مجموعة الاختبار المكونة من <span class="nodecor">1000</span> عينة. لمطالب <span class="nodecor">CoT</span>، ندمج أيضًا القيم المقابلة للجنس والعرق لـ <span class="nodecor">CCs</span> و <span class="nodecor">HPIs</span>.</p>
<p>بشكل إجمالي، نقترح ست استراتيجيات مختلفة لتوليد النصوص بناءً على المطالب لنموذج <span class="nodecor">Llama</span>. هذه هي: المطالبة المباشرة، باستخدام استراتيجيات التعلم بدون أمثلة، بعدد قليل من الأمثلة العشوائية، وبعدد قليل من الأمثلة المماثلة؛ ومطالب <span class="nodecor">CoT</span>، باستخدام استراتيجيات التعلم بدون أمثلة، بعدد قليل من الأمثلة العشوائية، وبعدد قليل من الأمثلة المماثلة.</p>
<p>أخيرًا، لتقييم كل إعداد، نولّد <span class="nodecor">HPIs</span> لكل <span class="nodecor">CC</span> في مجموعة الاختبار - لكل من نماذجنا الثلاثة المدربة بدقة حيث نمرر <span class="nodecor">CC</span> ورمز الفاصل الخاص &lt;|sep|&gt; فقط في وقت الاستدلال، ولكل من استراتيجياتنا الستة المبنية على المطالب. نقارن مجموعات <span class="nodecor">HPIs</span> المولدة مع <span class="nodecor">HPIs</span> الحقيقية لكل <span class="nodecor">CC</span> ونحسب درجات <span class="nodecor">ROUGE</span> (<span class="nodecor">linRouge</span>). نعرض أيضًا درجة الحيرة لكل نموذج بعد عملية التدريب الدقيق حيث يُستخدم التدريب الدقيق.</p>
<h1 id="sec:results">النتائج والتحليل</h1>
<p>يُظهر الجدول [tab:Rouge_table] نتائج كل استراتيجية توليد باستخدام التحسين والتلميح. بشكل مباشر، يحقق نموذج لاما <span class="nodecor">2</span> المحسن بـ <span class="nodecor">QLoRA</span> (لاما<span class="nodecor">2</span> + <span class="nodecor">QLoRA</span>) أفضل أداء، حيث يسجل <span class="nodecor">0.28</span> في <span class="nodecor">Rouge-1</span> ويتفوق أيضًا في جميع مقاييس <span class="nodecor">ROUGE</span> الأخرى. <span class="nodecor">BioGPT</span> هو النموذج التالي الأفضل أداءً بنتيجة <span class="nodecor">0.264</span> في <span class="nodecor">Rouge-1</span>، بتحسن قدره <span class="nodecor">3.4</span> نقاط عن نموذج <span class="nodecor">GPT-2</span> المحسن الأساسي. هذا يدل على أنه، كما هو متوقع، النماذج المحسنة، التي تتدرب على العديد من أمثلة أزواج <span class="nodecor">CC-HPI</span> يمكن أن تحقق أفضل أداء حيث تتوفر بيانات <span class="nodecor">EHR</span> لاستخدامها في التحسين. تعكس درجات الحيرة للنماذج المحسنة نتائجها في مقاييس <span class="nodecor">ROUGE</span>، حيث يحقق لاما <span class="nodecor">2</span> أدنى درجة حيرة.</p>
<p>بعد ذلك، نرى أن استخدام طريقتنا المقترحة <span class="nodecor">CoT</span> يوفر تحسنًا عن تلميحنا المباشر في إعداد بدون أمثلة. عند مقارنة النهجين نرى أن استخدام تلميح <span class="nodecor">CoT</span> يحسن أداء التوليد بـ <span class="nodecor">6.4</span> نقاط، بحيث أن أداء نموذج لاما <span class="nodecor">2</span> بدون أمثلة مع تلميح <span class="nodecor">CoT</span> مماثل لأداء نموذج <span class="nodecor">GPT-2</span> المحسن، ويفضله قليلاً. فيما يتعلق بأسئلة بحثنا (<span class="nodecor">RQs</span>) نجيب الآن على <span class="nodecor">RQ1</span> و<span class="nodecor">RQ2</span>. أولًا، فيما يتعلق بـ <span class="nodecor">RQ1</span>، نجد أن استخدام استراتيجية تلميح <span class="nodecor">CoT</span> لدينا، يمكن لنموذج لاما <span class="nodecor">2</span> <span class="nodecor">13b</span> بدون أمثلة محمل بتقنية التكميم <span class="nodecor">4-bit</span> أن يتفوق على نموذج <span class="nodecor">GPT-2</span> المحسن على بيانات <span class="nodecor">EHR</span> في نفس مهمة التوليد، ولكنه لا يحقق أداء النماذج المحسنة المتطورة مثل لاما<span class="nodecor">2</span> و<span class="nodecor">BioGPT</span>. ثانيًا، وفيما يتعلق بـ <span class="nodecor">RQ2</span>، فإن طريقة تلميح <span class="nodecor">CoT</span> لدينا تحسن أداء النموذج بدون أمثلة مقارنة بطريقة لا تستخدم <span class="nodecor">CoT</span>.</p>
<p>للإجابة على <span class="nodecor">RQ3</span>، نحلل نتائج استراتيجيتي التلميح لدينا في إعدادات التعلم بدون أمثلة وبأمثلة قليلة. بالنسبة للتلميح المباشر، يحسن التعلم بأمثلة قليلة أداء التوليد - درجة <span class="nodecor">Rouge-1</span>، باستخدام أمثلة عشوائية في التعلم بأمثلة قليلة، يحسن الأداء بـ <span class="nodecor">0.19</span>، ويحسن التعلم بأمثلة قليلة أيضًا الأداء عن النموذج بدون أمثلة في <span class="nodecor">Rouge-1</span> إلى <span class="nodecor">0.205</span>، بزيادة قدرها <span class="nodecor">0.033</span>. ومع ذلك، بالنسبة لتلميح <span class="nodecor">CoT</span>، يعيق التعلم بأمثلة قليلة الأداء عند استخدام أمثلة عشوائية وعند استخدام أمثلة مماثلة. يقلل التعلم بأمثلة قليلة عشوائية الأداء بأكبر قدر، بانخفاض <span class="nodecor">2.8</span> نقاط في <span class="nodecor">Rouge-1</span>. فيما يتعلق بـ <span class="nodecor">RQ3</span> يمكننا القول إن تلميحنا المباشر يحسن الأداء في مهمة التوليد لدينا. ومع ذلك، فإن محاولة إضافة أمثلة إلى طريقة تلميح <span class="nodecor">CoT</span> تقلل من أداء النموذج.</p>
<h1 id="الخلاصة">الخلاصة</h1>
<p>في هذا العمل، قمنا بتقييم فعالية نموذج <span class="nodecor">Llama 2</span> لتوليد السجلات الطبية الاصطناعية التمثيلية، في ظروف الصفر، والقليل من الأمثلة، والإعدادات المعدلة، مقارنة بعدة نماذج معدلة حديثة. علاوة على ذلك، اقترحنا استراتيجيتين مخصصتين للتلميح لتوليد أقسام تاريخ الحالة الحاضرة من السجلات الصحية الإلكترونية. وجدت تجاربنا على مجموعة بيانات <span class="nodecor">MIMIC-IV</span> أن نموذج <span class="nodecor">Llama 2</span> الحديث قدم أفضل أداء مع التعديل الدقيق. ومع ذلك، أظهرنا أيضًا أن استراتيجية التلميح المخصصة لدينا، والتي توفر معلومات حول محتوى السجلات الصحية الإلكترونية وأي أقسام منها يجب توليدها، يمكن أن تعزز أداء نموذج <span class="nodecor">LLM</span> في ظروف الصفر بحيث يصبح تنافسيًا مع نموذج <span class="nodecor">GPT-2</span> المعدل. نرى هذا كخطوة نحو تقليل الحاجة للوصول إلى البيانات السريرية الحساسة من أجل إجراء البحوث في المجال السريري وتستحق البحث المستقبلي.</p>
<h1 id="الشكر-والتقدير">الشكر والتقدير</h1>
<p>تم دعم هذا العمل من قبل مجلس العلوم الهندسية والفيزيائية [رقم المنحة <span class="nodecor">EP/X018237/1</span>]</p>
</body>
</html>
