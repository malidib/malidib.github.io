<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Angus Nicolson">
  <meta name="author" content="Lisa Schut">
  <meta name="author" content="J. Alison Noble">
  <meta name="author" content="Yarin Gal">
  <title>شرح القابلية للتفسير: فهم متجهات تنشيط المفاهيم</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>body { direction: rtl; font-size: 22px; }</style>
</head>
<body>
<header>
<h1 class="title">شرح القابلية للتفسير: فهم متجهات تنشيط المفاهيم</h1>
<p class="author"><span class="nodecor">Angus Nicolson</span></p>
<p class="author"><span class="nodecor">Lisa Schut</span></p>
<p class="author"><span class="nodecor">J. Alison Noble</span></p>
<p class="author"><span class="nodecor">Yarin Gal</span></p>
</header>
<p>latex</p>
<h1 id="ملخص">مُلَخَّص</h1>
<p>تقترح طرق القابلية للتفسير الحديثة استخدام تفسيرات قائمة على المفاهيم لترجمة التمثيلات الداخلية لنماذج التعلم العميق إلى لغة مفهومة للبشر: المفاهيم. يتطلب ذلك فهم المفاهيم الموجودة في فضاء التمثيل لشبكة عصبية. إحدى الطرق الشائعة لاكتشاف المفاهيم هي متجهات تنشيط المفاهيم (<span class="nodecor">CAVs</span>)، والتي يتم تعلمها باستخدام مجموعة بيانات استكشافية من أمثلة المفهوم. في هذا العمل، نحقق في ثلاث خصائص لـ <span class="nodecor">CAVs</span>. قد تكون <span class="nodecor">CAVs</span>: (<span class="nodecor">1</span>) غير متسقة بين الطبقات، (<span class="nodecor">2</span>) متشابكة مع مفاهيم مختلفة، و(<span class="nodecor">3</span>) تعتمد على الموقع. توفر كل خاصية تحديات وفرصاً في تفسير النماذج. نقدم أدوات مصممة للكشف عن وجود هذه الخصائص، وتقديم رؤى حول كيفية تأثيرها على التفسيرات المستخلصة، وتقديم توصيات لتقليل تأثيرها. يمكن استخدام فهم هذه الخصائص لصالحنا. على سبيل المثال، نقدم <span class="nodecor">CAVs</span> التي تعتمد على الموقع لاختبار ما إذا كان نموذج ما يتمتع بخاصية الثبات الترجمي بالنسبة لمفهوم وفئة معينة. تتم تجاربنا على <span class="nodecor">ImageNet</span> ومجموعة بيانات تركيبية جديدة، <span class="nodecor">Elements</span>. تم تصميم <span class="nodecor">Elements</span> لالتقاط علاقة حقيقة معروفة بين المفاهيم والفئات. نقوم بإصدار هذه المجموعة لتسهيل المزيد من البحث في فهم وتقييم طرق القابلية للتفسير.</p>
<h1 id="sec: Introduction">مقدمة</h1>
<p>أصبحت نماذج التعلم العميق شائعة الاستخدام، حيث تحقق أداءً يصل أو يتجاوز خبراء البشر في مجموعة متنوعة من المهام. ومع ذلك، فإن التعقيد الكامن في هذه النماذج يحجب قدرتنا على شرح عملية اتخاذ القرارات لديها. مع تطبيقها في عدد متزايد من المجالات العملية، تزداد الحاجة إلى فهم كيفية عملها. تتيح هذه الشفافية تصحيح الأخطاء بسهولة أكبر وفهماً أفضل لقيود النموذج.</p>
<p>يمكن أن تأخذ تفسيرات النموذج أشكالاً متعددة، مثل ميزات الإدخال، النماذج الأولية أو المفاهيم. أظهرت الأعمال الحديثة أن طرق الشرح التي تركز على الميزات المنخفضة المستوى يمكن أن تواجه مشاكل. على سبيل المثال، يمكن أن تعاني طرق البصمة من التحيز التأكيدي ونقص الإخلاص (<span class="nodecor">adebayo2018sanity</span>). حتى عندما تكون مخلصة، فإنها تظهر فقط ’أين’ ركز النموذج في الصورة، وليس ’ماذا’ ركز عليه (<span class="nodecor">achtibat2022where</span>, <span class="nodecor">colin2022what</span>).</p>
<p>لمعالجة هذه المشاكل، توفر الطرق المبنية على المفاهيم تفسيرات باستخدام مصطلحات عالية المستوى يعرفها البشر. إحدى الطرق الشائعة هي متجهات تنشيط المفهوم (CAVs): تمثيل خطي لمفهوم موجود في مساحة التنشيط لطبقة محددة باستخدام مجموعة بيانات استكشافية من أمثلة المفهوم (<span class="nodecor">kim2018interpretability</span>). ومع ذلك، تواجه الطرق المبنية على المفاهيم أيضاً تحديات، مثل حساسيتها لمجموعة البيانات الاستكشافية المحددة (<span class="nodecor">Ramaswamy2022OverlookedFI</span>, <span class="nodecor">Soni2020AdversarialT</span>).</p>
<p>في هذه الورقة، نركز على فهم ثلاث خصائص لمتجهات المفاهيم:</p>
<ol>
<li><p>قد لا تكون <strong>متسقة</strong> عبر الطبقات،</p></li>
<li><p>يمكن أن تكون <strong>متشابكة</strong> مع مفاهيم أخرى،</p></li>
<li><p>يمكن أن تكون <strong>معتمدة مكانياً</strong>.</p></li>
</ol>
<p>نوفر أدوات لتحليل كل خاصية ونظهر أنها يمكن أن تؤثر على الاختبار باستخدام CAVs (TCAV) (§[sec: layer_stability], §[sec: Entanglement] و §[sec: Spatial]). لتقليل تأثير هذه الآثار، نوصي بـ: إنشاء CAVs لعدة طبقات، التحقق من الاعتماديات المتوقعة بين المفاهيم ذات الصلة، وتصوير الاعتماد المكاني (§[sec: Recommendations]). لا تعني هذه الخصائص أنه لا ينبغي استخدام CAVs. على العكس، قد نتمكن من استخدام هذه الخصائص لفهم سلوك النموذج بشكل أفضل. على سبيل المثال، نقدم نسخة معدلة من CAVs التي تعتمد مكانياً ويمكن استخدامها لتحديد التغير الترجمي في الشبكات العصبية الالتفافية (CNNs).</p>
<p>لمساعدة في استكشاف هذه الخصائص، قمنا بإنشاء مجموعة بيانات تركيبية قابلة للتكوين: العناصر (§[sec:elements]). توفر هذه المجموعة التحكم في العلاقات الأساسية بين المفاهيم والفئات من أجل فهم سلوك النموذج. باستخدام مجموعة بيانات العناصر، يمكن للباحثين دراسة (1) إخلاص طريقة التفسير المبنية على المفهوم و(2) التشابك المفاهيمي في الشبكة.</p>
<h1 id="sec: Background">الخلفية: متجهات تفعيل المفهوم</h1>
<p>متجه تفعيل المفهوم (<span class="nodecor">CAV</span>) هو تمثيل متجهي لمفهوم موجود في فضاء التفعيل لطبقة من الشبكة العصبية (<span class="nodecor">NN</span>). فكر في شبكة عصبية يمكن تحليلها إلى دالتين: <span class="math inline">\(g_l(\vx) =\va_l \in \R^{m}\)</span> التي ترسم الإدخال <span class="math inline">\(\vx \in \R^n\)</span> إلى متجه <span class="math inline">\(\va_l\)</span> في فضاء التفعيل للطبقة <span class="math inline">\(l\)</span>، و<span class="math inline">\(h_l(\va_l)\)</span> التي ترسم <span class="math inline">\(\va_l\)</span> إلى المخرج. لإنشاء متجه تفعيل المفهوم لمفهوم <span class="math inline">\(c\)</span> نحتاج إلى مجموعة بيانات استكشافية <span class="math inline">\(\D_c\)</span> تتكون من عينات إيجابية <span class="math inline">\(\X_c^+\)</span> (أمثلة المفهوم)، وعينات سلبية <span class="math inline">\(\X_c^-\)</span> (صور عشوائية ضمن التوزيع). لمجموعتي <span class="math inline">\(\X_c^-\)</span> و <span class="math inline">\(\X_c^+\)</span>، ننشئ مجموعة مقابلة من التفعيلات في الطبقة <span class="math inline">\(l\)</span>: <span class="math display">\[\A_{c,l}^+ = \{ g_l(\vx_i) \quad \forall \vx_i \in \X_c^+\} , \text{ و}  \
    \A_{c,l}^- = \{ g_l(\vx_i) \quad \forall \vx_i \in \X_c^-\},\]</span> نجد متجه تفعيل المفهوم <span class="math inline">\(\vcl\)</span> بتدريب مصنف خطي ثنائي للتمييز بين المجموعتين <span class="math inline">\(\A_{c,l}^+\)</span> و <span class="math inline">\(\A_{c,l}^-\)</span>: <span class="math display">\[\label{eq:svm}
    \al \cdot \vcl + b_{c,l}  &gt; 0 \quad \forall \al \in \A_{c,l}^+ , \text{ و } 
    \al \cdot \vcl + b_{c,l}  \leq 0 \quad \forall \al \in \A_{c,l}^-,\]</span> حيث <span class="math inline">\(\vcl\)</span> هو المتجه العمودي للمستوى الفاصل بين التفعيلات <span class="math inline">\(\A_{c,l}^+\)</span> و <span class="math inline">\(\A_{c,l}^-\)</span>، و<span class="math inline">\(b_{c,l}\)</span> هو الجزء المقطوع.</p>
<p>لتحليل حساسية النموذج لـ <span class="math inline">\(\vcl\)</span>، يقدم كيم وآخرون (<span class="nodecor">kim2018interpretability</span>) اختباراً باستخدام متجهات تفعيل المفهوم (<span class="nodecor">TCAV</span>)، والذي يحدد حساسية المفهوم النموذجية عبر فئة كاملة. دع <span class="math inline">\(\X_k\)</span> تكون مجموعة من المدخلات التي تنتمي إلى الفئة <span class="math inline">\(k\)</span>. يعرف مقياس <span class="nodecor">TCAV</span> كما يلي <span class="math display">\[\operatorname{TCAV}_{c, k, l}=\frac{\left|\left\{\vx \in \X_{k}: S_{c, k, l}(\vx)&gt;0\right\}\right|}{\left|\X_{k}\right|},\]</span> حيث المشتقة الاتجاهية للمفهوم، <span class="math inline">\(S_{c, k, l}\)</span>، معرفة كما يلي <span class="math display">\[S_{c, k, l}(\vx) =\lim _{\epsilon \rightarrow 0} \frac{h_{l, k}\left(g_{l}(\vx)+\epsilon \vv_{c, l}\right)-h_{l, k}\left(g_{l}(\vx)\right)}{\epsilon}
        =\nabla h_{l, k}\left(g_{l}(\vx)\right) \cdot \vcl\]</span> حيث <span class="math inline">\(\nabla h_{l, k}\)</span> هو المشتق الجزئي لمخرج الشبكة العصبية للفئة <span class="math inline">\(k\)</span> إلى التفعيل. يقيس مقياس <span class="nodecor">TCAV</span> النسبة المئوية لمدخلات الفئة <span class="math inline">\(k\)</span> التي يتأثر تفعيلها في الطبقة <span class="math inline">\(l\)</span> بشكل إيجابي بالمفهوم <span class="math inline">\(c\)</span>. يستخدم اختبار إحصائي لمقارنة مقاييس متجهات تفعيل المفهوم بالمتجهات العشوائية لتحديد أهمية المفهوم (انظر الملحق [app: CAV]).</p>
<h1 id="sec: CAV properties">فرضيات المتجهات المفاهيمية الموجهة</h1>
<p>لكي نستخدم طرق التفسير المبنية على المتجهات المفاهيمية الموجهة في الممارسة العملية، من المهم فهم كيفية عملها. لذلك، ندرس ثلاث خصائص للمتجهات المفاهيمية الموجهة وتأثيراتها على نتائج المتجهات المفاهيمية الموجهة. نركز على هذه الفرضيات لأنها توفر رؤية حول تمثيلات الشبكة وعن المعنى المشفر بواسطة متجهات المفهوم.</p>
<p>نصوغ كل خاصية من خلال فرضية صفرية، والتي نقدم دليلاً لرفضها لاحقاً في الورقة. في النص التالي، نستخدم التنسيق <code>concept</code> للدلالة على مفهوم.</p>
<h2 id="الاتساق">الاتساق</h2>
<p>بشكل عام، نريد فهم سلوك <em>النموذج</em>. ومع ذلك، تفسر المتجهات المفاهيمية المنشطة (CAVs) ما إذا كان النموذج حساساً لمفهوم في طبقة <em>محددة</em>. في الواقع، قد يكون تحليل جميع الطبقات غير عملي حسابياً، وليس من الواضح أي الطبقات يجب اختيارها. لذلك، تستكشف فرضيتنا الأولى العلاقة بين المتجهات المفاهيمية المنشطة الموجودة في طبقات مختلفة. تذكر أن درجات TCAV تعتمد على المشتقة الاتجاهية: <em>كيف يتغير مخرج النموذج لتغيير لا نهائي صغير للتنشيطات في اتجاه متجه مفهومي منشط</em>. من خلال تعديل التنشيطات في اتجاه متجه مفهومي منشط، نستكشف ما إذا كان بإمكان متجهين مفهوميَين منشطين موجودين في طبقات مختلفة أن يكون لهما نفس التأثير على مخرجات النموذج. نشير إلى هذه الخاصية باسم <em>الاتساق</em>.</p>
<p>افترض أن لدينا دالة <span class="math inline">\(f(\cdot)\)</span> ترسم التنشيطات من الطبقة <span class="math inline">\(l_1\)</span> إلى التنشيطات في الطبقة <span class="math inline">\(l_2\)</span>، حيث <span class="math inline">\(l_1&lt;l_2\)</span>. المتجهات المفاهيمية، <span class="math inline">\(\vclo\)</span> و <span class="math inline">\(\vclt\)</span> متسقة إذا ولكل مدخل <span class="math inline">\(\vx\)</span> والتنشيطات المقابلة <span class="math inline">\(\va_{l_1}\)</span> و <span class="math inline">\(\va_{l_2}\)</span>، <span class="math inline">\(f(\va_{l_1} + \vclo) = \va_{l_2} + \vclt\)</span>.</p>
<p>إذا كان متجهان مفهوميَان منشطان متسقين، فإن لهما نفس التأثير اللاحق على النموذج عندما يتم تعديل التنشيطات في اتجاههما، أي، على الرغم من أنهما في طبقات مختلفة، فإن لهما تأثيراً مكافئاً على مخرجات النموذج وبالتالي يعطيهما النموذج نفس المعنى. فرضيتنا الأولى هي:</p>
<p><em><strong>الفرضية الصفرية 1 (NH1)</strong>: تمثيلات المتجه المفهومي متسقة عبر الطبقات</em></p>
<p>في §[sec: layer_stability] نستكشف هذه الفرضية رسمياً، ونقوم بتقييمات تجريبية على مجموعات بيانات العناصر وImageNet (<span class="nodecor">Deng2009ImageNet</span>). نظهر نظرياً الشروط التي يجب أن تحققها <span class="math inline">\(\vclt\)</span> و <span class="math inline">\(\va_{l_1}\)</span> لكي يكون المتجهان <span class="math inline">\(\vclo\)</span> و <span class="math inline">\(\vclt\)</span> متسقين عندما تكون <span class="math inline">\(f\)</span> إما وحدة خطية معتدلة (ReLU) أو دالة سيجمويد.</p>
<h2 id="متجهات-المفاهيم-المتشابكه">متجهات المفاهيم المتشابكة</h2>
<p>فكر في المعنى المشفر بواسطة متجه المفهوم. نقوم بتسمية متجه المفهوم باستخدام التسمية المقابلة لمجموعة البيانات التجريبية. على سبيل المثال، قد يتم تسمية متجه المفهوم بـ <span class="nodecor">striped</span> أو <span class="nodecor">red</span>. هذا يفترض ضمنياً أن التسمية هي وصف كامل ودقيق للمعلومات المشفرة بواسطة المتجه. عملياً، قد يمثل متجه المفهوم عدة مفاهيم – على سبيل المثال، استمراراً للمثال أعلاه، قد يشفر المتجه كلاً من <span class="nodecor">striped</span> و <span class="nodecor">red</span> في نفس الوقت. نشير إلى هذه الظاهرة باسم “تشابك المفاهيم”. من الناحية الرياضية، نصيغ هذا على النحو التالي. متجه المفهوم <span class="math inline">\(\vcl\)</span> أكثر تشابهاً مع التنشيطات المقابلة للصور التي تحتوي على المفهوم من التنشيطات للصور التي لا تحتوي على المفهوم، أي أنه يلبي <span class="math display">\[\va_{c,l}^+ \cdot \vcl &gt; \va_{c,l}^- \cdot \vcl \quad \forall \va_{c,l}^+ \in \A_{c,l}^+, \va_{c,l}^- \in \A_{c,l}^-.\]</span></p>
<p>افترض أن لدينا المفاهيم <span class="math inline">\(c_1\)</span> و <span class="math inline">\(c_2\)</span>، مع مجموعات بيانات تجريبية <span class="math inline">\(\D_{c_1}\)</span> و <span class="math inline">\(\D_{c_2}\)</span>، على التوالي. لكل مجموعة بيانات تجريبية، نجد مجموعات التنشيط: <span class="math inline">\(\A_{c_1,l} = \{A_{c_1,l}^+ \cup  A_{c_1,l}^- \}\)</span> و <span class="math inline">\(\A_{c_2,l} = \{ \A_{c_2,l}^+ \cup  \A_{c_2,l}^- \}\)</span>.</p>
<p>متجه المفهوم لمفهوم ما متشابك مع مفهوم آخر إذا وفقط إذا <span class="math display">\[\label{eqn: entangled definition}
        \begin{aligned}
            &amp;\textcolor{blue}{\va_{c_2,l}^+} \cdot \textcolor{red}{\vv_{c_1,l}} &gt; \textcolor{blue}{\va_{c_2,l}^-} \cdot \textcolor{red}{\vv_{c_1,l}}
            &amp;\forall \textcolor{blue}{\va_{c_2,l}^+} \in \textcolor{blue}{\A_{c_2,l}^+} , \textcolor{blue}{\va_{c_2,l}^-} \in \textcolor{blue}{\A_{c_2,l}^-} 
        \end{aligned}\]</span></p>
<p>فرضيتنا الثانية تستكشف تشابك المفاهيم:</p>
<p><em><strong>الفرضية الصفرية 2 (NH2)</strong>: يمثل متجه المفهوم المفهوم المقابل فقط لتسميته في مجموعة البيانات التجريبية الخاصة به</em></p>
<p>إذا كانت المفاهيم متشابكة، فلن يكون من الممكن فصل حساسية النموذج لمفهوم واحد عن حساسيته للمفاهيم المتعلقة – وبالتالي، إذا قمنا بقياس درجة TCAV لـ <span class="math inline">\(c_1\)</span>، فسنخلط دون علم تأثير <span class="math inline">\(c_2\)</span>.</p>
<p>في §[sec: Entanglement] نقدم أداة تصور لاستكشاف تشابك CAV ونناقش كيف يمكن أن يؤثر ذلك على TCAV.</p>
<h2 id="الاعتماد-المكاني">الاعتماد المكاني</h2>
<p>في هذا القسم، نستكشف تأثير الاعتماد المكاني على المفاهيم. لنفترض أن <span class="math inline">\(\D_{c, \mu_1}\)</span> و <span class="math inline">\(\D_{c,\mu_2}\)</span> تمثلان مجموعتي بيانات تحتويان على نفس المفهوم ولكن في مواقع مختلفة <span class="math inline">\(\mu_1 \neq \mu_2\)</span>. على سبيل المثال، قد تحتوي <span class="math inline">\(\D_{c, \mu_1}\)</span> على أمثلة للمفهوم <span class="nodecor">striped on the left</span> في الصورة، و <span class="math inline">\(\D_{c,\mu_2}\)</span> على أمثلة للمفهوم <span class="nodecor">striped on the right</span> في الصورة. كما في السابق، نقوم ببناء تمثيلات كامنة <span class="math inline">\(\A_{c,l,\mu_1}\)</span> و <span class="math inline">\(\A_{c,l,\mu_2}\)</span> لمجموعتي البيانات <span class="math inline">\(\D_{c, \mu_1}\)</span> و <span class="math inline">\(\D_{c, \mu_2}\)</span> على التوالي. ليكن <span class="math inline">\(\vcl\)</span> هو متجه المفهوم الذي تم العثور عليه باستخدام مجموعة البيانات الاستكشافية <span class="math inline">\(\D_{c, \mu_1}\)</span>.</p>
<p>ليكن <span class="math inline">\(\va_{l, i}\)</span> هي التنشيطات المقابلة للمدخل <span class="math inline">\(\vx_i\)</span> في الطبقة <span class="math inline">\(l\)</span>، وليكن <span class="math inline">\(\mu_{c,i}\)</span> هو موقع المفهوم <span class="math inline">\(c\)</span> في <span class="math inline">\(\vx_i\)</span>. تمتلك طبقة تمثيلاً مكانياً معتمداً لمفهوم إذا وفقط إذا <span class="math display">\[\exists \phi: \forall \vx_i \in \mathbb{X}_c^+, \phi(\va_{l, i}) = \mu_{c,i}\]</span></p>
<p>قد يكون الاعتماد المكاني للتنشيط في شبكة عصبية ناتجاً عن تصميم الهندسة، إجراء التدريب و/أو مجموعة بيانات التدريب. في الشبكات العصبية الالتفافية، هو نتيجة طبيعية لمجال الاستقبال لمرشحات الالتفاف التي تحتوي على مناطق مختلفة من المدخل. إذا كانت الشبكة العصبية تمتلك تنشيطات مكانياً معتمدة وكانت مجموعة البيانات الاستكشافية تمتلك اعتماداً مكانياً، فقد يكون من الممكن إنشاء متجه مفهوم مع اعتماد مكاني.</p>
<p>متجه المفهوم <span class="math inline">\(\vv_{c,l}\)</span> معتمد مكانياً بالنسبة للمواقع إذا وفقط إذا <span class="math display">\[\label{eqn: concept vector spatial dependence}
    \begin{aligned}
        &amp;\textcolor{red}{\va_{c,l,\mu_1}^+} \cdot \vv_{c,l} &gt; \textcolor{blue}{\va_{c,l,\mu_2}^+} \cdot \vv_{c,l}
        &amp;\forall \textcolor{red}{\va_{c,l,\mu_1}^+} \in \textcolor{red}{\A_{c,l,\mu_1}^+}, \textcolor{blue}{\va_{c,l,\mu_2}^+} \in \textcolor{blue}{\A_{c,l,\mu_2}^+}.
    \end{aligned}\]</span></p>
<p>إذا كان متجه التنشيط المفاهيمي معتمداً مكانياً، فبناءً على التعريف أعلاه، فهو أكثر تشابهاً مع التنشيطات من الصور التي تحتوي على المفهوم في موقع محدد. هذا يعني أن متجه التنشيط المفاهيمي يمثل ليس فقط تسمية المفهوم، ولكن تسمية المفهوم في موقع محدد، مثل الأشياء المخططة على اليمين من الصورة، بدلاً من الأشياء المخططة بشكل عام. كما فعلنا للخصائص الأخرى، نقترح فرضية ونسعى لرفضها لاحقاً في الورقة:</p>
<p><em><strong>الفرضية الباطلة 3 (NH3)</strong>: لا يمكن أن تكون متجهات التنشيط المفاهيمي معتمدة مكانياً</em></p>
<p>نرفض هذه الفرضية في §[sec: Spatial] من خلال تحليل كيفية تأثير موقع المفهوم في مجموعة البيانات الاستكشافية على الاعتماد المكاني لمتجهات المفهوم. رفض NH3 يحفز تقديم <em>متجهات التنشيط المفاهيمي المعتمدة مكانياً</em> (§ [sec: Spatial])، والتي يمكن استخدامها لاختبار ما إذا كان النموذج متغير الترجمة بالنسبة لمفهوم وفئة محددة.</p>
<h1 id="sec:elements">العناصر: مجموعة بيانات اصطناعية قابلة للتهيئة</h1>
<p>لاستكشاف هذه الفرضيات، نقدم مجموعة بيانات اصطناعية جديدة: العناصر. في هذه المجموعة، يمكننا التحكم في: (1) مجموعة البيانات التدريبية وتعريفات الفئات، مما يتيح لنا التأثير على خصائص النموذج، مثل ارتباط المفاهيم في فضاء التضمين، و(2) مجموعة البيانات الاختبارية، مما يتيح لنا اختبار خصائص متجه المفهوم، مثل الاعتماد المكاني لمتجه المفهوم. نقوم بمزيد من التفصيل حول هذه المزايا في الملحق [app: Elements].</p>
<p>كل صورة تحتوي على <span class="math inline">\(n\)</span> عناصر، حيث يتم تعريف العنصر بسبع خصائص: اللون، السطوع، الحجم، الشكل، النسيج، تحول النسيج، والإحداثيات داخل الصورة. يمكن تهيئة المجموعة بتغيير التركيبة المسموح بها للخصائص لكل عنصر. يتم إعطاء النطاقات والتكوينات المستخدمة لكل خاصية في الملحق [app: Elements].</p>
<h1 id="sec: related work">الأعمال ذات الصلة</h1>
<h4 id="الارتباط-والتشابك-بين-المفاهيم">الارتباط والتشابك بين المفاهيم</h4>
<p>يناقش تشن وآخرون (<span class="nodecor">Chen2020ConceptWF</span>) كيف يمكن أن تكون متجهات المفاهيم مرتبطة، مما يجعل من الصعب إنشاء متجه يمثل مفهوماً واحداً فقط. بينما يركز عملهم على فك الارتباط بين المفاهيم <em>أثناء التدريب</em>، نحن نركز على تحليل تأثير المفاهيم المرتبطة <em>بعد التدريب</em> ونظهر كيف يمكن أن تؤدي إلى تفسيرات مضللة (§[sec: Entanglement]). يستخدم فونغ وفيدالدي (<span class="nodecor">fong2018net2vec</span>) تشابه الجيب التمام لإظهار أن التشابه بين المفاهيم يختلف بناءً على طريقة إنشاء المتجه. في عملنا، نستخدم أيضاً تشابه الجيب التمام لمقارنة متجهات المفاهيم. الاختلاف يكمن في تركيزنا على متجهات التحليل العنقودي والرؤى التي تقدمها حول مجموعة البيانات والنموذج.</p>
<h4 id="الاعتماد-المكاني-1">الاعتماد المكاني</h4>
<p>يصف بيسكيوني وباورز (<span class="nodecor">Biscione2021Invariant</span>) كيف أن الشبكات العصبية الالتفافية ليست مترجمة بشكل طبيعي ولكن يمكن أن تتعلم أن تكون كذلك (تحت ظروف معينة على مجموعة البيانات). هذا الاكتشاف يتحدى الافتراض الشائع بأن الشبكات العصبية الالتفافية تمتلك ترجمة طبيعية. من خلال <em>متجهات التحليل العنقودي المعتمدة مكانياً</em>، نظهر الترجمة بالنسبة لمفهوم وفئة محددة، بدلاً من ذلك بشكل عام، مما يوفر معلومات أكثر تفصيلاً عن النموذج.</p>
<h4 id="ما-هي-تمثيلات-المفاهيم-التي-ينطبق-عليها-تحليلنا">ما هي تمثيلات المفاهيم التي ينطبق عليها تحليلنا؟</h4>
<p>تمثل معظم طرق التفسير المبنية على المفاهيم المفاهيم كـ <em>متجهات</em> في فضاء التنشيط لشبكة عصبية مدربة (<span class="nodecor">kim2018interpretability, fong2018net2vec, bolei2018ibd, ghorbani2019automating, zhang2020invertible, ramaswamy2022elude, fel2023craft</span>). ومع ذلك، تستخدم بعض الطرق المبنية على المفاهيم تمثيلات مختلفة: الخلايا العصبية الفردية (<span class="nodecor">bau2017network</span>)، مناطق فضاء التنشيط (<span class="nodecor">crabbe2022</span>) أو المفاهيم غير الخطية (<span class="nodecor">bai2022concept, li2023emergent</span>). يتركز عملنا على خصائص متجهات المفاهيم.</p>
<h4 id="كيف-يكون-عملنا-ذا-صلة-عمليا">كيف يكون عملنا ذا صلة عملياً؟</h4>
<p>لتقديم رؤية حول متى قد تكون الخصائص المختلفة ذات صلة، قمنا بمراجعة أوراق الرؤية الحاسوبية التي تستخدم متجهات التحليل العنقودي في (1) تطبيقات عالية الأهمية مثل التصوير الطبي (بما في ذلك سرطان الجلد، آفات الجلد، سرطان الثدي، وعلم الأنسجة (<span class="nodecor">Yan2023SkinCancer, Furbock2022Breast, Pfau2020Robust</span>))، و(2) بحوث الرؤية الحاسوبية على النماذج المدربة باستخدام مجموعات بيانات معروفة (<span class="nodecor">Krizhevsky2009CIFAR, Tsung2014COCO, Wah2011CUB,Zhou2017Places, Sagawa2020Waterbirds, Deng2009ImageNet</span>). يمكن العثور على جدول ملخص في الملحق [app: related work]. وجدنا أن الأوراق التالية كان يمكن أن تستفيد من تقييم: الاتساق (<span class="nodecor">Yan2023SkinCancer, Ramaswamy2022OverlookedFI, Furbock2022Breast, Yuksekgonul2023Post, Ghosh2023Dividing, Lucieri2020Oninterp</span>)، التشابك (<span class="nodecor">Yan2023SkinCancer, Ramaswamy2022OverlookedFI, Furbock2022Breast, Yuksekgonul2023Post, Ghosh2023Dividing, Graziani2020Concept, McGrath_2022, Lucieri2020Oninterp, Pfau2020Robust</span>)، والاعتماد المكاني (<span class="nodecor">Yan2023SkinCancer, Ramaswamy2022OverlookedFI, Furbock2022Breast, Yuksekgonul2023Post, Ghosh2023Dividing, McGrath_2022, Lucieri2020Oninterp, Pfau2020Robust</span>). نقدم مثالاً مفصلاً، باستخدام تطبيق تشخيص سرطان الجلد (<span class="nodecor">Yan2023SkinCancer</span>)، في § [sec: Recommendations] والملحق [app: Example UseCase].</p>
<h4 id="مجموعات-البيانات">مجموعات البيانات</h4>
<p>بينما تم تقديم العديد من مجموعات البيانات لتقييم طرق التفسير، فإنها تختلف عن مجموعة البيانات الخاصة بنا في بعض الطرق الرئيسية. هناك ثلاثة جوانب نهتم بها:</p>
<ol>
<li><p>هل يتم تمثيل المفهوم في الشبكة؟</p></li>
<li><p>هل يتم استخدام المفهوم لتنبؤ الشبكة؟</p></li>
<li><p>كيف تمثل الشبكة المفاهيم المرتبطة؟</p></li>
</ol>
<p>تسمح مجموعات البيانات الحالية فقط بالاطلاع على (1)، بينما تتيح لنا مجموعة البيانات الخاصة بنا تحليل (2) و(3) أيضاً. تقدم طريقة تقييم التفسير (<span class="nodecor">yang2019</span>) عناصر في صور المشاهد. بينما تستفيد من استخدام الصور الحقيقية والمفاهيم المعقدة (الكلب أو غرفة النوم)، فإنها تواجه أيضاً تحديات. أحد العيوب هو أن الاعتماد على الصور الحقيقية يجعل من الصعب إنشاء علاقة الحقيقة الأساسية بين المفاهيم وتنبؤات الفئة أو معرفة التشابهات بين المفاهيم. وبالتالي، لا تعطينا رؤية في (2) أو (3). مجموعة البيانات الاصطناعية في يه وآخرون (<span class="nodecor">yeh2020completeness</span>) هي الأقرب إلى مجموعة البيانات الخاصة بنا ولكن تم تصميمها لاكتشاف المفهوم، حيث تتميز الصور بأن كل عنصر يتوافق مع مفهوم واحد (الشكل). في مجموعة البيانات الخاصة بنا، يحتوي كل عنصر على مفاهيم متعددة، مما يتيح لنا إنشاء ارتباطات بينها. نركز على دقة التفسير من خلال التأكد من أن المفاهيم يجب أن تُستخدم بشكل صحيح من قبل النموذج لتحقيق دقة عالية. لذا، بالنسبة لنموذج دقيق، لدينا فهم حقيقي لكيفية استخدام كل مفهوم. يمكن العثور على مراجعة أدبية موسعة في الملحق [app: related work].</p>
<h1 id="النتائج-استكشاف-خصائص-متجه-المفهوم">النتائج: استكشاف خصائص متجه المفهوم</h1>
<p>نستكشف الفرضيات حول الاتساق (NH1)، التشابك (NH2)، والاعتماد المكاني (NH3) في § [sec: layer_stability]، § [sec: Entanglement] و § [sec: Spatial]، على التوالي. نقوم بتنفيذ التجارب باستخدام متجهات المفهوم المشروطة على مجموعات بيانات العناصر وImageNet. يمكن العثور على تفاصيل التنفيذ في الملحق [app: implementation].</p>
<h2 id="sec: layer_stability">المركبات الآلية المتسقة</h2>
<h3 id="النظرية">النظرية</h3>
<p>نبدأ بفحص NH1، والذي ينص على أن المتجهات المميزة للسيارات ذاتية القيادة متسقة عبر الطبقات، أي أن <span class="math inline">\(f(\va_{l_1} + \vv_{c, l_2}) = \va_{l_2} + \vv_{c, l_2}\)</span>. لنفترض أن <span class="math inline">\(\hat{\va}_{l_1}\)</span> و <span class="math inline">\(\hat{\va}_{l_2}\)</span> هما اضطرابات خطية للتنشيطات في الطبقتين <span class="math inline">\(l_1\)</span> و <span class="math inline">\(l_2\)</span> على التوالي: <span class="math display">\[\begin{aligned}
    \hat{\va}_{l_1} &amp;= \va_{l_1} + \vclo \\
    \hat{\va}_{l_2} &amp;= \va_{l_2} + \vclt = f(\va_{l_1}) + \vclt\end{aligned}\]</span> نريد أن نفحص إذا كان <span class="math inline">\(\vclo\)</span> و <span class="math inline">\(\vclt\)</span> لهما نفس التأثير على التنشيطات (وبالتالي على النموذج)، أي إذا كان: <span class="math display">\[\label{eqn: consistent cavs}
    \begin{aligned}
        f(\hat{\va}_{l_1}) &amp;= \hat{\va}_{l_2} \\
        f(\va_{l_1} + \vclo) &amp;= f(\va_{l_1}) + \vclt.
    \end{aligned}\]</span> لنفترض أننا وجدنا <span class="math inline">\(\vclo\)</span> ونود أن نجد <span class="math inline">\(\vclt\)</span> الذي يلبي المعادلة [eqn: consistent cavs]. إذا كانت <span class="math inline">\(f\)</span> تحافظ على جمع الناقلات، كما في طبقة خطية، فإنه يصح أن: <span class="math display">\[\begin{aligned}
        f(\va_{l_1}) + f(\vclo) &amp;= f(\va_{l_1}) + \vclt \\
        \vclt &amp;= f(\vclo).
    \end{aligned}\]</span> وبالتالي، من الممكن أن يكون لدينا ناقلات متسقة عبر الطبقات إذا كانت <span class="math inline">\(f\)</span> تحافظ على جمع الناقلات و <span class="math inline">\(\vclt = f(\vclo)\)</span>. بدلاً من ذلك، إذا لم تحافظ <span class="math inline">\(f\)</span> على جمع الناقلات، لا يمكننا تبسيط المعادلة [eqn: consistent cavs] و لناقل معين <span class="math inline">\(\vv_{c, l_1}\)</span>: <span class="math display">\[\label{eqn: consistency vcl2}
    \vv_{c, l_2} = f(\va_{l_1} + \vv_{c, l_1}) - f(\va_{l_1}).\]</span> إذا كان <span class="math inline">\(\vclt\)</span> يعتمد على <span class="math inline">\(\va_{l_1}\)</span>، فلا يوجد <span class="math inline">\(\vclt\)</span> بحيث تكون المعادلة [eqn: consistent cavs] صحيحة لجميع <span class="math inline">\(\va_{l_1}\)</span>. بمعنى آخر، لا يوجد ناقل في الطبقة <span class="math inline">\(l_2\)</span> له نفس التأثير على التنشيطات كناقل في الطبقة <span class="math inline">\(l_1\)</span> لجميع المدخلات إلى النموذج.</p>
<p>وظائف ReLU و sigmoid هي تنشيطات شائعة في الشبكات العصبية. باستخدام المعادلة [eqn: consistency vcl2]، لأي مدخل <span class="math inline">\(i\)</span>، إذا <span class="math display">\[\begin{aligned}
 \label{eqn: ReLU conditions}
    &amp; f=\text{ReLU}: \quad a_{l_1,i} + v_{l_1,i} &gt; 0, \ a_{l_1,i} \leq 0, \text{ أو } a_{l_1,i} + v_{l_1,i} \leq 0, \ a_{l_1,i} &gt; 0 \\
    \label{eqn: sigmoid conditions}
    &amp; f=\text{sigmoid}: \quad  v_{l_1,i} \neq 0\end{aligned}\]</span> فلا يوجد <span class="math inline">\(\vclt\)</span> متسق، أي أنه <strong>مستحيل</strong> أن يكون لدينا ناقلات متسقة تحت هذه الشروط. البراهين لـ [eqn: ReLU conditions,eqn: sigmoid conditions] متوفرة في الملحق [app: consistency proof]. بعد ذلك، نوضح أننا لا نستطيع العثور على ناقلات متسقة عملياً.</p>
<h3 id="التجارب">التجارب</h3>
<p>هدفنا هو استقصاء السؤال: هل المتجهات المفاهيمية المكتشفة باستخدام TCAV متسقة؟ نقيس الاتساق بين التباينات باستخدام خطأ الاتساق: <span class="math display">\[\begin{aligned}
        \epsilon_{\text{consistency}}  
        = ||f(\hat{\va}_{l_1}) -  \hat{\va}_{l_2}||
        = ||f(\va_{l_1} + \vclo) -  (\va_{l_2} + \vclt)||
    \end{aligned}\]</span> في تجاربنا، نستخدم مصطلح تحجيم لتقليل حجم <span class="math inline">\(\vclo\)</span> و <span class="math inline">\(\vclt\)</span> لضمان بقاء النشاط المضطرب ضمن التوزيع - راجع الملحق [app: Consistency gamma] للتفاصيل. إذا كان لدى التباينين خطأ اتساق يساوي <span class="math inline">\(0\)</span>، فهذا يعني أن لهما نفس التأثير على النموذج. نشمل المعايير التالية:</p>
<h4 id="cav-المحسن">CAV المحسن</h4>
<p>(الحد الأدنى): قد لا يجد TCAV <span class="math inline">\(\vclt\)</span> الذي يكون له خطأ اتساق يساوي <span class="math inline">\(0\)</span> مع <span class="math inline">\(\vclo\)</span>. لذلك، نستخدم الانحدار التدريجي على <span class="math inline">\(\vclt\)</span> لتقليل خطأ الاتساق، الذي يعمل كحد أدنى.</p>
<h4 id="cav-الموجه">CAV الموجه</h4>
<p>: الخطأ بين <span class="math inline">\(f(\vclo)\)</span> و <span class="math inline">\(\vv_{c, l_2}\)</span>، الذي يقيس مدى اتساق المتجهات عند توجيهها إلى الطبقة التالية. إذا كانت <span class="math inline">\(f(\cdot)\)</span> تحافظ على جمع المتجهات، فإن CAVs الموجهة ستكون لها خطأ يساوي <span class="math inline">\(0\)</span>.</p>
<h4 id="عشوائي">عشوائي</h4>
<p>(الحد الأعلى): نشمل معيارين. CAVs العشوائية المكتشفة باستخدام مجموعات بيانات الاختبار التي تحتوي على صور عشوائية، ومتجه الاتجاه العشوائي: <span class="math inline">\(\vv_{c, l_2} \sim \text{Uniform}(-1, 1)\)</span>. إذا كان خطأ الاتساق مشابهاً للعشوائي، فهذا يشير إلى أن CAVs بين الطبقات متشابهة مع بعضها البعض بقدر الاتجاهات العشوائية.</p>
<p>عدم القدرة على العثور على متجهات مفاهيمية متسقة عبر الطبقات يشير إلى أن الاتجاهات التي يتم ترميزها بواسطة CAVs في طبقات مختلفة ليست مكافئة؛ بل، نفترض أنها تمثل مكونات مختلفة من نفس المفهوم. هذا يتماشى مع الحدس بأن تمثيلات النموذج أكثر تعقيداً في وقت لاحق في الشبكة العصبية (<span class="nodecor">Mordvintsev2015DeepDream</span>, <span class="nodecor">olah2017feature</span>, <span class="nodecor">bau2017network</span>)، وبالتالي من غير المحتمل أن يتم تمثيل نفس جوانب المفهوم في طبقات مختلفة (يتم مناقشتها بمزيد من التفصيل في الملحق [app: DeepDream]). وبالتالي، يمكن أن تختلف درجات TCAV عبر الطبقات حيث تؤدي اختبارات مختلفة - فهي تقيس حساسية الفئة لنسخ مختلفة من المفهوم.</p>
<p>في الجانب الأيمن من [fig:consistency tcav scores]، نعرض درجات TCAV لفئات مختلفة في نموذج ResNet-50 المدرب على ImageNet. دقة المتجهات في ImageNet تزيد عن <span class="math inline">\(96\%\)</span> لجميع الطبقات التي تم اختبارها، مما يشير إلى أن المفهوم مرمز بواسطة النموذج في كل من الطبقات. كما في Elements، لا نلاحظ درجات TCAV متسقة عبر الطبقات. بدلاً من ذلك، نلاحظ تغيراً كبيراً في درجات TCAV في الطبقة قبل الأخيرة، مقارنة بالطبقات السابقة. ’layer4.1’ يشير إلى أنه يؤثر بشكل إيجابي على احتمالية فئتي النمر والفهد. ومع ذلك، تشير الطبقات السابقة إلى أن الفئة ليست حساسة للمفهوم. هذا يظهر كيف يمكن استخلاص استنتاجات مختلفة اعتماداً على الطبقات التي يتم اختبارها.</p>
<h2 id="sec: Entanglement">التشابك</h2>
<p>قد ترتبط المفاهيم المختلفة ببعضها البعض. على سبيل المثال، ضع في اعتبارك أن جانباً أساسياً من السماء هو أنها غالباً ما تكون زرقاء. هذه المفاهيم مرتبطة بشكل جوهري ولا ينبغي معاملتها على أنها مستقلة. ستناقش هذه الفقرة كيفية اكتشاف هذه الارتباطات باستخدام متجهات المفاهيم المنشأة والآثار المترتبة على تحليل المفاهيم المنشأة.</p>
<p>لاستكشاف التشابك، نقوم بتحديد وتصوير ارتباطات المفاهيم من خلال حساب متوسط التشابهات الزاوية الزوجية بين متجهات المفاهيم المنشأة (نحسب متجهات متعددة لكل مفهوم). نحقق في ثلاثة نماذج تم تدريبها على إصدارات مختلفة من مجموعة بيانات العناصر. كل مجموعة بيانات متطابقة باستثناء الارتباط بين و :</p>
<ul>
<li><p>كل تركيبة من اللون والشكل والملمس محتملة بنفس القدر،</p></li>
<li><p>الشكل الوحيد الذي يكون أحمر هو المثلثات،</p></li>
<li><p>المفاهيم الأحمر والمثلث تتشارك دائماً.</p></li>
</ul>
<p>في <span class="math inline">\(\E_1\)</span>، نلاحظ عدم وجود ارتباط إيجابي بين المفاهيم. في <span class="math inline">\(\E_2\)</span>، نلاحظ ارتباطاً إيجابياً صغيراً بين مفهومي المثلث والأحمر. أخيراً، في <span class="math inline">\(\E_3\)</span>، يقترب التشابه الزاوي بين متجهات المفاهيم المنشأة للأحمر والمثلث من التشابه مع المفهوم نفسه. الاتجاه بين <span class="math inline">\(\E_1\)</span>، <span class="math inline">\(\E_2\)</span> و <span class="math inline">\(\E_3\)</span> من المحتمل أن يكون بسبب الارتباط الكامن بين و الذي يزداد. نقوم بتحليلات مماثلة على ImageNet في الملحق [app: Entanglement].</p>
<p>من المثير للاهتمام، غالباً ما نلاحظ تشابهاً زاويّاً سلبياً بين المفاهيم المتبادلة الاستبعاد. النموذج قد قام بترميز المفاهيم التي لا يمكن أن تتشارك (، يمكن أن يكون لكل عنصر لون واحد فقط) في اتجاهات مرتبطة سلباً مع بعضها البعض. وجود يقلل من احتمال وجود أو ، ومن خلال ارتباط هذه المفاهيم سلباً مع بعضها البعض، يبني النموذج هذا التفكير. هذا يعني أن متجه المفهوم المنشأ للأحمر لا يدل فقط على ، بل يشمل أيضاً و .</p>
<p>بعد ذلك، نحقق في تأثير متجهات المفاهيم المتشابكة على نتيجة تحليل المفاهيم المنشأة. نحلل نتائج تحليل المفاهيم المنشأة لفئة ’المثلثات المخططة’ في <span class="math inline">\(\E_1\)</span> و <span class="math inline">\(\E_2\)</span>. تعتمد تسمية الفئة فقط على وجود و . لذلك، نتوقع أن تحصل جميع المفاهيم الأخرى على نتائج تحليل المفاهيم المنشأة منخفضة (مما يشير إلى حساسية سلبية)، حيث أن وجودها يجعل الفئة أقل احتمالاً، أو نتائج تحليل المفاهيم المنشأة غير مهمة، إذا كان المفهوم غير معلوم.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<p>النتائج لـ <span class="math inline">\(\E_1\)</span> و <span class="math inline">\(\E_2\)</span> معروضة في الأعلى والأسفل على التوالي. بالنسبة لـ <span class="math inline">\(\E_1\)</span> (مجموعة البيانات غير المعدلة)، نجد أن متجهات و فقط لديها نتيجة تحليل المفاهيم المنشأة عالية عبر طبقات متعددة. بالنسبة لـ <span class="math inline">\(\E_2\)</span> (مجموعة البيانات المعدلة)، ومع ذلك، يبدو أن النموذج حساس لـ ، و ، مع نتائج تحليل المفاهيم المنشأة عالية لكل منها. هذا بسبب الارتباط بين متجهات المفاهيم المنشأة للأحمر والمثلث. <span class="nodecor">2,374/5,000</span> صورة في مجموعة البيانات الاختبارية تحتوي على مثلثات مخططة. لم يتم تصنيف أي من هذه بشكل غير صحيح، لذا من غير المحتمل أن يستخدم النموذج مفهوم الأحمر لتوقعها. بدلاً من ذلك، يؤدي الارتباط بين متجهات المفاهيم المنشأة إلى نتيجة تحليل المفاهيم المنشأة مرتفعة بشكل مضلل لمفهوم الأحمر. في الختام، يمكن أن تؤدي متجهات المفاهيم المنشأة المرتبطة إلى تفسيرات مضللة.</p>
<h2 id="sec: Spatial">الاعتماد المكاني</h2>
<p>أخيراً، نحقق في NH3: <em>هل تعتمد CAVs مكانياً؟</em> نعيد تشكيل CAVs إلى الشكل الأصلي للتنشيطات، ونحسب القاعدة القنوية كما يلي: <span class="math display">\[\mathbf{S}_{c, l} = \|\mathrm{reshape}(\vcl, (H, W, D))\|_2,\]</span> حيث <span class="math inline">\(\mathbf{S}_{c, l} \in \R^{H \times W}\)</span>، و<span class="math inline">\(\| \cdot \|_2\)</span> هي قاعدة <span class="math inline">\(L_2\)</span> عبر بعد القناة. نشير إلى هذا المصفوف كقواعد مكانية لـ CAV.</p>
<p>إذا تباينت القاعدة المكانية لـ CAV بشكل كبير عبر أبعاد <span class="math inline">\((H, W)\)</span>، فهذا يدل على أن CAV تعتمد مكانياً (انظر الملحق [app: Spatial Norms] للحصول على تفسير). تصور القواعد المكانية لـ CAV يظهر لنا أي المناطق تساهم أكثر في المشتقة الاتجاهية وبالتالي في نتيجة TCAV.</p>
<p>لإنشاء CAVs التي تعتمد مكانياً، قمنا ببناء مجموعات بيانات استقصائية مكانياً للعناصر وImageNet حيث قمنا إما بتقييد موقع المفاهيم أو بتغميق أجزاء من الصورة - انظر [fig: elements examples] للأمثلة والملحق [app: Spatially dependent probes] لمزيد من التفاصيل.</p>
<p>عند استخدام مجموعة بيانات استقصائية مكانياً مستقلة لإنشاء CAVs، كما في الصف العلوي من [fig: mean spatial norms]، تكون القواعد المكانية موحدة، مما يشير إلى أن CAVs لا تعتمد مكانياً<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>. ومع ذلك، عندما تظهر مجموعة البيانات الاستقصائية اعتماداً مكانياً، فإن CAVs الناتجة تفعل ذلك أيضاً. المناطق ذات القاعدة القريبة من الصفر تشير إلى أن المناطق المكانية المقابلة من التدرجات لا تساهم في المشتقة الاتجاهية وبالتالي في نتيجة TCAV.</p>
<p>بعد ذلك، نحقق في السؤال <em>هل للنموذج حساسية مفاهيمية مختلفة تعتمد على موقع المفاهيم في صورة الإدخال؟</em> بما أن CAVs تعمل في فضاء التنشيط لطبقة محددة، يمكننا أن نظهر أن النموذج ليس ثابت الترجمة إذا:</p>
<ol>
<li><p>للنموذج اعتماد مكاني للتنشيط، تؤثر البكسلات في مواقع مختلفة على التنشيطات بشكل مختلف.</p></li>
<li><p>أن كل شريحة عمقية من التنشيطات، بشكل <span class="math inline">\((1, 1, D)\)</span>، تؤثر على الإخراج اللوجيت بشكل مختلف.</p></li>
</ol>
<p>كلا هذين العنصرين يؤثران في نتيجة TCAV. (1) يؤثر على <span class="math inline">\(\vcl\)</span> و(2) يؤثر على <span class="math inline">\(\nabla h_{l, k}\left(g_{l}(\vx)\right)\)</span>. لمعالجة (2)، نحسب نتائج TCAV لمجموعات مختلفة من CAVs التي تعتمد مكانياً لتحديد ما إذا كانت حساسية النموذج تتغير بناءً على موقع المفاهيم. للتحقيق في هذا، قمنا بإنشاء فئات تعتمد مكانياً في مجموعة بيانات العناصر، حيث تعتمد الفئة على المفاهيم الموجودة <em>و</em> على مكانها في الصورة، مثل ’مثلثات مخططة على اليسار’. نستخدم CAVs التي تعتمد مكانياً لإظهار أن النموذج ليس ثابت الترجمة بالنسبة لـ أو في [fig:spatial tcav scores elements]. هنا، نناقش النتائج لفئة ’مثلثات مخططة على اليسار’. نتائج TCAV لـ ، ، و مرتفعة، مما يشير إلى تأثير إيجابي لهذه المفاهيم على الفئة. ومع ذلك، فإن نتائج TCAV لـ و غالباً لا تختلف بشكل كبير عن النتائج الصفرية، مما لا يوفر أدلة تشير إلى أن النموذج حساس لهذه المفاهيم. الفرق بين نتائج TCAV المتحيزة لليمين واليسار يشير إلى أن النموذج ليس ثابت الترجمة بالنسبة لهذه المفاهيم حيث تعتمد حساسية النموذج على مكان وجود المفهوم في فضاء إدخال الصورة. بشكل عام، هذا يشير إلى أنه يمكننا استخدام CAVs للكشف عن ثبات الترجمة للنموذج. انظر الملحق [app: Spatial TCAV] لأمثلة على ImageNet.</p>
<h1 id="توصيات-الممارسين">توصيات الممارسين</h1>
<p>نتائجنا أظهرت أن الفشل في الأخذ بعين الاعتبار الاتساق، التشابك، والاعتماد المكاني قد يؤدي إلى استنتاجات خاطئة عند استخدام تحليل المفاهيم المعتمد على التفعيل. لذلك، نوصي بما يلي:</p>
<ul>
<li><p><em>الاتساق</em>: إنشاء متجهات المفاهيم المعتمدة على التفعيل لطبقات متعددة، بدلاً من طبقة واحدة؛</p></li>
<li><p><em>التشابك</em>: (1) التحقق من الاعتماديات المتوقعة بين المفاهيم ذات الصلة، و(2) الانتباه إلى أن درجة تحليل المفاهيم المعتمدة على التفعيل الإيجابية قد تكون بسبب تشابك المفاهيم؛</p></li>
<li><p><em>الاعتماد المكاني</em>: تصور الاعتماد المكاني لمتجه المفهوم باستخدام القواعد المكانية.</p></li>
</ul>
<p>في القسم [sec: related work]، قدمنا أوراق بحثية تستخدم متجهات المفاهيم المعتمدة على التفعيل وقد تتأثر بالخصائص المذكورة أعلاه. كمثال أكثر تحديداً، نفحص حالة استخدام يان وآخرون (<span class="nodecor">Yan2023SkinCancer</span>) التي تستخدم متجهات المفاهيم المعتمدة على التفعيل في سياق تشخيص سرطان الجلد. بعض المفاهيم لها اعتماديات مكانية متوقعة، على سبيل المثال، <code>الحدود الداكنة</code> و<code>الزوايا الداكنة</code>. يمكن استخدام القواعد المكانية لتأكيد وجود هذه الاعتماديات المكانية. كذلك، بالنسبة لمفاهيم مثل وجود <code>مسطرة</code>، يمكن للقواعد المكانية تأكيد أن متجهات المفاهيم المعتمدة على التفعيل لا تمتلك اعتماداً مكانياً عاماً. هناك مفاهيم متعددة لها معانٍ متعارضة، على سبيل المثال <code>الخطوط المنتظمة</code> و<code>الخطوط غير المنتظمة</code>. يمكن للتشابهات الجيبية بين متجهات المفاهيم المعتمدة على التفعيل تأكيد أن هذه المفاهيم مرتبطة سلبياً أو على الأقل أقل تشابهاً مع بعضها البعض مقارنة بمفاهيم أخرى. نقدم تحليلاً أكثر تفصيلاً لهذه الحالة في الملحق [app: Example UseCase].</p>
<h1 id="الخلاصة-والأعمال-المستقبلية">الخلاصة والأعمال المستقبلية</h1>
<p>في هذا العمل، نستكشف ثلاث خصائص رئيسية تؤثر على متجهات تنشيط المفاهيم (CAVs): الاتساق، التشابك، والاعتماد المكاني. أولاً، نستنتج الشروط التي تحتها لا تكون متجهات تنشيط المفاهيم في طبقات مختلفة متسقة وندعم نتائجنا بأدلة تجريبية. هذا يسلط الضوء على سبب تقديم طرق التفسير المبنية على CAVs استنتاجات متعارضة عبر الطبقات. بعد ذلك، نقدم أداة تصوير مصممة لتسهيل استكشاف الارتباطات بين المفاهيم داخل مجموعة البيانات والنموذج. أخيراً، نظهر أن الاعتماد المكاني يؤثر على متجهات تنشيط المفاهيم، ونقدم طريقة يمكن استخدامها لكشف الاعتماد المكاني داخل النماذج. تم إجراء كل هذه التجارب باستخدام مجموعة بيانات اصطناعية، العناصر، حيث يمكن إنشاء مجموعات بيانات استقصائية مخصصة بسهولة لتحليل الخصائص ذات الاهتمام. نحن نطلق هذه المجموعة للمساعدة في استكشاف هذا المجال الإشكالي بشكل أكبر.</p>
<p>في المقدمة، ذكرنا عدة طرق تفسير تُستخدم تمثيلات المتجه لنقل المفاهيم ذات المعنى الدلالي. لقد أضاءت دراستنا بعض الخصائص والنتائج الناجمة عن هذه النهج المبنية على المتجه. في البحوث المستقبلية، ينبغي التحقيق في الخصائص الكامنة في أشكال بديلة من التمثيل، مثل العناقيد داخل فضاء التنشيط (<span class="nodecor">crabbe2022</span>)، وتقييم الفضائل النسبية.</p>
<h1 id="الشكر-والتقدير">الشكر والتقدير</h1>
<p>نحن نقدر كل أعضاء مجموعة OATML ومجموعة Noble لدعمكم ومناقشاتكم خلال المشروع، وبشكل خاص أندرو جيسون. نحن ممتنون أيضاً لبين كيم لأفكاركم وتعليقاتكم على عملنا. يدعم A. Nicolson من قبل مركز EPSRC للتدريب الدكتوراه في علوم البيانات الصحية (<span class="nodecor">EP/S02428X/1</span>). تعترف J.A. Noble بمنح EPSRC <span class="nodecor">EP/X040186/1</span> و <span class="nodecor">EP/T028572/1</span>.</p>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>بافتراض أن النموذج يستخدم كل مفهوم بشكل صحيح<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>قد تظل CAVs الفردية تعتمد مكانياً، ولكن هذا يُلغى عبر تشغيلات التدريب. انظر الملحق [app: Individual Spatial Norms] للتفاصيل.<a href="#fnref2">↩</a></p></li>
</ol>
</section>
</body>
</html>
