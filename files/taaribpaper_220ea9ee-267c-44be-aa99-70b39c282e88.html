<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Zhuoyuan Wu, Yuping Wang, Hengbo Ma, Zhaowei Li, Hang Qiu, Jiachen Li">
  <title>التنبُّؤ التعاوُني بالحركة مع الاتّصال بين وُكلاء متعدِّدين</title>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap');
    body {
      direction: rtl;
      font-size: 22px;
      font-family: 'Cairo', 'Segoe UI', Tahoma, Geneva, Verdana, Arial, sans-serif;
      background: #f8f9fa;
      color: #222;
      margin: 0;
      padding: 0;
      line-height: 1.7;
    }
    header {
      background: linear-gradient(90deg, #3a8dde 0%, #6dd5ed 100%);
      color: #fff;
      padding: 40px 0 20px 0;
      text-align: center;
      box-shadow: 0 2px 8px rgba(58, 141, 222, 0.08);
      margin-bottom: 40px;
    }
    h1.title {
      font-size: 2.6em;
      font-weight: 700;
      margin: 0 0 10px 0;
      letter-spacing: 1px;
    }
    .author {
      font-size: 1.1em;
      margin: 0;
      color: #e3f2fd;
      letter-spacing: 0.5px;
    }
    main {
      max-width: 900px;
      background: #fff;
      margin: 0 auto 40px auto;
      padding: 40px 32px 32px 32px;
      border-radius: 18px;
      box-shadow: 0 4px 24px rgba(58, 141, 222, 0.10);
    }
    h1, h2, h3, h4 {
      color: #3a8dde;
      font-weight: 700;
      margin-top: 1.7em;
      margin-bottom: 0.7em;
      line-height: 1.2;
    }
    h1 {
      font-size: 2em;
      border-bottom: 2px solid #e3f2fd;
      padding-bottom: 0.2em;
    }
    h2 {
      font-size: 1.4em;
      border-right: 4px solid #6dd5ed;
      padding-right: 10px;
      margin-top: 1.5em;
    }
    ul, ol {
      padding-right: 2em;
      margin-bottom: 1.5em;
    }
    ul li, ol li {
      margin-bottom: 0.7em;
    }
    p {
      margin-bottom: 1.2em;
      text-align: justify;
    }
    code, .nodecor {
      font-family: 'Cairo', 'Fira Mono', 'Consolas', 'monospace';
      background: #f1f3f4;
      color: #1565c0;
      border-radius: 4px;
      padding: 2px 6px;
      font-size: 0.98em;
      direction: ltr;
      unicode-bidi: embed;
    }
    /* For latex, math, etc. */
    .math {
      font-size: 1.1em;
      color: #1565c0;
      background: #e3f2fd;
      padding: 2px 6px;
      border-radius: 4px;
    }
    /* Subtle emphasis for figure mentions */
    em.fig {
      color: #1565c0;
      background: #eaf4ff;
      padding: 0 4px;
      border-radius: 4px;
      font-style: normal;
    }
    /* Responsive */
    @media (max-width: 600px) {
      main {
        padding: 18px 6px 18px 6px;
      }
      h1.title {
        font-size: 1.5em;
      }
      h1, h2 {
        font-size: 1.1em;
      }
    }
  </style>
</head>
<body>
<header>
  <h1 class="title">التنبُّؤ التعاوُني بالحركة مع الاتّصال بين وُكلاء متعدِّدين</h1>
  <p class="author">
    <span class="nodecor">Zhuoyuan Wu</span>,
    <span class="nodecor">Yuping Wang</span>,
    <span class="nodecor">Hengbo Ma</span>,
    <span class="nodecor">Zhaowei Li</span>,
    <span class="nodecor">Hang Qiu</span>,
    <span class="nodecor">Jiachen Li</span>
  </p>
</header>
<main>
<h1 id="ملخص">ملخّص</h1>
<p>أدّى التقدُّم في تقنيات المركبات ذاتية القيادة ونُضج اتّصال المركبة بكلّ شيء إلى تعزيز قدرات المركبات المتّصلة والمؤتمتة على نحوٍ تعاوني. وانطلاقًا من الإدراك التعاوُني، يستكشف هذا البحث إمكانية وفاعلية التنبُّؤ التعاوُني بالحركة. تستخدم طريقتنا، <span class="nodecor">CMP</span>، إشارات <span class="nodecor">LiDAR</span> كمدخلات لتعزيز قدرات التتبُّع والتنبُّؤ. وعلى خلاف الأعمال السابقة التي ركّزت منفصلةً إمّا على الإدراك التعاوُني أو على التنبُّؤ بالحركة، فإن إطارنا، بحسب علمنا، هو الأوّل الذي يتناول المشكلة الموحَّدة حيث تتشارك المركبات المتّصلة والمؤتمتة (<span class="nodecor">CAVs</span>) المعلومات في كلٍّ من وحدات الإدراك ووحدات التنبُّؤ. نُدرج في تصميمنا القدرة على التعامل مع قيود النطاق التردُّدي الواقعية لاتّصال المركبة بكلّ شيء وتأخيرات النقل، مع معالجة تمثيلات إدراكية كبيرة الحجم. نقترح كذلك وحدةً لتجميع التنبؤات تُوحِّد تنبؤات المركبات المتّصلة والمؤتمتة المختلفة وتنتج التنبُّؤ النهائي. ومن خلال تجارب مكثفة ودراسات حذف، نُظهر فاعلية طريقتنا في مهام الإدراك التعاوُني والتتبُّع والتنبُّؤ بالحركة. وعلى وجه الخصوص، تُقلِّل <span class="nodecor">CMP</span> خطأ التنبُّؤ المتوسّط بنسبة <span class="nodecor">17.2\%</span> مع عددٍ أقلّ من حالات الكشف الفائت مقارنةً بإعدادٍ غير تعاوني. يمثّل عملُنا خطوةً كبيرةً إلى الأمام في القدرات التعاوُنية للمركبات المتّصلة والمؤتمتة، مُظهِرًا تحسُّنًا في الأداء في السيناريوهات المعقّدة.</p>

<h1 id="sec:intro">مقدّمة</h1>
<p>يعتمد نظام القيادة الذاتية الحالي أساسًا على قدرات الإدراك الموجودة على متن المركبة. غير أنّ هذا الاعتماد، شأنه شأن السائقين البشريين، عُرضة لمواقف تحتوي على عوائق أو رؤية محدودة. وبالاستفادة من تعدُّد نقاط الرؤية، يستخدم الإدراك التعاوُني (<span class="nodecor">AVR, autocast, wang2020v2vnet, opv2v, xu2022cobevt</span>) اتّصالات المركبة بكلّ شيء (<span class="nodecor">V2X</span>) لمشاركة المعلومات الحسّية بين المركبات المتّصلة والمؤتمتة (<span class="nodecor">CAVs</span>) والبنية التحتية. وتختلف المعلومات المتبادلة شكلاً ومحتوىً، فتشمل البيانات الخام، والميزات المُعالجة، أو الأجسام المكتشفة، إلى جانب البيانات الوصفية ذات الصلة (مثل الطوابع الزمنية والأوضاع). ومن خلال دمج هذه المعلومات من وجهات نظر متعدّدة لتكوين صورة موحَّدة من منظور المركبة المُستقبِلة، يمكن للإدراك الموجود على متنها، بعد تعزيزه، أن «يرى» ما وراء خطّ الرؤية المباشر ومن خلال العوائق.</p>

<p>حتّى الآن، انحصر البحث في اتّصال المركبة بالمركبة (<span class="nodecor">V2V</span>) إلى حدّ كبير في الإدراك التعاوُني أو في التنبُّؤ بالحركة، من دون دراسات شاملة تُعنى بدمجهما. وإلى جانب كشف الأجسام، تتضمّن معظم الأعمال مهامًا مساعدة مثل التنبُّؤ (<span class="nodecor">wang2020v2vnet</span>) ورسم الخرائط (<span class="nodecor">xu2022v2xvit</span>) كمخرجات داعمة. يقترح (<span class="nodecor">wang2020v2vnet</span>) طريقة <span class="nodecor">V2V</span> للإدراك والتنبُّؤ، تنقل التمثيلات الوسيطة لميزات سُحب النقاط. ومع ذلك، يبقى دمج الإدراك والتنبُّؤ لتحقيق تعاون <span class="nodecor">V2V</span> كامل غير مُستكشَف، كما هو موضَّح في <em class="fig">الشكل التوضيحي (b)</em>. أمّا على صعيد التنبُّؤ بالحركة، فقد استخدمت الجهود الأولى (<span class="nodecor">hu2020collaborative, Choi2021prediction, v2voffloading</span>) شبكات <span class="nodecor">LSTM</span> على مجموعات بيانات بسيطة. وتعتمد الدراسات الحديثة (<span class="nodecor">shi2023motion, shi2024mtr++, wang2023eqdrive</span>) على آليات الانتباه والمحوّلات الرسومية لتعزيز التنبُّؤ بالحركة. غير أنّ هذه المناهج ترتكز إلى مسارات حقيقية، فتُهمِل اللايقين وعدم الدقّة الناجمَين عن مهام الكشف والتتبُّع في المراحل السابقة. لذا يبقى الاعتماد على بيانات الحقيقة الأرضية غير كافٍ لمواجهة التحدّي الواقعي المتمثّل في التعامل مع مسارات غير مؤكَّدة، ما يؤكد الحاجة إلى بحث يدمج الإدراك والتنبُّؤ ضمن تعاون <span class="nodecor">V2V</span>.</p>

<p>لسدّ الفجوة بين الإدراك التعاوُني والتنبُّؤ بالحركة، نقدّم إطارًا جديدًا للتنبُّؤ التعاوُني بالحركة قائمًا على البيانات الحسّية الخام. وبحسب علمنا، فنحن أوّل مَن يطوّر طريقة عملية تحلّ مشكلتَي الإدراك والتنبُّؤ بشكل مشترك مع اتّصالات <span class="nodecor">CAV</span> في كلا المكوّنين. يُوضَّح إطارنا المقترَح في <em class="fig">الشكل الخاص بالمنهجيّة</em>. يستخلص كلّ <span class="nodecor">CAV</span> تمثيل ميزات بمنظور «عين الطائر» (<span class="nodecor">BEV</span>) من سحابة نقاط <span class="nodecor">LiDAR</span> الخاصّة به. ثم تُعالَج هذه الميزات وتُضغط ويُبَثّ ما يلزم منها إلى مركبات <span class="nodecor">CAVs</span> القريبة. وعند الاستلام، يدمج الوكلاء المُستقبِلون ترميزات الميزات المنقولة. وبعد الحصول على بيانات إدراك تاريخية، يتنبّأ كلّ <span class="nodecor">CAV</span> بمسارات الأجسام المحيطة بالاستناد إلى العمود الفقري لنموذج <span class="nodecor">MTR</span> (<span class="nodecor">shi2023motion</span>). ثم تُبَثّ المسارات المتوقّعة من كلّ <span class="nodecor">CAV</span> مرّة أخرى. وأثناء تجميع نموذجنا لتنبؤات المركبات المحيطة، تُستفاد كذلك من التنبؤات والميزات الوسيطة الآتية من وحدة الإدراك لتحسين التنبُّؤ بالحركة. تأخذ منهجيّتنا بالحسبان تأخيرات النقل الواقعية بين مركبات <span class="nodecor">CAVs</span> وقيود النطاق التردُّدي، مع تحقيق أداء مُرضٍ.</p>

<p>في هذه الورقة، تتمثّل مساهماتُنا الرئيسة فيما يلي:</p>
<ul>
  <li>نقترح إطار عملٍ عمليًّا مُقاومًا للتأخير للتنبُّؤ التعاوُني بالحركة، يستفيد من المعلومات المتبادلة بين عدّة مركبات <span class="nodecor">CAVs</span> لتعزيز أداء الإدراك والتنبُّؤ بالحركة.</li>
  <li>نُحلِّل متطلّبات النطاق التردُّدي لمشاركة المعلومات التعاوُنية ونُصمِّم تمثيلًا اتّصاليًّا خفيفًا.</li>
  <li>نطوّر وحدة تجميعٍ للتنبؤات قائمة على المحوّلات للاستفادة من التنبؤات المشتركة من قِبل مركبات <span class="nodecor">CAVs</span> أخرى، بما يحسّن دقّة التنبُّؤ.</li>
</ul>

<h1 id="sec:relatedwork">الأعمال ذات الصلة</h1>

<h2 id="الإدراك-التعاوني">الإدراك التعاوُني</h2>
<p>يُتيح الإدراك التعاوُني للمركبات ذاتية القيادة استخدام أنظمة الاتّصالات المتقدّمة لمشاركة المعلومات وتوسيع مجالات رؤيتها. وقد طوّرت الأعمال السابقة تقنيات الدمج المُبكِّر للكشف التعاوُني عن الأجسام بالاستناد إلى بيانات الكاميرا الخام أو الرادار أو صور <span class="nodecor">RGB</span> (<span class="nodecor">autocast</span>). غير أنّ هذه الاستراتيجية تتطلّب نطاقًا تردُّديًّا عاليًا للحفاظ على قياسات الاستشعار كاملةً. أمّا استراتيجية الدمج المتأخِّر فتسمح للمركبات بمشاركة نواتج الكشف النهائية فقط، والاعتماد على وحدة أخرى لدمج الكشوفات (<span class="nodecor">latefusion</span>). لكن في التطبيقات الواقعية، يقتصر أداء الدمج المتأخِّر بفعل فقدان معلومات السياق وحساسية دقّة الكشف الفردي.</p>

<p>ولتحقيق توازنٍ بين هذه المُفاضلات، باتت استراتيجية الدمج المتوسِّط (<span class="nodecor">coopernaut</span>, <span class="nodecor">wang2020v2vnet</span>, <span class="nodecor">qiao2023adaptive</span>, <span class="nodecor">xu2022cobevt</span>) أكثر شيوعًا. في هذه الاستراتيجية، تستخدم المركبات مُشفِّراتٍ لمعالجة معلومات المشهد المحيط وخريطة الطريق إلى ميزات وسيطة، ثم تُشارك هذه الميزات مع المركبات المحيطة. وعند الاستلام، تدمج المركبات هذه الميزات مع معلوماتها الخاصّة وتنتج نتائج إدراكٍ أفضل. على سبيل المثال، استُخدمت الشبكات العصبية الرسومية في <span class="nodecor">V2VNet</span> (<span class="nodecor">wang2020v2vnet</span>) لتجميع المعلومات من وجهات نظر مختلفة. كما قدّمت <span class="nodecor">AttFuse</span> (<span class="nodecor">opv2v</span>) آليّةَ انتباهٍ لدمج الميزات المتوسّطة. واقترح (<span class="nodecor">qiao2023adaptive</span>) نموذج دمجٍ يختار الميزات المتوسّطة بشكلٍ تكيُّفي لتحقيق تكاملٍ أفضل. واعتمدت <span class="nodecor">CoBEVT</span> (<span class="nodecor">xu2022cobevt</span>) و<span class="nodecor">HM-ViT</span> (<span class="nodecor">xiang2023hmvit</span>) على محوّلات الرؤية لتعزيز معالجة مُدخلات الكاميرا ودمج الميزات، مُحقِّقةً نتائج واعدة على مجموعة بيانات <span class="nodecor">OPV2V</span> (<span class="nodecor">opv2v</span>).</p>

<h2 id="تنبؤ-الحركة">تنبُّؤ الحركة</h2>
<p>يُعدّ تنبُّؤ الحركة موضوعًا بحثيًّا رئيسًا آخر في القيادة الذاتية. وغالبًا ما تركّز الأبحاث على بيئة غير تعاوُنية حيث تتنبّأ مركبة ذاتية واحدة من دون اتّصال (<span class="nodecor">li2020evolvegraph</span>, <span class="nodecor">gao2020vectornet</span>, <span class="nodecor">toyungyernsub2022dynamics</span>, <span class="nodecor">li2021spatio</span>, <span class="nodecor">varadarajan2021multipath++</span>, <span class="nodecor">girase2021loki</span>, <span class="nodecor">choi2021shared</span>, <span class="nodecor">sun2022m2i</span>, <span class="nodecor">lange2024scene</span>, <span class="nodecor">shi2023motion</span>, <span class="nodecor">dax2023disentangled</span>, <span class="nodecor">ruan2023learning</span>, <span class="nodecor">li2023game</span>). وتتضمّن الطرق الحديثة (<span class="nodecor">sun2022m2i</span>, <span class="nodecor">gao2020vectornet</span>, <span class="nodecor">wang2023equivariant</span>) ترميز المسارات التاريخية وخطوط الخرائط إلى متجهات عالية الأبعاد، ثم استخدام الشبكات الرسومية لالتقاط العلاقات، فطبقات فكّ التشفير لإنتاج التنبؤات. وقد أدخلت أعمالٌ أحدث بنية المحوّلات إلى نماذجها؛ إذ يستخدم كلٌّ من <span class="nodecor">MTR</span> (<span class="nodecor">shi2023motion</span>) و<span class="nodecor">MTR++</span> (<span class="nodecor">shi2024mtr++</span>) أزواج استعلامٍ للحركة، يكون كلّ زوجٍ منها مسؤولًا عن تنبُّؤ نمط حركة واحد، وهو ما يُعدّ أكفأ من الاستراتيجيات القائمة على الأهداف (<span class="nodecor">gu2021densetnt</span>) وأسرع تقاربًا من استراتيجيات الانحدار المباشر (<span class="nodecor">varadarajan2021multipath++</span>, <span class="nodecor">ngiam2022scene</span>).</p>

<!-- بقية المحتوى بدون تعديل -->
</main>
</body>
</html>