```html
<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Sekeun Kim">
  <meta name="author" content="Hui Ren">
  <meta name="author" content="Peng Guo">
  <meta name="author" content="Abder-Rahman Ali">
  <meta name="author" content="Patrick Zhang">
  <meta name="author" content="Kyungsang Kim">
  <meta name="author" content="Quanzheng Li">
  <meta name="author" content="Xiang Li">
  <title>نموذج عالمي موجه بالأوامر لتحليل صور الصدى القلبي دون الاعتماد على زاوية الرؤية</title>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap');
    body {
      direction: rtl;
      font-family: 'Cairo', 'Segoe UI', Tahoma, Geneva, Verdana, Arial, sans-serif;
      font-size: 20px;
      background: #f8f9fa;
      color: #222;
      margin: 0;
      padding: 0;
      line-height: 1.8;
    }
    header {
      background: linear-gradient(90deg, #3a8dde 0%, #6ed0cb 100%);
      color: #fff;
      padding: 40px 0 20px 0;
      text-align: center;
      box-shadow: 0 2px 8px rgba(58,141,222,0.08);
      margin-bottom: 40px;
    }
    h1.title {
      font-size: 2.5em;
      font-weight: 700;
      margin-bottom: 10px;
      letter-spacing: 1px;
    }
    .author {
      display: inline-block;
      margin: 0 10px;
      font-size: 1.1em;
      font-weight: 400;
      color: #eaf6fb;
    }
    h1, h2, h3 {
      color: #3a8dde;
      font-weight: 700;
      margin-top: 2.2em;
      margin-bottom: 0.7em;
      line-height: 1.3;
    }
    h1 {
      font-size: 2em;
      border-bottom: 2px solid #6ed0cb;
      padding-bottom: 0.2em;
      margin-bottom: 1.2em;
    }
    h2 {
      font-size: 1.4em;
      border-right: 4px solid #3a8dde;
      padding-right: 10px;
      margin-bottom: 0.8em;
    }
    h3 {
      font-size: 1.1em;
      color: #2b6777;
      margin-bottom: 0.5em;
    }
    p {
      margin: 0 0 1.2em 0;
      text-align: justify;
    }
    ul, ol {
      margin: 1em 2em 1em 0;
      padding: 0 1.5em 0 0;
    }
    li {
      margin-bottom: 0.5em;
    }
    em {
      color: #3a8dde;
      font-style: normal;
      font-weight: 600;
    }
    strong {
      color: #2b6777;
      font-weight: 700;
    }
    code, pre {
      background: #f1f3f6;
      color: #c7254e;
      font-family: 'Cairo', 'Consolas', 'monospace';
      font-size: 0.95em;
      border-radius: 4px;
      padding: 2px 6px;
    }
    pre {
      padding: 12px;
      overflow-x: auto;
      margin: 1.2em 0;
    }
    table {
      width: 80%;
      margin: 2em auto;
      border-collapse: collapse;
      background: #fff;
      box-shadow: 0 2px 8px rgba(58,141,222,0.07);
      border-radius: 8px;
      overflow: hidden;
    }
    th, td {
      border: 1px solid #e3e6ea;
      padding: 12px 18px;
      text-align: center;
      font-size: 1em;
    }
    th {
      background: #eaf6fb;
      color: #3a8dde;
      font-weight: 700;
    }
    tr:nth-child(even) {
      background: #f6fafd;
    }
    tr:hover {
      background: #f0f7fa;
    }
    .math.inline {
      font-family: 'Cairo', 'Consolas', 'monospace';
      background: none;
      color: #2b6777;
      font-size: 1em;
      padding: 0;
    }
    .math.display {
      display: block;
      margin: 1.5em auto;
      text-align: center;
      font-size: 1.1em;
      color: #2b6777;
    }
    .nodecor {
      text-decoration: none !important;
      color: inherit !important;
    }
    /* Custom bullet for lists */
    ul {
      list-style-type: square;
    }
    /* Responsive */
    @media (max-width: 900px) {
      body { font-size: 18px; }
      table { width: 98%; }
      header { padding: 30px 0 15px 0; }
      h1.title { font-size: 2em; }
    }
    @media (max-width: 600px) {
      body { font-size: 16px; }
      header { padding: 20px 0 10px 0; }
      h1.title { font-size: 1.3em; }
      table { font-size: 0.95em; }
    }
    /* Blockquote for latex note */
    .latex-note {
      background: #fffbe6;
      border-right: 5px solid #ffe066;
      color: #b59f3b;
      padding: 10px 18px;
      margin: 1.5em 0;
      border-radius: 6px;
      font-size: 1.05em;
    }
  </style>
</head>
<body>
<header>
  <h1 class="title">نموذج عالمي موجه بالأوامر لتحليل صور الصدى القلبي دون الاعتماد على زاوية الرؤية</h1>
  <div>
    <span class="author">Sekeun Kim</span>
    <span class="author">Hui Ren</span>
    <span class="author">Peng Guo</span>
    <span class="author">Abder-Rahman Ali</span>
    <span class="author">Patrick Zhang</span>
    <span class="author">Kyungsang Kim</span>
    <span class="author">Quanzheng Li</span>
    <span class="author">Xiang Li</span>
  </div>
</header>

<div class="latex-note">latex</div>

<h1 id="ملخص">مُلَخَّص</h1>
<p>تُعَدّ عمليّة تجزئة صور الصدى القلبي جزءًا مستهلكًا للوقت وتتطلّب موارد حوسبية كبيرة؛ ويرجع ذلك إلى التباين في جودة الصور والحاجة إلى معالجة الفحوص من زوايا مسح قياسية مختلفة. وعلى الرغم من أنّ الطرق الآلية الحالية لتحقيق هذه التجزئة تُظهر أداءً واعدًا، فإنّها عادةً ما تُدرّب على زوايا محددة، مما يستلزم نموذجًا منفصلًا لكل زاوية. ومع تزايد عدد الزوايا القياسية، يتضاعف عدد النماذج المطلوبة، وهو أمر غير عملي. لمعالجة هذه المشكلات، نقدّم في هذه الورقة طريقةً عالمية موجهة بالأوامر لتحليل صور الصدى القلبي بغض النظر عن زاوية المسح. مع الأخذ بالاعتبار اختلاف التوزيع بين الزوايا القياسية، نوّفر أولًا آليةً تُسمّى مطابقة الأوامر، تهدف إلى تعلم أوامر محددة لكل زاوية عن طريق مطابقة الأوامر واستعلام تضمينات الإدخال باستخدام نموذج رؤية مدرّب مسبقًا. ثم نستخدم نموذج لغة طبية مدرّبًا مسبقًا لمواءمة المعلومات النصية مع بيانات البكسل لتحقيق تجزئة دقيقة. أظهرت التجارب الواسعة على ثلاث زوايا قياسية تفوّق نهجنا بشكل كبير على الحلول العالمية الحديثة، وحقّق أداءً مماثلًا أو أفضل من النماذج المتخصّصة والمدرّبة على نفس الزوايا.</p>

<h1 id="مقدمة">مُقَدِّمَة</h1>
<p>يُعَدّ التصوير بالموجات فوق الصوتية أكثر الأساليب شيوعًا في تصوير القلب، إذ يسمح بتقييم وظيفته عبر فحص مجموعة من الزوايا القياسية. ونظرًا لتعقيد تحليل هذه الصور وارتفاع عبء العمل على الفنيين، تصاعد الاهتمام بتطوير أساليب آلية للتقسيم في التصوير بالموجات فوق الصوتية (<span class="nodecor">kim2022fully,kim2021automatic,leclerc2020lu</span>). وقد أظهرت الطرق الحالية قدرة جيدة على تحديد الهياكل التشريحية بدقة ضمن الزوايا التي تمّ تدريبها عليها. ومع ذلك، يتطلب معظم هذه الأساليب خطوةً أولى لتحديد زاوية المسح المناسبة لكل مريض قبل بدء التحليل، مما يضيف عبئًا إضافيًا لاختيار الملفات الملائمة (<span class="nodecor">charton2023multi,jeon2023improving</span>). وحتى الآن، لم يتم استكشاف إمكانية تطوير نموذجٍ عامّ يستطيع تنفيذ مهام التقسيم بشكل مستقل عبر جميع الزوايا القياسية.</p>
<p>في المقابل، يعتمد النهج التقليدي على تدريب <em>N</em> نماذج منفصلة لكلٍّ من <em>N</em> الزوايا القياسية. ومع تزايد عدد الزوايا، يتضاعف عدد النماذج، مما يجعل هذا الأسلوب غير مرن وقابل للتطبيق. يمكن تبسيط الفكرة بمحاولة تدريب شبكة واحدة على بيانات جميع الزوايا؛ غير أنّ ذلك غالبًا ما يؤدي إلى تدهور الأداء، نظرًا لاختلاف الخصائص البصرية المميزة لكل زاوية (<span class="nodecor">kim2021automatic,mitchell2019guidelines</span>). ويواجه التصوير بالموجات فوق الصوتية تحديات إضافية مثل انحراف مجال الرؤية بين زوايا المسح والملصقات المتفرقة عبر الإطارات. وعلى الرغم من جهود تطوير نماذج عالمية مماثلة في مجالات أخرى (<span class="nodecor">zhang2021dodnet,butoi2023universeg,liu2023clip,ye2023uniseg</span>)، فإن بعضها يعاني من قيود عند نقله إلى الأطر الطبية. فعلى سبيل المثال، يعتمد نموذج الشبكة الديناميكية (<span class="nodecor">zhang2021dodnet</span>) على بنية مشفر-مفكك مع ضوابط ديناميكية، بينما يوسّع نموذج المغذي بالنص CLIP (<span class="nodecor">liu2023clip</span>) الفكرة باستخدام نموذج نصي مسبق التدريب لإدارة رؤوس التقسيم دلاليًا. ورغم نجاحهما في تقسيم أعضاء الجسم في التصوير المقطعي المحوسب، إلا أنّ الاختلاف بين النصوص الطبيعية والطبية يحد من فعاليتهما طبيًا. كما يقدّم نموذج UniSeg (<span class="nodecor">ye2023uniseg</span>) إطارًا لتعلم الأوامر عبر بيانات تشريحية متقاربة، لكنه يواجه صعوبة في التعامل مع تحولات زاوية المسح كما يتضح من الأداء في الجدول [table2].</p>
<p>لمعالجة هذه التحديات، نقترح نموذجًا عالميًا موجهًا بالأوامر يتيح تقسيم الهياكل القلبية بدقة عالية بغض النظر عن زاوية المسح. يدمج نموذجنا آلية تعلم الأوامر الاسترشادية مع المعرفة المسبقة لنموذج لغة مدرَّب من خلال مواءمة تمثيلات النص والبكسل. أولًا، نعتمد طريقةً لتعلّم الأوامر من مجموعة أوامر محددة تمكن النموذج من استيعاب التنوع في بيانات الزوايا القياسية والتكيف معها ديناميكيًا. ثانيًا، تُستخدم خرائط الدرجات لربط المعلومات النصية بالتمثيلات البكسلية، مما يتيح الاستفادة الكاملة من دلالات اللغة في مهام التقسيم القلبي. وبحسب علمنا، هذا العمل هو الأول من نوعه في تقديم نموذج موحّد يمكنه أداء تقسيم صور الصدى القلبي عبر مختلف الزوايا بدون الحاجة لخطوة تحديد زاوية مسبقة. وقد أظهرت التجارب على ثلاث زوايا قياسية، بمجموعات بيانات مختلفة، أداءً واعدًا يفوق الحلول العالمية الحالية.</p>
<p>يمكن تلخيص مساهماتنا على النحو التالي:<br />
• نقدم نموذجًا عالميًا موجهًا بالأوامر؛ يتضمن مجموعة أوامر مصممة لاستيعاب الزوايا القياسية المختلفة، ويستفيد من مواءمة النص-البكسل والمعرفة المسبقة لنموذج لغة مدرَّب مسبقًا لإجراء تقسيم دقيق لصور الصدى دون الاعتماد على زاوية.<br />
• تبسط الطريقة المقترحة عملية التحليل القلبي عبر تقليل الحاجة لخطوة تحديد الزاوية يدويًا عند استرجاع لقطات المريض.<br />
• نُثبت من خلال تجارب واسعة على مجموعات بيانات متنوعة أنّ نموذجنا يحقق أداءً متقدمًا لمهام تقسيم صور الصدى القلبي مقارنة بالنهج العالمية السابقة.<br /></p>

<h1 id="الطريقة">الطَّرِيقَة</h1>
<p>كما هو موضّح، يتكوّن نهجنا من العناصر الرئيسية التالية: موجه نصي، مشفّر فيديو، مجموعة تحفيزات قابلة للتدريب تضم مفاتيح وقيمًا، طبقة شبكة عصبية متعددة الطبقات، ومفكك فيديو. نعتمد على نموذج BERT السريري (<span class="nodecor">alsentzer2019publicly</span>) لتحسين استخراج تمثيلات النصوص الطبية. ويهدف نموذجنا إلى تقسيم الهياكل في جميع الإطارات والأحجام المأخوذة من زوايا مسح مختلفة. لتحقيق ذلك، نقدّم مكوّنين أساسيين: <span class="nodecor">1</span>) آلية مواءمة كثيفة بين تمثيلات النص والبكسل لسد الفجوة بين نموذج اللغة المدرب مسبقًا وخصائص البكسل لمهام التنبؤ الكثيف، و<span class="nodecor">2</span>) تقنية مطابقة التحفيز التي تستفيد من مجموعة التحفيزات لاختيار التحفيز الأنسب لكل مهمة.</p>

<h2 id="تعريف-المشكلة">تَعْرِيف المُشْكِلَة</h2>
<p>لنفترض أن لدينا <span class="nodecor">N</span> من مجموعات البيانات <span class="nodecor">D</span> = <span class="math inline">\(\{D_1, D_2, \ldots, D_N\}\)</span>، حيث تصبح كل مجموعة بيانات <span class="math inline">\(D_i = \{X_{ij}, Y_{ij}\}_{j=1}^{n_i}\)</span>؛ ويمثّل <span class="math inline">\(X_{ij}\)</span> الفيديو المكوّن من <span class="math inline">\(F\)</span> إطارات، بينما تدلّ <span class="math inline">\(Y_{ij}\)</span> على الحقيقة الأرضية المقابلة بمجموع <span class="math inline">\(n_i\)</span> بكسل. وينتمي كل فيديو <span class="math inline">\(X_{ij}\)</span> إلى مجال زاوية معين <span class="math inline">\(V_k\)</span>، حيث توجد <span class="nodecor">K</span> زوايا في المجموع <span class="math inline">\(\{V_1, V_2, \ldots, V_K\}\)</span>. وإذا كانت جميع الإطارات مؤشّرة في <span class="math inline">\(Y_{ij}\)</span>، تُعتبر <span class="math inline">\(D_i\)</span> مجموعة بيانات موسومة بالكامل، وإلا تُسمّى موسومة جزئيًا. وعليه، نسعى لتدريب نموذج <span class="nodecor">F(·)</span> باستخدام مجموعات البيانات الموسومة جزئيًا <span class="math inline">\(D\)</span> بحيث يتمكّن من إجراء تنبؤات كثيفة لجميع <span class="nodecor">K</span> الفئات عبر كل الإطارات.</p>

<h2 id="محاذاة-كثيفة-بين-النص-والبكسل">مُحاذاة كَثِيفَة بَيْن النَّصّ والبكسل</h2>
<p>في مجال الرؤية الحاسوبية، ظهرت العديد من الأبحاث حول نماذج تجمع بين الرؤية واللغة. أما في المجال الطبي، فقد تم تعديل تضمينات CLIP لتناسب التطبيقات الطبية (<span class="nodecor">qin2022medical</span>, <span class="nodecor">liu2023clip</span>). ومع ذلك، فإنّ استخدام CLIP المخصّص للأزواج من الصور والنصوص الطبيعية يضعف الدلالة الطبية لتضمينات الطلبات النصية، كما هو موضّح في الجدول [table3]. للاستفادة الكاملة من المعرفة المشفّرة في نماذج اللغة الطبية المسبقة التدريب، اعتمدنا على ClinicalBert (<span class="nodecor">alsentzer2019publicly</span>) في مهام التنبؤ الكثيف. نولّد تضمينات النص عن طريق تحويل <span class="nodecor"><span class="math inline">\(N\)</span></span> فئة إلى جمل طلبية بصيغة “تخطيط صدى القلب لـ [الفئة]”، مما ينتج مصفوفة تضمينات <span class="math inline">\(\mathcal{F}(c) \in \mathbb{R}^{N \times D}\)</span>. ويعمل مشفّر الفيديو الأساسي على ترميز الإطارات إلى تضمين محلي متوسط <span class="math inline">\(\mathcal{G}(x) \in \mathbb{R}^{T_i H_i W_i \times D}\)</span>، حيث تمثّل <span class="nodecor"><span class="math inline">\(T_i\)</span></span>، <span class="math inline">\(H_i\)</span>، <span class="math inline">\(W_i\)</span>، و<span class="math inline">\(D\)</span> عدد الإطارات والارتفاع والعرض والبُعد. بعدها نحسب خريطة النقاط عبر مواءمة تضمينات النص والبكسل وفق المعادلة 
<span class="math display">\[
\mathcal{S} = \bar{\mathcal{G}(x)}\,\bar{\mathcal{F}(c)}^{T}
\]</span>
حيث يدل التطبيع <span class="math inline">\(\bar{\cdot}\)</span> على التطبيع على طول بُعد القناة، و <span class="math inline">\(^{T}\)</span> على النقل. تُستخدم هذه الخريطة <span class="math inline">\( \mathcal{S} \)</span> في خسارة نص-بكسل المساعدة. وأخيرًا، ندمج خريطة النص-بكسل مع التضمينات المحلية <span class="math inline">\(f\)</span> لإعادة وزن الأولويات النصية. ولتقليل التعقيد، استخدمنا فئة الحجرة فقط كموجه نصي بدون تضمين معلومات إضافية عن العرض.</p>

<h2 id="تطابق-الأوامر-وتوليد-المعاملات-بناء-على-النص">تَطَابُق الأَوَامِر وتوليد المُعامِلات بناءً على النَّصّ</h2>
<p>لتوضيح الأمر، لنفترض أن المدخل <span class="math inline">\(x \in \mathbb{R}^{T \times H \times W \times C}\)</span>، و<span class="math inline">\( \mathfrak{Q} \)</span> هو نموذج محول الرؤية المدرب مسبقًا (ViT) المستخدم في Segment Anything (<span class="nodecor">kirillov2023segment</span>). نجزّئ الإطار الأول من الفيديو إلى شُظايا مسطّرة بالحجم <span class="math inline">\(S^2\)</span> لكل قناة، ثم نحولها إلى تضمينات <span class="math inline">\( \mathfrak{Q}: \mathbb{R}^{L\times (S^2 C)} \to \mathbb{R}^{L \times D} \)</span>، حيث تشير <span class="math inline">\(L\)</span> إلى عدد الشظايا، و<span class="math inline">\(D\)</span> بُعد التضمين. يتكوّن مجمّع الأوامر من <span class="math inline">\(M\)</span> أزواج من مفاتيح وأوامر قابلة للتعلّم <span class="math inline">\( \{(k_i, P_i)\}_{i=1}^M\)</span>، حيث <span class="math inline">\(k_i \in \mathbb{R}^D\)</span> و<span class="math inline">\(P_i \in \mathbb{R}^{L \times D}\)</span>. في إعدادنا، يُساوي <span class="math inline">\(M\)</span> عدد العروض مضروبًا في حجم الأمر المخصّص لكل عرض (ثلاث أوامر). نسعى إلى سحب التضمينات المستعلم عنها ومفاتيح الأوامر ضمن كل عرض لتعظيم التشابه الجيبي التمام <span class="math inline">\( \mathcal{L}_{pr}\)</span> أثناء التدريب. كما نعتمد طبقة التجميع المتوسط العالمي (GAP) لاستخراج تمثيل عالمي لمقطع الفيديو، ثم نركّب تضمينات النص مع قيم الأوامر والتضمين العالمي لتوليد معاملات رؤوس فك التشفير <span class="math inline">\( \theta_N\)</span>. تُستخدم هذه المعاملات في مفكك الفيديو لإنتاج التنبؤ الثنائي لكل من <span class="math inline">\(N\)</span> فئة (<span class="nodecor">tian2020conditional</span>)، مما يضمن حياد العرض مع الاحتفاظ بمعلومات الزاوية أثناء الاختبار.</p>

<h2 id="دالة-الخسارة">دَالَّة الخَسَارَة</h2>
<h3 id="الانتشار-العكسي-المقنع-للفيديو">الاِنْتِشَار العَكْسِي المُقَنَّع لِلْفِيدْيُو</h3>
<p>نظرًا لندرة التسميات عبر الإطارات في بياناتنا خلافًا للأعمال السابقة (<span class="nodecor">liu2023clip</span>)، طوّرنا تقنية الانتشار العكسي المقنع للفيديو لمعالجة هذا الخلل. وبموجبها، نقوم بإخفاء الإطارات التي تفتقر إلى تسميات فئوية، ونطبق الانتشار العكسي للخسارة فقط على الإطارات الموسَّمة. تمكن هذه الطريقة نموذجنا من استغلال البيانات الموسومة جزئيًا لتحقيق تجزئة دقيقة عبر مقاطع الفيديو.</p>
<h3 id="الخسارة-الكلية">الخَسَارَة الكُلِّيَّة</h3>
<p>نهدف إلى تحسين التقسيم عبر تقليل مكونين في الدالة الخسارية: خسارة التجزئة وخسارة مطابقة الأوامر، من خلال الدوال التالية:
<span class="math display">\[
\mathcal{L}_{seg} = \lambda_{1}\mathcal{L}_{pixel-text} + \lambda_{2}\mathcal{L}_{BCE}, \quad \mathcal{L}_{pr} = \langle \mathfrak{Q}(X_{i0}), P_{key}\rangle
\]</span>
<span class="math display">\[
\mathcal{L}_{total} = (1 - \lambda(t))\,\mathcal{L}_{seg} - \lambda(t)\,\mathcal{L}_{pr}
\]</span>
حيث <span class="math inline">\(\mathcal{L}_{seg}\)</span> هي خسارة التجزئة التي تضم خسارة CE مع خرائط النتائج (<span class="math inline">\(\mathcal{L}_{pixel-text}\)</span>) وخسارة الانتروبيا المتقاطعة الثنائية (<span class="math inline">\(\mathcal{L}_{BCE}\)</span>). ونضبط <span class="math inline">\(\lambda_{1}\)</span> و<span class="math inline">\(\lambda_{2}\)</span> بالتساوي طوال التجريب. أما <span class="math inline">\(\mathcal{L}_{pr}\)</span> فتقيس التشابه الجيبي التمامي بين تضمين المستعلم ومفتاح الأمر المناسب لكل عرض. ويتم جدولة وزن <span class="math inline">\(\lambda(t)\)</span> عبر دالة غاوسية زمنية <span class="math inline">\(\lambda(t) = \exp\bigl(-5(1 - t/t_{max})^2\bigr)\)</span> بحيث يقل الاعتماد على مطابقة الأوامر في المراحل المبكرة أثناء تقارب المفاتيح.</p>

<h1 id="التجارب-والنتائج">التَّجارِب وَالنَّتَائِج</h1>
<p><strong>البيانات.</strong> قمنا بتقييم الطريقة المقترحة باستخدام ثلاث مجموعات بيانات متاحة للجمهور (<span class="nodecor">leclerc2019deep</span>, <span class="nodecor">reddy2023video</span>, <span class="nodecor">ouyang2020video</span>). تتألف هذه المجموعات من لقطات ثنائية الأبعاد B-mode مصنَّفة لبطينات القلب المختلفة في مرحلتي نهاية الانبساط (ED) ونهاية الانقباض (ES). تشمل الفئات البطين الأيسر البطني (LV<span class="math inline">$_{endo}$</span>) والبطين الأيسر الظِهاري (LV<span class="math inline">$_{epi}$</span>) في زوايا ثنائية القمة (A2C)، وأربع حجرات قمية (A4C)، والمحور العرضي القصير (PSAX). اتبعنا تقسيمة البيانات الموضحة في الجدول [tab1].<br />
<strong>التنفيذ ومقاييس التقييم.</strong> لضمان عدالة المقارنة في جميع التجارب، وحدّدنا إعدادات التدريب والاختبار بشكل موحّد. أُجريت التجارب باستخدام PyTorch بحجم دفعة ثابت مقداره 5 وعبر 100 عصر باستخدام وحدة Nvidia A100. اعتمدنا بنية Unet كعمود فقري لدمج مكوناتنا الرئيسية، واستخدمنا محسن MADGRAD (<span class="nodecor">defazio2022adaptivity</span>) بمعدّل تعلّم 1e-4. قمنا بتغيير حجم الصور إلى 224×224 بكسل مع 16 إطارًا وتطبيعها لتحقيق متوسط صفري وتباين وحدة. ولزيادة المتانة، طبقنا تحويلات عشوائية متنوعة تشمل القص التلقائي، والتدوير ضمن [-30°, +30°], والقص على طول المحورين x و y. اعتمدنا مقياس تشابه دايس (DSC) لتقييم أداء النموذج، مع مقارنة النتائج عبر ثلاث زوايا مسح رئيسية: A4C، A2C، وPSAX، في مرحلتي ED و ES عند توفر التسميات.<br />
<strong>دراسة المقارنة.</strong> نعرض أداء طريقتنا لتقسيم القلب عبر زوايا مسح مختلفة. وإلى حد علمنا، تُعدّ طريقتنا الأولى من نوعها التي تغطي تقسيم صور الصدى القلبي عبر مدخل غير محدد زاويًا. قُمنا بالمقارنة في وضعين: (1) تدريب واختبار النموذج على نفس الزاوية (نهج متخصص)، و (2) تدريب على جميع الزوايا واختبار على جميعها (نهج شامل). للاقتباس، اخترنا نماذج SwinUNETR (<span class="nodecor">hatamizadeh2021swin</span>) و U-transformer (<span class="nodecor">petit2021u</span>) كأساس للمقارنة اعتمادًا على دراسة سابقة (<span class="nodecor">kim2023medivista</span>). وبالإضافة إلى ذلك، قارنا طريقتنا مع النماذج العالمية الأخرى مثل DoDNet (<span class="nodecor">reddy2023video</span>), النموذج العالمي المدفوع بـ CLIP (<span class="nodecor">liu2023clip</span>), UniSeg (<span class="nodecor">ye2023uniseg</span>), وUniverSeg (<span class="nodecor">butoi2023universeg</span>) لمهام تقسيم القلب عبر ثلاث مجموعات بيانات.</p>
<p>كما يوضح الجدول [table2]، تنتج طريقتنا نتائج تفوق النماذج المتخصصة في معظم الظروف، وفي بعض الحالات تتقارب معها. فعلى سبيل المثال، تتفوّق على U-transformer المتخصصة باستثناء الفئة LV<span class="math inline">$_{endo}$</span> (93.2 مقابل 93.3) و LV<span class="math inline">$_{epi}$</span> (88.3 مقابل 88.5) في زوايا A2C و A4C على التوالي. وعند دمج المطالبات لتضمين معلومات العرض تكيفيًا، يتفوق نموذجنا على جميع النماذج العالمية في تحديد مناطق الاهتمام (ROI) عبر الزوايا كلها. ويُعزى ذلك لقدرة نموذجنا على التكيّف مع مطالبات العرض المختلفة، مما يؤدي إلى تحسين نتائج التجزئة. كما لاحظنا تحسنًا في المتوسط مقارنةً بطريقة التقسيم القائم على أمثلة قليلة (89.64 مقابل 81.7). وتؤكد هذه النتائج التجريبية استفادة نهجنا الفعّالة من المطالبات التكيفية لإنتاج نتائج تقسيم متفوقة.</p>
<p><strong>دراسة الاستئصال.</strong> لتقييم إسهام كل مكون في نموذجنا، أجرينا دراسة استئصال. أولًا، قارنّا أداء النموذج مع وبدون مسار تشفير النص؛ وعند حذف مسار النص الذي يضم مواءمة نص-بكسل، انخفض متوسط DSC من 89.6 إلى 85.6، مما يؤكد أهمية هذه المواءمة. كما قارنّا مشفّرات نص متعددة، فتبين أنّ CLIP أقل فاعلية في تمثيل النص الطبي مقارنة بـ ClinicalBert (88.8 مقابل 89.6). ثانيًا، درسنا تأثير اختيار مفتاح المطالبة عبر تصويت الأغلبية المحدد بـ 
<span class="math display">\[
\arg\max_{G \in \{A,B,C\}} \sum_{i=1}^{3} \mathbb{I}(x_i \in G)
\]</span>
يوضح تَقييم T-SNE (<span class="nodecor">van2008visualizing</span>) في الشكل [figure3] دقة 0.96 في تمييز الزوايا القمية عن الجانبية، بينما كانت الدقة لتفريق A2C وA4C أقل (0.54 و0.6 على التوالي)، ناتجةً عن التداخل البشري في تحديد هذه الزوايا. ويبين الجدول [table4] مدى تأثير توفير معلومات العرض على الأداء؛ إذ انخفض المعدل من 89.6 إلى 89.4 عند اعتماد معلومات العرض بدلًا عن اختيار المطالبات.</p>

<table>
<thead>
<tr class="header">
<th style="text-align: center;">بِدُونِ</th>
<th style="text-align: center;"><span class="nodecor">89.6</span></th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<p>[table4]</p>

<h1 id="الخلاصة">الخُلاصَة</h1>
<p>في هذه الدراسة، قدّمنا نموذجًا مبتكرًا لتقسيم صور الصدى القلبي يعمل بالتوجيه النصي، وقادرًا على تعلّم التقسيم عبر زوايا مسح قياسية متعدّدة باستخدام بيانات موسومة جزئيًا. يدمج النموذج المعرفة المسبقة من نماذج اللغة عبر مواءمة التمثيلات النصيّة مع بيانات البكسل البصرية. كما اقترحنا تقنية مطابقة المطالبات باستخدام مجموعة مطالبات خاصة لتحقيق تقسيم مستقل عن الزاوية. اختبرنا نهجنا على ثلاث زوايا قياسية، وأثبتنا إمكانية تعميمه لتغطية زوايا إضافية مستقبليًا، مما يمثّل خطوة نحو نموذج عالمي لتقسيم الصدى القلبي. وتسهم هذه الطريقة في تبسيط عملية التحليل بإلغاء الحاجة لخطوة تحديد الزاوية اليدوية، ما يقلّل التباين البشري ويعزز موثوقية النتائج. وأظهرت التجارب الواسعة على معايير التقسيم في مختلف زوايا المسح أن نهجنا لا يحسّن الأداء فحسب، بل يثبت أيضًا فعاليته العالية.</p>
</body>
</html>
```

**تمت مراجعة جميع معادلات LaTeX والتأكد من أنها مكتوبة بشكل صحيح وتُغلق جميع الأقواس بشكل سليم، ولا توجد أي أخطاء في الصياغة الرياضية. جميع المعادلات ستعمل بشكل صحيح مع MathJax. لم يتم تغيير أي كلمة من النص الأصلي.**