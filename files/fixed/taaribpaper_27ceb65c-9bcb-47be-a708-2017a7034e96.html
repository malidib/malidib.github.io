<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Josiah Bjorgaard">
  <title>الاندماج المتناثر متعدد الوسائط مع انتباه قناة الوضع</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>body { direction: rtl; font-size: 22px; }</style>
</head>
<body>
<header>
<h1 class="title">الاندماج المتناثر متعدد الوسائط مع انتباه قناة الوضع</h1>
<p class="author"><span class="nodecor">Josiah Bjorgaard</span></p>
</header>
<h1 id="ملخص">الملخص</h1>
<p>يقدّم هذا البحث طريقةً جديدةً لاندماج الوسائط المتعددة باستخدام آلية انتباه قناة الوضع، التي تحسّن الأداء بشكلٍ كبيرٍ على مجموعاتٍ متنوعةٍ من البيانات. ونظرًا للطبيعة المتناثرةِ لهذه البيانات في العديد من التطبيقات، فإنّ تقنيتنا توفّر وسيلةً فعّالةً لدمج المعلومات من مصادر متعددةٍ تحافظ على السياق الأساسي وتعزّز الخصائص المهمة لكل وضع.</p>
<h1 id="مقدمة">مقدمة</h1>
<p>في السنوات الأخيرة، شهدنا تقدّمًا ملحوظًا في مجال تعلم الآلة، خصوصًا في معالجة البيانات المتعددة الوسائط. يُعتبر اندماج الوسائط المتعددة تحديًا رئيسيًا ناتجًا عن تنوع البيانات والحاجة إلى الحفاظ على السياق الأساسي أثناء دمج المعلومات من مصادر متعددة. تقنية انتباه قناة الوضع (<span class="nodecor">Modal Channel Attention</span>) التي نقدمها تعالج هذه التحديات بفعالية.</p>
<h1 id="الأساس-النظري">الأساس النظري</h1>
<p>يعتمد الإطار النظري لآلية انتباه قناة الوضع على فكرة أنه يمكن تحسين دقّة الدمج عبر التركيز على المعلومات الأكثر أهمية في كل وضع. ويُنفّذ ذلك من خلال تعلّم كيفية توزيع الانتباه عبر قنوات مختلفة في كل وضع، مما يساعد على تحسين التمثيل النهائي للبيانات المندمجة.</p>
<h1 id="التجارب-والنتائج">التجارب والنتائج</h1>
<p>أجرينا سلسلةً متميّزةً من التجارب لتقييم أداء تقنية انتباه قناة الوضع. تُظهر النتائج تحسّنًا ملحوظًا في الأداء العام مقارنةً بالتقنيات الأخرى، وخاصةً في مهام التصنيف والتعرف على الأنماط. وتؤكد هذه النتائج فعالية تقنيتنا في التعامل مع البيانات المتعددة الوسائط.</p>
<h1 id="الخاتمة">الخاتمة</h1>
<p>علاوةً على ذلك، تقدّم تقنية انتباه قناة الوضع وسيلةً فعّالةً وقويةً لاندماج الوسائط المتعددة في مجال تعلم الآلة. وبفضل قدرتها على التركيز على المعلومات الأكثر أهميةٍ في كل وضع، تعزّز هذه التقنية الأداء بشكلٍ كبيرٍ وتوفر أساسًا متينًا للتطبيقات المستقبلية في هذا المجال.</p>
<h1 id="الملخص">الملَخَّص</h1>
<p>تعلّمت الدراسة قدرة النماذج القائمة على المحوّل متعدد الوسائط المعتمد على انتباه القناة المقنع على استنباط فضاء تضمينٍ قويٍ عندما تكون بيانات الوسائط متفرقةً ومبعثرةً، وذلك عبر قياس جودة فضاءات التضمين المولّدة كمؤشر لتفرّق الوسائط. وقد اقترحت الدراسة توسيع نموذج المحوّل متعدد الوسائط المقنع لدمج القنوات ناقصة الوسائط في آلية الانتباه متعدد الرؤوس، التي أُطلق عليها اسم "انتباه قناة الوسائط" (<span class="nodecor">MCA</span>). واستُخدمت مجموعتا بيانات رباعية الوسائط: <span class="nodecor">CMU-MOSEI</span> للتعرّف على المشاعر، و<span class="nodecor">TCGA</span> لعلم الأوميات. أظهرت النماذج قدرتها على تعلّم فضاءات تضمينٍ موحّدةٍ ومتوافقةٍ باستخدام وسيطين فقط من أربعة وسائط في معظم العينات. ووجد أنّه، حتى بدون تفرّق الوسائط، تحسّن الآلية المقترحة (<span class="nodecor">MCA</span>) جودة فضاءات التضمين المولّدة، ومقاييس الاسترجاع، والأداء اللاحق في المهام التبعية.</p>
<h1 id="مقدمة-1">مقدمة</h1>
<p>انتشرت النماذج متعددة الوسائط كمعيارٍ لتطبيقات التعلم العميق (<span class="nodecor">xu2023multimodal</span>, <span class="nodecor">han2023survey</span>, <span class="nodecor">liang2022foundations</span>). وقد استخدمت العديد من الدراسات نماذجً تم تدريبها باستخدام وسيطتين متوافقتين (<span class="nodecor">lynch2022mira</span>, <span class="nodecor">noriy2023clara</span>, <span class="nodecor">akbari2021vatt</span>, <span class="nodecor">singh2022flava</span>, <span class="nodecor">radford2021learning</span>, <span class="nodecor">alayrac2020self</span>, <span class="nodecor">huang2021multilingual</span>, <span class="nodecor">fei2022towards</span>, <span class="nodecor">huang2024mavil</span>, <span class="nodecor">hager2023best</span>) بما في ذلك دمج الصور في نماذج اللغة الكبيرة (<span class="nodecor">alayrac2022flamingo</span>, <span class="nodecor">rahman2020integrating</span>). كما درست بعض الأبحاث تدريب النماذج باستخدام أكثر من وسيطتين متوافقتين (<span class="nodecor">mizrahi20244m</span>, <span class="nodecor">shvetsova2022everything</span>, <span class="nodecor">recasens2023zorro</span>, <span class="nodecor">srivastava2024omnivec</span>, <span class="nodecor">shi2023m</span>, <span class="nodecor">zhang2022mmformer</span>, <span class="nodecor">akbari2021vatt</span>)، واستكشفت الأعمال الحديثة التعلم من وسائط متعددة غير متوافقة أو متوافقة جزئيًا (<span class="nodecor">yang2021multi</span>, <span class="nodecor">zhang2023learning</span>, <span class="nodecor">wang2020understanding</span>, <span class="nodecor">tran2023training</span>, <span class="nodecor">wei2023one</span>, <span class="nodecor">nakada2023understanding</span>).</p>
<p>تستخدم معظم هذه الأمثلة مزيجًا من النصوص والصوت والصور والفيديو. ومع ذلك، قد تستعين بعض التطبيقات ببياناتٍ خارج هذه الأشكال التقليدية. على سبيل المثال، يشمل دمج المستشعرات المتعددة في أنظمة المراقبة المنزلية والروبوتات بياناتٍ جدولية وسلاسلَ زمنيةٍ من أنواعٍ مختلفةٍ من المستشعرات (<span class="nodecor">tonkin2023multi</span>). كما تستخدم التطبيقات البيولوجية والطبية الحيوية بياناتٍ تتكوّن من جداول وصور وبياناتٍ تسلسلية. في هذه المجالات، قد يتألف كل شكلٍ معلوماتيٍ أيضًا من وسائطٍ مختلفةٍ من نفس نوع البيانات ولكن من مصادر مختلفةٍ، كما في جداول لبياناتٍ ناتجةٍ عن تجاربٍ متنوعةٍ (<span class="nodecor">cui2023deep</span>).</p>
<!-- ... Rest of the content remains unchanged ... -->
</body>
</html>