<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Rachmad Vidya Wicaksana Putra, Alberto Marchisio, Muhammad Shafique">
  <title>SNN4Agents: إطار عمل لتطوير الشبكات العصبية النبضية ثلاثية الأبعاد ذات الكفاءة العالية في استهلاك الطاقة للوكلاء المستقلين</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>body { direction: rtl; font-size: 22px; }</style>
</head>
<body>
<header>
<h1 class="title">SNN4Agents: إطار عمل لتطوير الشبكات العصبية النبضية ثلاثية الأبعاد ذات الكفاءة العالية في استهلاك الطاقة للوكلاء المستقلين</h1>
<p class="author"><span class="nodecor">Rachmad Vidya Wicaksana Putra</span>, <span class="nodecor">Alberto Marchisio</span>, <span class="nodecor">Muhammad Shafique</span></p>
</header>
<h1 id="ملخص">مُلخّص</h1>
<p>أظهرت الاتجاهات الحديثة أن الوكلاء المستقلين، مثل المركبات الأرضية المستقلة (<span class="nodecor">AGVs</span>)، والطائرات بدون طيار (<span class="nodecor">UAVs</span>)، والروبوتات المتنقلة، تساهم في تحسين إنتاجية الإنسان في تنفيذ المهام المتنوعة. ومع ذلك، ونظرًا لأن هذه الوكلاء غالبًا ما تعمل ببطاريات محمولة، فهي تتطلب استهلاكًا منخفضًا جدًا للطاقة/القدرة لتحقيق عمر تشغيلي طويل. لمعالجة هذا التحدي، ظهرت الحوسبة العصبية المستوحاة من الأحياء كحل واعد، حيث تُستخدم الشبكات العصبية النبضية (<span class="nodecor">SNNs</span>) لمعالجة النبضات القادمة من الكاميرات القائمة على الأحداث أو تحويل البيانات قبل المعالجة لأداء الحسابات الموزعة بكفاءة. ومع ذلك، فإن دراسات نشر <span class="nodecor">SNN</span> للوكلاء المستقلين لا تزال في مراحلها المبكرة. وبالتالي، لم يتم تحديد مراحل التحسين لتمكين نشر <span class="nodecor">SNN</span> ثلاثية الأبعاد بكفاءة للوكلاء المستقلين بشكل منهجي. بناءً على ذلك، نقترح إطار عمل جديد يُسمى <strong>SNN4Agents</strong> يتكون من مجموعة من تقنيات التحسين لتصميم الشبكات العصبية النبضية ثلاثية الأبعاد ذات الكفاءة العالية في استهلاك الطاقة والموجهة لتطبيقات الوكلاء المستقلين. يستخدم <span class="nodecor">SNN4Agents</span> تقنيات تقليل الأوزان، وتقليل الخطوات الزمنية، وتقليل نافذة الانتباه لتحسين كفاءة استهلاك الطاقة، وتقليل بصمة الذاكرة، وتحسين زمن المعالجة، مع الحفاظ على دقة عالية. في التقييم، نحقق في حالات استخدام التعرف على السيارات القائمة على الأحداث، ونستكشف الموازنة بين الدقة، والزمن، والذاكرة، واستهلاك الطاقة. تظهر النتائج التجريبية أن إطار العمل المقترح يمكن أن يحافظ على دقة عالية (<span class="nodecor">84.12%</span>) مع توفير في الذاكرة بنسبة <span class="nodecor">68.75%</span>، وتسريع بمقدار <span class="nodecor">3.58</span> مرة، وتحسين في كفاءة استهلاك الطاقة بمقدار <span class="nodecor">4.03</span> مرة مقارنة بالعمل الرائد في مجال مجموعة بيانات <span class="nodecor">NCARS</span>، مما يمكّن من نشر <span class="nodecor">SNN</span> ثلاثي الأبعاد عالي الكفاءة في استهلاك الطاقة للوكلاء المستقلين.</p>
<h1 id="الكلمات-المفتاحيه">الكلمات المفتاحية:</h1>
<p>الحوسبة العصبية الشكلية، الشبكات العصبية النبضية، الوكلاء المستقلون، بيانات السيارات، المعالج العصبي الشكلي، كفاءة الطاقة.</p>
<h1 id="Sec_Intro">مقدمة</h1>
<p>في السنوات الأخيرة، ازداد الاهتمام بتطبيق الذكاء الاصطناعي العصبي المستوحى من الشبكات العصبية النبضية للوكلاء المستقلين (المعروفين بـ <em>الوكلاء المستقلين المعتمدين على الشبكات العصبية النبضية</em>) بشكل متسارع. السبب هو أن الشبكات العصبية النبضية يمكن أن تقدم دقة عالية بفضل آلية التعلم الفعالة (<span class="nodecor">Ref_Rathi_SNNsurvey_CSUR23, Ref_Putra_SpikeDyn_DAC21</span>)، وزمن حساب منخفض بفضل ترميز النبضات الفعال (<span class="nodecor">Ref_Guo_NeuralCoding_FNINS21</span>)، واستهلاك طاقة/قدرة منخفض جدًا بفضل العمليات القائمة على النبضات المتفرقة (<span class="nodecor">Ref_Putra_FSpiNN_TCAD20</span>). لتحقيق مثل هذه الأنظمة في الحياة الواقعية، تتطلب القدرات على حل مهام تعلم الآلة مثل تصنيف الصور (<span class="nodecor">Ref_Putra_SparkXD_DAC21, Ref_Putra_EnforceSNN_FNINS22, Ref_Putra_RescueSNN_FNINS23</span>)، وكشف الأجسام (<span class="nodecor">Ref_Viale_CarSNN_IJCNN21, Ref_Cordone_ObjDetSNN_IJCNN22</span>)، أو تجزئة الأجسام (<span class="nodecor">Ref_Li_SpiCalib_arXiv22</span>) من الصور/الفيديوهات. بالإضافة إلى هذه الوظائف، تتطلب الوكلاء المستقلين المعتمدين على الشبكات العصبية النبضية أيضًا (١) بصمة ذاكرة صغيرة لأنها غالبًا ما تُستخدم على منصات أجهزة محدودة الموارد، (٢) استهلاك طاقة/قدرة منخفض للحفاظ على عمر البطارية لأنها غالبًا ما تعمل ببطاريات محمولة، و(٣) إخراج في الوقت الحقيقي بدقة عالية لتوفير قرار سريع (<span class="nodecor">Ref_Bonnevie_DynamicEnv_ICARA21, Ref_Putra_lpSpikeCon_IJCNN22, Ref_Putra_TopSpark_IROS23</span>). لتعظيم فوائد العمليات المتفرقة للشبكات العصبية النبضية، يمكن استخدام البيانات القائمة على الأحداث لأنها توفر تنسيق بيانات متوافق مباشرة لمعالجة الشبكات العصبية النبضية وتقلل من مرحلة المعالجة المسبقة، مثل تحويل البيانات إلى نبضات (مثلاً، بيانات البكسل إلى قطار نبضات) وترميز النبضات. لذلك، يجب أن تأخذ تطويرات الوكلاء المستقلين المعتمدين على الشبكات العصبية النبضية في الاعتبار البيانات القائمة على الأحداث، مثل مجموعة بيانات NCARS (<span class="nodecor">Ref_Sironi_HATS_CVPR18, Ref_Putra_NeuromorphicAI4Robotics_arXiv24, Ref_Bano_StudySNNParams_arXiv24</span>).</p>
<p>انطلاقًا من الدوافع المذكورة أعلاه لإمكانات الوكلاء المستقلين المعتمدين على الشبكات العصبية النبضية، <em><strong>المشكلة البحثية المستهدفة هي كيفية تطوير وكلاء مستقلين معتمدين على الشبكات العصبية النبضية بكفاءة في استهلاك الطاقة مع الأخذ في الاعتبار عبء العمل للبيانات القائمة على الأحداث.</strong></em> سيمكن حل فعال لهذه المشكلة الوكلاء المستقلين المعتمدين على الشبكات العصبية النبضية من تحقيق دقة عالية مع بصمة ذاكرة صغيرة، وزمن معالجة منخفض، واستهلاك طاقة منخفض.</p>
<h2 id="Sec_Intro_SOTA">أعمال الحالة الفنية وقيودها</h2>
<p>لا تزال دراسة تطوير الوكلاء المستقلين المعتمدين على الشبكات العصبية النبضية في مراحلها الأولى. تم تلخيص الأعمال الفنية الحالية في الجدول [Tab_SOTA]. هنا، نلاحظ أن معظم الأعمال القائمة تركز على اقتراح الأطر و/أو التقنيات لتحقيق دقة عالية (<span class="nodecor">Ref_Putra_lpSpikeCon_IJCNN22</span>, <span class="nodecor">Ref_Putra_Mantis_ICARA23</span>, <span class="nodecor">Ref_Putra_TopSpark_IROS23</span>, <span class="nodecor">Ref_Putra_SpikeNAS_arXiv24</span>). ومع ذلك، لم تأخذ هذه الأعمال في الاعتبار عبء البيانات القائمة على الأحداث، مما يتطلب مرحلة معالجة مسبقة معقدة نسبيًا، تشمل تحويل البيانات إلى تدفقات وترميز التدفقات. تستكشف أعمال أخرى تقنيات لتحقيق دقة عالية مع الأخذ في الاعتبار بيانات السيارات القائمة على الأحداث (<span class="nodecor">Ref_Viale_CarSNN_IJCNN21</span>, <span class="nodecor">Ref_Viale_LaneSNN_IROS22</span>, <span class="nodecor">Ref_Cordone_ObjDetSNN_IJCNN22</span>). ومع ذلك، لم تأخذ هذه الأعمال في الاعتبار تحسين حجم النموذج ليتناسب مع الوكلاء المستقلين المقيدين بالموارد. تكشف جميع القيود المذكورة أعلاه للأعمال الفنية الحالية أنه لم يتم تحديد مراحل التحسين لتمكين نشر الشبكات العصبية النبضية بكفاءة للوكلاء المستقلين بشكل منهجي.</p>
<h2 id="Sec_Intro_CaseStudy">دراسة حالة تحفيزية</h2>
<p>لتوضيح إمكانات تحسين الشبكات العصبية النبضية للوكلاء المستقلين مقارنة بالحالة الراهنة للفن، نقوم بدراسة حالة تجريبية نبحث فيها تطبيق مستويات مختلفة من تقليل الأوزان (أي الدقة) على نموذج شبكة عصبية نبضية من عمل (<span class="nodecor">Ref_Viale_CarSNN_IJCNN21</span>) باستخدام مجموعة بيانات NCARS القائمة على الأحداث. سيتم مناقشة تفاصيل الإعداد التجريبي بشكل أكبر في القسم [Sec_Eval]. تظهر النتائج التجريبية عدة ملاحظات رئيسية كما هو موضح فيما يلي.</p>
<ul>
<li><p>التكميم بدقة <span class="nodecor">12</span>-بت يحقق دقة مماثلة للدقة الأصلية <span class="nodecor">32</span>-بت (بدون تكميم) عبر فترات التدريب، مع توفير <span class="nodecor">2.7</span>x في الذاكرة.</p></li>
<li><p>إعدادات التكميم بدقة <span class="nodecor">8</span>-بت و <span class="nodecor">4</span>-بت تعاني من تدهور كبير في الدقة حيث تحقق تقريبًا <span class="nodecor">50</span>% دقة عبر فترات التدريب. نظرًا لأن مجموعة بيانات NCARS لديها <span class="nodecor">2</span> فئتين (أي "سيارة" أو "خلفية")، تشير هذه النتائج إلى أن الشبكة تؤدي تخمينات عشوائية لأنها لم تتدرب بشكل صحيح.</p></li>
</ul>
<p>توضح هذه الملاحظات أن هناك فرصة لتحسين الشبكات العصبية النبضية بشكل أكبر لجعلها مناسبة للوكلاء المستقلين المقيدين بالموارد. ومع ذلك، فإن التكميم العدواني ببساطة على الشبكة المعطاة قد يؤدي إلى تدهور كبير في الدقة. لذلك، <em><strong>تحدي البحث</strong></em> هو كيفية تنفيذ تقنيات التحسين المختلفة بفعالية دون تدهور كبير في الدقة.</p>
<h2 id="Sec_Intro_Novelty">مساهماتنا الجديدة</h2>
<p>لمعالجة المشكلة البحثية المستهدفة والتحديات المتعلقة بها، نقترح <em>إطار عمل جديد يُسمى <strong>SNN4Agents</strong> لتطوير الشبكات العصبية النبضية الموفرة للطاقة للوكلاء المستقلين</em>. يتم وصف الخطوات الرئيسية لإطار عمل SNN4Agents بإيجاز فيما يلي.</p>
<ul>
<li><p><strong>تكميم الأوزان (القسم [Sec_Frame_Quantize]):</strong> لإيجاد إعدادات التكميم المناسبة التي تلبي قيود الذاكرة، نقوم باستكشاف مساحة التصميم لمستويات الدقة المختلفة مع مراقبة تأثيرها على الدقة.</p></li>
<li><p><strong>تقليل الخطوات الزمنية (القسم [Sec_Frame_Timestep]):</strong> لإيجاد عدد الخطوات الزمنية المناسبة التي تلبي قيود الوقت، نقوم باستكشاف مساحة التصميم لقيم الخطوات الزمنية المختلفة مع مراقبة تأثيرها على الدقة.</p></li>
<li><p><strong>تقليل نافذة الانتباه (القسم [Sec_Frame_AttWindow]):</strong> لتقليل متطلبات الحساب وبالتالي الطاقة/القدرة على المعالجة، نستكشف أحجام نوافذ الانتباه المختلفة من عينات الإدخال ونلاحظ تأثيرها على الدقة.</p></li>
<li><p><strong>استراتيجية التحسين المشترك (القسم [Sec_Frame_Joint]):</strong> لتعظيم الفوائد من خطوات التحسين الفردية السابقة، نقوم بتنفيذ استراتيجية تحسين مشتركة من خلال الاستفادة من استكشاف مساحة التصميم التي تأخذ في الاعتبار الإعدادات المناسبة من خطوات التحسين الفردية.</p></li>
</ul>
<h1 id="Sec_Prelim">المقدمات</h1>
<h2 id="Sec_Prelim_SNNs">الشبكات العصبية النبضية</h2>
<h3 id="نظرة-عامة">نظرة عامة</h3>
<p>تُعد الشبكات العصبية النبضية (Spiking Neural Networks) الجيل الثالث من الشبكات العصبية (<span class="nodecor">Ref_Maass_SNN_NeuNet97</span>). توضح النظرة العامة لوظائف الشبكات العصبية النبضية كيفية معالجة قطارات النبضات الداخلة بواسطة الخلايا العصبية النبضية وانتقال المعلومات إلى الخلايا العصبية في الطبقات التالية. من أشهر نماذج الخلايا العصبية النبضية، يبرز نموذج الخلية العصبية النبضية المتسربة (Leaky-Integrate-and-Fire) (<span class="nodecor">Wang_2014EMBC_LeakyIntegrateAndFire</span>) كتوازن فعال بين التعقيد والواقعية. يُعرف الوقت التشغيلي للخلية العصبية لمعالجة قطار نبضات من بيانات إدخال واحدة (مثلاً، بكسل صورة) بـ"الخطوة الزمنية" (<span class="nodecor">Ref_Putra_TopSpark_IROS23</span>). في كل خطوة زمنية، يزداد الجهد الكهربائي <span class="math inline">\(V_m\)</span> للخلية العصبية مع كل نبضة إدخال قادمة. عندما يتجاوز <span class="math inline">\(V_m\)</span> عتبة الجهد <span class="math inline">\(V_{th}\)</span>، تصدر الخلية العصبية نبضة خرج (<span class="nodecor">Ref_Putra_SoftSNN_DAC22</span>). بهذه الطريقة، تنتقل النبضات من الإدخال إلى الإخراج وعبر طبقات متعددة من الخلايا العصبية النبضية في الشبكة.</p>
<p>بينما تتبع الشبكات العصبية النبضية موجة نجاح الشبكات العصبية العميقة التقليدية (غير النبضية)، فإنها تقدم المزايا التالية:</p>
<ul>
<li><p><em>الواقعية البيولوجية:</em> وظائف الشبكات العصبية النبضية مستوحاة من سلوك الدماغ البيولوجي، حيث تنتقل النبضات عبر الخلايا العصبية لنقل المعلومات. قد يفتح هذا إمكانيات للإدراك والمرونة لحل مهام التعلم الآلي المتنوعة.</p></li>
<li><p><em>استهلاك الطاقة/القدرة المنخفض للغاية:</em> الطاقة الديناميكية في الشبكات العصبية النبضية تُستهلك فقط عند وجود النبضات، مما يوفر قدرة/طاقة معالجة منخفضة للغاية خلال فترة تشغيل طويلة.</p></li>
<li><p><em>التكامل الفعال مع أجهزة الاستشعار القائمة على الأحداث:</em> يمكن استخدام تسلسلات الأحداث التي تلتقطها أجهزة الاستشعار القائمة على الأحداث مباشرة كمدخلات للشبكات العصبية النبضية دون معالجة مسبقة معقدة (مثل تحويل البيانات إلى نبضات).</p></li>
</ul>
<p>بالإضافة إلى هذه المزايا، من الصعب فعليًا تدريب الشبكات العصبية النبضية بكفاءة بسبب عدم قابلية تفاضل دالة الخسارة النبضية (<span class="nodecor">Ruckauer_2019arxiv_NonDifferentiableLossFunctionSNN</span>). لذلك، للتغلب على هذا التحدي، تم اقتراح تقنيتين ممكنتين في الأدبيات. (١) نهج تحويل الشبكة العصبية العميقة إلى شبكة عصبية نبضية (<span class="nodecor">Ref_Hao_ANNtoSNNCalibration_ICLR23</span>, <span class="nodecor">Ref_Bu_ANNtoSNNConversion_ICLR22</span>) حيث يتم تدريب شبكة عصبية عميقة ثم تحويل النموذج إلى نظيره النبضي. (٢) نهج تدريب الشبكة العصبية النبضية مباشرة (<span class="nodecor">Ref_Neftci_SurrogateSNNs_IEEEMSP19</span>) باستخدام دالة تدرج بديلة لتقريب دالة الخسارة النبضية، بحيث يمكن تفاضلها ودمجها في تدفق الانتشار العكسي. نظرًا لأن النهج-(١) يتطلب تدريب الشبكة العصبية العميقة، فلا يمكن استخدامه مباشرة عند التعامل مع البيانات القائمة على الأحداث (<span class="nodecor">Massa_2020IJCNN_EfficientSNNGestures</span>). بالإضافة إلى ذلك، فإنه يتطلب عادة عددًا أكبر من الخطوات الزمنية مقارنة بالنهج-(٢) (<span class="nodecor">Ref_Chowdhury_OneTimestepIsAllYouNeed_arxiv21</span>). لذلك، <em>في هذا العمل، نعتمد تدريب الشبكة العصبية النبضية مباشرة، أي قاعدة التعلم بالانتشار الخلفي الزمكاني (Spatio-Temporal Back-Propagation)، التي تستفيد من المعلومات المكانية والزمانية ضمن تدفق النبضات</em> (<span class="nodecor">Ref_Wu_STBP_FNINS18</span>, <span class="nodecor">Ref_Viale_CarSNN_IJCNN21</span>).</p>
<h2 id="Sec_Prelim_Quantize">التكميم</h2>
<p>التكميم هو تقنية تحسين بارزة يمكن أن تضغط نماذج الشبكات العصبية المتقدمة بكفاءة وبتكلفة منخفضة نسبيًا، حيث تحتاج فقط إلى تقليل دقة البيانات (<span class="nodecor">Ref_Gupta_Precision_ICML15</span>, <span class="nodecor">Ref_Micikevicius_Precision_ICLR18</span>). يتطلب تنفيذ التكميم عددًا من الأنظمة تشمل <em>نظام التكميم</em> و<em>نظام التقريب</em> كما سيتم مناقشته فيما يلي.</p>
<p><strong>أنظمة التكميم:</strong> هناك نظامان شائعان لتكميم الشبكات العصبية المتقدمة: <em>التكميم بعد التدريب (PTQ)</em>، و<em>التدريب المدرك للتكميم (QAT)</em> (<span class="nodecor">Ref_Putra_QSpiNN_IJCNN21</span>). في PTQ يتم عادة تدريب الشبكة المعطاة بدقة نقطة عائمة، مثل نقطة عائمة <span class="nodecor">32</span>-بت (FP32)، ثم يتم تطبيق التكميم على نموذج الشبكة العصبية المتقدمة المدربة بمستوى الدقة المعطى، مما ينتج عنه نموذج شبكة عصبية متقدمة مكمم لمرحلة الاستدلال. في المقابل، يؤدي QAT عادة التكميم للشبكة المعطاة بمستوى الدقة المعطى خلال مرحلة التدريب، مما ينتج عنه نموذج شبكة عصبية متقدمة مدرب ومكمم يمكن استخدامه مباشرة لمرحلة الاستدلال. عملية PTQ عادة ما تكون أبسط وأكثر كفاءة من QAT لأنها تؤدي التكميم مرة واحدة بعد انتهاء مرحلة التدريب.</p>
<p><strong>أنظمة التقريب:</strong> يتطلب تنفيذ التكميم عادة نظام تقريب محدد لتحديد كيفية تقليص القيمة. من الأدبيات، هناك ثلاثة أنظمة تقريب شائعة الاستخدام لنماذج الشبكات العصبية المتقدمة: <em>التقطيع (TR)</em>، <em>التقريب إلى الأقرب (RN)</em>، و<em>التقريب العشوائي (SR)</em> (<span class="nodecor">Ref_Putra_QSpiNN_IJCNN21</span>). من بين هذه الأنظمة، يمتلك TR أبسط عملية حيث يحتفظ فقط بعدد المعنويات الأكثر أهمية ويتجاهل البتات المتبقية.</p>
<p>في هذا العمل، <em>نستخدم نظام PTQ مع نظام تقريب TR لأن تركيبهما يمكن أن يوفر بسرعة نتائج تمثيلية لإعدادات التكميم المختلفة، مما يمكّن من استكشاف سريع لمساحة التصميم (DSE)، وهو أمر مهم لدراستنا</em>.</p>
<h2 id="Sec_Prelim_AutoData">بيانات السيارات القائمة على الأحداث</h2>
<p><strong>مجموعة بيانات Prophesee NCARS (<span class="nodecor">Ref_Sironi_HATS_CVPR18</span>):</strong> تحتوي هذه المجموعة القائمة على الأحداث على مجموعة من <span class="nodecor">24K</span> عينة، كل منها بمدة <span class="nodecor">100</span> مللي ثانية، تم تسجيلها باستخدام كاميرا الاستشعار الزمني غير المتزامن (ATIS) (<span class="nodecor">Posch_2011JSSC_ATISSensor</span>). كل عينة مصنفة إما كـ"سيارة" أو "خلفية"، ومشفرة كتسلسل من الأحداث التي تحتوي على المعلومات التالية:</p>
<ul>
<li><p>الطابع الزمني <span class="math inline">\(t\)</span> لوقت حدوث الحدث؛</p></li>
<li><p>الإحداثيات المكانية <span class="math inline">\(x\)</span> و <span class="math inline">\(y\)</span> للبكسل؛</p></li>
<li><p>قطبيته <span class="math inline">\(p\)</span> لتغير السطوع، والتي يمكن أن تكون إيجابية أو سلبية.</p></li>
</ul>
<p>تم تقسيم البيانات إلى <span class="nodecor">15,422</span> عينة للتدريب و <span class="nodecor">8,607</span> عينة للاختبار. كل عينة لها أحجام متغيرة ويمكن قصها. بناءً على توزيع الأحداث، يمكننا تحديد <em>نافذة انتباه</em>، أي منطقة يتركز فيها الأحداث بشكل أكبر. الأحجام النموذجية لنوافذ الانتباه المستخدمة في الأعمال الرائدة (<span class="nodecor">Ref_Viale_CarSNN_IJCNN21</span>) يمكن أن تصغر إلى <span class="nodecor">100</span> <span class="math inline">\(\times\)</span> <span class="nodecor">100</span> أو <span class="nodecor">50</span> <span class="math inline">\(\times\)</span> <span class="nodecor">50</span> وتقلل بشكل كبير من متطلبات الحوسبة والذاكرة للشبكة العصبية النبضية، دون التأثير كثيرًا على الدقة.</p>
<h2 id="هندسة-الشبكة-العصبية-المتقطعة">هندسة الشبكة العصبية النبضية</h2>
<p>تتكون هندسات الشبكة العصبية النبضية من تسلسل طبقات من الخلايا العصبية النبضية. يحدد هيكلها واتصالاتها نوع الطبقات. في هذا العمل، نستخدم هندسات الشبكة العصبية النبضية للسيارات (<span class="nodecor">Ref_Viale_CarSNN_IJCNN21</span>) التي تنفذ التعرف على السيارات بكفاءة باستخدام قاعدة التعلم المبنية على STBP. نقوم بتنفيذ هندستين للشبكة العصبية النبضية مبنيتين بأحجام مختلفة لنافذة الانتباه. كلا النموذجين مكونان من تسلسل متداخل من طبقتين تلافيفيتين وثلاث طبقات تجميع متوسط، يليهما طبقتان متصلتان بالكامل. الهندسة الأولى للشبكة العصبية النبضية، الموصوفة في الجدول [Tab_SNNarch_100x100]، لديها نافذة انتباه بحجم <span class="math inline">\(100 \times 100\)</span>، بينما الهندسة الثانية للشبكة العصبية النبضية، الموصوفة في الجدول [Tab_SNNarch_50x50]، لديها نافذة انتباه بحجم <span class="math inline">\(50 \times 50\)</span>. لاحظ أن أحجام نوافذ الانتباه المختلفة تؤثر على أحجام خرائط الميزات لكل طبقة من طبقات الشبكة العصبية النبضية. وبالتالي، تمتلك هذه الهندسات عددًا مختلفًا من قنوات الإدخال والإخراج في الطبقات المتصلة بالكامل مقارنة بالأخرى.</p>
<h1 id="Sec_Frame">إطار عمل SNN4Agents</h1>
<h2 id="Sec_Frame_Overview">نظرة عامة</h2>
<p>يستخدم إطار عملنا SNN4Agents مجموعة من تقنيات التحسين التي تستهدف جوانب تصميم مختلفة، بما في ذلك <em>ضغط النموذج من خلال تكميم الأوزان</em>، <em>تحسين الكمون من خلال تقليل الخطوات الزمنية</em>، <em>تحسين بيانات الإدخال من خلال تقليل نافذة الانتباه</em>؛ ثم ينفذ <em>استراتيجية التحسين المشترك</em> لتعظيم الفوائد من تقنيات التحسين الفردية. يتم توضيح سير عمل إطار SNN4Agents في الشكل [Fig_SNN4Agents]، ويتم تقديم مناقشة مفصلة لخطواته في القسم [Sec_Frame_Quantize] - القسم [Sec_Frame_Joint].</p>
<h2 id="Sec_Frame_Quantize">ضغط النموذج من خلال التكميم</h2>
<p>لضغط حجم النموذج بكفاءة، نقوم بتكميم الأوزان من خلال PTQ مع نظام تقريب TR. للقيام بذلك، نقوم أولاً بتدريب الشبكة المعطاة بدون تكميم، مع استخدام الإعدادات الأساسية للخطوة الزمنية، نافذة الانتباه، وعدد عصور التدريب. في هذا السيناريو، نستخدم دقة <span class="nodecor">32</span>-بت، <span class="nodecor">20</span> خطوة زمنية، نافذة انتباه <span class="nodecor">100x100</span>، و<span class="nodecor">200</span> عصر تدريب. بمجرد انتهاء مرحلة التدريب، نقوم بعملية التكميم للشبكة المدربة. بعد ذلك، نقوم بتنفيذ DSE تحت مستويات دقة الأوزان المختلفة (<span class="nodecor">32</span>، <span class="nodecor">16</span>، <span class="nodecor">12</span>، <span class="nodecor">10</span>، <span class="nodecor">8</span>، <span class="nodecor">6</span>، و<span class="nodecor">4</span> بت) لتقييم تأثيرها على الدقة؛ انظر إعدادات المعلمات لـ DSE في الجدول [Tab_Setting_Quantize].</p>
<p>نتائج التجربة لـ DSE تظهر في القائمة التالية:</p>
<ul>
<li><p>في بداية مرحلة التدريب (مثلاً، <span class="math inline">\(\leq\)</span> <span class="nodecor">60</span> عصر تدريب)، لا تزال الشبكة تتعلم معلومات جديدة، وبالتالي فإن منحنى الدقة يزداد لمستويات دقة <span class="nodecor">16</span>-، <span class="nodecor">12</span>-، و<span class="nodecor">10</span>-بت، كما هو موضح بـ .</p></li>
<li><p>استخدام مستويات دقة <span class="nodecor">16</span>-، <span class="nodecor">12</span>-، و<span class="nodecor">10</span>-بت لأوزان SNN يؤدي إلى دقة مماثلة لنموذج SNN الأصلي بدقة <span class="nodecor">32</span>-بت (بدون تكميم) بعد تشغيل ما لا يقل عن <span class="nodecor">80</span> عصر تدريب، كما هو موضح بـ .</p></li>
<li><p>استخدام مستويات دقة <span class="nodecor">8</span>-، <span class="nodecor">6</span>-، و<span class="nodecor">4</span>-بت لأوزان SNN يؤدي إلى تدهور كبير في الدقة، حيث يمكنهم فقط الوصول إلى حوالي <span class="nodecor">50</span>% دقة عبر عصور التدريب، كما هو موضح بـ . هذه النتائج تشير إلى أن الشبكة لم تتدرب بشكل صحيح.</p></li>
</ul>
<p>هذه الملاحظات تكشف عن عدة إرشادات تصميم رئيسية يجب أن نأخذها في الاعتبار عند تطبيق التكميم. أولاً، يجب <em>اختيار مستوى الدقة بعناية</em>، بحيث لا يؤدي إلى تدهور كبير في الدقة يقلل من فوائد التكميم. ثانيًا، يقدم مستوى الدقة <em><span class="nodecor">10</span>-بت توازنًا جيدًا بين الدقة وبصمة الذاكرة</em> حيث يمكنه تحقيق دقة مماثلة لتلك المستويات الأعلى بعد تشغيل ما لا يقل عن <span class="nodecor">80</span> عصر تدريب.</p>
<h2 id="Sec_Frame_Timestep">تحسين الكمون من خلال تقليل الخطوات الزمنية</h2>
<p>لتقليل وقت المعالجة بكفاءة، نقوم بتقليل الخطوات الزمنية. للقيام بذلك، نقلل عدد الخطوات الزمنية لمعالجة الشبكات العصبية المتقدمة من الإعداد الأساسي، مما يقلل من نافذة الزمن لعرض قطارات النبضات. هنا، ننظر في إعدادات خطوات زمنية مختلفة (أي <span class="nodecor">20</span>، <span class="nodecor">15</span>، <span class="nodecor">10</span>، و <span class="nodecor">5</span>) لاستكشاف تأثيرها على الدقة. بمجرد تقليل الخطوة الزمنية، يتم تدريب الشبكة تحت الإعداد الأساسي لمستوى الدقة (بدون تكميم)، نافذة الانتباه، وعدد عصور التدريب. لهذا السيناريو، نستخدم دقة <span class="nodecor">32</span>-بت، نافذة انتباه <span class="nodecor">100x100</span>، و <span class="nodecor">200</span> عصر تدريب. إذا لم نلاحظ اختلافات ملحوظة في الدقة الأساسية، فقد نستخدم مستوى دقة أصغر، مثل أوزان <span class="nodecor">16</span>- و <span class="nodecor">4</span>-بت، لتحفيز تغير الدقة. يتم توفير إعدادات المعلمات لتقييم النظام الديناميكي في الجدول [Tab_Setting_Timestep].</p>
<p>نتائج التجارب لتقييم النظام الديناميكي تظهر في القائمة التالية:</p>
<ul>
<li><p>استخدام إعدادات الخطوة الزمنية <span class="nodecor">15</span>، <span class="nodecor">10</span>، و <span class="nodecor">5</span> بدون تكميم يؤدي إلى دقة مماثلة للنموذج الأساسي (أي الخطوة الزمنية <span class="nodecor">20</span> بدون تكميم) بعد <span class="nodecor">60</span> عصر تدريب، كما هو موضح بـ . بالمثل، استخدام إعدادات الخطوة الزمنية <span class="nodecor">20</span>، <span class="nodecor">15</span>، <span class="nodecor">10</span>، و <span class="nodecor">5</span> مع دقة <span class="nodecor">16</span>-بت يؤدي أيضًا إلى دقة مماثلة للأساس بعد <span class="nodecor">60</span> عصر تدريب؛ انظر .</p></li>
<li><p>استخدام إعدادات الخطوة الزمنية <span class="nodecor">20</span>، <span class="nodecor">15</span>، <span class="nodecor">10</span> و <span class="nodecor">5</span> مع مستوى دقة <span class="nodecor">4</span>-بت يؤدي إلى تدهور كبير في الدقة، كما هو موضح بـ . يعني ذلك أن دقة <span class="nodecor">4</span>-بت صغيرة نسبيًا لتمثيل الميزات الزمنية والمكانية من مجموعة بيانات NCARS.</p></li>
</ul>
<p>توضح هذه الملاحظات أنه <em>يمكننا تطبيق تقليل الخطوة الزمنية بشكل عدواني نسبيًا (مثل الخطوة الزمنية <span class="nodecor">5</span>) دون فقدان كبير في الدقة، طالما نستخدم أيضًا مستوى دقة مناسب</em>، مما يستوعب المعلومات الزمنية والمكانية لمجموعة البيانات المعطاة (مثل NCARS).</p>
<h2 id="Sec_Frame_AttWindow">تقليل نافذة الانتباه لعينات الإدخال</h2>
<p>نهدف أيضًا إلى تقليل حجم نافذة الانتباه لعينات الإدخال لتحسين متطلبات الحساب، وبالتالي تقليل الزمن المستغرق واستهلاك الطاقة. لتحقيق ذلك، ندرس أحجام نوافذ انتباه مختلفة (أي <span class="nodecor">100x100</span> و <span class="nodecor">50x50</span>)، مع استخدام إعدادات أساسية لمستوى الدقة والخطوة الزمنية وعدد عصور التدريب؛ انظر إعدادات المعاملات لـ DSE في الجدول [Tab_Setting_Window].</p>
<p>[Tab_Setting_Window]</p>
<table>
<caption>إعدادات المعاملات لاستكشاف تأثير أحجام نوافذ الانتباه المختلفة.</caption>
<thead>
<tr class="header">
<th style="text-align: center;"><strong>الدقة (بت)</strong></th>
<th style="text-align: center;"><strong>الخطوة الزمنية</strong></th>
<th style="text-align: center;"><em><strong>نافذة الانتباه</strong></em></th>
<th style="text-align: center;"><strong>عصر التدريب</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="nodecor">32</span></td>
<td style="text-align: center;"><span class="nodecor">20</span></td>
<td style="text-align: center;"><span class="nodecor">100x100</span> و <span class="nodecor">50x50</span></td>
<td style="text-align: center;"><span class="nodecor">0-200</span></td>
</tr>
</tbody>
</table>
<p>تظهر النتائج التجريبية لـ DSE أن الدقة التي يمكن الحصول عليها بواسطة نافذة انتباه أصغر (<span class="nodecor">50x50</span>) يمكن أن تتشبع بشكل أسرع من النافذة الأكبر (<span class="nodecor">100x100</span>) مما يوفر وقت تدريب أسرع؛ انظر . في الوقت نفسه، توفر نافذة انتباه أكبر دقة أفضل من النافذة الأصغر؛ انظر . السبب هو أن نافذة الانتباه الأصغر توفر معلومات أقل، وبالتالي تتطلب وقتًا أقصر لتدريب الشبكة لكنها تحد من الدقة التي يمكن تحقيقها. تشير هذه الملاحظات إلى أن <em>تقليل نافذة الانتباه ممكن طالما تم تحقيق الدقة المستهدفة</em>.</p>
<h2 id="Sec_Frame_Joint">استراتيجية التحسين المشترك</h2>
<p>لقد أظهرت كل خطوة تحسين فردية من الأقسام الفرعية السابقة إمكانية تقليل بصمة الذاكرة والتأخير، مع الحفاظ على دقة عالية. لذلك، <em>لتعظيم فوائد هذه التحسينات، نقترح استراتيجية لدمج خطوات التحسين الفردية معًا</em>. هنا، نستفيد من الملاحظات الرئيسية وإرشادات التصميم من التحليلات السابقة في القسم [Sec_Frame_Quantize]-القسم [Sec_Frame_AttWindow] لوضع الاستراتيجية التالية.</p>
<ul>
<li><p>نقوم بأداء تقييم التصميم المنظم للإعدادات التالية: (<span class="nodecor">1</span>) مستويات دقة التكميم من <span class="nodecor">10</span>-<span class="nodecor">32</span> بت، (<span class="nodecor">2</span>) <span class="nodecor">5</span>-<span class="nodecor">20</span> خطوة زمنية، و (<span class="nodecor">3</span>) أحجام نافذة الانتباه <span class="nodecor">50x50</span> و <span class="nodecor">100x100</span>.</p></li>
<li><p>لإيجاد المرشحين للحلول، نحلل النتائج التجريبية للدقة، بصمة الذاكرة، التأخير، واستهلاك الطاقة، مع مراعاة قيود الذاكرة والتأخير.</p></li>
<li><p>إذا كان هناك عدة مرشحين للحلول، يمكننا اختيار الأنسب للقيود المعطاة من خلال الموازنة بين مقاييس التصميم، بما في ذلك الدقة، بصمة الذاكرة، التأخير، واستهلاك الطاقة.</p></li>
</ul>
<h1 id="Sec_Eval">منهجية التقييم</h1>
<p>لتقييم إطار عملنا SNN4Agents، نقوم ببناء واستخدام التجهيز التجريبي الموضح في الشكل [Fig_ExpSetup]، مع الأخذ بعين الاعتبار نفس شروط التقييم المستخدمة على نطاق واسع في مجتمع الشبكات العصبية المتقدمة للوكلاء المستقلين (<span class="nodecor">Ref_Putra_Mantis_ICARA23, Ref_Viale_CarSNN_IJCNN21</span>). نستخدم تنفيذًا مبنيًا على لغة Python ونقوم بتشغيله على أجهزة Nvidia RTX 6000 Ada GPU لتقييم مختلف مقاييس الأداء لإطار عملنا SNN4Agents، بما في ذلك الدقة، وزمن المعالجة، واستهلاك الطاقة. ثم يتم استخدام زمن المعالجة واستهلاك الطاقة لتقدير استهلاك الطاقة. في الوقت نفسه، يتم تقدير بصمة الذاكرة من خلال الاستفادة من مستوى الدقة وعدد الأوزان في بنية الشبكة العصبية المتقدمة المقابلة. في حالة نافذة الانتباه <span class="nodecor">100x100</span>، نأخذ بعين الاعتبار بنية الشبكة من الجدول [Tab_SNNarch_100x100]؛ بينما في حالة <span class="nodecor">50x50</span>، نأخذ بعين الاعتبار بنية الشبكة من الجدول [Tab_SNNarch_50x50]. بالنسبة للحمل العملي، نأخذ بعين الاعتبار مجموعة بيانات NCARS (<span class="nodecor">Ref_Sironi_HATS_CVPR18</span>). لغرض تقييم النظام، نأخذ بعين الاعتبار إعدادات المعلمات الموضحة في الجدول [Tab_ExpSetup]، بالإضافة إلى العمل الرائد CarSNN (<span class="nodecor">Ref_Viale_CarSNN_IJCNN21</span>) كأساس مرجعي.</p>
<p>علاوة على ذلك، نستخدم عدة مصطلحات لتمثيل نموذج الشبكة للاختصار، كما يلي.</p>
<ul>
<li><p><span class="math inline">\(B\)</span>b_<span class="math inline">\(T\)</span>t: يمثل شبكة بدقة <span class="math inline">\(B\)</span> بت و <span class="math inline">\(T\)</span> خطوة زمنية. في هذه الحالة، سيتم شرح ومناقشة نافذة الانتباه بشكل صريح لتمييز نموذج الشبكة ونتائجه التجريبية بوضوح. سيتم استخدام هذا المصطلح في القسم [Sec_Res_Accuracy]،  [Sec_Res_Time]، و  [Sec_Res_Energy].</p></li>
<li><p><span class="math inline">\(B\)</span>b_<span class="math inline">\(W\)</span>w: يمثل شبكة بدقة <span class="math inline">\(B\)</span> بت ونافذة انتباه <span class="math inline">\(W\)</span>x<span class="math inline">\(W\)</span>، والتي تشمل إعدادات خطوة زمنية مختلفة. يتم استخدام هذا المصطلح عند مناقشة بصمة الذاكرة في القسم [Sec_Res_Mermory]، حيث تمتلك الشبكات بخطوات زمنية مختلفة نفس بصمة ذاكرة الوزن.</p></li>
<li><p><span class="math inline">\(B\)</span>b_<span class="math inline">\(T\)</span>t_<span class="math inline">\(W\)</span>t: يمثل شبكة بدقة <span class="math inline">\(B\)</span> بت، <span class="math inline">\(T\)</span> خطوة زمنية، ونافذة انتباه <span class="math inline">\(W\)</span>x<span class="math inline">\(W\)</span>. يتم استخدام هذا المصطلح عند مناقشة تحليل التوازن في القسم [Sec_Res_TradeOff].</p></li>
</ul>
<h1 id="Sec_Res">النتائج التجريبية والمناقشة</h1>
<h2 id="Sec_Res_Accuracy">الحفاظ على دقة عالية</h2>
<p>تقدم النتائج التجريبية للدقة في الشكل [Fig_Result_Accuracy]. تظهر هذه النتائج أن النموذج الأساسي (<span class="nodecor">32b_20t</span>) يمكن أن يحقق دقة بنسبة <span class="nodecor">85.95</span>%، بينما يمكن لنماذج الشبكة العصبية النبضية المحسنة مع نافذة انتباه <span class="nodecor">100x100</span> تحقيق دقة تتراوح بين <span class="nodecor">84.12</span>% و <span class="nodecor">85.76</span>%، وتحقق نماذج الشبكة العصبية النبضية المحسنة مع نافذة انتباه <span class="nodecor">50x50</span> دقة تتراوح بين <span class="nodecor">76.81</span>% و <span class="nodecor">78.56</span>%. في حالة نافذة الانتباه <span class="nodecor">100x100</span>، نلاحظ أن مستويات الدقة <span class="nodecor">10-bit</span> تؤدي عمومًا إلى جودة تعلم أقل (أي دقة) عبر جميع فترات التدريب مقارنة بمستويات الدقة الأخرى؛ انظر و . تشير هذه الملاحظات إلى أن مستويات الدقة الأصغر لها قدرات تمثيل قيمة أقل من تلك الأكبر، وبالتالي تتطلب فترة تدريب أطول لتحقيق دقة مماثلة. على سبيل المثال، يمكن لمستويات الدقة <span class="nodecor">10-bit</span> تحقيق دقة تقارب <span class="nodecor">80</span>% في <span class="nodecor">40</span> فترة تدريب، بينما يمكن لمستويات الدقة الأخرى تحقيق ذلك في <span class="nodecor">20</span> فترة تدريب. لنفس السبب، تلاحظ أنماط مماثلة في حالة نافذة الانتباه <span class="nodecor">50x50</span>؛ انظر و . ومع ذلك، في هذه الحالة، لا تختلف درجات الدقة الناتجة عن مستويات الدقة المختلفة كثيرًا، حيث تقع ضمن نطاق دقة يبلغ حوالي <span class="nodecor">2</span>%؛ انظر . السبب هو أن نافذة انتباه أصغر تعني معلومات أقل لنقلها ومعالجتها بواسطة مستويات الدقة المختلفة، مما يحد من الدقة النهائية.</p>
<h2 id="Sec_Res_Mermory">توفير الذاكرة</h2>
<p>تقدم النتائج التجريبية لبصمة الذاكرة في الشكل [Fig_Result_Memory]. تظهر هذه النتائج أن خطوة تكميم الوزن لدينا تقلل بشكل فعال من بصمة الذاكرة حتى <span class="nodecor">68.75</span>% بسبب مستويات الدقة الأصغر لتمثيل قيم الوزن. على سبيل المثال، في حالة نافذة الانتباه <span class="nodecor">100x100</span>، يؤدي تكميم الوزن لدينا إلى توفير حوالي <span class="nodecor">50</span>% من الذاكرة لـ <span class="nodecor">16b_100w</span>، وتوفير <span class="nodecor">62.50</span>% من الذاكرة لـ <span class="nodecor">12b_100w</span>، وتوفير <span class="nodecor">68.75</span>% من الذاكرة لـ <span class="nodecor">10b_100w</span>؛ انظر . في الوقت نفسه، في حالة نافذة الانتباه <span class="nodecor">50x50</span>، يؤدي تكميم الوزن لدينا إلى توفير حوالي <span class="nodecor">91.42</span>% من الذاكرة لـ <span class="nodecor">32b_50w</span>، وتوفير <span class="nodecor">95.71</span>% من الذاكرة لـ <span class="nodecor">16b_50w</span>، وتوفير <span class="nodecor">96.78</span>% من الذاكرة لـ <span class="nodecor">12b_50w</span>، وتوفير <span class="nodecor">97.32</span>% من الذاكرة لـ <span class="nodecor">10b_50w</span>؛ انظر . تأتي المدخرات الكبيرة في الذاكرة في حالة نافذة الانتباه <span class="nodecor">50x50</span> من التكميم بالإضافة إلى تقليل عدد الأوزان بسبب الاختلافات المعمارية في الشبكة كما هو موضح في الجدول [Tab_SNNarch_100x100] والجدول [Tab_SNNarch_50x50].</p>
<h2 id="Sec_Res_Time">تسريع وقت المعالجة</h2>
<p>تظهر النتائج التجريبية لزمن المعالجة أن خطوة تقليل الخطوات الزمنية لدينا تقلل بفعالية من زمن المعالجة مقارنة بالنموذج الأساسي (<span class="nodecor">32b_20t</span>). على سبيل المثال، في حالة نافذة الانتباه <span class="nodecor">100x100</span>، يؤدي تقليل الخطوات الزمنية لدينا إلى تسريعات بمقدار <span class="nodecor">1.27x</span> - <span class="nodecor">1.31x</span> لإعداد <span class="nodecor">15</span> خطوة زمنية (أي <span class="nodecor">32b_15t</span>, <span class="nodecor">16b_15t</span>, <span class="nodecor">12b_15t</span>، و<span class="nodecor">10b_15t</span>)؛ بمقدار <span class="nodecor">1.86x</span> - <span class="nodecor">2.02x</span> لإعداد <span class="nodecor">10</span> خطوات زمنية (أي <span class="nodecor">32b_10t</span>, <span class="nodecor">16b_10t</span>, <span class="nodecor">12b_10t</span>، و<span class="nodecor">10b_10t</span>)؛ وكذلك بمقدار <span class="nodecor">3.58x</span> - <span class="nodecor">3.69x</span> لإعداد <span class="nodecor">5</span> خطوات زمنية (أي <span class="nodecor">32b_5t</span>, <span class="nodecor">16b_5t</span>, <span class="nodecor">12b_5t</span>، و<span class="nodecor">10b_5t</span>)؛ كما هو موضح بواسطة . بينما في حالة نافذة الانتباه <span class="nodecor">50x50</span>، يؤدي تقليل الخطوات الزمنية لدينا إلى تسريعات بمقدار <span class="nodecor">1.28x</span> - <span class="nodecor">1.32x</span> لإعداد <span class="nodecor">15</span> خطوة زمنية (أي <span class="nodecor">32b_15t</span>, <span class="nodecor">16b_15t</span>, <span class="nodecor">12b_15t</span>، و<span class="nodecor">10b_15t</span>)؛ بمقدار <span class="nodecor">2.04x</span> - <span class="nodecor">2.11x</span> لإعداد <span class="nodecor">10</span> خطوات زمنية (أي <span class="nodecor">32b_10t</span>, <span class="nodecor">16b_10t</span>, <span class="nodecor">12b_10t</span>، و<span class="nodecor">10b_10t</span>)؛ وكذلك بمقدار <span class="nodecor">3.85x</span> - <span class="nodecor">3.95x</span> لإعداد <span class="nodecor">5</span> خطوات زمنية (أي <span class="nodecor">32b_5t</span>, <span class="nodecor">16b_5t</span>, <span class="nodecor">12b_5t</span>، و<span class="nodecor">10b_5t</span>)؛ كما هو موضح بواسطة . تأتي هذه التسريعات الكبيرة من تقليل الخطوات الزمنية التي تقلل من زمن المعالجة لقطارات النبضات.</p>
<h2 id="Sec_Res_Energy">تحسينات كفاءة الطاقة</h2>
<p>تظهر النتائج التجريبية لاستهلاك الطاقة أن تقنيات التحسين لدينا تقلل بفعالية من استهلاك الطاقة مقارنة بالنموذج الأساسي (<span class="nodecor">32b_20t</span>). على سبيل المثال، في حالة نافذة الانتباه <span class="nodecor">100x100</span>، أدت تحسيناتنا إلى تحسينات في الطاقة بمقدار <span class="nodecor">1.36x</span> - <span class="nodecor">1.41x</span> للإعدادات <span class="nodecor">16b_15t</span>، <span class="nodecor">12b_15t</span>، و<span class="nodecor">10b_15t</span>؛ بمقدار <span class="nodecor">1.94x</span> - <span class="nodecor">2.08x</span> للإعدادات <span class="nodecor">16b_10t</span>، <span class="nodecor">12b_10t</span> و<span class="nodecor">10b_10t</span>؛ وكذلك بمقدار <span class="nodecor">3.82x</span> - <span class="nodecor">4.03x</span> للإعدادات <span class="nodecor">16b_5t</span>، <span class="nodecor">12b_5t</span>، و<span class="nodecor">10b_5t</span>؛ كما هو موضح بواسطة . في حالة نافذة الانتباه <span class="nodecor">50x50</span>، أدت تحسيناتنا إلى تحسينات في الطاقة بمقدار <span class="nodecor">1.35x</span> - <span class="nodecor">1.54x</span> للإعدادات <span class="nodecor">16b_15t</span>، <span class="nodecor">12b_15t</span>، و<span class="nodecor">10b_15t</span>؛ بمقدار <span class="nodecor">2.24x</span> - <span class="nodecor">2.48x</span> للإعدادات <span class="nodecor">16b_10t</span>، <span class="nodecor">12b_10t</span> و<span class="nodecor">10b_10t</span>؛ وكذلك بمقدار <span class="nodecor">4.32x</span> - <span class="nodecor">4.66x</span> للإعدادات <span class="nodecor">16b_5t</span>، <span class="nodecor">12b_5t</span>، و<span class="nodecor">10b_5t</span>؛ كما هو موضح بواسطة . تأتي هذه التحسينات الكبيرة في كفاءة الطاقة من الفوائد المشتركة من تقليل دقة الوزن، تقليل الخطوات الزمنية، وتقليل نافذة الانتباه التي تقلل من قدرة المعالجة وزمن الاستجابة، وبالتالي استهلاك الطاقة.</p>
<h2 id="Sec_Res_TradeOff">تحليل التوازن</h2>
<p>لتحديد النموذج المناسب من الشبكة العصبية النبضية للقيود المحددة للذاكرة والتأخير، نقوم بتحليل التوازن. لهذا، نحلل العلاقة بين الدقة وبصمة الذاكرة، الدقة والتأخير، وكذلك الدقة واستهلاك الطاقة. <em>لتحليل الدقة-الذاكرة</em>، نلاحظ أن الدقة تقل كلما قلت بصمة الذاكرة، وهذا ما يُشار إليه بمستويات دقة البتات الأقل مع أحجام نوافذ الانتباه الأصغر؛ انظر الشكل [Fig_Result_TradeOff](a). يعني ذلك أننا بحاجة لاختيار نموذج الشبكة المناسب الذي تتناسب بصمة ذاكرته مع القيد المحدد للذاكرة. على سبيل المثال، إذا كان القيد المحدد للذاكرة هو <span class="nodecor">8MB</span>، فيمكننا اختيار نماذج الشبكة بدقة <span class="nodecor">12-</span> و <span class="nodecor">10-bit</span> تحت نافذة انتباه <span class="nodecor">100x100</span>، وكذلك جميع نماذج الشبكة تحت نافذة انتباه <span class="nodecor">50x50</span>. <em>لتحليل الدقة-التأخير</em>، نلاحظ أن الدقة تقل كلما قل التأخير، وهذا ما يُشار إليه بفترات الزمن الأقصر؛ انظر الشكل [Fig_Result_TradeOff](b). يعني ذلك أننا بحاجة لاختيار نموذج الشبكة المناسب الذي يتناسب تأخيره مع القيد المحدد للذاكرة. على سبيل المثال، إذا كان القيد المحدد للتأخير هو <span class="nodecor">0.25x</span> من التأخير الأساسي، فيمكننا اختيار نماذج الشبكة بـ <span class="nodecor">5</span> خطوات زمنية تحت كل من نوافذ الانتباه <span class="nodecor">100x100</span> و <span class="nodecor">50x50</span>. <em>لتحليل الدقة-الطاقة</em>، نلاحظ أن الدقة تقل أيضًا كلما قل استهلاك الطاقة، وهذا ما يُشار إليه بمستويات دقة البتات الأقل مع فترات الزمن الأقصر وأحجام نوافذ الانتباه الأصغر؛ انظر الشكل [Fig_Result_TradeOff](c). على سبيل المثال، إذا كانت القيود المحددة هي <span class="nodecor">8MB</span> للذاكرة مع <span class="nodecor">0.25x</span> التأخير من التأخير الأساسي، فيمكننا اختيار نموذج الشبكة بإعداد <span class="nodecor">10b_5t_100w</span>، الذي يحقق <span class="nodecor">84.12%</span> مع توفير <span class="nodecor">68.75%</span> في الذاكرة وتسريع بمقدار <span class="nodecor">3.58x</span>، وتحسين كفاءة الطاقة بمقدار <span class="nodecor">4.03x</span> من النموذج الأساسي؛ انظر . علاوة على ذلك، إذا كان القيد المحدد للذاكرة أصغر بكثير (مثلاً، <span class="nodecor">1MB</span> للذاكرة) مع <span class="nodecor">0.25x</span> التأخير من التأخير الأساسي، فيمكننا اختيار نموذج الشبكة بإعداد <span class="nodecor">10b_5t_50w</span>، الذي يحقق <span class="nodecor">77.10%</span> مع توفير <span class="nodecor">97.32%</span> في الذاكرة وتسريع بمقدار <span class="nodecor">4x</span>، وتحسين كفاءة الطاقة بمقدار <span class="nodecor">5.85x</span> من النموذج الأساسي؛ .</p>
<p>باختصار، <em>جميع هذه النتائج التجريبية تظهر أن إطار عملنا SNN4Agents يحسن بفعالية كفاءة استهلاك الطاقة لنماذج الشبكة العصبية النبضية لتطبيقات الوكلاء الذاتيّة</em>. علاوة على ذلك، يمكن لإطار العمل الخاص بنا <em>مساعدة المستخدمين في إيجاد واختيار النموذج المناسب من الشبكة العصبية النبضية لتلبية القيود المحددة للذاكرة والتأخير</em>، أي من خلال تعديل إعدادات التحسين لتكميم الوزن، إعداد الخطوة الزمنية، وحجم نافذة الانتباه.</p>
<h1 id="Sec_Conclusion">الخلاصة</h1>
<p>في هذا العمل، نقترح إطار عمل <span class="nodecor">SNN4Agents</span> الذي يستخدم مجموعة من تقنيات التحسين لتطوير الشبكات العصبية النبضية الموفرة للطاقة والموجهة لتطبيقات الوكلاء المستقلين. هنا، يقوم إطار عمل <span class="nodecor">SNN4Agents</span> بضغط نموذج <span class="nodecor">SNN</span> من خلال تكميم الأوزان، ويحسن وقت المعالجة من خلال تقليل الخطوات الزمنية، ويحسن عينات الإدخال من خلال تقليل نافذة الانتباه. تظهر النتائج التجريبية أن الإطار المقترح يحسن كفاءة استخدام الطاقة بفعالية، ويقلل من بصمة الذاكرة والتأخير، مع الحفاظ على دقة عالية. إذا اعتبرنا نطاق تسامح بنسبة <span class="nodecor">2%</span> أقل دقة من الأساس، يمكننا تحقيق دقة <span class="nodecor">84.12%</span> مع توفير <span class="nodecor">68.75%</span> في الذاكرة، وتسريع <span class="nodecor">3.58x</span>، وتحسين كفاءة الطاقة بمقدار <span class="nodecor">4.03x</span>. بهذه الطريقة، يمكن لإطار عمل <span class="nodecor">SNN4Agents</span> تطوير وكلاء مستقلين فعالين يعتمدون على <span class="nodecor">SNN</span>.</p>
<h1 id="Sec_DataStatement" class="unnumbered">بيان توافر البيانات</h1>
<p>تم استخدام مجموعات بيانات متاحة للعامة في هذه الدراسة. يمكن العثور على هذه المجموعات في الموقع التالي: <span class="nodecor">https://www.prophesee.ai/2018/03/13/dataset-n-cars/</span> (مجموعة بيانات <span class="nodecor">NCARS</span>).</p>
<h1 id="Sec_Author" class="unnumbered">مساهمات المؤلفين</h1>
<p>قام كل من رشمد فيديا ويكاكسانا بوترا، ألبيرتو مارشيسيو، ومحمد شفيق بالمساهمة في تصور الإطار. قام رشمد فيديا ويكاكسانا بوترا وألبيرتو مارشيسيو بتطوير وتنفيذ الإطار، بالإضافة إلى كتابة النسخة الأولى من المخطوطة. نظم رشمد فيديا ويكاكسانا بوترا التجارب. أشرف محمد شفيق على العمل البحثي. ساهم جميع المؤلفين في كتابة المخطوطة، وقراءتها، والموافقة على النسخة المقدمة.</p>
<h1 id="Sec_Ack" class="unnumbered">الشكر والتقدير</h1>
<p>تم دعم هذا العمل جزئيًا من قبل مركز جامعة نيويورك أبوظبي للأمن السيبراني (<span class="nodecor">CCS</span>)، الممول من تمكين تحت جائزة معهد أبحاث جامعة نيويورك أبوظبي <span class="nodecor">G1104</span>، ومركز الذكاء الاصطناعي والروبوتات (<span class="nodecor">CAIR</span>)، الممول من تمكين تحت جائزة معهد أبحاث جامعة نيويورك أبوظبي <span class="nodecor">CG010</span>.</p>
</body>
</html>
