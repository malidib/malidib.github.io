<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Daniel Menges">
  <meta name="author" content="Adil Rasheed">
  <title>تحليلات تنبؤية قوية وفعالة من حيث الحساب والذاكرة باستخدام البيانات الضخمة</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>body { direction: rtl; font-size: 22px; }</style>
</head>
<body>
<header>
<h1 class="title">تحليلات تنبؤية قوية وفعالة من حيث الحساب والذاكرة باستخدام البيانات الضخمة</h1>
<p class="author"><span class="nodecor">Daniel Menges</span></p>
<p class="author"><span class="nodecor">Adil Rasheed</span></p>
</header>
<p>latex</p>
<h1 id="ملخص">مُلَخَّص</h1>
<p>في عصر البيانات المكثفة الحالي، أصبحت البيانات الضخمة أصلاً هاماً للذكاء الاصطناعي، حيث تُستخدم كأساس لتطوير النماذج المعتمدة على البيانات وتوفير الرؤى في مجالات متعددة غير معروفة. تتناول هذه الدراسة التحديات المتعلقة بشكوك البيانات، وقيود التخزين، ونمذجة البيانات التنبؤية باستخدام البيانات الضخمة. نستخدم تحليل المكونات الرئيسية القوي لتقليل الضوضاء بفعالية والقضاء على القيم الشاذة، وتحديد مواقع الاستشعار المثلى لضغط البيانات بكفاءة وتخزينها. تمكن تقنية تحديد مواقع الاستشعار المثلى من ضغط البيانات دون فقدان كبير للمعلومات مع تقليل الحاجة إلى التخزين في الوقت نفسه. بينما يقدم تحليل المكونات الرئيسية القوي بديلاً محسناً لتحليل المكونات الرئيسية التقليدي لإدارة البيانات ذات الأبعاد العالية، يمتد نطاق هذا العمل لاستخدامه، مع التركيز على النمذجة المعتمدة على البيانات القوية والملائمة لمجموعات البيانات الضخمة في الوقت الفعلي. لهذا الغرض، يتم تطبيق شبكات الذاكرة القصيرة والطويلة الأمد، وهي نوع من الشبكات العصبية المتكررة، لنمذجة البيانات والتنبؤ بها استناداً إلى مجموعة فرعية منخفضة الأبعاد تم الحصول عليها من تحديد مواقع الاستشعار المثلى، مما يؤدي إلى تسريع حاسم في مرحلة التدريب. تعتبر شبكات الذاكرة القصيرة والطويلة الأمد مناسبة لالتقاط الاعتماديات طويلة المدى في بيانات السلاسل الزمنية، مما يجعلها ملائمة بشكل خاص للتنبؤ بالحالات المستقبلية للأنظمة الفيزيائية استناداً إلى البيانات التاريخية. تم تنظير جميع الخوارزميات المقدمة ومحاكاتها والتحقق منها باستخدام بيانات التصوير الحراري الحقيقية التي ترسم محرك سفينة.</p>
<h1 id="مقدمة">مُقَدِّمَة</h1>
<p>في سياق الذكاء الاصطناعي، أصبحت البيانات تحتل مركز الصدارة، مؤثرة في عمليات اتخاذ القرار في العديد من المجالات، من الرعاية الصحية (<span class="nodecor">raghupathi_big_2014</span>) إلى الاقتصاد القياسي (<span class="nodecor">varian_big_2014</span>)، والتصنيع (<span class="nodecor">nagorny_big_2017</span>)، وغيرها. ومع ذلك، بينما تقدم البيانات الضخمة إمكانات هائلة، من الضروري فهم نقاط قوتها وعيوبها الكامنة، خاصة أن البيانات قد تكون خاطئة بسبب عوامل مختلفة مثل عدم دقة المستشعرات وأخطاء النقل. لذلك، قد تُفسر البيانات أحياناً بشكل خاطئ إذا لم يتم استخدامها بشكل مناسب، خاصة عندما تكون البيانات الأساسية معيبة أو غير دقيقة (<span class="nodecor">pitici_rise_2014</span>). القدرة على التعامل بفعالية مع هذه الأحجام المتزايدة من البيانات وتحليلها وتفسيرها أمر ضروري. لذلك، فإن تطوير ونشر تقنيات تحليل البيانات القوية أمر بالغ الأهمية.</p>
<p>من بين الأدوات المختلفة المتاحة لتحليل البيانات، اكتسب تحليل المكونات الرئيسية (<span class="nodecor">PCA</span>) (<span class="nodecor">jolliffe_principal_2002</span>) اهتماماً كبيراً بسبب قدرته على تقليل أبعاد مجموعات البيانات مع الاحتفاظ بمعظم المعلومات الأساسية (<span class="nodecor">abdi_principal_2010</span>). ومع ذلك، فإن تحليل المكونات الرئيسية التقليدي يتأثر بشكل كبير بالقيم الشاذة والتلف في البيانات، مما يمكن أن يؤثر بشكل كبير على أدائه ودقة التحليلات اللاحقة. ونتيجة لذلك، هناك حاجة إلى تقنيات أكثر قوة يمكنها التعامل مع مثل هذه الاختلالات. تحليل المكونات الرئيسية القوي (<span class="nodecor">RPCA</span>)، وهو نسخة متقدمة من تحليل المكونات الرئيسية، يقدم نتائج أكثر موثوقية من خلال فصل قوي للمكونات منخفضة الرتبة والمتفرقة في البيانات، حتى في وجود قيم شاذة وتلف (<span class="nodecor">hubert_robpca_2005</span>). يتم وصف مفهوم تحليل المكونات الرئيسية القوي لتحليل مصفوفة البيانات إلى مكون منخفض الرتبة ومكون متفرق بدقة في (<span class="nodecor">candes_robust_2011</span>). تُستخدم المكونات المحللة ببرنامج محدب يُسمى مطاردة المكونات الرئيسية. الطريقة، التي يمكنها استعادة المكونات الرئيسية حتى عندما تكون إدخالات البيانات تالفة أو مفقودة، لها تطبيقات في مراقبة الفيديو لاكتشاف الأجسام، في الخلفيات المزدحمة والتعرف على الوجوه لإزالة الظلال، في الانعكاسات، وأكثر. يتم تقديم مقارنة مفصلة بين تحليل المكونات الرئيسية وتحليل المكونات الرئيسية القوي في (<span class="nodecor">scherl_robust_2019</span>)، مما يُظهر فوائد وقوة تحليل المكونات الرئيسية القوي.</p>
<p>بالتوازي، مع الحاجة المتزايدة للبيانات الضخمة، يظهر أحد التحديات الرئيسية وهو التخزين الفعال ونقل هذه الأحجام الهائلة من البيانات. نهج جديد لهذه المشكلة هو مفهوم وضع المستشعرات الأمثل (<span class="nodecor">OSP</span>) (<span class="nodecor">manohar_data-driven_2018</span>). يتضمن وضع المستشعرات الأمثل تموضعاً استراتيجياً للمستشعرات لالتقاط البيانات الأكثر صلة، مما يقلل بشكل كبير من الازدواجية ويسهل التخزين الفعال للبيانات ونقلها. في جوهره، يهدف وضع المستشعرات الأمثل إلى الحصول على نسخة مضغوطة من البيانات دون فقدان كبير للمعلومات.</p>
<p>من خلال فحص شامل لتحليل المكونات الرئيسية القوي ووضع المستشعرات الأمثل، تهدف هذه الدراسة إلى استكشاف التآزر بين هذه المنهجيات وتأثيرها الجماعي في تحسين دقة وكفاءة نمذجة وتحليل البيانات الضخمة.</p>
<p>علاوة على ذلك، نوسع هذا العمل من خلال دمج نهج نمذجة مدفوع بالبيانات للتنبؤات الفورية باستخدام شبكات الذاكرة القصيرة والطويلة الأمد (<span class="nodecor">LSTM</span>)، التي اقترحت لأول مرة من قبل (<span class="nodecor">hochreiter_long_1997</span>). يسمح تصميم شبكات الذاكرة القصيرة والطويلة الأمد، بآليات بواباتها، لها بتعلم الاعتماديات طويلة الأمد في البيانات (<span class="nodecor">chung_gated_2015</span>). لقد اكتسبت الشبكات العصبية الاصطناعية (<span class="nodecor">ANNs</span>) اهتماماً كبيراً في مختلف مجالات التنبؤ بسبب قابليتها للتكيف، وعدم الخطية، والقدرة على تمثيل الوظائف التعسفية. ومع ذلك، فإنها تتطلب الكثير من الوقت الحاسوبي للتدريب (<span class="nodecor">zhang_forecasting_1998</span>). لذلك، نقوم بإنشاء نماذج شبكات الذاكرة القصيرة والطويلة الأمد استناداً إلى عدد قليل من نقاط البيانات المختارة التي تم الحصول عليها من خلال خوارزمية وضع المستشعرات الأمثل. تسرع هذه الطريقة بشكل كبير من مرحلة التدريب، مما يجعل النهج المقترح قابلاً للتكيف مع مجموعة واسعة من التطبيقات. بمجرد التنبؤ بهذه النقاط القليلة (القياسات) باستخدام شبكات الذاكرة القصيرة والطويلة الأمد، نعيد بناء البعد الكامل للبيانات من خلال مفهوم وضع المستشعرات الأمثل، مما يسمح بالتنبؤ بالحالات المستقبلية بدقة ملحوظة في البعد الكامل. يقدم دمج تحليل المكونات الرئيسية القوي، ووضع المستشعرات الأمثل، وشبكات الذاكرة القصيرة والطويلة الأمد نهجاً جديداً لنمذجة البيانات الضخمة، ويعد بالقوة والقدرة على التوسع في مختلف السيناريوهات الواقعية.</p>
<p>في هذه الدراسة، طبقنا الخوارزميات على مجموعة بيانات من كاميرا حرارية ترسم خريطة لمحرك سفينة. وقدمت الصور الحرارية رؤية فريدة لملفات درجات الحرارة وتقلباتها، مما يوفر منظوراً فريداً على سلوك التشغيل والأداء لمحرك السفينة. المراقبة الشرطية ضرورية للحفاظ على العمليات بأمان (<span class="nodecor">mohanty_machinery_2014</span>) ويمكن أن توفر رؤى حول موثوقية محرك السفينة ومكوناته. من خلال تحديد الشذوذ مبكراً، من الممكن التنبؤ بعمر هذه المكونات ومنع الأعطال الكبيرة.</p>
<h1 id="التحديات-الأساسية">التحديات الأساسية</h1>
<p>في الخلاصة، تتناول هذه الدراسة ثلاث تحديات أساسية:</p>
<ul>
<li><p>المعالجة القوية للشكوك مثل القيم الشاذة والتلف في البيانات بسبب استخدام قياسات الكاميرا الحرارية غير المتطفلة ومنخفضة التكلفة.</p></li>
<li><p>الحاجة إلى تقنيات تخزين فعالة من حيث استخدام الذاكرة بسبب الكم الهائل من البيانات المولدة.</p></li>
<li><p>القدرة على الصيانة الاستباقية في الوقت الفعلي من خلال النمذجة التنبؤية المعتمدة على البيانات.</p></li>
</ul>
<p>كما أشار (<span class="nodecor">inproceedings</span>)، نادراً ما يستخدم القطاع البحري الصيانة التنبؤية. بدلاً من ذلك، تميل أنشطة الصيانة في السفن إلى أن تكون وقائية. وهذا يؤدي غالباً إلى تكاليف أعلى حيث أن الأجزاء المستبدلة قد تكون لديها قدرة تحمل قابلة للاستخدام لفترة أطول.</p>
<h1 id="النظرية">النظرية</h1>
<p>يوفر هذا القسم نظرة مفصلة عن التقنيات الإحصائية المستخدمة في هذه الدراسة. نقدم مفهوم تحليل المكونات الرئيسية (Principal Component Analysis) ونظيره القوي، تحليل المكونات الرئيسية القوي (Robust Principal Component Analysis)، لتنظيف البيانات. علاوة على ذلك، يغطي القسم فكرة تحديد مواقع الاستشعار الأمثل (Optimal Sensor Placement) المستخدمة لضغط البيانات بفعالية وإدارة التخزين.</p>
<h2 id="تحليل-المكون-الرئيسي">تحليل المكون الرئيسي</h2>
<p>تحليل المكون الرئيسي (Principal Component Analysis) هو إجراء إحصائي يستخدم تحويلاً متعامداً لتحويل مجموعة من الملاحظات لمتغيرات محتملة الارتباط إلى مجموعة من المتغيرات غير المرتبطة خطياً، والتي تُسمى المكونات الرئيسية. يسمح هذا الإجراء بتحديد الاتجاهات (المكونات الرئيسية) التي تتفاوت فيها البيانات بشكل أكبر. هناك نهجان رئيسيان لحساب تحليل المكون الرئيسي: نهج المتجه الذاتي ونهج تحليل القيمة المفردة (Singular Value Decomposition). توصف المفاهيم العامة بالتفصيل في (<span class="nodecor">shlens_tutorial_2014</span>). غالباً ما يتم اختيار نهج تحليل القيمة المفردة لأنه أكثر قوة من الناحية العددية.<br />
</p>
<h3 id="نهج-تحليل-القيمة-المفردة" class="unnumbered">نهج تحليل القيمة المفردة</h3>
<p>يرتبط تحليل المكون الرئيسي ارتباطاً وثيقاً بتحليل القيمة المفردة، وهو تحليل لمصفوفة حقيقية أو مركبة. لأي مصفوفة حقيقية <span class="math inline">\(\mathbf{A}\in \mathbb{R}^{m\times n}\)</span>، حيث <span class="math inline">\(m \geq n\)</span>، يوجد تحليل من الشكل <span class="math display">\[\mathbf{A} = \mathbf{U} \mathbf{\Sigma} \mathbf{V}^T,\]</span> حيث <span class="math inline">\(\mathbf{U}\in \mathbb{R}^{m\times m}\)</span>، و<span class="math inline">\(\mathbf{\Sigma}\in \mathbb{R}^{m\times n}\)</span>، و<span class="math inline">\(\mathbf{V}\in \mathbb{R}^{n\times n}\)</span>. أعمدة <span class="math inline">\(\mathbf{U}\)</span> هي متجهات ذاتية متعامدة لـ <span class="math inline">\(\mathbf{AA}^T\)</span>، وأعمدة <span class="math inline">\(\mathbf{V}\)</span> هي متجهات ذاتية متعامدة لـ <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span>. العناصر القطرية لـ <span class="math inline">\(\mathbf{\Sigma}\)</span> هي الجذور التربيعية للقيم الذاتية لـ <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span> (أو بالمثل، <span class="math inline">\(\mathbf{AA}^T\)</span>)، وتسمى القيم المفردة لـ <span class="math inline">\(\mathbf{A}\)</span>. لرؤية ذلك، نعتبر أولاً المصفوفة <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span>، وهي مصفوفة متماثلة. بموجب نظرية الطيف، يمكننا تحليلها كما يلي: <span class="math display">\[\mathbf{A}^T\mathbf{A} = \mathbf{V} \mathbf{\Sigma}^2\mathbf{V}^T.\]</span> بالمثل، يمكننا تحليل <span class="math inline">\(\mathbf{AA}^T\)</span> كما يلي: <span class="math display">\[\mathbf{AA}^T = \mathbf{U} \mathbf{\Sigma}^2 \mathbf{U}^T.\]</span> باستخدام هاتين الهويتين، يمكن إظهار أن <span class="math display">\[\mathbf{A} = \mathbf{U} \mathbf{\Sigma} \mathbf{V}^T,\]</span> وهو تحليل القيمة المفردة لـ <span class="math inline">\(\mathbf{A}\)</span>.</p>
<p>ننظر إلى مصفوفة بيانات <span class="math inline">\(\mathbf{X} \in \mathbb{R}^{m \times n}\)</span>، حيث كل صف هو ملاحظة وكل عمود هو متغير. نفترض أن البيانات قد تم توسيطها، أي تم طرح متوسطات الأعمدة.</p>
<ol>
<li><p><em>أداء تحليل القيمة المفردة ذو الرتبة المنخفضة:</em> احسب تحليل القيمة المفردة لـ <span class="math inline">\(\mathbf{X}\)</span> بواسطة <span class="math inline">\(\mathbf{X} = \mathbf{U}_r\mathbf{\Sigma}_r\mathbf{V}_r^T+\mathbf{E}\)</span>. هنا، <span class="math inline">\(\mathbf{U}_r \in \mathbb{R}^{m \times r}\)</span> و <span class="math inline">\(\mathbf{V}_r^\top \in \mathbb{R}^{r \times n}\)</span> هما مصفوفتان متعامدتان تحتويان على المتجهات الذاتية اليسرى واليمنى و <span class="math inline">\(r\)</span> هو عدد المكونات الرئيسية، على التوالي. المصفوفة <span class="math inline">\(\mathbf{\Sigma}_r \in \mathbb{R}^{r \times r}\)</span> تحتوي على أكبر <span class="math inline">\(r\)</span> قيم مفردة بترتيب تنازلي على القطر. بالإضافة إلى ذلك، تحتوي المصفوفة <span class="math inline">\(\mathbf{E}\)</span> على البقايا غير الممثلة بسبب تقليل الأبعاد.</p></li>
<li><p><em>المكونات الرئيسية:</em> أخيراً، تُعطى المكونات الرئيسية لـ <span class="math inline">\(\mathbf{X}\)</span> بواسطة <span class="math inline">\(\mathbf{X}\mathbf{V}_r \approx \mathbf{U}_r \mathbf{\Sigma}_r\)</span>. العمود <span class="math inline">\(i\)</span> من <span class="math inline">\(\mathbf{X}\mathbf{V}_r\)</span> هو إسقاط البيانات على الاتجاه الرئيسي <span class="math inline">\(i\)</span> (أي المتجه الذاتي <span class="math inline">\(i\)</span>).</p></li>
</ol>
<p>يُظهر هذا الإجراء كيف يمكن استنتاج تحليل المكون الرئيسي من تحليل القيمة المفردة لمصفوفة البيانات. ومع ذلك، فإن تحليل المكون الرئيسي التقليدي حساس للغاية للقيم الشاذة وتلف البيانات.</p>
<h2 id="sec:RPCA">تحليل المكون الرئيسي القوي</h2>
<p>الميزة الأكثر أهمية لتحليل المكون الرئيسي القوي عن تحليل المكون الرئيسي القياسي هي مقاومته للقيم الشاذة. يكون تحليل المكون الرئيسي القياسي حساساً للقيم الشاذة لأنه يحاول إيجاد تمثيل ذو بعد أقل يفسر بشكل أفضل التباين في البيانات. إذا كانت هناك قيم شاذة، قد يتأثر تحليل المكون الرئيسي بشكل كبير بها، مما يؤدي إلى تمثيل لا يعكس بدقة معظم الهيكل الأساسي للبيانات. من ناحية أخرى، يقوم تحليل المكون الرئيسي القوي بنمذجة هذه القيم الشاذة بشكل صريح، مما يؤدي إلى تمثيل أكثر دقة وقوة للهيكل الأساسي للبيانات.</p>
<p>في سياقات معينة، يمكن لتحليل المكون الرئيسي القوي أن يستعيد بشكل أفضل الهيكل منخفض الرتبة الحقيقي للبيانات مقارنة بتحليل المكون الرئيسي، خاصة عندما تكون البيانات مفسدة بشكل كبير أو عندما يكون هناك نقص كبير في البيانات.</p>
<p>يعمل تحليل المكون الرئيسي القوي عن طريق تحليل مصفوفة البيانات إلى مصفوفة ذات رتبة منخفضة ومصفوفة متفرقة. تلتقط المصفوفة ذات الرتبة المنخفضة المكونات الرئيسية، وتلتقط المصفوفة المتفرقة القيم الشاذة أو الشوائب. يمكن أن يكون هذا الفصل مفيداً جداً في العديد من التطبيقات، مثل معالجة الصور والفيديو، حيث يمكن أن يتوافق المكون ذو الرتبة المنخفضة مع الخلفية والمكون المتفرق يتوافق مع الأجسام المتحركة. الفكرة العامة هي تحليل مصفوفة البيانات <span class="math inline">\(\mathbf{X}\)</span> إلى مكونين يعبر عنهما بالمعادلة <span class="math display">\[\mathbf{X} = \mathbf{L} + \mathbf{S}.\]</span> هنا، تصف المصفوفة <span class="math inline">\(\mathbf{L}\)</span> المصفوفة ذات الرتبة المنخفضة التي تلتقط الهيكل الرئيسي للبيانات، بينما المصفوفة <span class="math inline">\(\mathbf{S}\)</span> متفرقة وتلتقط القيم الشاذة والتلفيات. لذلك، الهدف هو إيجاد <span class="math inline">\(\mathbf{L}\)</span> و <span class="math inline">\(\mathbf{S}\)</span> اللذين يحققان <span class="math display">\[\begin{split}
&amp; \underset{\mathbf{L}, \mathbf{S}}{\text{تصغير}} \hspace{0.5cm}\mathrm{rank}(\mathbf{L}) + \|\mathbf{S}\|_0, \\
&amp; \text{خاضع لـ} \hspace{0.5cm} \mathbf{L} + \mathbf{S} = \mathbf{X},
\end{split}
\label{eq:RPCA_ideal}\]</span> حيث يصف <span class="math inline">\(\|\mathbf{S}\|_0\)</span> قاعدة الصفر لـ <span class="math inline">\(\mathbf{S}\)</span>، و <span class="math inline">\(\mathrm{rank}(\mathbf{L})\)</span> يحدد رتبة <span class="math inline">\(\mathbf{L}\)</span>. ومع ذلك، بسبب الطبيعة غير المحدبة لكل من الرتبة(<span class="math inline">\(\mathbf{L}\)</span>) و <span class="math inline">\(\|\mathbf{S}\|_0\)</span>، تصبح مشكلة التحسين هذه غير قابلة للتنفيذ (<span class="nodecor">scherl_robust_2019</span>). للتغلب على هذه المشكلة، يوفر الاسترخاء المحدب (<span class="nodecor">JMLR:v11:zhang10a</span>) نهجاً لتقريب القابلية للتحدب للمشاكل غير المحدبة. يسمح الاسترخاء المحدب بتحويلها إلى <span class="math display">\[\begin{split}
&amp; \underset{\mathbf{L}, \mathbf{S}}{\text{تصغير}} \hspace{0.5cm}\|\mathbf{L}\|_* + \lambda \|\mathbf{S}\|_1, \\
&amp; \text{خاضع لـ} \hspace{0.5cm} \mathbf{L} + \mathbf{S} = \mathbf{X},
\end{split}
\label{eq:PCP}\]</span> حيث <span class="math inline">\(\|\cdot\|_1\)</span> هو قاعدة <span class="math inline">\(L_1\)</span> المعطاة بمجموع القيم المطلقة لإدخالات المصفوفة، <span class="math inline">\(\|\cdot\|_*\)</span> هو القاعدة النووية المعطاة بمجموع القيم الذاتية، و <span class="math inline">\(\lambda\)</span> هو معامل. بينما يؤدي تصغير <span class="math inline">\(\|\mathbf{S}\|_1\)</span> إلى تقريب تصغير <span class="math inline">\(\|\mathbf{S}\|_0\)</span>، يؤدي تصغير <span class="math inline">\(\|\mathbf{L}\|_*\)</span> إلى تقريب أدنى رتبة ممكنة لـ <span class="math inline">\(\mathrm{rank}(\mathbf{L})\)</span>. المشكلة الموصوفة هنا محدبة وتعرف باسم مطاردة المكون الرئيسي (PCP). لحل هذه المشكلة المحدبة، يقترح خوارزمية مضاعف لاغرانج المعزز (<span class="nodecor">lin_augmented_2010</span>). يمكن صياغة مضاعف لاغرانج المعزز كما يلي <span class="math display">\[\hspace{-0.7em}\resizebox{.93\hsize}{0.012\vsize}{$\mathcal{L}(\mathbf{L}, \mathbf{S}, \mathbf{\Lambda})=\|\mathbf{L}\|_* + \lambda \|\mathbf{S}\|_1+\langle \mathbf{\Lambda}, \mathbf{X} - \mathbf{L} - \mathbf{S} \rangle + \frac{\mu}{2}\|\mathbf{X}-\mathbf{L}-\mathbf{S}\|_{F}^2$}, \label{eq:ALM}\]</span> حيث <span class="math inline">\(\mathbf{\Lambda}\)</span> هي مصفوفة مضاعفات لاغرانج، <span class="math inline">\(\mu\)</span> هو معامل، <span class="math inline">\(\langle \cdot \rangle\)</span> يدل على الجداء الداخلي، و <span class="math inline">\(\|\cdot\|_F\)</span> هو قاعدة فروبينيوس، المعروفة أيضاً باسم القاعدة الأوروبية، وهي مقياس للحجم أو الطول لمصفوفة. بعد ذلك، نقوم بتصغير <span class="math inline">\(\mathcal{L}\)</span> لحل <span class="math inline">\(\mathbf{L}_k\)</span> و <span class="math inline">\(\mathbf{S}_k\)</span> في الخطوة الزمنية <span class="math inline">\(k\)</span>، حيث يتم تحديث مصفوفة مضاعفات لاغرانج بواسطة <span class="math display">\[\mathbf{\Lambda}_{k+1} = \mathbf{\Lambda}_{k} + \mu(\mathbf{X}-\mathbf{L}_k-\mathbf{S}_k).\]</span> نتيجة لذلك، يقوم تحليل المكون الرئيسي القوي بتحليل مصفوفة البيانات <span class="math inline">\(\mathbf{X}\)</span> إلى مكون ذو رتبة منخفضة <span class="math inline">\(\mathbf{L}\)</span> ومكون متفرق <span class="math inline">\(\mathbf{S}\)</span>.</p>
<h2 id="تحديد-مواقع-الاستشعار-الأمثل">تحديد مواقع الاستشعار الأمثل</h2>
<p>تحديد مواقع الاستشعار الأمثل هو طريقة لتحديد أكثر المواقع فائدة داخل نظام ما لوضع المستشعرات. يمكن لهذه الطريقة أن تعظم اكتساب القياسات للمعلومات (الانتروبيا) مع تقليل عدد المستشعرات المطلوبة. هنا، تصف الانتروبيا وفرة المعلومات داخل النظام.</p>
<p>ليكن <span class="math inline">\(\boldsymbol{x} \in \mathbb{R}^n\)</span> نقطة بيانات واحدة في الزمن، والتي يمكن تقريبها كالتالي <span class="math display">\[\boldsymbol{x} \approx \mathbf{\Psi}_r \boldsymbol{a},\]</span> حيث <span class="math inline">\(\boldsymbol{a} \in \mathbb{R}^{r}\)</span> تحتوي على المعاملات التي تتغير مع الزمن بينما أعمدة <span class="math inline">\(\mathbf{\Psi}_r\)</span> هي أوضاع التحليل الأرثوغونالي الصحيح منخفض الرتبة. التحليل الأرثوغونالي الصحيح مشابه جداً لتحليل المكونات الرئيسية. ومع ذلك، لا يتم توزيع أوضاع التحليل الأرثوغونالي الصحيح بواسطة مصفوفة القيم الفردية <span class="math inline">\(\mathbf{\Sigma}\)</span>، مثل المكونات الرئيسية لتحليل المكونات الرئيسية. لذلك، <span class="math inline">\(\mathbf{\Psi}_r = \mathbf{U}_r\)</span>. إذا افترضنا أن القياسات يمكن التعبير عنها بواسطة <span class="math display">\[\boldsymbol{y} = \mathbf{C}\boldsymbol{x},\]</span> مع <span class="math inline">\(\mathbf{C}\in \mathbb{R}^{s\times n}\)</span> كونها مصفوفة قياس متناثرة و<span class="math inline">\(s\)</span> عدد المستشعرات، يمكن تقريب القياسات بواسطة <span class="math display">\[\boldsymbol{y} \approx \mathbf{C}\mathbf{\Psi}_r \boldsymbol{a}.\]</span> إذا دللنا <span class="math inline">\(\mathbf{\Theta} = \mathbf{C}\mathbf{\Psi}_r\)</span>، يمكن تمثيل المعاملات المقدرة بواسطة <span class="math display">\[\boldsymbol{\hat{a}} = \mathbf{\Theta}^\dagger\boldsymbol{y}. \label{eq:a_est}\]</span> وبالتالي، يمكننا استنتاج تقدير لـ<span class="math inline">\(\boldsymbol{x}\)</span> ينتج <span class="math display">\[\boldsymbol{\hat{x}} = \mathbf{\Psi}_r\boldsymbol{\hat{a}} = \mathbf{\Psi}_r(\mathbf{C}\mathbf{\Psi}_r)^\dagger\boldsymbol{y}. \label{eq:OSP_reconstruction}\]</span> بما أن <span class="math inline">\(\mathbf{\Psi}_r\)</span> يمكن تحديدها باستخدام تحليل القيم الفردية منخفض الرتبة، فإن الكيان الوحيد المجهول هو مصفوفة القياس المتناثرة <span class="math inline">\(\mathbf{C}\)</span>. كما وصف (<span class="nodecor">manohar_data-driven_2018</span>)، يمكن تحقيق تحديد مواقع الاستشعار الأمثل عن طريق تطبيق تحليل QR مع الاستدلال العمودي على أوضاع التحليل الأرثوغونالي الصحيح <span class="math inline">\(\mathbf{\Psi}_r\)</span>. في هذا الصدد، من المهم ملاحظة أن عدد المستشعرات <span class="math inline">\(s\)</span> يجب أن يحقق <span class="math inline">\(s \geq r\)</span>.</p>
<h1 id="المنهجية">المنهجية</h1>
<p>تصف هذه الفقرة إمكانية تدفق عمل البيانات الضخمة لتنظيف البيانات، ضغط البيانات، والنمذجة المدفوعة بالبيانات بكفاءة حسابية. يتم بناء جوهر الإطار المقترح بواسطة تحليل المكون الرئيسي القائم على القوة، البرمجة المثلى، وشبكات الذاكرة طويلة الأمد.</p>
<h2 id="تنظيف-البيانات">تنظيف البيانات</h2>
<p>نستخدم تحليل المكونات الرئيسية القائم على القوة لتنظيف البيانات، كما تم تقديمه في القسم [sec:RPCA]. تم اختيار معاملات التوليف الموصوفة بحيث <span class="math inline">\(\lambda = 0.006\)</span> و <span class="math inline">\(\mu = 10^{-5}\)</span>. بعد الحصول على تحليل مصفوفة البيانات <span class="math inline">\(\mathbf{X}\)</span> إلى <span class="math inline">\(\mathbf{L}\)</span> (مصفوفة ذات رتبة منخفضة) و <span class="math inline">\(\mathbf{S}\)</span> (مصفوفة متفرقة)، يمكن إعادة بناء نسخة نظيفة من البيانات. تمثل المصفوفة ذات الرتبة المنخفضة <span class="math inline">\(\mathbf{L}\)</span> الفيزياء الكامنة، بينما تحتوي المصفوفة المتفرقة <span class="math inline">\(\mathbf{S}\)</span> على الشوائب والاضطرابات. نتيجة لذلك، تمثل المصفوفة <span class="math inline">\(\mathbf{L}\)</span> نسخة نظيفة من مصفوفة البيانات <span class="math inline">\(\mathbf{X}\)</span>.</p>
<h2 id="ضغط-البيانات">ضغط البيانات</h2>
<p>لضغط البيانات مع الاحتفاظ في الوقت نفسه بالمعلومات الأساسية حول النظام الأساسي، نطبق الاستشعار الأمثل الموضح في القسم [sec:OSP] على مصفوفة البيانات المنظفة <span class="math inline">\(\mathbf{L}\)</span> المستخلصة من تحليل المكونات الرئيسية القائم على القوة. المبدأ الأساسي وراء الاستشعار الأمثل هو تعظيم دقة البيانات مع تقليل عدد الحساسات أو نقاط البيانات. من خلال وضع الحساسات في المواقع التي تلتقط أكبر قدر من التباين أو المعلومات في البيانات، يمكننا تمثيل البيانات الأصلية ذات الأبعاد العالية <span class="math inline">\(\mathbf{X}\)</span> بمجموعة أصغر بكثير من القياسات <span class="math inline">\(\mathbf{Y}\)</span>، حيث تحتوي <span class="math inline">\(\mathbf{Y}\)</span> على <span class="math inline">\(\boldsymbol{y}\)</span> مكدسة على نافذة تاريخية محددة. يتم تمثيل هذه المجموعة الأصغر من القياسات بواسطة مصفوفة القياسات المتفرقة <span class="math inline">\(\mathbf{C}\)</span>. القياسات أو الحساسات المختارة تنتج نسخة مضغوطة من البيانات الأصلية. من خلال تقليل عدد الحساسات المطلوبة، يمكن للاستشعار الأمثل أن يؤدي إلى توفير كبير في التكاليف في السيناريوهات التي يكون فيها نشر الحساسات مكلفاً.</p>
<h2 id="نمذجه-القياسات-المتناثرة-باستخدام-شبكات-lstm">نمذجة القياسات المتناثرة باستخدام شبكات LSTM</h2>
<p>في مجال النمذجة المعتمدة على البيانات، تم إثبات قوة الشبكات العصبية، وخاصة شبكات LSTM، في العديد من التطبيقات. تم تصميم شبكات LSTM لتذكر الأنماط على مدى تسلسلات طويلة، مما يجعلها مناسبة لنمذجة بيانات السلاسل الزمنية. ومع ذلك، قد لا تكون شبكات LSTM مناسبة من الناحية الحسابية لمجموعات البيانات الكبيرة. لذلك، نطبق LSTM على مجموعة فرعية ذات أبعاد أقل <span class="math inline">\(\mathbf{Y}\)</span> المستخلصة من OSP.</p>
<p>يمكن أن يقلل الجمع بين شبكات LSTM و OSP من التكاليف الحسابية المطلوبة لتدريب شبكات LSTM بشكل كبير. عندما نستخدم شبكات LSTM لنمذجة هذه القياسات المتناثرة المختارة بواسطة OSP، نهدف إلى التقاط الديناميكيات الزمنية الكامنة. بمجرد تدريب هذه الشبكات، يمكن استخدامها للتنبؤ بنقاط البيانات المتناثرة. من خلال تطبيق خوارزمية إعادة البناء المعطاة بواسطة ، يمكننا تحويل هذه التنبؤات المتناثرة إلى مساحة الاستشعار بالحجم الكامل، مما يعيد تخطيط أبعاد البيانات الأصلية. لاحظ أنه إذا تم أخذ العينات من البيانات بتردد غير متسق، فإن الاستيفاء الأولي للبيانات يمكن أن يؤدي إلى نماذج أكثر دقة.</p>
<h2 id="تدفق-البيانات-الضخمة">تدفق البيانات الضخمة</h2>
<p>النهج الموصوف سابقاً يمكن أن تتفاعل لدمج قوتها في تدفق بيانات ضخمة محسّن. نوضح فيما يلي إطار عمل محتمل، قابل للتطبيق على تطبيقات متنوعة لمعالجة البيانات المسبقة، والضغط، والنمذجة. يتكون التدفق من الهيكل التالي:</p>
<ol>
<li><p><strong>تنظيف البيانات:</strong> يولد تحليل المكونات الرئيسية القوي نسخة نظيفة <span class="math inline">\(\mathbf{L}\)</span> من مصفوفة البيانات <span class="math inline">\(\mathbf{X}\)</span>. بما أن <span class="math inline">\(\mathbf{L}\)</span> يحتوي على المعلومات ذات الاهتمام (مثل الديناميكيات الأساسية للنظام)، يمكن نقل <span class="math inline">\(\mathbf{L}\)</span> إلى طرق المعالجة والتحليل اللاحقة.</p></li>
<li><p><strong>ضغط البيانات:</strong> تمكن خوارزمية الاستشعار المثالي القوي من ضغط شديد لمصفوفة البيانات النظيفة <span class="math inline">\(\mathbf{L}\)</span>. من خلال حساب أوضاع تحليل المكونات الرئيسية <span class="math inline">\(\mathbf{\Psi}_r\)</span> لـ <span class="math inline">\(\mathbf{L}\)</span> وإيجاد مصفوفة القياس النادرة <span class="math inline">\(\mathbf{C}\)</span>، يمكن أن تكون مجموعة فرعية صغيرة <span class="math inline">\(\mathbf{Y}\)</span> كافية لتخزين البيانات. يمكن إرسال المجموعة الفرعية <span class="math inline">\(\mathbf{Y}\)</span> للتحليل والنمذجة المستمرة. لاحظ أنه يجب أيضاً تخزين <span class="math inline">\(\mathbf{\Psi}_r\)</span> و <span class="math inline">\(\mathbf{C}\)</span> لتوسيع المجموعة الفرعية <span class="math inline">\(\boldsymbol{y}\)</span> إلى بعدها الأصلي <span class="math inline">\(\boldsymbol{\hat{x}}\)</span> (انظر ).</p></li>
<li><p><strong>النمذجة المدفوعة بالبيانات:</strong> في هذه الخطوة، يتم بناء نماذج مدفوعة بالبيانات للمجموعة الفرعية المنقولة <span class="math inline">\(\mathbf{Y}\)</span> باستخدام شبكة عصبية مبنية على الذاكرة طويلة الأمد. يمكن بعد ذلك استخدام النماذج المدفوعة بالبيانات المبنية للمجموعة الفرعية للتنبؤ بالحالات المستقبلية. بعد التنبؤ بالمجموعة الفرعية المستقبلية، يمكن حساب التنبؤات لبعد البيانات الأصلي <span class="math inline">\(\mathbf{\hat{X}_{pred}}\)</span> باستخدام <span class="math inline">\(\mathbf{\Psi}_r\)</span> و <span class="math inline">\(\mathbf{C}\)</span> من خوارزمية الاستشعار المثالي القوي.</p></li>
</ol>
<h1 id="إعداد-المحاكاة">إعداد المحاكاة</h1>
<p>تستخدم هذه الدراسة بيانات تم الحصول عليها من كاميرا حرارية ترسم خريطة لمحرك سفينة. تم توفير البيانات بواسطة Idletechs AS. نظراً لأن البيانات كانت غير مفسدة وخالية من القيم الشاذة، قمنا بمحاكاة اضطرابات اصطناعية تؤثر على البيانات المحددة أدناه. بالإضافة إلى ذلك، نصف إعداد شبكة الذاكرة طويلة الأمد العصبية التي اخترناها لهذه الدراسة.</p>
<h2 id="البيانات">البيانات</h2>
<p>تم استخراج مجموعة البيانات من صور الكاميرا الحرارية، التي تلتقط صورة لمحرك سفينة، وتحديداً محرك عبارة. الغرض الأساسي من الحصول على هذه الصور كان لمراقبة السلوك الحراري للمحرك خلال حالات التشغيل المختلفة، بما في ذلك الإقلاع، القيادة المستقرة، والرسو.</p>
<p>استمرت عملية جمع البيانات لمدة أربعة أيام متتالية. في كل يوم، تمت مراقبة المحرك بشكل مستمر لمدة تقارب ست ساعات، مما أسفر عن فترة مراقبة إجمالية تبلغ 24 ساعة على مدار الأيام الأربعة. ومع ذلك، لم يكن تردد أخذ العينات متسقاً. يبلغ متوسط الوقت بين العينات المتتالية حوالي <span class="nodecor">0.5</span> ثانية.</p>
<p>كل صورة مأخوذة من الكاميرا الحرارية تحتوي على <span class="nodecor">19,200</span> بكسل، بأبعاد تبلغ <span class="nodecor">120x160</span> بكسل. يلتقط كل بكسل الإشعاعات الحرارية من المحرك، والتي يمكن أن تقدم رؤى حول أداء المحرك الحراري للسفينة وأي أنماط غير طبيعية أو بقع ساخنة قد تظهر أثناء تشغيله.</p>
<h2 id="Section: Perturbations">الاضطرابات</h2>
<p>لتقييم الطرق تحت ظروف مختلفة، قمنا بأداء أربع سيناريوهات محاكاة تشمل الشذوذ، التلوث، الضوضاء، ومزيجاً منها.</p>
<h3 id="السيناريو-1" class="unnumbered">السيناريو 1</h3>
<p>تم تعكير البيانات بواسطة ضوضاء غاوسية، حيث تم توليد الضوضاء بمتوسط <span class="nodecor">0</span> وانحراف معياري <span class="nodecor">4</span>، مما يضمن تركيز قيم الضوضاء بشكل رئيسي ضمن النطاق <span class="nodecor">[-4, 4]</span>.</p>
<h3 id="السيناريو-2" class="unnumbered">السيناريو 2</h3>
<p>تم تعكير البيانات بواسطة شذوذ. تم إدخال هذه الشذوذ من خلال اختيار عشوائي لـ <span class="nodecor">100</span> نقطة بيانات (بكسل) واستبدال قيمها الأصلية بقيم مولدة عشوائياً ضمن النطاق <span class="nodecor">[30, 40]</span> و <span class="nodecor">[-40, -30]</span>. تم اختيار هذا النطاق لضمان أن حجم الشذوذ يختلف بشكل كبير عن ذلك الخاص بالمتغيرات الفعلية لمحاكاة الشذوذ الشديد في عمليات القياس.</p>
<h3 id="السيناريو-3" class="unnumbered">السيناريو 3</h3>
<p>تم تعكير البيانات بواسطة تلوث. تم محاكاة هذا التلوث بإضافة ضوضاء عشوائية موزعة بالتساوي إلى <span class="nodecor">10%</span> من مجموعة البيانات على الفترة <span class="nodecor">[-15, 30]</span>. تم اختيار هذه الفترة لضمان حجم كبير للتلوث، لمحاكاة التشويه، ولتوفير اختبار صارم لمتانة خوارزميات تحليل المكونات الرئيسية (PCA)، وتحليل المكونات الرئيسية القوي (RPCA)، وخوارزميات OSP.</p>
<h3 id="السيناريو-4" class="unnumbered">السيناريو 4</h3>
<p>تم تعكير البيانات بمزيج من السيناريوهات المذكورة سابقاً 1، 2، و3، مما أدى إلى تراكب جميع السيناريوهات.</p>
<h2 id="هندسة-شبكة-الذاكرة-طويلة-الأمد">هندسة شبكة الذاكرة طويلة الأمد</h2>
<p>لتدريب شبكة الذاكرة طويلة الأمد، تم اختبار تعديلات مختلفة للمعاملات. وأخيراً، تم اختيار المعاملات الموضحة في الجدول [tab:LSTM_parameters]. تم تدريب الشبكة باستخدام محسن آدم، حيث تم تعيين الخطأ التربيعي الجذري المتوسط كمقياس لتقييم أداء النموذج أثناء التدريب. للتنبؤات، تم تدريب الشبكة بحجم نافذة يتكون من <span class="nodecor">50</span> عينة تاريخية، وتم اختيار زمن التنبؤ ليكون <span class="nodecor">100</span> خطوة زمنية. تتكون هيكلية الشبكة من طبقة إدخال، وطبقة الذاكرة طويلة الأمد، وطبقة تغذية أمامية كثيفة، وطبقة إخراج. نظراً لأن الشبكات العصبية العميقة ذات المعاملات الكثيرة غالباً ما تعاني من التخصيص الزائد، فقد تم إدخال طبقة إسقاط. الإسقاط هو تقنية لمعالجة التخصيص الزائد حيث يتم، أثناء التدريب، حذف وحدات عشوائية واتصالاتها (<span class="nodecor">nitish_srivastava_geoffrey_hinton_alex_krizhevsky_ilya_sutskever_and_ruslan_salakhutdinov_dropout_2014</span>).</p>
<h1 id="النتائج-والمناقشة">النتائج والمناقشة</h1>
<p>فيما يلي، تتم مناقشة نتائج الطرق المستقلة فيما يتعلق بتنظيف البيانات، ضغط البيانات، والنمذجة المعتمدة على البيانات.</p>
<h2 id="تنظيف-البيانات-1">تنظيف البيانات</h2>
<p>تُظهر مرحلة تنظيف البيانات في السيناريوهات الأربعة المختلفة الموصوفة في القسم <span class="nodecor">Section: Perturbations</span>. لاحظ أن الصورة غير المضطربة تعكس الحقيقة الأساسية. تتم مقارنة نتائج تحليل المكونات الرئيسية القوي منخفض الرتبة (RPCA) مع تلك الخاصة بتحليل المكونات الرئيسية (PCA). يُظهر كيف يقوم RPCA بتحليل بيانات الصورة الحرارية إلى المصفوفات <span class="math inline">\(\mathbf{L}\)</span> و <span class="math inline">\(\mathbf{S}\)</span>. تصور المصفوفة <span class="math inline">\(\mathbf{L}\)</span> بوضوح الصورة غير المضطربة، بينما تلتقط المصفوفة <span class="math inline">\(\mathbf{S}\)</span> المكونات المتناثرة للبيانات، والتي تحتوي بشكل رئيسي على جميع الشظايا والشوائب غير المرغوب فيها. على النقيض من ذلك، فإن إعادة بناء الصورة باستخدام PCA التقليدي تكون عرضة بشكل خاص للتلف الشديد والقيم الشاذة. لذلك، تعتبر قدرة RPCA على تحليل البيانات إلى مصفوفة منخفضة الرتبة <span class="math inline">\(\mathbf{L}\)</span> ومصفوفة متناثرة <span class="math inline">\(\mathbf{S}\)</span> تحسيناً لدقة العديد من تطبيقات الذكاء الاصطناعي التي تستخدم البيانات الضخمة.</p>
<h2 id="ضغط-البيانات-1">ضغط البيانات</h2>
<p>تطبيق <span class="nodecor">OSP</span> على بيانات الصور الحرارية يمكن أن يقلل بشكل كبير من أبعاد البيانات. في هذه الدراسة، استخدمنا فقط <span class="nodecor">10</span> من أصل <span class="nodecor">19200</span> قياس بكسل. كما هو موضح، من الواضح أنه يمكن إعادة بناء الصور الحرارية الأصلية باستخدام مجموعة مخفضة بشكل كبير من قياسات البكسل.</p>
<p>من وجهة نظر ضغط البيانات، تبرز القدرة على إعادة بناء الصور الحرارية الشاملة باستخدام قياسات بكسل محدودة كفاءة الطاقة والذاكرة لـ <span class="nodecor">OSP</span>. هذا التمثيل المخفض لا يعني فقط تخفيضاً كبيراً في حجم البيانات، ولكنه يعني أيضاً أن الميزات والخصائص الأساسية للصور الحرارية يتم التقاطها بفقدان ضئيل للمعلومات. ونتيجة لذلك، يمكن لهذا النهج في ضغط البيانات من تسريع أوقات المعالجة، وتقليل متطلبات الذاكرة، وخفض استهلاك الطاقة في التطبيقات الواقعية أو السيناريوهات التي تعاني من قيود النطاق الترددي.</p>
<p>يمكن اعتبار توفير الذاكرة على النحو التالي. بفرض وجود مصفوفة بيانات <span class="math inline">\(\mathbf{X}\in \mathbb{R}^{m\times n}\)</span>، حيث <span class="math inline">\(m\)</span> هو البعد المكاني و<span class="math inline">\(n\)</span> يعبر عن البعد الزمني، بينما تمتد مصفوفة القياسات ذات الأبعاد المنخفضة <span class="math inline">\(\mathbf{Y}\in \mathbb{R}^{r\times n}\)</span> ببعد منخفض <span class="math inline">\(r\)</span>، فإن نسبة توفير الذاكرة تُعطى بالمعادلة <span class="math display">\[\alpha = \frac{m}{r}.\]</span> في هذه الدراسة التجريبية، تؤدي نسبة توفير الذاكرة إلى <span class="math display">\[\alpha = \frac{19200}{10} = 1920.\]</span> هذا يعني أنه، بالنظر إلى ذاكرة متساوية، يمكننا تخزين <span class="nodecor">1920</span> مرة أكثر من الصور الحرارية.</p>
<h2 id="نمذجه-تنبؤيه-معتمدة-على-البيانات">نمذجة تنبؤية معتمدة على البيانات</h2>
<p>تم تدريب شبكة <span class="nodecor">LSTM</span> باستخدام فضاء فرعي متناثر <span class="math inline">\(\mathbf{Y}\)</span>، تم الحصول عليه من خلال <span class="nodecor">OSP</span>. نظراً لأن هذه الدراسة تعاملت مع بيانات تحتوي على عينات زمنية غير متسقة، قمنا باستيفاء البيانات قبل بناء نماذج معتمدة على البيانات عبر شبكات <span class="nodecor">LSTM</span>. لإظهار تأثير الاستيفاء المسبق للبيانات، نصور <span class="nodecor">RMSE</span> لتنبؤات النموذج بالنسبة للنموذج المعتمد على البيانات مع وبدون استيفاء أولي. <span class="nodecor">RMSE</span> مرتبط بالصور المعاد بناؤها لحجم الصورة الأصلي (<span class="nodecor">19,200</span> بكسل) باستخدام تنبؤات النموذج من القياسات القليلة لـ <span class="nodecor">OSP</span> (<span class="nodecor">10</span> بكسل). علاوة على ذلك، يتم عرض مقارنة للوقت الحسابي لمرحلة التدريب في الشكل المذكور، مما يُظهر تحسن كفاءة النهج المقترح بشكل هائل. للمقارنة، تم استخدام هيكل الشبكة ومعايير التدريب من الجدول المذكور. تؤكد الكفاءة الحسابية على العملية العملية للطريقة، خاصة عند النظر في التطبيقات الفعلية. بمجرد التدريب، تصبح قدرة النموذج على إجراء التنبؤات فورية، مما يسمح بإجراء توقعات في الوقت الفعلي في أجزاء من الثانية. بالإضافة إلى ذلك، اعتماداً على التطبيق والمعايير المختارة للتدريب (مثل عدد العصور)، يمكن للنهج المقترح تمكين التدريب عبر الإنترنت في الوقت الفعلي.</p>
<h1 id="الخلاصة">الخلاصة</h1>
<p>في الختام، تطبيق تحليل المكونات الرئيسية القوي على بيانات الصور الحرارية يعزز بشكل كبير جودة البيانات، مما يسمح بإجراء تحليلات لاحقة أكثر فائدة. نظراً لمتانته وتنوعه، يمكن توسيع هذه الطريقة لتشمل تطبيقات بيانات متنوعة، مما يوسع من أهميتها وتأثيرها المحتمل عبر مجالات متعددة. علاوة على ذلك، يقدم استخدام تحديد مواقع الحساسات الأمثل نهجاً واعداً لأولئك الذين يتطلعون إلى تعظيم كفاءة استراتيجيات تخزين وضغط البيانات لديهم، خاصة في البيئات التي تكون فيها مساحة التخزين وقدرات نقل البيانات محدودة. يمكن لتطبيق الشبكات العصبية طويلة الأمد على فضاء ذي أبعاد أقل تم الحصول عليه بواسطة تحديد مواقع الحساسات الأمثل أن يحسن الكفاءة الحسابية ويعزز دقة التنبؤات الزمنية. تفاعل النهج المقدمة يعمل على تحسين كل من معالجة البيانات والتحليلات اللاحقة، مما يمكن أن يحسن جودة البيانات والكفاءة الحسابية وكفاءة الذاكرة مع تمكين القدرات التنبؤية في الوقت الفعلي.</p>
</body>
</html>
