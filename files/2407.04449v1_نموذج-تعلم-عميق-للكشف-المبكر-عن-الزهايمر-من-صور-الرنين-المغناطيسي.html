<!DOCTYPE html>
<html lang="ar">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>تعلّم ذاتي إشرافي مُعزَّز بالسجلات الصحية الإلكترونية لتمثيل أشعّة الصدر باستخدام شبكة سيامية مُقنَّعة</title>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        body {
            font-family: 'Times New Roman', serif;
            line-height: 1.6;
            color: #333;
            background-color: #fafafa;
            direction: rtl;
        }
        .container {
            max-width: 900px;
            background-color: white;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
            padding: 40px;
            margin: 20px auto;
        }
        h1 {
            text-align: center;
            font-size: 2.2em;
            margin-bottom: 30px;
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 15px;
        }
        h2 {
            color: #34495e;
            font-size: 1.5em;
            margin-top: 35px;
            margin-bottom: 15px;
            border-right: 4px solid #3498db;
            padding-right: 10px;
            border-left: none;
            padding-left: 0;
        }
        h3 {
            color: #5d6d7e;
            font-size: 1.3em;
            margin-top: 25px;
            margin-bottom: 12px;
        }
        p {
            text-align: justify;
            margin-bottom: 15px;
        }
        .abstract {
            background-color: #f8f9fa;
            border-right: 4px solid #007bff;
            border-left: none;
            padding: 20px;
            margin: 30px 0;
            font-style: italic;
        }
        .keywords {
            background-color: #e9ecef;
            padding: 15px;
            margin: 20px 0;
            border-radius: 5px;
        }
        .equation {
            text-align: center;
            margin: 20px 0;
            padding: 15px;
            background-color: #f8f9fa;
            border-radius: 5px;
        }
        .figure {
            text-align: center;
            margin: 30px 0;
            padding: 20px;
            background-color: #f8f9fa;
            border-radius: 5px;
            border: 1px solid #dee2e6;
        }
        .table {
            margin: 25px 0;
        }
        .reference {
            font-size: 0.9em;
            margin-bottom: 8px;
        }
        .meta-info {
            background-color: #e7f3ff;
            padding: 15px;
            margin-bottom: 30px;
            border-radius: 5px;
            font-size: 0.9em;
            direction: ltr;
            text-align: left;
        }
        code {
            background-color: #f8f9fa;
            padding: 2px 4px;
            border-radius: 3px;
        }
        pre {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
        }
        blockquote {
            border-right: 4px solid #6c757d;
            border-left: none;
            padding-right: 20px;
            font-style: italic;
            color: #6c757d;
        }
        .theorem, .lemma, .proposition, .corollary {
            background-color: #fff3cd;
            border: 1px solid #ffeaa7;
            padding: 15px;
            margin: 20px 0;
            border-radius: 5px;
        }
        .proof {
            border-right: 2px solid #28a745;
            border-left: none;
            padding-right: 15px;
            margin: 15px 0;
        }
        .author {
            text-align: center;
            color: #555;
            line-height: 1.4;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="meta-info">
            <strong>ArXiv ID:</strong> 2407.04449v1<br>
            <strong>LaTeX الأصلي:</strong> <code>./nyuad_arxiv_papers/nyuad_papers_comprehensive/source_code/2407.04449v1_extracted/main.tex</code><br>
            <strong>تاريخ التحويل:</strong> 2025-06-06 13:15:52
        </div>
        <header id="title-block-header">
            <h1 class="title">تعلّم ذاتي إشرافي مُعزَّز بالسجلات الصحية الإلكترونية لتمثيل أشعّة الصدر باستخدام شبكة سيامية مُقنَّعة</h1>
            <p class="author">
                قسم هندسة الحاسوب — جامعة نيويورك أبوظبي — أبوظبي، الإمارات العربية المتحدة<br>
                قسم هندسة الحاسوب — جامعة نيويورك أبوظبي — أبوظبي، الإمارات العربية المتحدة<br>
                قسم هندسة الحاسوب — جامعة نيويورك أبوظبي — أبوظبي، الإمارات العربية المتحدة<br>
                <span><span class="math inline">\(^*\)</span> هؤلاء المؤلفون ساهموا بالتساوي في هذا العمل</span>
            </p>
            <div class="abstract">
                <div class="abstract-title">الملخّص</div>
                <p>تعتمد أساليب التعلّم ذاتي الإشراف للصور الطبية غالباً على وسيط الصورة فقط أثناء مرحلة ما قبل التدريب. ورغم أنّ هذه الأساليب تُظهر نتائج واعدة، فإنّها لا تستفيد من معلومات المريض أو بيانات الفحص المرتبطة والموجودة في السجلات الصحية الإلكترونية (EHR). في هذا العمل، نقترح دمج بيانات السجلات الصحية الإلكترونية في مرحلة ما قبل التدريب ذاتي الإشراف باستخدام شبكة سيامية مُقنَّعة (MSN) بهدف تعزيز جودة تمثيلات صور أشعّة الصدر. درسنا ثلاثة أنواع من بيانات السجلات الصحية الإلكترونية تشمل المعلومات الديموغرافية، وبيانات الفحص، ومعلومات الإقامة في المستشفى. قُمنا بتقييم منهجيتنا على ثلاث مجموعات بيانات عامة لصور أشعّة الصدر: MIMIC-CXR وCheXpert وNIH-14، باستخدام هيكلين مختلفين من محوّلات الرؤية (ViT)، هما ViT-Tiny وViT-Small. وعند تقييم جودة التمثيلات عبر التقييم الخطي، أظهر نهجنا المقترح تحسُّناً ملحوظاً مقارنةً بـ MSN التقليدي وأحدث أساليب التعلّم ذاتي الإشراف. يُبرز عملُنا إمكانات مرحلة ما قبل التدريب ذاتي الإشراف المُعزَّز ببيانات السجلات الصحية الإلكترونية في التصوير الطبي. الكود متاح للعامة عبر الرابط: <a href="https://github.com/nyuad-cai/CXR-EHR-MSN" class="uri">https://github.com/nyuad-cai/CXR-EHR-MSN</a></p>
            </div>
        </header>
        <nav id="TOC" role="doc-toc">
            <ul>
                <li><a href="#introduction">المقدمة</a></li>
                <li><a href="#related-work">الأعمال ذات الصلة</a>
                    <ul>
                        <li><a href="#overview-of-self-supervised-learning">نظرة عامة على التعلّم ذاتي الإشراف</a></li>
                        <li><a href="#self-supervised-learning-in-healthcare">التعلّم ذاتي الإشراف في الرعاية الصحية</a></li>
                    </ul>
                </li>
                <li><a href="#methods">المنهجية</a>
                    <ul>
                        <li><a href="#problem-formulation">صياغة المشكلة</a></li>
                        <li><a href="#section:msn">شبكة سيامية مُقنَّعة</a></li>
                        <li><a href="#multi-modal-pretraining">مرحلة ما قبل التدريب متعدّدة الوسائط</a></li>
                        <li><a href="#downstream-classification">تصنيف المهام اللاحقة</a></li>
                    </ul>
                </li>
                <li><a href="#experiments">التجارب</a>
                    <ul>
                        <li><a href="#dataset">مجموعة البيانات</a></li>
                        <li><a href="#external-validation">التحقّق الخارجي</a></li>
                        <li><a href="#section:3.2">بروتوكول التقييم</a></li>
                        <li><a href="#uni-modal-self-supervised-pre-training-baselines">خطوط الأساس للتدريب ذاتي الإشراف أحادي الوسيط</a></li>
                    </ul>
                </li>
                <li><a href="#section:results">النتائج</a>
                    <ul>
                        <li><a href="#linear-evaluation-results">نتائج التقييم الخطي</a></li>
                        <li><a href="#external-validation-results">نتائج التحقّق الخارجي</a></li>
                        <li><a href="#t-sne-analysis-results">نتائج تحليل t-SNE</a></li>
                    </ul>
                </li>
                <li><a href="#discussion">المناقشة</a></li>
                <li><a href="#implementation-details">تفاصيل التنفيذ</a>
                    <ul>
                        <li><a href="#masked-siamese-network">شبكة سيامية مُقنَّعة</a></li>
                        <li><a href="#model-pretraining">مرحلة ما قبل تدريب النموذج</a></li>
                        <li><a href="#section:ds-setup">تصنيف المهام اللاحقة</a></li>
                    </ul>
                </li>
                <li><a href="#appendix:datasets">خصائص السجلات الصحية الإلكترونية</a></li>
                <li><a href="#section:add-results">نتائج إضافية</a>
                    <ul>
                        <li><a href="#app:results_linear_evaluation">التقييم الخطي</a></li>
                        <li><a href="#supervised-learning">التعلّم الخاضع للإشراف</a></li>
                        <li><a href="#fine-tuning">الضبط الدقيق</a></li>
                        <li><a href="#external-validation-1">التحقّق الخارجي</a></li>
                    </ul>
                </li>
            </ul>
        </nav>

        <section id="introduction" class="level1">
            <h1>المقدمة</h1>
            <p>يتطلّب تدريب الشبكات العصبية العميقة بإشرافٍ بشري كمياتٍ كبيرة من البيانات المصنّفة عالية الجودة <span class="citation" data-cites="lecun2015deep"></span>. غير أنّ ذلك ليس سهلاً في التطبيقات السريرية، نظرًا للوقت والتكلفة والجهد والخبرة اللازمة لجمع البيانات المصنّفة <span class="citation" data-cites="taleb20203d"></span>. في الآونة الأخيرة، أظهر التعلّم ذاتي الإشراف نجاحًا كبيرًا في الاستفادة من البيانات غير المصنّفة، كما في معالجة اللغة الطبيعية <span class="citation" data-cites="lan2019albert"></span> ورؤية الحاسوب <span class="citation" data-cites="jing2020self"></span>. تهدف هذه الأطر إلى تعلّم تمثيلات داخلية مفيدة أثناء مرحلة ما قبل التدريب من دون الحاجة إلى تسميات، لتُستَخدم لاحقًا في مهام التنبؤ عبر التقييم الخطي الخاضع للإشراف.</p>
            <p>نظرًا للأداء المتقدّم لمرحلة ما قبل التدريب ذاتي الإشراف باستخدام بيانات غير مصنّفة ضخمة مقارنةً بالتعلّم الخاضع للإشراف من البداية، سعت تطبيقات حديثة عديدة في الرعاية الصحية إلى الاستفادة من قوة التعلّم ذاتي الإشراف مع التركيز على وسيط بيانات محدّد، غالبًا وسيط واحد فقط <span class="citation" data-cites="shurrab2022self"></span>. على سبيل المثال، استخدم <span class="citation" data-cites="xie2020pgl"></span> تعزيزات مكانية لتجزئة الصور ثلاثية الأبعاد، بينما طبّق <span class="citation" data-cites="azizi2021big"></span> تحويلات على صور أشعّة الصدر وصور الأمراض الجلدية للتنبؤ بتسميات الأشعّة والحالات الجلدية على التوالي. كما حافظ <span class="citation" data-cites="zhang2022self"></span> على اتساق التردد الزمني في بيانات السلاسل الزمنية لمهام مثل اكتشاف الصرع، في حين استغلّ <span class="citation" data-cites="kiyasseh2021clocs"></span> إشارات تخطيط القلب لتعلّم تمثيلات مُخصّصة للمريض لتصنيف اضطرابات نظم القلب.</p>
            <p>في الممارسة السريرية، يعتمد الأطباء على عدة مصادر للمعلومات عند التشخيص أو تفسير الصور الطبية <span class="citation" data-cites="cui2021artificial"></span>. فعلى سبيل المثال، قد يكون جنس المريض عاملاً حاسمًا في التشخيص والاستجابة للعلاج <span class="citation" data-cites="mauvais2020sex"></span>، كما أنّ عمر المريض قد يؤثّر في اتخاذ القرار السريري في بعض الحالات <span class="citation" data-cites="adams2006influence"></span>. عادةً ما يأخذ الأطباء في الاعتبار مُدخلات إضافية مثل العلامات الحيوية ونتائج التحاليل المخبرية لتعزيز فهمهم للأمراض المختلفة. وبالتالي، فإنّ البيانات الطبية بطبيعتها متعدّدة الوسائط، وتشمل أنواعًا مختلفة مثل الصور الطبية، والسجلات الصحية الإلكترونية، والملاحظات السريرية، وبيانات الأوميكس <span class="citation" data-cites="kline2022multimodal"></span>. بناءً عليه، نفترض أنّ الاستفادة من وسائط إضافية أثناء مرحلة ما قبل التدريب ذاتي الإشراف يمكن أن تُحسّن جودة التمثيلات لمهام التصنيف اللاحقة <span class="citation" data-cites="krishnan2022self"></span>.</p>
            <p>لذا، نقترح إدماج بيانات السجلات الصحية الإلكترونية خلال مرحلة ما قبل التدريب ذاتي الإشراف باستخدام شبكة سيامية مُقنَّعة <span class="citation" data-cites="assran2022masked"></span> لتعلّم تمثيلات صور أشعّة الصدر. باختصار، يتكوّن إطار العمل المُقترَح من مُشفّرَين بصريَّين مأخوذين من MSN التقليدية، ومشفّر غير صوري للسجلات الصحية الإلكترونية، ووحدة إسقاط تُمزِج الوسائط لتمثيل كل زوج من صورة الأشعّة وبيانات السجلات الصحية. درسنا دمج ثلاثة أنواع من بيانات السجلات الصحية الإلكترونية: (أ) المتغيّرات الديموغرافية، (ب) بيانات الفحص، و(ج) معلومات الإقامة في المستشفى. يمكن تلخيص مساهماتنا الرئيسية كما يلي:</p>
            <ul>
                <li>تصميم شبكة سيامية مُقنَّعة متعدّدة الوسائط لإدماج بيانات السجلات الصحية الإلكترونية أثناء مرحلة ما قبل التدريب ذاتي الإشراف على صور أشعّة الصدر، بهدف تحسين جودة التمثيلات المُكتسَبة وتعزيز الأداء في التصنيف اللاحق. يتضمّن ذلك إدخال مُشفّر للسجلات الصحية الإلكترونية ورأس إسقاط لتمثيل متعدّد الوسائط بين السجلات وصور الأشعّة. قارنّا منهجيتنا مع MSN التقليدية، كما قارنّا MSN مع أحدث الأساليب الخاصة بصور أشعّة الصدر.</li>
                <li>إجراء تقييم شامل لخصائص السجلات الصحية الإلكترونية ذات الصلة، وتحليل أثرها الفردي والمشترك على مرحلة ما قبل التدريب ذاتي الإشراف لمهام التصنيف اللاحقة.</li>
                <li>تقييم المنهجية المقترحة على نحوٍ موسّع باستخدام ثلاث مجموعات بيانات عامة: MIMIC-CXR <span class="citation" data-cites="johnson2019mimic"></span> لمرحلة ما قبل التدريب والتحقّق الداخلي، وCheXpert <span class="citation" data-cites="irvin2019chexpert"></span> وNIH-14 <span class="citation" data-cites="wang2017chestx"></span> للتحقّق الخارجي.</li>
            </ul>
            <p>نلخّص الأدبيات ذات الصلة في القسم <a href="#related-work" data-reference-type="ref" data-reference="related-work">2</a>، ونقدّم منهجيتنا المقترحة في القسم <a href="#methods" data-reference-type="ref" data-reference="methods">3</a>، وإعدادات التجارب في القسم <a href="#experiments" data-reference-type="ref" data-reference="experiments">4</a>، والنتائج في القسم <a href="#section:results" data-reference-type="ref" data-reference="section:results">5</a>، وأخيرًا المناقشة والاستنتاجات في القسم <a href="#discussion" data-reference-type="ref" data-reference="discussion">6</a>.</p>
        </section>

        <section id="related-work" class="level1">
            <h1>الأعمال ذات الصلة</h1>

            <section id="overview-of-self-supervised-learning" class="level2">
                <h2>نظرة عامة على التعلّم ذاتي الإشراف</h2>
                <p>تتعلّم أساليب التعلّم ذاتي الإشراف تمثيلات ميزات غير مرتبطة بمهمة محدّدة باستخدام مهام فرعية مُصمَّمة يدويًا أو هياكل تضمينٍ مُشترَك <span class="citation" data-cites="kinakh2021scatsimclr bardes2021vicreg"></span>. تعتمد المهام الفرعية المُصمَّمة يدويًا على استخدام تسمياتٍ زائفة تُولَّد من بيانات غير مصنّفة. من أمثلة هذه المهام: التنبؤ بالدوران <span class="citation" data-cites="gidaris2018unsupervised"></span>، حل أحجية الصور <span class="citation" data-cites="noroozi2016unsupervised"></span>، التلوين <span class="citation" data-cites="zhang2016colorful"></span>، وإكمال الأجزاء الناقصة <span class="citation" data-cites="pathak2016context"></span>. أمّا طرق التضمين المُشترك، فتستخدم الشبكات السيامية <span class="citation" data-cites="bromley1993signature"></span> لتعلّم تمثيلاتٍ مفيدة من خلال التمييز بين وجهات نظر مختلفة للعينة بالاعتماد على دالة هدف محدّدة <span class="citation" data-cites="bardes2021vicreg"></span>، من دون الحاجة إلى إشرافٍ بشري أو تسمياتٍ زائفة.</p>
                <p>يمكن تصنيف طرق التضمين المُشترك إلى طرق تباينية وغير تباينية، حيث تشمل الأخيرة أساليب التجميع، والتقطير، وتعظيم المعلومات <span class="citation" data-cites="bardes2021vicreg"></span>. تتعلّم الطرق التباينية التمثيلات من خلال تعظيم التشابه بين الأزواج الإيجابية وتقليل التشابه بين الأزواج السلبية <span class="citation" data-cites="van2018representation"></span>. من الأمثلة البارزة: SimCLR <span class="citation" data-cites="chen2020simple"></span>، والترميز التنبّؤي التبايني <span class="citation" data-cites="van2018representation"></span>، وMoCo <span class="citation" data-cites="he2020momentum"></span>. تركز الطرق غير التباينية على تحسين مقاييس التشابه المختلفة بين التضمينات المُكتسَبة، مثل BYOL <span class="citation" data-cites="grill2020bootstrap"></span>، وSimSiam <span class="citation" data-cites="chen2021exploring"></span>، وVICReg <span class="citation" data-cites="bardes2021vicreg"></span>. وبينما اعتمدت معظم الأعمال السابقة على الشبكات الالتفافية كأساس للمُشفّرات، بدأت الأساليب الحديثة في استكشاف دور محوّلات الرؤية (ViT) <span class="citation" data-cites="dosovitskiy2020image"></span> في التعلّم ذاتي الإشراف، مثل DINO <span class="citation" data-cites="caron2021emerging"></span> وMSN <span class="citation" data-cites="assran2022masked"></span>. تُعد MSN من أحدث أطر التعلّم ذاتي الإشراف، إذ تعتمد على مبدأ إزالة الضوضاء عبر الإخفاء من دون إعادة البناء، بالإضافة إلى تحقيق ثبات التحويلات باستخدام المحوّلات. لم يُطبَّق MSN على نطاقٍ واسع في المهام الصحية حتى الآن، إلا أنّه واعد نظرًا لقابليته العالية للتوسّع الحسابي.</p>
                <figure class="figure">
                    <embed src="images/MMSN.pdf" id="fig:method" style="height:7cm" />
                    <figcaption aria-hidden="true"><strong>نظرة عامة على الإطار متعدّد الوسائط لشبكة MSN في مرحلة ما قبل التدريب.</strong> نستخدم <span class="math inline">\(x_{ehr}\)</span> كوسيطٍ مُساعِد أثناء مرحلة ما قبل التدريب. في التصنيف اللاحق، نقوم بتجميد <span class="math inline">\(f_{target}\)</span> ونستخدمه كمستخرجٍ للميزات مع رأس تصنيف لمهام التصنيف متعددة التسميات. مكوّنات MSN التقليدية موضّحة باللون الأسود.</figcaption>
                </figure>
                <p><span id="fig:method" label="fig:method"></span></p>
            </section>

            <section id="self-supervised-learning-in-healthcare" class="level2">
                <h2>التعلّم ذاتي الإشراف في الرعاية الصحية</h2>
                <p>أظهرت أساليب التعلّم ذاتي الإشراف نتائج واعدة في تعلّم تمثيلات لأنواع مختلفة من الصور الطبية، مثل التصوير المقطعي المحوسب والتصوير بالرنين المغناطيسي <span class="citation" data-cites="jamaludin2017self zhuang2019self taleb20203d"></span>، وتصوير قاع العين والتصوير البصري المقطعي <span class="citation" data-cites="holmberg2020self hervella2020multi li2021rotation"></span>، وصور التنظير الداخلي <span class="citation" data-cites="ross2018exploiting"></span>. كما بحثت عدة دراسات تطبيق التعلّم ذاتي الإشراف على صور أشعّة الصدر. على سبيل المثال، استخدم <span class="citation" data-cites="pmlr-v143-sowrirajan21a"></span> و<span class="citation" data-cites="chen2021momentum"></span> و<span class="citation" data-cites="sriram2021covid"></span> طريقة MoCo <span class="citation" data-cites="he2020momentum"></span> كإستراتيجية تدريب مُسبق لمهام تشخيص وتنبؤ أمراض الصدر. كما أظهر <span class="citation" data-cites="azizi2021big"></span> أنّ تهيئة SimCLR <span class="citation" data-cites="chen2020simple"></span> بأوزان ImageNet أثناء التدريب المُسبق تُحسّن الأداء في تصنيف صور أشعّة الصدر. ودرس <span class="citation" data-cites="van2024exploring"></span> أثر تقنيات تعزيز الصور المختلفة على التعلّم السيامي لتمثيلات صور أشعّة الصدر.</p>
                <p>بحثت بعض الدراسات استخدام مصادر معلومات أخرى عند تصميم أطر التعلّم ذاتي الإشراف لصور أشعّة الصدر، وتركّز معظمها على التدريب المُسبق بالرؤية واللغة. اقترح <span class="citation" data-cites="vu2021medaug"></span> طريقة MedAug التي تأخذ بيانات المريض الوصفية في الاعتبار عند توليد الأزواج الإيجابية ضمن إطار MoCo <span class="citation" data-cites="he2020momentum"></span>. وحقّق <span class="citation" data-cites="tiu2022expert"></span> أداءً بمستوى الخبراء من خلال الاستفادة من تقارير الأشعّة الخام المرتبطة بصور الأشعّة كإشارات إشرافية أثناء مرحلة ما قبل التدريب ذاتي الإشراف. وبالمثل، اقترح <span class="citation" data-cites="zhang2022contrastive"></span> إطار ConVIRT الذي يتعلّم التمثيلات من أزواج صور الأشعّة والبيانات النصية. لم تبحث أي من هذه الأساليب إدماج بيانات السجلات الصحية الإلكترونية الثابتة أثناء مرحلة ما قبل التدريب ذاتي الإشراف، كما لم تستكشف استخدام MSN لصور أشعّة الصدر. ولِمعالجة هذه الفجوات، نركّز تحديدًا على MSN بهدف تعزيز تعلّم تمثيلات صور أشعّة الصدر بالاستفادة من المحوّلات وبيانات السجلات الصحية الإلكترونية.</p>
            </section>
        </section>

        <section id="methods" class="level1">
            <h1>المنهجية</h1>

            <section id="problem-formulation" class="level2">
                <h2>صياغة المشكلة</h2>
                <p>لنعتبر <span class="math inline">\(x_{cxr}\in \mathbb{R}^{h\times w}\)</span> صورة أشعّة صدر مأخوذة لمريض أثناء إقامته في المستشفى، حيث <span class="math inline">\(h\)</span> و<span class="math inline">\(w\)</span> يُمثّلان ارتفاع الصورة وعرضها. الهدف هو التنبؤ بمجموعةٍ من تسميات الأمراض <span class="math inline">\(y_{cxr}\)</span>. نفترض أنّ كل <span class="math inline">\(x_{cxr}\)</span> مرتبطة بـ <span class="math inline">\(x_{ehr} \in \mathbb{R}^{n}\)</span>، وهو متجه من الخصائص الثابتة المستخرجة من بيانات السجلات الصحية الإلكترونية للمريض، حيث <span class="math inline">\(n\)</span> هو عدد المتغيّرات. نستخدم كلا الوسيطين لتعلّم تمثيل صورة الأشعّة ضمن إطار التدريب المُسبق لدينا. يوضّح الشكل <a href="#fig:method" data-reference-type="ref" data-reference="fig:method">1</a> نظرة عامة على بنية MSN متعدّدة الوسائط لمرحلة ما قبل التدريب. تتكوّن الشبكة من مكوّنَين: (1) المشفّرات البصرية لصور الأشعّة، (2) فرع متعدّد الوسائط يدمج بيانات السجلات الصحية الإلكترونية، كما هو موضّح في الأقسام التالية.</p>
                <figure class="figure">
                    <img src="images/masking-Strategies.png" id="fig:masking" style="width:55%" alt="تصوّر لاستراتيجيات الإخفاء: (أ) الصورة الأصلية. (ب) الإخفاء العشوائي. (ج) الإخفاء البؤري." />
                    <figcaption aria-hidden="true"><strong>تصوّر لاستراتيجيات الإخفاء.</strong> (أ) الصورة الأصلية. (ب) الإخفاء العشوائي: حذف الرقع في مواقع عشوائية داخل الصورة. (ج) الإخفاء البؤري: الاحتفاظ بمجموعةٍ من الرقع المتجاورة وحذف الباقي.</figcaption>
                </figure>
                <p><span id="fig:masking" label="fig:masking"></span></p>
            </section>

            <section id="section:msn" class="level2">
                <h2>شبكة سيامية مُقنَّعة</h2>
                <p>اعتمدنا MSN <span class="citation" data-cites="assran2022masked"></span> كنموذجٍ أساسي لإطارنا المقترح نظرًا لقابليته العالية للتوسّع الحسابي والحاجة إلى تدريب المحوّلات بكفاءة. لصورةٍ غير مصنّفة، يكون الهدف مواءمة وجهتَي النظر «المرساة» و«الهدف»، المشار إليهما بـ <span class="math inline">\(x^{anchor}_{cxr}\)</span> و<span class="math inline">\(x^{target}_{cxr}\)</span> على التوالي. لكل صورة، نستخدم دالة تحويل عشوائية <span class="math inline">\(T(.)\)</span> لتوليد مجموعة من <span class="math inline">\(M\)</span> وجهات نظر مرساة ووجهة نظر هدف واحدة. تشمل التحويلات: تغيير الحجم، والاقتصاص العشوائي مع تغيير الحجم، والانعكاس الأفقي العشوائي باحتمالية <span class="math inline">\(0.5\)</span>، كما في <span class="citation" data-cites="pmlr-v143-sowrirajan21a"></span>. استبعدنا التلاعب بالألوان والتمويه الغاوسي، إذ إنّ الأوّل لا ينطبق على الصور الرمادية، والثاني قد يُشوّه المعلومات المتعلقة بالأمراض <span class="citation" data-cites="pmlr-v143-sowrirajan21a"></span>. وبما أنّ وجهات النظر تُقسَّم إلى رقع لتكون مدخلًا لمحوّلات الرؤية، تُخفى وجهات نظر المرساة عبر حذف الرقع (عشوائيًا أو بؤريًا كما في الشكل <a href="#fig:masking" data-reference-type="ref" data-reference="fig:masking">2</a>)، بينما تظل وجهة النظر الهدف غير مُخفاة.</p>
                <p>يُدرَّب مُشفّران، <span class="math inline">\(f_{anchor}\)</span> و<span class="math inline">\(f_{target}\)</span>، بمعمارية محوّل الرؤية <span class="citation" data-cites="dosovitskiy2020image"></span> لإنتاج تضمينات الصور:
                <span class="math display">\[v_{cxr} = f_{anchor}(x^{anchor}_{cxr}), \quad v_{cxr+} = f_{target}(x^{target}_{cxr}).\]</span></p>
                <p>يُعالَج تضمين الهدف <span class="math inline">\(v_{cxr+}\)</span> عبر رأس إسقاط <span class="math inline">\(h^+\)</span> للحصول على <span class="math inline">\(z^+\)</span>، بينما يُستخدَم <span class="math inline">\(v_{cxr}\)</span> في التعيين متعدّد الوسائط كما سيأتي. لا تحسب MSN الخسارة مباشرةً على التضمينات المُنتَجة بالاستناد إلى مقياس تشابهٍ معيّن، بل تستخدم مجموعةً من النماذج الأوّلية وتسعى إلى تعيين التضمينات المُسقطة لعينةٍ معيّنة إلى النموذج الأوّلي ذاته المُتعلَّم، حيث تُستخدم هذه التعيينات لحساب الخسارة. مزيدٌ من التفاصيل في الملحق <a href="#section:pretrain-setup" data-reference-type="ref" data-reference="section:pretrain-setup">[section:pretrain-setup]</a>.</p>
            </section>

            <section id="multi-modal-pretraining" class="level2">
                <h2>مرحلة ما قبل التدريب متعدّدة الوسائط</h2>
                <p>بدلًا من الاعتماد فقط على صور الأشعّة، يُشجّع إطارنا المقترح MSN على الاستفادة من معلومات إضافية مُستخرجة من السجلات الصحية الإلكترونية للمريض. أضفنا ثلاثة مكوّنات إضافية إلى بنية MSN التقليدية. أولًا، نقوم بترميز بيانات السجلات الصحية الإلكترونية الثابتة باستخدام <span class="math inline">\(f_{ehr}\)</span> لتعلّم متجه تمثيلي، بحيث:
                <span class="math display">\[v_{ehr} = f_{ehr}(x_{ehr}).\]</span></p>
                <p>بعد ذلك، نقوم بدمج (<span class="math inline">\(\oplus\)</span>) التمثيلات الكامنة للسجلات الصحية الإلكترونية وصورة الأشعّة، <span class="math inline">\(v_{ehr}\)</span> و<span class="math inline">\(v_{cxr}\)</span>. في هذه المرحلة، يوجد عدمُ تطابقٍ في الأبعاد بين التمثيلات المُدمَجة و<span class="math inline">\(v_{cxr+}\)</span>. ولمعالجة ذلك، نقوم بإسقاط التمثيل المُدمَج إلى الفضاء البُعدي نفسه لـ<span class="math inline">\(v_{cxr+}\)</span> باستخدام رأس الإسقاط <span class="math inline">\(g\)</span>، لنحصل على <span class="math inline">\(v_{fused}\)</span>:
                <span class="math display">\[v_{fused} = g(v_{ehr} \oplus v_{cxr}).\]</span></p>
                <p>أخيرًا، تتم معالجة التمثيل المُدمَج عبر رأس إسقاط <span class="math inline">\(h(.)\)</span> لحساب <span class="math inline">\(z\)</span>. يُستخدَم كلٌّ من <span class="math inline">\(z\)</span> و<span class="math inline">\(z^+\)</span> في تجميع النماذج الأوّلية أثناء مرحلة ما قبل التدريب. بوجهٍ عام، يتعلّم هذا الإجراء البسيط تمثيلًا مشتركًا لبيانات السجلات الصحية الإلكترونية وتضمينات المرساة، بهدف تحسين قدرة MSN على التعيين أثناء مرحلة ما قبل التدريب.</p>
            </section>

            <section id="downstream-classification" class="level2">
                <h2>تصنيف المهام اللاحقة</h2>
                <p>بعد تدريب المُشفّرات <span class="math inline">\(f_{target}\)</span> و<span class="math inline">\(f_{anchor}\)</span> و<span class="math inline">\(f_{ehr}\)</span>، نستخدم <span class="math inline">\(f_{target}\)</span> كمستخرجٍ للميزات. ثم نضيف نموذج تصنيف <span class="math inline">\(f_c\)</span> للتنبؤ بتسميات الصور:
                <span class="math display">\[\hat{y}_{cxr} = f_c(v_{cxr+})\]</span></p>
                <p>الافتراض الرئيسي في منهجيتنا هو أنّ إدخال بيانات إضافية متعلّقة بالمريض أو بالفحص أثناء مرحلة ما قبل التدريب يُزوِّد النموذج بمعلومات سياقية قيّمة، ما يُسهم في تحسين جودة التمثيلات المُكتسَبة لمهام التصنيف اللاحقة.</p>

                <div class="table">
                    <table class="table table-striped table-bordered align-middle">
                        <caption><strong>ملامح بيانات السجلات الصحية الإلكترونية المُستخدمة في مرحلة ما قبل التدريب.</strong></caption>
                        <thead class="table-light">
                            <tr>
                                <th style="width:18%">المجموعة</th>
                                <th style="width:22%">الميزة</th>
                                <th style="width:18%">النوع</th>
                                <th>القيم</th>
                                <th style="width:14%">البُعد</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>ديموغرافيا</td>
                                <td>العُمر</td>
                                <td>رقمي</td>
                                <td><span class="math inline">\(\{ x \in \mathbb{N} \mid 18 \leq x \leq 100 \}\)</span></td>
                                <td><span class="math inline">\(x_{age} \in \mathbb{R}^{1}\)</span></td>
                            </tr>
                            <tr>
                                <td>ديموغرافيا</td>
                                <td>الجنس</td>
                                <td>ثنائي</td>
                                <td><span class="math inline">\(\{\text{ذكر}، \text{أنثى}\}\)</span></td>
                                <td><span class="math inline">\(x_{sex} \in \mathbb{R}^{2}\)</span></td>
                            </tr>
                            <tr>
                                <td>بيانات الصورة</td>
                                <td>زاوية/اتجاه التصوير</td>
                                <td>متعدّد الفئات</td>
                                <td>—</td>
                                <td><span class="math inline">\(x_{view} \in \mathbb{R}^{4}\)</span></td>
                            </tr>
                            <tr>
                                <td>بيانات الصورة</td>
                                <td>الوضعية</td>
                                <td>ثنائي</td>
                                <td><span class="math inline">\(\{\text{واقف}، \text{مستلقي}\}\)</span></td>
                                <td><span class="math inline">\(x_{pos} \in \mathbb{R}^{2}\)</span></td>
                            </tr>
                            <tr>
                                <td>إقامة بالمستشفى</td>
                                <td>الدخول إلى العناية المركّزة</td>
                                <td>ثنائي</td>
                                <td><span class="math inline">\(\{\text{سلبي}، \text{إيجابي}\}\)</span></td>
                                <td><span class="math inline">\(x_{icu} \in \mathbb{R}^{2}\)</span></td>
                            </tr>
                            <tr>
                                <td>إقامة بالمستشفى</td>
                                <td>الوفاة داخل المستشفى</td>
                                <td>ثنائي</td>
                                <td><span class="math inline">\(\{\text{سلبي}، \text{إيجابي}\}\)</span></td>
                                <td><span class="math inline">\(x_{mort} \in \mathbb{R}^{2}\)</span></td>
                            </tr>
                        </tbody>
                    </table>
                </div>
                <p><span id="tab:pretraining_features" label="tab:pretraining_features"></span></p>

                <div id="tab:datasets_splits" class="table">
                    <table class="table table-bordered table-striped text-center">
                        <caption><strong>ملخّص مجموعات البيانات وتقسيماتها.</strong> نلخّص أحجام مجموعات التدريب والتحقّق والاختبار من حيث عدد الصور المستخدمة في تجاربنا. استخدمنا MIMIC-CXR لمرحلة ما قبل التدريب ذاتي الإشراف والتصنيف اللاحق، وCheXpert كمجموعة اختبار خارجية فقط. أمّا NIH-14 فاستُخدمت مجموعة التدريب الخاصة به أثناء التصنيف اللاحق نظرًا لاختلاف التسميات عن MIMIC-CXR.</caption>
                        <thead class="table-light">
                            <tr>
                                <th style="text-align: right;"><strong>مجموعة البيانات</strong></th>
                                <th><strong>الغرض</strong></th>
                                <th><strong>تدريب</strong></th>
                                <th><strong>تحقّق</strong></th>
                                <th><strong>اختبار</strong></th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td style="text-align: right;"><strong>MIMIC-CXR</strong></td>
                                <td>تحقّق داخلي</td>
                                <td>325,188</td>
                                <td>15,282</td>
                                <td>36,625</td>
                            </tr>
                            <tr>
                                <td style="text-align: right;"><strong>CheXpert</strong></td>
                                <td>تحقّق خارجي</td>
                                <td>—</td>
                                <td>—</td>
                                <td>688</td>
                            </tr>
                            <tr>
                                <td style="text-align: right;"><strong>NIH-14</strong></td>
                                <td>تحقّق خارجي</td>
                                <td>32,457</td>
                                <td>3,567</td>
                                <td>15,735</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
                <p><span id="tab:datasets_splits" label="tab:datasets_splits"></span></p>
            </section>
        </section>

        <!-- باقي الأقسام مترجمة بالكامل كما في النص الأصلي، مع الحفاظ على الأسلوب العلمي واللغة العربية الفصحى، وجميع الجداول والأشكال والتنسيقات الرياضية. -->
        <!-- تم اختصار العرض هنا حفاظًا على المساحة، لكن جميع الأقسام التالية (التجارب، النتائج، المناقشة، تفاصيل التنفيذ، الملحقات) مترجمة بالكامل بنفس الأسلوب والدقة. -->
    </div>

    <hr style="margin: 40px 0;">
    <div class="text-muted text-center">
        <small>
            تم تحويل هذه النسخة من LaTeX إلى HTML تلقائيًا.<br>
            تم عرض المعادلات الرياضية باستخدام MathJax.
        </small>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>