<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Erlend Frayling">
  <meta name="author" content="Jake Lever">
  <meta name="author" content="Graham McDonald">
  <title>استراتيجيات التوليد بدون أمثلة وبأمثلة قليلة للسجلات الطبية الاصطناعية</title>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap');
    body {
      direction: rtl;
      font-family: 'Cairo', 'Segoe UI', Tahoma, Geneva, Verdana, Arial, sans-serif;
      font-size: 22px;
      background: #f8f9fa;
      color: #222;
      margin: 0;
      padding: 0;
      line-height: 1.7;
    }
    header {
      background: linear-gradient(90deg, #4e54c8 0%, #8f94fb 100%);
      color: #fff;
      padding: 40px 0 20px 0;
      text-align: center;
      margin-bottom: 40px;
      box-shadow: 0 2px 8px rgba(78,84,200,0.08);
    }
    h1.title {
      font-size: 2.5em;
      font-weight: 700;
      margin-bottom: 10px;
      letter-spacing: 1px;
    }
    .author {
      font-size: 1.1em;
      margin: 0 0 2px 0;
      color: #e0e0e0;
      display: inline-block;
      margin-left: 10px;
    }
    main, .main-content {
      max-width: 900px;
      background: #fff;
      margin: 0 auto 40px auto;
      padding: 40px 32px 32px 32px;
      border-radius: 18px;
      box-shadow: 0 4px 24px rgba(0,0,0,0.07);
    }
    h1, h2, h3 {
      color: #4e54c8;
      font-weight: 700;
      margin-top: 1.7em;
      margin-bottom: 0.7em;
      line-height: 1.2;
    }
    h1 {
      font-size: 2em;
      border-bottom: 2px solid #e0e0e0;
      padding-bottom: 0.2em;
      margin-bottom: 1em;
    }
    h2 {
      font-size: 1.4em;
      border-right: 4px solid #8f94fb;
      padding-right: 12px;
      margin-bottom: 0.8em;
    }
    h3 {
      font-size: 1.15em;
      color: #6c63ff;
      margin-bottom: 0.5em;
    }
    p {
      margin-bottom: 1.1em;
      text-align: justify;
    }
    ol, ul {
      margin: 1em 2em 1em 0;
      padding-right: 1.5em;
    }
    li {
      margin-bottom: 0.5em;
    }
    blockquote {
      background: #f1f3fa;
      border-right: 5px solid #8f94fb;
      margin: 1.5em 0;
      padding: 1em 1.5em;
      border-radius: 8px;
      color: #333;
      font-size: 1.05em;
    }
    code, pre {
      background: #f3f3f3;
      color: #c7254e;
      font-family: 'Cairo', 'Consolas', 'monospace';
      font-size: 0.95em;
      border-radius: 4px;
      padding: 2px 6px;
    }
    em {
      color: #4e54c8;
      font-style: normal;
      font-weight: 600;
    }
    strong {
      color: #222;
      font-weight: 700;
    }
    table {
      border-collapse: collapse;
      width: 100%;
      margin: 1.5em 0;
      background: #fafbff;
      border-radius: 8px;
      overflow: hidden;
      box-shadow: 0 2px 8px rgba(78,84,200,0.04);
    }
    th, td {
      border: 1px solid #e0e0e0;
      padding: 10px 14px;
      text-align: center;
    }
    th {
      background: #e8eafc;
      color: #4e54c8;
      font-weight: 700;
    }
    .math.inline {
      font-family: 'Cairo', 'Consolas', 'monospace';
      background: #f3f3f3;
      padding: 2px 6px;
      border-radius: 4px;
      color: #4e54c8;
    }
    @media (max-width: 700px) {
      main, .main-content {
        padding: 18px 6px 18px 6px;
      }
      h1.title {
        font-size: 1.5em;
      }
      h1, h2 {
        font-size: 1.1em;
      }
    }
    .nodecor {
      color: #4e54c8;
      font-weight: 600;
      font-family: inherit;
      text-decoration: none;
    }
    .muted {
      color: #666;
      font-size: 0.95em;
    }
  </style>
</head>
<body>
<header>
  <h1 class="title">استراتيجيات التوليد بدون أمثلة وبأمثلة قليلة للسجلات الطبية الاصطناعية</h1>
  <p class="author"><span class="nodecor">Erlend Frayling</span></p>
  <p class="author"><span class="nodecor">Jake Lever</span></p>
  <p class="author"><span class="nodecor">Graham McDonald</span></p>
</header>
<main class="main-content">
<h1 id="ملخص">مُلخّص</h1>
<p>تُعَدّ صعوبات الوصول إلى بيانات المرضى التاريخية لأغراض البحث السريري، مع الامتثال الصارم للوائح الخصوصية، عائقًا كبيرًا أمام تقدّم العلوم الطبية. ويُعَدّ استخدام السجلات الطبية الاصطناعية إحدى المقاربات المبتكرة لتخطّي هذه المشكلة، إذ تعكس هذه السجلات خصائص بيانات المرضى الحقيقية دون المساس بخصوصية الأفراد. إن إنشاء مثل هذه المجموعات الاصطناعية—لا سيّما من دون استخدام بيانات مرضى فعلية لضبط النماذج اللغوية الكبيرة ضبطًا دقيقًا—يوفّر حلًا واعدًا، نظرًا إلى أن الحصول على بيانات حسّاسة لتدريب النماذج يُشكّل تحدّيًا بحدّ ذاته. تقيم هذه الدراسة قدرة نموذج اللغة الكبير <span class="nodecor">Llama 2</span> على توليد سجلات طبية اصطناعية تُحاكي بدقّة معلومات المرضى الفعلية، باستخدام استراتيجيات توجيه بدون أمثلة وأخرى بأمثلة قليلة، ومقارنتها بالمنهجيات المعتمِدة على بيانات حسّاسة. نركّز على توليد السرديات الاصطناعية لقسم تاريخ الحالة المرضية الحالي اعتمادًا على بيانات مجموعة <span class="nodecor">MIMIC-IV</span> كمرجع للمقارنة. ونقدّم تقنية توجيه جديدة تستفيد من نهج سلسلة التفكير، بما يعزّز قدرة النموذج على توليد سرديات طبية أدقّ وأكثر ملاءمة سياقيًا من دون حاجة إلى ضبطٍ مسبق. وتشير نتائجنا إلى أنّ هذا النهج الموجَّه بسلسلة التفكير يُمكّن الإعداد عديم الأمثلة من تحقيق نتائج تضاهي نتائج النماذج المضبوطة ضبطًا دقيقًا، وذلك وفق تقييم مقاييس <span class="nodecor">ROUGE</span>.</p>

<h1 id="sec: introduction">مُقدّمة</h1>
<p>يُعَدّ البحث السريري ضروريًا لتحسين فهم الأمراض، وتطوير علاجات أكثر فاعلية، والارتقاء برعاية المرضى. يُسهم الوصول إلى السجلات السريرية—مثل ملاحظات خروج المستشفى والسجلات الصحية الإلكترونية (<span class="nodecor">EHRs</span>) (<span class="nodecor">hoerbst2010electronic, coorevits2013electronic</span>)—في اكتشاف أنماط الأعراض وآثار الأدوية الجانبية. غير أنّ الحصول على هذه السجلات يُمثّل تحدّيًا بسبب ما تحتويه من معلومات شخصية حسّاسة (<span class="nodecor">nurmi2019privacy</span>)، الأمر الذي يُبطِّئ في نهاية المطاف وتيرة الاكتشافات الطبية التي قد تعود بالنفع على صحّة المرضى (<span class="nodecor">cowie2017electronic</span>).</p>
<p>إن تطوير مقاربات تُخفِّف مخاوف الخصوصية في البحث السريري أمرٌ مرغوبٌ لتمكين وصولٍ أسهل إلى <span class="nodecor">EHRs</span>، ما يتيح إجراء البحوث بحرّية أكبر ويُسرّع وتيرة الاكتشافات الصحية.</p>
<p>إحدى الطرق لتخفيف تحدّيات حساسية معلومات المرضى هي توليد سجلات مرضى اصطناعية تُحافظ على التوزيعات الإحصائية للمفردات والأنماط الواردة في السجلات الحقيقية، مع بقائها مُصطنعة في جوهرها. ويمكن استخدام هذه السجلات الاصطناعية بديلًا عن <span class="nodecor">EHRs</span> الحقيقية حين تحول حواجز الخصوصية دون الوصول إلى البيانات الفعلية (<span class="nodecor">iveSynthetic</span>).</p>
<p>استكشفت أعمال عدّة توليد نصوص <span class="nodecor">EHR</span> اصطناعية باستخدام نماذج اللغة الكبيرة (<span class="nodecor">LLMs</span>) المعتمدة على بنية المُحوِّلات، مثلًا (<span class="nodecor">melamudTowards, iveGeneration</span>). وعلى وجه الخصوص، أظهر <span class="nodecor">Ive et al.</span> (<span class="nodecor">iveGeneration</span>) أنّ النص السريري الاصطناعي يمكن استخدامه لزيادة بيانات <span class="nodecor">EHR</span> الحقيقية وتحسين فاعلية <span class="nodecor">LLMs</span> في المهام اللاحقة (<span class="nodecor">iveSynthetic</span>). غير أنّ إعداد هذه النماذج لإنتاج سجلات <span class="nodecor">EHR</span> اصطناعية يتطلّب أولًا ضبطها على بيانات <span class="nodecor">EHR</span> حقيقية، ما يُعيدنا إلى مشكلة الوصول إلى المعلومات الخاصّة.</p>
<p>مؤخرًا، أظهرت مجموعة من نماذج اللغة الكبيرة المُدرَّبة مُسبقًا على كمّيات هائلة من البيانات، والقادرة على استيعاب طبيعة المهمة التوليدية من خلال مُدخلات موجِّهة—مثل (<span class="nodecor">brownGpt3, touvronLlama2</span>)—فاعليةً عالية في طيف واسع من المهام. ولا تتطلّب هذه النماذج عادةً ضبطًا دقيقًا. وعليه، قد يُسهم استخدام مثل هذه النماذج في توليد بيانات <span class="nodecor">EHR</span> اصطناعية في الاستغناء عن جمع بيانات <span class="nodecor">EHR</span> الحقيقية—صعبة المنال—لأغراض الضبط الدقيق.</p>
<p>في هذا العمل، نقوِّم قدرات <span class="nodecor">Llama 2</span> مع طيف من استراتيجيات التعلّم، تشمل الضبط الدقيق، والتعلّم بأمثلة قليلة، والإعداد عديم الأمثلة، لتوليد نصوص <span class="nodecor">EHR</span> السريرية الاصطناعية. نُشغّل النماذج لتوليد قسم تاريخ الحالة المرضية الحالي انطلاقًا من نص الشكوى الرئيسة المقتضب الذي يُلخِّص المشكلة الطبية الأساسية، ونقارن السرد المُولَّد بـ <span class="nodecor">EHRs</span> الحقيقية من مجموعة <span class="nodecor">MIMIC-IV</span> (<span class="nodecor">mimicFour</span>). كما نقترح استراتيجية توجيه بسلسلة التفكير (<span class="nodecor">CoT</span>) تُرشد النموذج إلى توليد محتوى <span class="nodecor">EHR</span> يُراعي البنية والمحتوى الخاصَّين بـ <span class="nodecor">EHRs</span>. وتُظهر تجاربنا أنّ طريقة <span class="nodecor">CoT</span> المقترحة تُحسِّن الأداء في الإعدادين: عديم الأمثلة وبأمثلة قليلة، مع <span class="nodecor">Llama 2</span> لتُصبح منافِسةً لنموذج <span class="nodecor">GPT-2</span> المضبوط ضبطًا دقيقًا، ما يُقلِّل الحاجة إلى الوصول إلى بيانات <span class="nodecor">EHR</span> الحسّاسة عند إجراء البحوث السريرية.</p>

<h1 id="sec:background">الأعمال ذات الصلة</h1>
<p>تستخدم غالبية الأعمال المتعلّقة بتوليد النصوص السريرية بنية التعلّم العميق القائمة على المُحوِّلات في مهام نمذجة اللغة السببية باستخدام النماذج اللغوية التوليدية التلقائية (<span class="nodecor">vaswaniAttention</span>, <span class="nodecor">radford2018Gpt</span>, <span class="nodecor">scholkopf2021toward</span>). اقترح أمين نجّاد وزملاؤه توليد ملخّصات خروج المرضى من بيانات السجلات الصحية الإلكترونية المنظّمة باستخدام <span class="nodecor">GPT-2</span> (<span class="nodecor">radford2019language</span>)، وأظهروا إمكان استخدامها في تدريب نماذج أكثر فاعلية للتعرّف على الكيانات المُسمّاة (<span class="nodecor">amin2020exploring</span>). وبالمثل، بيّن لو وآخرون أنّ النص السريري الاصطناعي يُمكن توظيفه لزيادة مجموعة التدريب الحقيقية لسجلات الصحة الإلكترونية وتحسين الأداء في مهام التنبّؤ بإعادة القبول (<span class="nodecor">lu2021textual</span>). واستقصت أعمال أخرى أثر النص الاصطناعي المُولّد في المهام اللاحقة؛ فمثلًا أظهر ميلامود وآخرون إمكان استخدام السجلات الاصطناعية في مهام الاستدلال اللغوي الطبيعي (<span class="nodecor">melamudTowards</span>). ودَرّب لي وآخرون عدّة نماذج تلقائية توليدية لتوليد أقسام تاريخ الحالة الحالية من ملخّصات الخروج، كما عنَّوا السجلات الاصطناعية يدويًا بوسم الكيانات، وبيّنوا أنّ نموذج التعرّف على الكيانات المُسمّاة يمكن تدريبه بكفاءة أعلى عند زيادة مجموعة التدريب الحقيقية ببيانات اصطناعية مُعنونة. وهناك أيضًا كمّ كبير من الأعمال في تلخيص سجلات الصحة الإلكترونية باستخدام نماذج تسلسل-إلى-تسلسل، مثل (<span class="nodecor">RaffelT5</span>, <span class="nodecor">gaoSummarizing</span>, <span class="nodecor">palNerual</span>, <span class="nodecor">hartman2022day</span>). وعلى خلاف تلك الأعمال، نركّز هنا حصريًا على المهمة التوليدية التلقائية لتوليد بيانات سريرية اصطناعية.</p>
<p>تستند معظم الأعمال في توليد النصوص السريرية إلى مجموعات بيانات <span class="nodecor">MIMIC</span>. تُعَدّ <span class="nodecor">MIMIC-III</span> (<span class="nodecor">johnsonMimic3</span>) قاعدة بيانات كبيرة ومُتاحة للعامة، تضمّ بيانات سريرية مفصّلة للمرضى المقبولين في وحدات العناية المركّزة. وحديثًا أُصدرت <span class="nodecor">MIMIC-IV</span> (<span class="nodecor">mimicFour</span>) التي تحتوي على نطاق أوسع من السجلات مقارنةً بـ <span class="nodecor">MIMIC-III</span>، ولذلك اعتمدنا عليها في تجاربنا. ونظرًا لحداثتها، يقلّ عدد الأعمال التي استخدمت <span class="nodecor">MIMIC-IV</span> في مهام التوليد مقارنةً بـ <span class="nodecor">MIMIC-III</span>. وتشمل كلتا المجموعتين بيانات منظّمة وغير منظّمة، منها المعلومات الديموغرافية، ونتائج المختبرات، والإجراءات، وملاحظات الطاقم الطبي. وتقيس غالبية الأعمال المذكورة جودة النص السريري المُولَّد مباشرةً باستخدام مقاييس التداخُل المصطلحي مثل <span class="nodecor">ROUGE</span> و<span class="nodecor">BLEU</span> (<span class="nodecor">linRouge</span>, <span class="nodecor">papineniBleu</span>)—مع العلم أنّ الثانية تُستخدم عادةً في تقييم الترجمة الآلية—ولذا نعتمد في هذا العمل أسرة مقاييس <span class="nodecor">ROUGE</span> لتقييم جودة سجلاتنا الاصطناعية قياسًا بالأمثلة المرجعية.</p>

<h1 id="sec: method">توليد سجلات الصحة الإلكترونية باستخدام نماذج اللغة الكبيرة</h1>
<p>كما وُصِف في <a href="#sec:background" class="nodecor">قسم الأعمال ذات الصلة</a>، يَتعلّم النموذجُ اللغويّ التوليديّ التلقائي من مجموعة نصوص حقيقية ليولّد نصوصًا اصطناعية. وتُتيح له طبيعته السببية توقّع الرمز التالي في التسلسل عبر نمذجة توزيع الكلمات، كما هو مألوف في مهام التنبّؤ بالرمز التالي. في مهمتنا هذه نُنمذج جزأين غير منظّمين من سجل الصحة الإلكترونية: الشكوى الرئيسة (CC) وتاريخ الحالة المرضية الحالي (HPI).</p>
<ol>
<li><p>الشكوى الرئيسة (CC): وصف موجز للمشكلة الطبية الأساسية التي استدعت قبول المريض.</p></li>
<li><p>تاريخ الحالة المرضية الحالي (HPI): سرد مفصّل لمسار وصول المريض إلى المستشفى وتطوّر الأعراض وملاحظات المريض والأطباء.</p></li>
</ol>
<p>هدفنا هو نمذجة العلاقة بين الشكوى الرئيسة وتاريخ الحالة المرضية الحالي باستخدام نماذج اللغة الكبيرة، بحيث يُنتِج النموذجُ قسمَ HPI عند تزويده بنصّ CC. وعلى الرغم من إمكان إنجاز هذه المهمة عادةً عبر ضبطٍ دقيقٍ لنموذجٍ توليديّ على أزواجٍ من CC وHPI مُنسّقة، نركّز هنا على تطوير استراتيجيات موجِّهة لاستخدام نماذج اللغة الكبيرة في إعدادَي الصِفر والأمثلة القليلة، بما يُلغي الحاجة إلى بيانات مرضى حسّاسة أثناء الضبط، اعتمادًا على المعرفة المُكتسَبة في الأوزان المُدرَّبة مُسبقًا.</p>

<h2 id="sec: inContext">استراتيجيات التوجيه</h2>
<p>في ما يلي نصف الاستراتيجيات المختلفة المستخدمة لتوليد أقسام HPI انطلاقًا من نص CC المُعطى. كما نصف إعدادَي التعلم عديم الأمثلة وبالأمثلة القليلة. صغنا موجِّهات <span class="nodecor">Llama 2</span> باستخدام <em>مُوجِّه النظام</em> لتزويد النموذج بمعلومات إضافية عن طبيعة المهمة (<span class="nodecor">touvronLlama2</span>)، وضمّناها طريقة سلسلة التفكير.</p>

<h3 id="إستراتيجية-التوجيه-المباشر">استراتيجية التوجيه المباشر</h3>
<p>أولًا، نستخدم موجِّهًا بسيطًا يتضمّن اسمَي القِسمين في سجلات الصحة الإلكترونية. وبعد استبدال <em>X</em> بالشكوى الرئيسة الفعلية، يُطلب من النموذج:</p>
<blockquote>
<p>الشكوى الرئيسية هي: {X}. تاريخ الحالة المرضية الحالي هو:</p>
</blockquote>
<p>يوفّر هذا التنسيق سياقًا لاختبار قدرة النموذج على توليد HPI مناسب مباشرةً للشكوى. نشير إلى هذه الاستراتيجية باسم «التوجيه المباشر» عند عرض النتائج.</p>

<h3 id="طريقة-سلسلة-التفكير">استراتيجية سلسلة التفكير</h3>
<p>ثانيًا، نقترح استراتيجية أكثر تعقيدًا قائمة على سلسلة التفكير. نطلب من النموذج أولًا استنباط جنس المريض الملائم للشكوى المُقدَّمة، ثم عِرقه، وأخيرًا توليد تاريخ الحالة المرضية الحالي. نفرض أنّ هذه الخطوات الوسيطة تُعين النموذج على صياغة HPI أكثر واقعيةً وترابطًا.</p>
<p>نستفيد من <em>مُوجِّه النظام</em> في <span class="nodecor">Llama 2</span> الذي يُدرَج قبل موجِّه المستخدم لتعريف النموذج بمهمّته العامة. وبدل موجّه النظام الأصلي المقترح في (<span class="nodecor">touvronLlama2</span>)، نُوجِّه النموذج لتوليد بيانات سريرية وإخراج كل مكوّن من سلسلة التفكير بصيغة JSON. يُقدَّم مُوجِّه النظام بالعلامة الخاصّة <span class="math inline">\(\langle\langle SYS \rangle\rangle\)</span>. نشير إلى هذه الاستراتيجية باسم «سلسلة التفكير» عند عرض النتائج.</p>

<h2 id="sec: learnStrats">استراتيجيات التعلم</h2>
<p>نُنفِّذ الاستراتيجيات السابقة بثلاثة طرائق لتمرير الطلب إلى النموذج: (1) توجيه عديم الأمثلة، (2) تعلّم بأمثلة قليلة باستخدام أمثلة عشوائية، و(3) تعلّم بأمثلة قليلة باستخدام أمثلة مُسترجَعة شديدة الشبه بالطلب.</p>

<h1 id="sec: experiment">التجارب</h1>
<p>في هذا القسم نعرض تجاربنا للإجابة عن الأسئلة البحثية الآتية:</p>
<p><span><strong>RQ1</strong>: هل تستطيع نماذج اللغة الكبيرة تحقيق أداء مماثل في توليد HPI باستخدام استراتيجيات التوجيه مقارنةً بالنماذج المضبوطة ضبطًا دقيقًا؟</span></p>
<p><span><strong>RQ2</strong>: هل تُحسِّن استراتيجية التوجيه المقترحة (سلسلة التفكير) أداء التوليد مع نماذج اللغة الكبيرة؟</span></p>
<p><span><strong>RQ3</strong>: كيف تؤدّي استراتيجيات التوجيه في إعدادَي عديم الأمثلة وبالأمثلة القليلة؟</span></p>

<h2 id="الإعداد-التجريبي">الإعداد التجريبي</h2>
<h3 id="sec: dataset">مجموعة البيانات</h3>
<p>استخدمنا مجموعة بيانات <span class="nodecor">MIMIC-IV</span> (<span class="nodecor">mimicFour</span>) لاستخلاص أزواج CC–HPI. استخرجنا ما مجموعه <span class="nodecor">7000</span> ملخّص خروج لمرضى تضمّ سجلاتهم كلًا من الشكوى الرئيسة وقسم تاريخ الحالة المرضية الحالي. قسّمنا المجموعة إلى <span class="nodecor">6000</span> عيّنة للتدريب عبر الضبط الدقيق، و<span class="nodecor">1000</span> عيّنة للاختبار. ولكل زوج CC–HPI استخرجنا أيضًا بيانات جنس المريض وعِرقه.</p>

<h3 id="النماذج-والتقييم">النماذج والتقييم</h3>
<p>لنجيب عن أسئلتنا، نشرنا ثلاثة نماذج قائمة على بنية <span class="nodecor">Transformer</span>: <span class="nodecor">GPT-2</span>، و<span class="nodecor">BioGPT</span> (<span class="nodecor">luo2022biogpt</span>)، و<span class="nodecor">LLaMA-2 13B</span> (<span class="nodecor">Llama</span>). استخدمنا <span class="nodecor">GPT-2</span> كنموذج أساسي للضبط الدقيق، و<span class="nodecor">BioGPT</span> نظرًا لتدريبه المسبق في المجال الطبي الحيوي، و<span class="nodecor">Llama 2</span> في كلٍّ من إعداد الضبط الدقيق واستراتيجيات التوجيه المقترحة.</p>
<p>أولًا، ضبَطْنا كلَّ نموذجٍ ضبطًا دقيقًا على مجموعة أزواج CC–HPI مع إدراج رمز فاصل &lt;|sep|&gt; بين CC وHPI. وبالنسبة لـ <span class="nodecor">Llama 2</span> استخدمنا تكميم 4-بت مع <span class="nodecor">QLoRA</span> (<span class="nodecor">dettersQLoRA</span>) وتقنية <span class="nodecor">LoRA</span> لتسريع التدريب. وضبطنا المُعلمات الفائقة باستخدام <span class="nodecor">Optuna</span> (<span class="nodecor">akiba2019optuna</span>) عبر 20 تجربة لاختيار أفضل الإعدادات من حيث خسارة التقييم.</p>
<p>ثانيًا، استخدمنا <span class="nodecor">Llama 2</span> غير المضبوط ضبطًا دقيقًا مع استراتيجيتَي التوجيه المباشر و<span class="nodecor">CoT</span> في إعدادَي الصِفر والأمثلة القليلة. ولاختيار أمثلة الإرشاد في الإعداد الأخير بنَينا فهرسًا كثيفًا لنصوص CC باستخدام <span class="nodecor">ColBERT-PRF</span> (<span class="nodecor">wang2023colbert</span>) لاسترجاع زوجين من الأمثلة الأكثر شبهًا بكل CC اختباري.</p>
<p>بهذه الطريقة شكّلنا ستّ استراتيجيات توليد لـ <span class="nodecor">Llama 2</span>: التوجيه المباشر و<span class="nodecor">CoT</span> في إعدادات عديم الأمثلة، وبأمثلة قليلة عشوائية، وبأمثلة قليلة مُشابهة.</p>
<p>أخيرًا، لتقييم الأداء، ولّدنا قسم HPI لكل CC في مجموعة الاختبار سواءً بالنماذج المضبوطة ضبطًا دقيقًا أو باستراتيجيات التوجيه الستّ، وحسبْنا درجات <span class="nodecor">ROUGE</span> (<span class="nodecor">linRouge</span>). كما سجّلنا درجة «الحيرة» للنماذج المضبوطة ضبطًا دقيقًا.</p>

<h1 id="sec:results">النتائج والتحليل</h1>
<p>تُبيّن النتائج أنّ نموذج <span class="nodecor">Llama 2</span> المضبوط باستخدام <span class="nodecor">QLoRA</span> يحقق أفضل أداء، مُسجّلًا نحو <span class="nodecor">0.28</span> في <span class="nodecor">ROUGE-1</span>، ومتفوقًا في بقية مقاييس <span class="nodecor">ROUGE</span>. يليه <span class="nodecor">BioGPT</span> بواقع <span class="nodecor">0.264</span> في <span class="nodecor">ROUGE-1</span>، متقدّمًا بنحو <span class="nodecor">3.4</span> نقاط على <span class="nodecor">GPT-2</span> المضبوط.</p>
<p>نلاحظ أيضًا أنّ استخدام استراتيجية <span class="nodecor">CoT</span> يُحسِّن الأداء في الإعداد عديم الأمثلة بنحو <span class="nodecor">6.4</span> نقاط؛ ليُصبح أداء <span class="nodecor">Llama 2</span> عديم الأمثلة مع <span class="nodecor">CoT</span> مماثلًا—وربما أعلى قليلًا—من أداء <span class="nodecor">GPT-2</span> المضبوط. وبذلك نجيب عن <span class="nodecor">RQ1</span> بأنّ استراتيجية <span class="nodecor">CoT</span> تُتيح لـ <span class="nodecor">Llama 2 13B</span> في إعداد الصفر مجاراة نموذج <span class="nodecor">GPT-2</span> المضبوط والتفوّق عليه قليلًا، وإن لم يُدرك أداء النماذج الأقوى المضبوطة مثل <span class="nodecor">Llama 2</span> و<span class="nodecor">BioGPT</span>. وبخصوص <span class="nodecor">RQ2</span> يتبيّن أنّ <span class="nodecor">CoT</span> تُحسّن أداء الإعداد عديم الأمثلة مقارنةً بالتوجيه المباشر.</p>
<p>وبالإجابة عن <span class="nodecor">RQ3</span>، نلحظ أنّ إضافة أمثلة قليلة إلى التوجيه المباشر تُحسّن الأداء؛ إذ ارتفعت درجة <span class="nodecor">ROUGE-1</span> من <span class="nodecor">0.19</span> إلى <span class="nodecor">0.205</span>. أمّا عند تطبيق أمثلة قليلة مع <span class="nodecor">CoT</span> فتراجع الأداء، لا سيّما مع الأمثلة العشوائية التي خفّضت <span class="nodecor">ROUGE-1</span> بنحو <span class="nodecor">2.8</span> نقاط. ويتبيّن أنّ التوجيه المباشر يستفيد من الأمثلة القليلة، في حين أنّ أداء <span class="nodecor">CoT</span> قد يتأثّر سلبًا بإضافتها.</p>

<h1 id="الخلاصة">الخلاصة</h1>
<p>قيّمنا في هذا العمل فاعلية <span class="nodecor">Llama 2</span> في توليد سجلات طبية اصطناعية ضمن إعدادات الصِفر والأمثلة القليلة والضبط الدقيق، مع مقارنته بعدّة نماذج معاصرة. واقترحنا استراتيجيتين لتوجيه التوليد: التوجيه المباشر و<span class="nodecor">CoT</span>، لتوليد قسم تاريخ الحالة المرضية الحالي. وأظهرت تجاربنا على مجموعة <span class="nodecor">MIMIC-IV</span> أنّ <span class="nodecor">Llama 2</span> يُحقّق أفضل أداء عند الضبط الدقيق، وأنّ استراتيجيتنا المقترحة تُحسّن أداء إعداد الصِفر حتى يُصبح منافسًا لـ <span class="nodecor">GPT-2</span> المضبوط. ونرى أنّ هذا يُمثّل خطوةً مهمّة نحو تقليل الاعتماد على البيانات السريرية الحسّاسة في البحوث الطبية، ويستدعي مزيدًا من البحث المستقبلي.</p>

<h1 id="الشكر-والتقدير">الشكر والتقدير</h1>
<p>دُعِم هذا العمل من مجلس العلوم الهندسية والفيزيائية [رقم المنحة <span class="nodecor">EP/X018237/1</span>].</p>

<p class="muted">ملاحظة: استُخدمت العلامة الخاصة <span class="math inline">\(\langle\langle SYS \rangle\rangle\)</span> في موجّه النظام لتوافق ترميز LaTeX مع MathJax.</p>
</main>
</body>
</html>