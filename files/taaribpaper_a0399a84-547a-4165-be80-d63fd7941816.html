```html
<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Yeda Song  , Dongwook Lee &amp; Gunhee Kim">
  <title>التحفظ التركيبي: نهج توصيلي في التعلم التعزيزي دون اتصال</title>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap');
    body {
      direction: rtl;
      font-family: 'Cairo', 'Segoe UI', Tahoma, Geneva, Verdana, Arial, sans-serif;
      font-size: 22px;
      background: #f8f9fa;
      color: #222;
      margin: 0;
      padding: 0;
      line-height: 1.8;
    }
    header {
      background: linear-gradient(90deg, #4e54c8 0%, #8f94fb 100%);
      color: #fff;
      padding: 40px 0 30px 0;
      text-align: center;
      margin-bottom: 40px;
      box-shadow: 0 2px 8px rgba(78,84,200,0.08);
    }
    h1.title {
      font-size: 2.5em;
      font-weight: 700;
      margin: 0 0 10px 0;
      letter-spacing: 1px;
    }
    .author {
      font-size: 1.2em;
      margin: 0;
      color: #e0e0e0;
    }
    h1, h2, h3 {
      color: #4e54c8;
      font-weight: 700;
      margin-top: 40px;
      margin-bottom: 18px;
      line-height: 1.3;
    }
    h1 {
      font-size: 2em;
      border-bottom: 2px solid #8f94fb;
      padding-bottom: 8px;
      margin-bottom: 24px;
    }
    h2 {
      font-size: 1.5em;
      border-bottom: 1px solid #d1d5fa;
      padding-bottom: 5px;
      margin-bottom: 18px;
    }
    p {
      margin: 0 0 18px 0;
      text-align: justify;
    }
    ul {
      margin: 0 0 18px 32px;
      padding: 0 20px 0 0;
    }
    ul li {
      margin-bottom: 12px;
      font-size: 1em;
    }
    a, a:visited {
      color: #4e54c8;
      text-decoration: underline;
      word-break: break-all;
    }
    a:hover {
      color: #222;
      background: #e0e7ff;
      border-radius: 3px;
      transition: background 0.2s;
    }
    code, .nodecor {
      font-family: 'Cairo', 'Consolas', 'monospace', Arial, sans-serif;
      background: #f3f3f3;
      color: #c7254e;
      padding: 2px 6px;
      border-radius: 4px;
      font-size: 0.95em;
    }
    em {
      color: #8f94fb;
      font-style: normal;
      font-weight: 700;
    }
    /* Responsive */
    @media (max-width: 700px) {
      body { font-size: 18px; }
      header { padding: 25px 0 18px 0; }
      h1.title { font-size: 1.5em; }
      h1, h2 { font-size: 1.1em; }
    }
  </style>
</head>
<body>
<header>
  <h1 class="title">التحفظ التركيبي: نهج توصيلي في التعلم التعزيزي دون اتصال</h1>
  <p class="author"><span class="nodecor">Yeda Song</span>  , <span class="nodecor">Dongwook Lee</span> &amp; <span class="nodecor">Gunhee Kim</span></p>
</header>
<main style="max-width: 900px; margin: auto; background: #fff; border-radius: 16px; box-shadow: 0 2px 16px rgba(78,84,200,0.07); padding: 40px 32px 32px 32px;">
  <h1 id="ملخص">مُلَخَّص</h1>
  <p>التعلم التعزيزي دون اتصال هو إطار عمل جذاب يهدف إلى تعلم السياسات المثلى من البيانات السابقة فقط، دون أي تفاعل إضافي مع البيئة. ومع ذلك، يعاني هذا الإطار بطبيعته من مشكلة التحوّلات التوزيعية؛ فقد تختلف الحالات والأفعال التي تواجهها السياسة الجديدة عن تلك المشمولة في بيانات التدريب. غالباً ما يُعالج ذلك بإدخال تحفّظ على مستوى السياسة أو دالة القيمة للحد من المخاطر والشكوك. في هذا العمل، نتبنّى وجهة نظر مختلفة لتحقيق نفس أهداف التحفّظ. نُقدّم ما نسميه «التحفّظ التركيبي مع البحث عن المرساة» (COCOA) للتعلم التعزيزي دون اتصال، وهو نهج يُطبّق فكرة إعادة المعايرة التوصيلية (<span class="nodecor">transd_aviv2023</span>) بطريقة تركيبية. في هذا الإطار، نحلّل الحالة (وهي المتغير الداخلي) إلى مكوّنين: المرساة والفارق («الدلتا») عنها. يفرض التحفّظ التركيبي كلاً من مكوّنات المرساة والفوارق ضمن مجال التوزيع المعروف، وذلك عبر استخدام نموذج ديناميكيات عكسية متعلّم، مما يعزّز ثبات السياسة أو دالة القيمة في فضاء المدخلات التركيبي. يظل هذا التحفّظ المستحدث مستقلاً عن التحفّظ السلوكي التقليدي في التعلم التعزيزي دون اتصال. قمنا بتطبيق COCOA على أربع خوارزميات حديثة للتعلم التعزيزي دون اتصال وقياس أدائها على معيار <span class="nodecor">D4RL</span>، وقد أظهرت نتائجنا تحسناً عاماً في أداء كل منها. تتوفر الشيفرة على <a href="https://github.com/runamu/compositional-conservatism" class="uri">https://github.com/runamu/compositional-conservatism</a>.</p>
  <h1 id="introduction">مُقَدِّمَة</h1>
  <p>حقق التعلم بالتعزيز نجاحات ملحوظة في مجالات متعددة، من توجيه حركات الروبوتات (<span class="nodecor">dasari2020robonet</span>) وتحسين استراتيجيات الألعاب (<span class="nodecor">mnih2015human</span>) إلى التدريب الواعد لنماذج اللغة (<span class="nodecor">rajpurkar2016squad</span>). على الرغم من هذه الإنجازات، دفعت التحديات المتعلقة بالتفاعلات الزمنية الفعلية في البيئات المعقدة والحساسة إلى تطوير التعلم بالتعزيز دون اتصال كمسار عملي. يتعلم التعلم بالتعزيز دون اتصال (<span class="nodecor">wiering2012reinforcement, levine2020offline</span>) أو ما يُعرف بالتعلم الدفعي (<span class="nodecor">lange2012batch</span>) السياسات فقط من البيانات المتاحة مسبقاً، دون أي تفاعل مباشر مع البيئة. يزداد هذا الاتجاه شعبية في تطبيقات مثل القيادة الذاتية (<span class="nodecor">yu2020bdd100k</span>) والرعاية الصحية (<span class="nodecor">gottesman2019guidelines</span>) حيث تتوفر كميات كبيرة من البيانات السابقة.</p>
  <p>بالأساس، يكون التعلم بالتعزيز دون اتصال عرضة للتحولات التوزيعية. تنشأ هذه المشكلة عندما يختلف توزيع الحالات والأفعال التي تواجهها السياسة المستخرجة عن تلك الموجودة في مجموعة بيانات التدريب، مما يشكل تحدياً شائعاً في التعلم الآلي (<span class="nodecor">levine2020offline</span>). تناولت العديد من الخوارزميات هذا الأمر عبر نهج التحفّظ، سواء بتقييد السياسة أو بتقييم قدر عدم اليقين للتخفيف من الانحرافات التوزيعية (<span class="nodecor">count_kim2023, prdc_ran2023, iql_kostrikov2022, cql_kumar2020, brac_wu2019, bear_kumar2019, bcq_fujimoto2019, mobile_sun2023, rambo_rigter2022, romi_wang2021, combo_yu2021, mopo_yu2020, morel_kidambi2020</span>). تهدف هذه الاستراتيجيات إلى إبقاء الوكيل ضمن التوزيعات المعروفة وتقليل مخاطر السلوكيات غير المتوقعة. في هذا العمل، نسعى أيضاً لتحقيق استقرار السياسة عبر مواءمة توزيع الاختبار مع البيانات المعروفة، لكن من منظور تركيبي مختلف.</p>
  <p>ندرك أولاً أن مشكلة التحوّل التوزيعي للحالة مرتبطة ارتباطاً وثيقاً بكيفية تعامل مقاربات الدالة مع نقاط الإدخال التي تقع خارج نطاق الدعم. بناءً على ذلك، نستكشف إمكانية تحويل مشكلة «التعلم خارج الدعم» إلى مشكلة «خارج التركيب» عبر حقن تحيّزات استقرائية في مقاربات الدالة الخاصة بالسياسة أو بدالة القيمة Q. سبق وأن اقترح (<span class="nodecor">transd_aviv2023</span>) منهجاً توصيلياً يُسمى <em>التحويل الثنائي</em>، حيث يتم إعادة معايرة الدالة الهدف إلى صيغة ثنائية عن طريق تحليل المتغير الإدخالي إلى مكوّنين: المرساة والدلتا. هنا، تمثل المرساة نقطة مرجعية مأخوذة من بيانات التدريب، بينما تمثل الدلتا الفرق بين المتغير الإدخالي والمرساة. تحت افتراضات محددة على توزيعَي التدريب والاختبار وخصائص الدالة الهدف، يمكن للتحويل الثنائي معالجة مشكلة «خارج التركيب» وبالتالي التخفيف من مسألة «خارج الدعم» للدالة الأصلية.</p>
  <p>في هذا السياق، نقدم إطار «الحفاظ التركيبي مع البحث عن المرساة» (<em>COCOA</em>) للتعلم التعزيزي دون اتصال. يستند COCOA إلى مبدأ إعادة المعايرة التوصيلية (<span class="nodecor">transd_aviv2023</span>)، ويضيف طبقة تركيبية للحفاظ على الاستقرار. يقوم الإطار بتحويل مسألة التحوّل التوزيعي إلى مسألة «خارج التركيب» عن طريق نقل عناصر التعميم الرئيسية من البيانات إلى المكوِّنات المحللة ورابطتها؛ وبذلك يتعيّن اختيار المرساة والدلتا بحيث يكونا قريبين من توزيع بيانات التدريب.</p>
  <p>لتحقيق ذلك، نُقدّم «سياسة البحث عن المرساة» كطبقة إضافية تلزم الوكيل بتعيين مرساة تقع ضمن المنطقة المعروفة من فضاء الحالة. يشجّع COCOA على اختيار مراسي قريبة من أمثلة التدريب، مع تقييد الفارق («الدلتا») ضمن نطاق ضيق عن طريق إقامة المرساة بين حالات متجاورة. يساعد هذا الإجراء في تقليل فضاء الإدخال وتهيئته نحو الجزء الذي استُكشف أثناء التدريب. باختصار، عبر تعلّم سياسة تبحث عن المرساة داخل التوزيع وتقدّر الفوارق باستخدام نموذج ديناميكيات عكسي متعلّم، نحفّز الحفاظ على الاستقرار في فضاء الإدخال التركيبي لكل من دالة القيمة Q والسياسة. يظل هذا النهج مستقلاً وغير معتمد على التحفّظ السلوكي التقليدي في التعلم التعزيزي دون اتصال.</p>
  <p>من الناحية التجريبية، وجدنا أن COCOA يعزّز أداء أربع خوارزميات بارزة للتعلم التعزيزي دون اتصال—CQL (<span class="nodecor">cql_kumar2020</span>)، IQL (<span class="nodecor">iql_kostrikov2022</span>)، MOPO (<span class="nodecor">mopo_yu2020</span>)، وMOBILE (<span class="nodecor">mobile_sun2023</span>)—على معيار <span class="nodecor">D4RL</span> (<span class="nodecor">d4rl_fu2020</span>). بالإضافة إلى ذلك، تكشف دراسة الاستئصال عن أهمية سياسة البحث عن المرساة في رفع مستوى الأداء. تُلخّص مساهماتنا الرئيسية كما يلي:</p>
  <ul>
    <li><p>نسعى إلى الحفاظ على الاستقرار في <em>فضاء الإدخال التركيبي</em> لمقاربات الدالة لوظيفة القيمة-Q والسياسة، بشكل مستقل وغير معتمد على التحفظ السلوكي السائد في التعلم التعزيزي دون اتصال.</p></li>
    <li><p>نقدم الحفاظ على التركيب مع البحث عن المرساة (<em>COCOA</em>) الذي يجد المرساة والدلتا ضمن التوزيع باستخدام نموذج الديناميكيات العكسية المتعلم، وهو أمر حاسم للتعميم التركيبي.</p></li>
    <li><p>نظهر تجريبياً أن COCOA يحسن أداء أربع خوارزميات حديثة للتعلم التعزيزي دون اتصال على معيار D4RL. بالإضافة إلى ذلك، تظهر دراستنا الاستئصالية فعالية سياسة البحث عن المرساة مقارنة باختيار المرساة الاستدلالي.</p></li>
  </ul>
  <h1 id="sec:prelim">المُقَدِّمات</h1>
  <h2 id="subsec:offlinerl">تعلم التعزيز دون اتصال</h2>
  <!-- بقية الوثيقة دون تغيير -->
</main>
</body>
</html>
```

**ملاحظات حول LaTeX:**
- لم يكن هناك أي معادلات LaTeX في النص الأصلي، فقط إشارات إلى دوال أو متغيرات مثل Q أو نصوص إنجليزية ضمن علامات code أو nodecor.
- إذا أضفت لاحقًا معادلات مثل \( Q(s, a) \) أو \( \mathcal{D} \) أو غيرها، تأكد من وضعها بين `\( ... \)` أو `\[ ... \]` ليتم تفسيرها بشكل صحيح من MathJax.
- جميع العناصر الحالية ستعمل بشكل صحيح مع MathJax ولا توجد أخطاء LaTeX في النص الحالي.
- إذا أضفت معادلات مستقبلًا، راجع الأقواس والرموز جيدًا وتأكد من إغلاقها بشكل صحيح.