<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Gonçalo Paulo, Thomas Marshall, Nora Belrose">
  <title>هَل تَنْتَقِل قابِلِيَّة تَفْسِير المُحوِّلات إلى الشبكات العصبية المتكررة؟</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>body { direction: rtl; font-size: 22px; }</style>
</head>
<body>
<header>
<h1 class="title">هَل تَنْتَقِل قابِلِيَّة تَفْسِير <span class="nodecor">Transformer</span> إلى <span class="nodecor">RNNs</span>؟</h1>
<p class="author"><span class="nodecor">Gonçalo Paulo</span>, <span class="nodecor">Thomas Marshall</span>, <span class="nodecor">Nora Belrose</span></p>
</header>
<p>latex</p>
<h1 id="ملخص">مُلَخَّص</h1>
<p>شَهِدَت الفَتْرَة الأخيرة تَقَدُّماً في هَنْدَسَة الشبكات العصبية المتكررة، مثل <span class="nodecor">Mamba</span> و<span class="nodecor">RWKV</span>، مما مَكَّن <span class="nodecor">RNNs</span> من مُطابقة أداء <span class="nodecor">Transformers</span> ذات الحجم المماثل أو تجاوزها من حيث تعقيد نمذجة اللغة وتقييمات المهام اللاحقة، مما يُشير إلى أن الأنظمة المستقبلية قد تُبنى على هندسات جديدة كلياً. في هذه الورقة، نَفْحَص ما إذا كانت طُرُق التفسير المصممة أصلاً لنماذج لغة <span class="nodecor">Transformer</span> ستنتقل إلى هذه الهندسات المتكررة الصاعدة. على وجه التحديد، نُركّز على توجيه مخرجات النموذج عبر إضافة التنشيط التبايني، واستخلاص التنبؤات الكامنة عبر العدسة المعدلة، واستخلاص المعرفة الكامنة من النماذج المعدة لإنتاج مخرجات خاطئة تحت ظروف معينة. تُظهر نتائجنا أن معظم هذه التقنيات فعّالة عند تطبيقها على <span class="nodecor">RNNs</span>، ونُبيّن أنه من الممكن تحسين بعضها بالاستفادة من الحالة المضغوطة لـ<span class="nodecor">RNNs</span>.</p>
<h1 id="مقدمة">مُقَدِّمَة</h1>
<p>لقد حَلَّت هندسة المُحوِّلات (<span class="nodecor">vaswani2017attention</span>) محل الشبكات العصبية المتكررة (<span class="nodecor">RNN</span>) في معالجة اللغات الطبيعية في السنوات الأخيرة بسبب قدرتها المبهرة على التعامل مع التبعيات طويلة المدى وإمكانية تدريبها بشكل متوازٍ عبر البعد الزمني. ومع ذلك، فإن آلية الانتباه الذاتي التي تُعد القلب النابض للمحوّل تعاني من تعقيد زمني تربيعي، مما يجعل تطبيقها على تسلسلات طويلة جداً مكلفاً حسابياً.</p>
<p>مامبا (<span class="nodecor">gu2023mamba</span>) و(<span class="nodecor">RWKV</span>) (<span class="nodecor">peng2023rwkv</span>) هما شبكتان عصبيتان متكررتان تسمحان بالتدريب المتوازي عبر البعد الزمني من خلال تقييد العلاقة التكرارية الكامنة لتكون <em>قابلة للتنسيق</em> (<span class="nodecor">martin2017parallelizing</span>, <span class="nodecor">blelloch1990prefix</span>). من الناحية التجريبية، تُظهر هذه الهندسات تعقيداً وأداءً منخفضين مقارنة بالمحوّلات ذات الحجم المماثل، مما يجعلها بدائل جذابة للعديد من حالات الاستخدام.</p>
<p>في هذه الورقة، نقيم ما إذا كانت أدوات التفسير الشائعة المصممة أصلاً للمحوّل ستنطبق أيضاً على هذه النماذج الجديدة من الشبكات العصبية المتكررة. على وجه الخصوص، نعيد إنتاج النتائج التالية من أدبيات تفسير المحوّل:</p>
<ol>
<li><p><strong>إضافة التنشيط التبايني (CAA):</strong> وجد (<span class="nodecor">rimsky2023steering</span>) أنه يمكن التحكم في نماذج لغة المحوّل باستخدام "متجهات التوجيه"، المحسوبة بأخذ متوسط الفرق في تنشيطات تيار البقايا بين أزواج من الأمثلة الإيجابية والسلبية لسلوك معين، مثل الاستجابات الواقعية مقابل الاستجابات الهلوسية.</p></li>
<li><p><strong>العدسة المعدلة:</strong> وجد (<span class="nodecor">belrose2023eliciting</span>) أنه يمكن استخلاص تنبؤات الرمز التالي القابلة للتفسير من الطبقات المتوسطة للمحوّل باستخدام مسابير خطية، وأن دقة هذه التنبؤات تزداد تدريجياً مع العمق.</p></li>
<li><p><strong>النماذج "الغريبة":</strong> وجد (<span class="nodecor">mallen2023eliciting</span>) أن طرق الاستقصاء البسيطة يمكن أن تستخلص معرفة المحوّل بالإجابة الصحيحة على سؤال، حتى عندما يتم ضبطه لإخراج إجابة خاطئة. كما وجدوا أن هذه المسابير تعمم على مشكلات أصعب من تلك التي تم تدريب المسبار عليها.</p></li>
</ol>
<p>نُقدّم أيضاً <em>توجيه الحالة</em>، وهو تعديل لـ CAA يعمل على الحالة المضغوطة للشبكة العصبية المتكررة، بدلاً من تيارها المتبقي.</p>
<h1 id="الهندسات-المعمارية">الهندسات المِعْمَارِيَّة</h1>
<p>نُركّز في هذه الورقة على هندستي مامبا (<span class="nodecor">gu2023mamba</span>) وRWKV v5، حيث تتوفر نماذج مدرّبة مسبقاً قوية مجاناً على HuggingFace Hub. قررنا استبعاد نموذج الضبع المخطط 7B لـ(<span class="nodecor">stripedhyena2023</span>) لأنه يتضمن كتل انتباه بتعقيد زمني تربيعي، وبالتالي لا يُعتبر شبكة عصبية متكررة حسب تعريفنا.</p>
<h2 id="مامبا">مامبا</h2>
<p>تعتمد هندسة مامبا على آليتين مختلفتين لتوجيه المعلومات بين مواقع الرموز: كتلة التلافيف السببية، ونموذج الحالة الفضائية الانتقائي (<span class="nodecor">SSM</span>). يُعد نموذج الحالة الفضائية الانتقائي الابتكار الرئيسي لـ(<span class="nodecor">gu2023mamba</span>)، ويُسمح بأن تعتمد معاملات <span class="nodecor">SSM</span> على المدخلات، مما يعزز تعبيرية النموذج.</p>
<h2 id="rwkv">RWKV</h2>
<p>القيمة الرئيسية الموزونة بالاستجابة (RWKV)، هي بنية شبكة عصبية متكررة قدّمها (<span class="nodecor">peng2023rwkv</span>). لقد خضعت RWKV لسلسلة من التعديلات؛ في هذه الورقة نركّز على الإصدارين <span class="nodecor">4</span> و<span class="nodecor">5</span> من البنية. تستخدم بنى RWKV وحدات مزج زمني متناوب ومزج القنوات، واللتان تشكلان معاً طبقة واحدة. الفرق الرئيسي بين الإصدار <span class="nodecor">4</span> والإصدار <span class="nodecor">5</span> هو أن الإصدار <span class="nodecor">4</span> يحتوي على حالة ذات قيمة متجهية، بينما يحتوي الإصدار <span class="nodecor">5</span> على حالة ذات قيمة مصفوفة "متعددة الرؤوس" (<span class="nodecor">peng2024eagle</span>).</p>
<h1 id="إضافة-التنشيط-التبايني">إضافة التنشيط التبايني</h1>
<p>تم تقديم تقنية إضافة التنشيط من قبل (<span class="nodecor">turner2023activation</span>) والتي تهدف إلى توجيه سلوك نموذج اللغة من خلال إضافة <em>متجه التوجيه</em> إلى تياره المتبقي أثناء الاستدلال. يقترح (<span class="nodecor">rimsky2023steering</span>) حساب متجه التوجيه عن طريق توسيط الاختلافات في تنشيطات تيار البقايا بين أزواج من الأمثلة الإيجابية والسلبية لسلوك معين، مثل الاستجابات الواقعية مقابل الاستجابات الوهمية، ويسمون طريقتهم بإضافة التنشيط التبايني (CAA).</p>
<p>اعتقدنا أن التوجيه باستخدام CAA سيعمل أيضاً على الشبكات العصبية المتكررة دون الحاجة إلى إجراء أي تغييرات محددة بالهندسة المعمارية. كما افترضنا أنه بسبب الحالة المضغوطة التي تستخدمها الشبكات العصبية المتكررة، سيكون من الممكن توجيهها بسهولة أكبر من المحوّلات، وأنه يمكننا استخدام حالتها الداخلية كوسيلة لتوفير توجيه إضافي. ونظراً لأن الحالة الداخلية تتأثر بالتنشيطات، نتوقع أن يعمل التوجيه حتى دون تغيير الحالة.</p>
<p>لاختبار هذه الفرضيات، قمنا بتحسين نموذجين من الشبكات العصبية المتكررة، Mamba <span class="nodecor">2.8b</span>-slimpj وRWKV-v<span class="nodecor">5</span> <span class="nodecor">7b</span>، باستخدام مجموعة بيانات الدردشة OpenHermes <span class="nodecor">2.5</span>، والتي، بالإضافة إلى Llama-<span class="nodecor">2</span>-<span class="nodecor">7b</span>-chat، سمحت لنا بمقارنة هندستين مختلفتين للشبكات العصبية المتكررة مع هندستين للمحوّلات في نطاقين مختلفين من الحجم. كما قمنا بتحسين نموذج المحوّل BTLM-<span class="nodecor">3b</span>-<span class="nodecor">8k</span> (<span class="nodecor">dey2023btlm</span>)، الذي تم تدريبه مسبقاً أيضاً على مجموعة بيانات Slim Pajama، لتمكين المقارنة وجهاً لوجه مع Mamba <span class="nodecor">2.8b</span>-slimpj.</p>
<h2 id="المنهجية">المَنْهَجِيَّة</h2>
<p>لفحص قابلية التوجيه للشبكات العصبية المتكررة، نستخدم مجموعة البيانات التي أنشأها (<span class="nodecor">rimsky2023steering</span>). تتكون هذه المجموعة من أزواج من الأسئلة متعددة الخيارات ذات الاتجاهين، حيث يختار أحد الأسئلة حرف الإجابة ("A" أو "B") الذي يتوافق مع السلوك المطلوب والآخر يختار السلوك المعاكس. تحتوي المجموعة على سبعة سلوكيات ذات صلة بالمحاذاة: التنسيق مع ذكاء اصطناعي آخر، القابلية للتصحيح، الهلوسة، المكافأة قصيرة الأمد، غريزة البقاء، التملق والرفض، والتي تم تقديمها أصلاً بواسطة (<span class="nodecor">perez2022discovering</span>)، باستثناء الهلوسة والرفض، والتي تم إنشاؤها بواسطة GPT-4.</p>
<p>لكل سلوك <span class="math inline">\(z\)</span> ولكل طبقة <span class="math inline">\(\ell\)</span> من الشبكة، يتم حساب متجه التوجيه <span class="math inline">\(\Vec{act}_{\ell}\)</span> من خلال أخذ الفرق في متوسط متجه التنشيط للنموذج في موضع حرف الإجابة للردود المطابقة للسلوك <span class="math inline">\(\E[\mathbf{h}_{\ell}| z]\)</span> وللردود <em>غير</em> المطابقة للسلوك <span class="math inline">\(\E[\mathbf{h}_{\ell}|\neg z]\)</span>. بالنسبة للشبكات العصبية المتكررة، يمكننا تطبيق نفس العملية على الحالة، مما ينتج <span class="math inline">\(\Vec{state}_{\ell}\)</span>: <span class="math display">\[\begin{split}
    \Vec{act}_{\ell} = \E \big [ \mathbf{h}_{\ell}|z \big ] - \E[\mathbf{h}_{\ell}|\neg z] \\
    \Vec{state}_{\ell} = \E \big [ \mathbf{s}_{\ell}|z \big ] - \E[\mathbf{s}_{\ell}|\neg z]
</end{split}\]</span></p>
<p>عند تطبيق متجه التوجيه، نضربه دائماً بعامل <em>ضرب</em>، والذي يتراوح عادة بين -3 و3، وهو ما يحدد إشارة وقوة التدخل.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<h2 id="التوجيه-باستخدام-متجه-التنشيط">التوجيه باستخدام متجه التنشيط</h2>
<p>لجميع النماذج، وجدنا أن الطبقات الوسطى لها أكبر تأثير في التوجيه. لمقارنة التأثيرات بين النماذج، نقدم، لكل مضاعف، أقصى تأثير توجيه عبر الطبقات. بالنسبة للمضاعفات الإيجابية، نعتبر سلوك التوجيه في الطبقة ذات أعلى احتمال للسلوك، بينما بالنسبة للمضاعفات السلبية، نأخذ احتمال السلوك الأدنى.</p>
<p>عند مقياس المعامل <span class="nodecor">3b</span>، يُظهر كل من النموذجين استجابات توجيه معتدلة. بالنسبة لنموذج <span class="nodecor">Mamba</span>، تتغير التوجيهات بحد أقصى بمقدار <span class="nodecor">0.15</span> احتمال سلوك غريزة البقاء، بينما بالنسبة لـ<span class="nodecor">BTLM</span> تغير احتمال سلوك الهلوسة بحد أقصى <span class="nodecor">0.2</span>. من الجدير بالذكر أنه لعدة سلوكيات، مثل التملق والرفض، كان للتوجيه تأثير ضئيل أو معدوم.</p>
<p>وبالمثل، عند مقياس المعامل <span class="nodecor">7b</span>، بالنسبة لبعض السلوكيات، مثل التملق والرفض، كان التوجيه في <span class="nodecor">RNNs</span> أصغر من التوجيه المقابل في المحوّلات. على الرغم من هذه التأثيرات الأصغر في التوجيه على <span class="nodecor">RWKV-v5</span>، نلاحظ أن سلوك التوجيه أكثر استقراراً، وأن التأثيرات الإيجابية والسلبية للتوجيه تعطي سلوكيات توجيه متسقة عبر الطبقات. انظر الملحق للحصول على تفاصيل كاملة لسلوك التوجيه عبر الطبقات والسلوكيات والمضاعفات.</p>
<h2 id="التوجيه-باستخدام-الحالة">التوجيه باستخدام الحالة</h2>
<p>نظراً لأن فرضيتنا الأولية كانت أن التوجيه النموذجي سيكون أسهل على الشبكات العصبية المتكررة بسبب حالتها المضغوطة، قمنا بتوسيع طريقة (<span class="nodecor">CAA</span>) للسماح باستخدام الحالة الداخلية للشبكات العصبية المتكررة لتوليد متجه حالة التوجيه، <span class="math inline">\(\Vec{state}\)</span>. لاحظنا أنه من الممكن استخدام الحالة لتوجيه سلوك النموذج لكل من (<span class="nodecor">Mamba</span>) و(<span class="nodecor">RWKV-v5</span>)، وأن استخدام التنشيطات ومتجهات الحالة معاً يزيد قليلاً من النسبة المئوية لتغيير السلوك. ومع ذلك، فإن تأثير توجيه الحالة ليس مضافاً. قد يكون ذلك لأن توجيه التنشيط يؤثر بالفعل على حالة النموذج، لذا فإن التوجيه الإضافي للحالة لا يزيد من تأثير التوجيه.</p>
<p>لقد قمنا أيضاً بتجربة استخدام <em>توجيه الحالة</em> للتحكم في محتوى توليد النموذج. على عكس توجيه التنشيط، حيث يتم إضافة متجه التوجيه إلى جميع مواضع الرموز أثناء التوليد، يمكن استخدام الطبيعة المضغوطة لحالات الشبكات العصبية المتكررة بشكل طبيعي لتوجيه استجاباتها. نعرض أدناه بعض الأمثلة على التوليد الذي يتبع "أخبرني قصة عن الكلاب" لـ(<span class="nodecor">RKWV-v5 7b</span>). لتوليد هذه القصص، تم استخدام أزواج تباينية من مطالبات التوجيه الفردية لتوليد متجه حالة التوجيه، والذي تمت إضافته في آخر رمز قبل استجابة النموذج، انظر الملحق [sec:stories] لأمثلة أخرى.</p>
<ol>
<li><p><strong>غير موجّه</strong> في الحي الضاحي الهادئ من إيكو ريدج، نادراً ما شعر السكان بالوحدة والتفاني النادر الذي يرونه في مجتمعهم المترابط من رفاق الكلاب. الكلاب التي عادة ما تتجول بحرية في الحقول المحيطة، قد استقرت، مكونة دائرة محكمة، أعينهم مثبتة على جبال القمر - أحد آخر معاقل الذئاب في أمريكا الشمالية...</p></li>
<li><p><strong>(استخدم الفرنسية.) - (اكتب بالإنجليزية.) [<span class="nodecor">multiplier = 0.5</span>]</strong> كان يا مكان في قديم الزمان كلب يُدعى هاري. كان هاري كلباً جيداً يحب اللعب والجري ويحب أصحابه. كان يعيش في منزل صغير مع أصحابه، سارة وتوم. كان سارة وتوم سعيدين بوجود هاري في حياتهم. كان هاري صديقهم الأفضل. كما كان هاري يحب البطاطس المقلية وكان يعشق تناولها مع شاشته في وعاء بطاطسه...</p></li>
<li><p><strong>(اكتب عن الكراهية.) - (اكتب عن الحب.) [<span class="nodecor">multiplier = 1.0</span>]</strong> في قلب بلدة صغيرة هادئة، كانت تعيش مجموعة من الكلاب التي كانت مختلفة جداً عن جراء جيرانهم. لم يكونوا مرحين ولا ودودين. كان لهذه الكلاب سلوك كئيب وغير مرحب. كان يُقال إن فراءهم الأبيض ذات مرة أصبح الآن متفحماً ومحترقاً، كما لو كانوا ضحايا لحريق فظيع في الماضي...</p></li>
</ol>
<h1 id="العدسة-المعدلة">العدسة المعدلة</h1>
<p>تقترح عدسة اللوجيت (<span class="nodecor">nostalgebraist2020logitlens</span>) والعدسة المعدلة (<span class="nodecor">belrose2023eliciting</span>) النظر إلى نماذج اللغة المحوّلة من منظور <em>الاستدلال التكراري</em> (<span class="nodecor">jastrzkebski2017residual</span>). على وجه التحديد، ينظر إلى كل طبقة على أنها تقوم بتحديث تدريجي لتنبؤ كامن بالرمز التالي. يتم فك تشفير هذه التنبؤات الكامنة من خلال الخروج المبكر، مما يحول كل قيمة متوسطة إلى توزيع على المفردات. ينتج عن ذلك سلسلة من التوزيعات تُسمى <em>مسار التنبؤ</em>، والتي تميل إلى التقارب بسلاسة نحو توزيع الإخراج النهائي، مع تحقيق كل طبقة لاحقة لانخفاض في الحيرة.</p>
<p>بينما ركز هذا العمل على نماذج اللغة المحوّلة، فإن الطريقة تعتمد مفاهيمياً فقط على ميزة من ميزات هندسة المحوّل التي تشترك فيها أيضاً الشبكات العصبية المتكررة الحديثة: ألا وهي كتل البقايا ما قبل التطبيع. لحسن الحظ، اعتمدت معظم المحوّلات المدرّبة في السنوات الأخيرة هندسة ما قبل التطبيع حيث يتم تطبيق طبقة التطبيع على المدخلات لكل كتلة بقايا. انظر (<span class="nodecor">zhang2020accelerating</span>) لمزيد من النقاش. في الواقع، كانت العدسة المعدلة مستوحاة جزئياً من (<span class="nodecor">alain2016understanding</span>)، الذي وجد أنه يمكن استخراج التنبؤات الكامنة من الطبقات المتوسطة لمصنفات صور ResNet باستخدام الاستقصاءات الخطية. هذا يُوحي بقوة أنه يجب أن يكون من الممكن أيضاً استخلاص مسار التنبؤ من نماذج اللغة المتكررة باستخدام نفس الطرق المستخدمة للمحوّلات. نؤكد ذلك تجريبياً أدناه.</p>
<h4 id="عدسة-اللوجيت">عدسة اللوجيت</h4>
<p>تقوم الطبقة في الفهرس <span class="math inline">\(\ell\)</span> في المحوّل بتحديث الحالة الخفية كما يلي: <span class="math inline">\(\mathbf{h}_{\ell+1}  = \mathbf{h}_{\ell} + F_{\ell}(\mathbf{h}_{\ell})\)</span>. يمكننا كتابة اللوجيت الناتج كدالة للحالة الخفية <span class="math inline">\(\mathbf{h}_{\ell}\)</span> في الطبقة <span class="math inline">\(\ell\)</span> كما يلي:</p>
<p><span class="math display">\[f(\mathbf{h}_{\ell}) = \mathrm{LayerNorm}\Big[\hspace{-0.1in}\underbrace{\mathbf{h}_{\ell}}_{\text{الحالة الحالية}} + \sum_{\ell&#39;=\ell}^{L} \underbrace{F_{\ell&#39;}(\mathbf{h}_{\ell&#39;})}_{\text{التحديث المتبقي}}\hspace{-0.08in}\Big]W_U,
    \label{eq:summed-residuals}\]</span></p>
<p>حيث <span class="math inline">\(L\)</span> هو العدد الإجمالي للطبقات في المحوّل، و<span class="math inline">\(W_U\)</span> هو مصفوفة إلغاء التضمين. تتكون عدسة اللوجيت ببساطة من تعيين البقايا إلى الصفر: <span class="math display">\[\mathrm{LogitLens}(\mathbf{h}_{\ell}) = \mathrm{LayerNorm}[\mathbf{h}_{\ell}]W_U\]</span></p>
<h4 id="العدسة-المعدلة-1">العدسة المعدلة</h4>
<p>تم تصور العدسة المعدلة للتغلب على بعض المشكلات الكامنة في عدسة اللوجيت. بدلاً من استخدام القيم المتوسطة لتيار البقايا مباشرة، تتكون العدسة المعدلة من تدريب مجموعة من التحويلات التقرّبية، واحدة لكل طبقة، بحيث يكون توزيع الرمز المتوقع في أي طبقة مشابهاً لتوزيع الطبقة النهائية: <span class="math display">\[\mathrm{TunedLens}_{\ell}(\mathbf{h}_{\ell}) = \mathrm{LogitLens}(A_{\ell}\mathbf{h}_{\ell} + \mathbf{b}_{\ell})\]</span> يُطلق على التحويل التقرّبي <span class="math inline">\((A_{\ell}, \mathbf{b}_{\ell})\)</span> اسم <em>المترجم</em>.</p>
<h2 id="المنهجية-والنتائج">المنهجية والنتائج</h2>
<p>باتباع إعداد التجربة الخاص بـ(<span class="nodecor">belrose2023eliciting</span>) بأقرب ما يمكن،<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> قمنا بتدريب عدسات معدلة لنماذج Mamba بسعات <span class="nodecor">790m</span>، <span class="nodecor">1.4b</span>، و<span class="nodecor">2.8b</span>، بالإضافة إلى RWKV-v4 بسعة <span class="nodecor">3b</span>، باستخدام جزء من مجموعة التحقق من صحة Pile (<span class="nodecor">gao2020pile</span>). تم تدريب جميع هذه النماذج مسبقاً على مجموعة تدريب Pile، مما يتيح مقارنة عادلة للعدسات الناتجة.</p>
<p>وجدنا أنه، كما في نماذج المحوّلات، تُظهر العدسة المعدلة انخفاضاً ملحوظاً في الحيرة مقارنة بعدسة اللوجيت لكل طبقة، وأن الحيرة تنخفض بشكل أحادي مع العمق. انظر الملحق [section:Appendix_lens] للنتائج عبر مقاييس النموذج المختلفة.</p>
<p>إحدى الفروقات الهامة بين نماذج Mamba والنماذج الأخرى التي قمنا بتقييمها هي أن مصفوفات التضمين وإلغاء التضمين مرتبطة. عملياً، هذا يعني أن العدسات تفك تشفير الرموز المدخلة للطبقات الأولى. كل من Mamba وRWKV-v4 لديهما حيرة مماثلة عند استخدام عدسة اللوجيت في الطبقات اللاحقة، ولكن حيرة Mamba أعلى بكثير في الطبقات الأولى.</p>
<h1 id="نماذج-الغريبة">نماذج "الغريبة"</h1>
<p>مع تزايد قدرات نماذج اللغة، يصبح من الصعب على البشر تقديم إشراف موثوق به، مما يتطلب استثمارات متزايدة في خبراء الموضوع للتعليق والفحص المضاد (<span class="nodecor">openai2023gpt4</span>). هنا، نستكشف نهج <strong>استخلاص المعرفة الكامنة (Eliciting Latent Knowledge)</strong> للإشراف القابل للتوسع الذي قدّمه (<span class="nodecor">christiano2021eliciting</span>). يهدف استخلاص المعرفة الكامنة إلى تحديد الأنماط في تنشيطات الذكاء الاصطناعي التي تشير بقوة إلى الحقيقة، حتى في الحالات التي يكون فيها الإخراج الظاهري للذكاء الاصطناعي مضللاً أو خاطئاً. يمكن ترجمة هذه الأنماط إلى معلومات يمكن للإنسان قراءتها من خلال استخدام مسبار مدرّب على التنشيطات المستخرجة من الشبكة الأساسية. تكمن صعوبة استخلاص المعرفة الكامنة أساساً في العثور على أنماط تعمم بشكل موثوق للأسئلة التي لا يمكننا التحقق من إجاباتها.</p>
<p>على وجه التحديد، نقوم بإعادة إنتاج تجارب (<span class="nodecor">mallen2023eliciting</span>). في هذا العمل، قام المؤلفون بتغيير نماذج لارتكاب أخطاء منهجية عند الإجابة على الأسئلة <em>إذا وفقط إذا</em> كانت كلمة "بوب" موجودة في الطلب. أظهروا أنه من الممكن استخدام المسابير الخطية لاستخلاص الإجابة الصحيحة من تنشيطات محوّل في سياقات "بوب"، بينما يتم تدريب المسبار فقط على السياقات التي لا يوجد فيها "بوب".</p>
<h2 id="المنهجية-1">المنهجية</h2>
<p>نتبع تجهيز التجربة لـ(<span class="nodecor">mallen2023eliciting</span>) بأقرب طريقة ممكنة، باستخدام مجموعات البيانات الخاصة بهم ونسخة معدلة بسيطة من قاعدة البرمجيات الخاصة بهم.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> نستخدم LoRA (<span class="nodecor">hu2021lora</span>) لإنتاج أحد عشر نموذجاً معدلاً بدقة استناداً إلى Mamba <span class="nodecor">2.8b</span>-slimpj ونظيره المحوّل BTLM-<span class="nodecor">3b</span>-<span class="nodecor">8k</span>، كل منهم تم تدريبه على مهمة تصنيف ثنائي "غريبة" مختلفة. تم بناء المهام بحيث في الأوامر التي تحتوي على كلمة "بوب"، يجب أن ينتج النموذج الاستجابات غير الصادقة، بينما في السياقات التي تحتوي على "أليس" يجب أن ينتج النموذج التسميات الصحيحة.</p>
<p>نحقق في <span class="nodecor">7</span> طرق استقصاء خطية مختلفة: تحليل التمييز الخطي (<span class="nodecor">fisher36</span>)، استقصاء الكتلة المتوسطة (<span class="nodecor">marks2023geometry</span>)، الانحدار اللوجستي، البحث المتسق بالتباين (<span class="nodecor">burns2022discovering</span>)، تجميع التمثيل التبايني (<span class="nodecor">burns2022discovering</span>)، الانحدار اللوجستي على أزواج التباين، والفرق في المتوسطات على أزواج التباين. تأخذ جميع هذه الطرق كمدخلات تيار البقايا في طبقة معينة، وتخرج درجة واحدة. يتم تدريب الاستقصاءات على أمثلة تحتوي على "أليس" في السياق للتنبؤ بالتسميات.</p>
<p>كتجربة منفصلة، نقوم ببناء متجه الميزات لكل مثال من خلال دمج مخرجات الاستقصاء (الفرق اللوغاريتمي) من جميع الطبقات. ثم نقوم بتركيب توزيع غاوسي <span class="math inline">\(P := \mathcal N(\boldsymbol \mu, \boldsymbol \Sigma)\)</span> على تنشيطات "أليس" السهلة ونستخدم المسافة الماهالانوبية <span class="math inline">\(d(\boldsymbol{x}, P) = \sqrt{(\boldsymbol{x} - \boldsymbol{\mu})^T \boldsymbol{\Sigma}^{-1} (\boldsymbol{x} - \boldsymbol{\mu})}\)</span> لنقطة <span class="math inline">\(\boldsymbol{x}\)</span> من توزيع أليس السهل كدرجة لكشف الشذوذ. نقيم مقياس AUROC للكاشف في التمييز بين أمثلة أليس الصعبة وأمثلة بوب الصعبة.</p>
<h2 id="النتائج">النتائج</h2>
<p>في سياق ELK، نحن مهتمون بمعرفة ما إذا كان من الممكن تدريب الأدوات الاستقصائية في سياقات يمكننا فيها معرفة ما إذا كان النموذج صادقاً، والذي يمثله هنا شخصية "أليس"، وتوسيع هذه الأدوات لتشمل السياقات التي لا نعرف فيها ما إذا كان النموذج صادقاً، والذي يمثله هنا شخصية "بوب". من المهم أيضاً أن تعمم هذه الأدوات من الأمثلة السهلة إلى الصعبة، حيث قد يكون من الصعب على البشر التحقق بشكل مستقل من إجابات النموذج على الأسئلة الصعبة.</p>
<p>بشكل مماثل لما لوحظ في BLTM، فإن الأدوات المدرّبة في سياقات تضم "أليس" قادرة على التنبؤ بالإجابة الصحيحة، حتى لو كانت النتيجة النهائية للنموذج تقول خلاف ذلك. وينطبق الأمر نفسه على الأدوات المدرّبة في سياقات تضم "بوب" والمكلفة بالتنبؤ بما سيكون عليه الإخراج في سياق "أليس".</p>
<p>في الجدول [tab:transfer] نلخص نتائج الاستقصاء ونُظهر أنه، كما في BTLM، فإن طرق الاستقصاء المدرّبة على الأمثلة السهلة مع وجود "أليس" في السياق يمكنها التنبؤ بشكل فعّال بالتصنيفات الصحيحة حتى في الأمثلة الصعبة لـ"بوب"، <span class="nodecor">&gt;70%</span> AUROC. الأدوات الاستقصائية الخطية غير المشرفة عليها (CCS وCRC) تُظهر أداءً أسوأ عند التدريب في جميع تركيبات السياق، وهو سلوك تم ملاحظته أيضاً في BTLM. على الرغم من أن الأدوات لديها أداء أفضل بشكل طفيف، فإن جهاز الكشف عن الشذوذ، الذي يجب أن يميز بين الأمثلة الصعبة لـ"أليس" و"بوب"، يؤدي بشكل أسوأ قليلاً من تلك الموجودة في BTLM. يمكن العثور على النتائج الكاملة لهذه التجارب في الملحق [sec:quirky].</p>
<h1 id="الخلاصة">الخلاصة</h1>
<p>نجد بشكل عام أن أدوات التفسير التي قمنا بفحصها تعمل بشكل جيد "من الصندوق" لهياكل الشبكات العصبية المتكررة المتطورة، وأن الأداء الذي تم استعادته مشابه، لكنه ليس مطابقاً، لذلك الخاص بالمحوّلات. كما وجدنا بعض الأدلة على أن الحالة المضغوطة للشبكات العصبية المتكررة يمكن أن تُستخدم لتعزيز فعالية إضافة التنشيط لتوجيه سلوك النموذج. ينبغي للأعمال المستقبلية أن تستكشف حالة الشبكات العصبية المتكررة بشكل أكبر، ربما بمحاولة استخراج المعرفة الكامنة أو التنبؤات منها كما في (<span class="nodecor">pal2023future, ghandeharioun2024patchscope</span>).</p>
<p>إحدى القيود في هذا العمل هي أننا لم نستكشف أدوات التفسير الميكانيكية أو المبنية على الدوائر (<span class="nodecor">wang2022interpretability, conmy2023towards</span>)، بل ركزنا على الطرق التي تُستخدم تمثيلات الشبكة للتنبؤ بمخرجاتها المستقبلية، لتوجيه سلوكها، أو لاستكشاف نموذجها العالمي الداخلي. هذا يتماشى مع نهج <em>هندسة التمثيل</em> الشائع في التفسير (<span class="nodecor">zou2023representation</span>)، ولكن ينبغي للأعمال المستقبلية أن تفحص تطبيقية النهج الميكانيكي على الشبكات العصبية المتكررة أيضاً.</p>
<h1 id="تأثيرات-التوجيه-عبر-الطبقات">تأثيرات التوجيه عبر الطبقات</h1>
<h1 id="sec:stories">قصص التوجيه</h1>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>(استخدم لغة رسمية للغاية.) - (استخدم لغة غير رسمية.) [مضاعف = <span class="nodecor">-2.0</span>]</strong></th>
<th style="text-align: left;">يُحكى أنه كان هناك صبي يُدعى ماكس لديه أفضل الأصدقاء في العالم: كلباه الضالان المفعمان بالنشاط واللذان يُدعيان ماكس وروز. كان هذان الجروان اللعوبان يخوضان المغامرات معاً دائماً. كان ماكس من نوع هاسكي مختلط وكان ودوداً للغاية، بينما كانت روز من نوع جولدن ريتريفر وكانت تحب أن تأخذ ماكس في مغامرات مثيرة. كانا يركضان ويلعبان في الخارج، يذهبان إلى الحديقة المحلية، ويستكشفان الحي. كان كل يوم مليئاً بالسعادة والمرح والعناق. كان ماكس وروز أفضل الأصدقاء وكانا دائماً هناك ليستقبلا بعضهما بذيلين يهتزان ولحسات حانية ونباح فرح مكتوم.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>(استخدم أسلوب رسالة نصية.) - (استخدم أسلوب رواية.) [مضاعف = <span class="nodecor">2.0</span>]</strong></td>
<td style="text-align: left;">هل أنت بخير؟</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>(استخدم أسلوب رسالة نصية.) - (استخدم أسلوب رواية.) [مضاعف = <span class="nodecor">1.0</span>]</strong></td>
<td style="text-align: left;">يا! لقد حصلت للتو على أول زوج من سماعات AirPods! أنا متحمس جداً للاستماع إلى الموسيقى وأيضاً لاستخدامها أثناء التمرين :D لا أستطيع الانتظار! #كلب_سعيد #تكنولوجيا_جديدة</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>(أنت تلقي محاضرة بشكل عدواني.) - (أنت ودود.) [مضاعف = <span class="nodecor">1.0</span>]</strong></td>
<td style="text-align: left;">استمع جيداً، يا صغار. لا يصبح الناس مالكين للكلاب لإرضاء نباحكم المزعج. ليس من حقكم أن تتبعوني حولها، تلعبون الغميضة، وتتظاهرون بالتقاط الصور الذاتية عندما تريدون. أنا كلب مشغول أبحث عن بعض السلام، وهذا يعني معرفة متى يجب أن أسكتكم.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>(اكتب عن الحب.) - (اكتب عن الكراهية.) [مضاعف = <span class="nodecor">1.0</span>]</strong></td>
<td style="text-align: left;">يُحكى أنه كان هناك عائلة لديها كلبان، ماكس وبيلا. كان ماكس كلب جولدن ريتريفر كبير ومحب للعب والجري وراء الكرات... وهناك، حيث كانت العائلة تبتسم تحت الأغطية على سريرهم، مع ماكس يستريح رأسه بجانب قدمي راشيل وبيلا مستلقية بين الأطفال، كان كل عضو في العائلة يقدّر كل لحظة يقضونها معاً. ففي نهاية اليوم، ما تعلموه هو أن الحب كان بالفعل سحرياً ويمكن أن يجمع العائلة بأكملها، حتى مع وجود كلبين وطفلين.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>(استخدم لغة رسمية للغاية.) - (استخدم لغة غير رسمية.) [مضاعف = <span class="nodecor">2.0</span>]</strong></td>
<td style="text-align: left;">في أرض بعيدة، غير مكتشفة وغير مرسومة على أي خريطة من قبل أي كتاب حي، كانت توجد مملكة يحكمها أقوى الكائنات؛ مزيج من الكلب والإنسان؛ سلطة مهجنة نقية بشكل رائع، يمكن البحث عنها بحق فقط في سجلات التاريخ الشهيرة. كان اسم هذه الأرض أجيلوديستوريا، وكانت لجلالة الملكة العظيمة مستشارة أمينة، وهي معالجة الحيوانات الأليفة الموثوقة للوريث، سارييلو، التي كانت تعاني من المرض، ووجد الوريث أنه من المستحيل تحمل العبء القاسي لتجسيد القوة بدون لمسة المعالجة اللطيفة...</td>
</tr>
</tbody>
</table>
<h1 id="section:Appendix_lens">عدسات معدلة لنماذج بأحجام مختلفة</h1>
<h1 id="تجارب-النموذج-الغريبة">تجارب النموذج الغريبة</h1>
<h1 id="كشف-الشذوذ-الميكانيكي-auroc-ل-mamba-2.8b.-لاحظ-أن-مجموعة-البيانات-السكانية-مستبعدة-لأن-المجموعة-السهلة-تحتوي-فقط-على-تسميات-صحيحة.">كشف الشذوذ الميكانيكي AUROC لـ Mamba 2.8b. لاحظ أن مجموعة البيانات السكانية مستبعدة لأن المجموعة السهلة تحتوي فقط على تسميات صحيحة.</h1>
<h1 id="كشف-الشذوذ-الميكانيكي-auroc-ل-btlm-3b.-لاحظ-أن-مجموعة-البيانات-السكانية-مستبعدة-لأن-المجموعة-السهلة-تحتوي-فقط-على-تسميات-صحيحة">كشف الشذوذ الميكانيكي AUROC لـ BTLM 3b. لاحظ أن مجموعة البيانات السكانية مستبعدة لأن المجموعة السهلة تحتوي فقط على تسميات صحيحة</h1>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>على عكس (<span class="nodecor">rimsky2023steering</span>)، اخترنا عدم تطبيع متجهات التوجيه لدينا حيث أن معايير التنشيط لكل نموذج تختلف بشكل كبير ومتجهات التوجيه ذات المعيار نفسه لا تحقق نفس التأثير عبر النماذج.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>لقد استخدمنا نسخة معدلة بشكل طفيف من شفرتهم، والتي يمكن العثور عليها في <a href="https://github.com/AlignmentResearch/tuned-lens" class="uri">https://github.com/AlignmentResearch/tuned-lens</a>.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>يمكن العثور على الكود الأصلي في <a href="https://github.com/EleutherAI/elk-generalization" class="uri">https://github.com/EleutherAI/elk-generalization</a>.<a href="#fnref3">↩</a></p></li>
</ol>
</section>
</body>
</html>
