<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Daniel Menges">
  <meta name="author" content="Adil Rasheed">
  <title>تحليلات تنبؤية قوية وفعّالة حسابياً وذاكرياً باستخدام البيانات الضخمة</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>body { direction: rtl; font-size: 22px; }</style>
</head>
<body>
<header>
<h1 class="title">تحليلات تنبؤية قوية وفعّالة حسابياً وذاكرياً باستخدام البيانات الضخمة</h1>
<p class="author"><span class="nodecor">Daniel Menges</span></p>
<p class="author"><span class="nodecor">Adil Rasheed</span></p>
</header>
<p>معادلات LaTeX</p>
<h1 id="ملخص">مُلَخَّص</h1>
<p>في عصر البيانات الضخمة، أصبحت هذه البيانات ركيزة أساسية للذكاء الاصطناعي، حيث تُستخدم لتطوير نماذج قائمة على البيانات واستخلاص رؤى في مجالات متنوعة. تتناول هذه الدراسة التحديات المرتبطة بعدم اليقين في البيانات وقيود التخزين، إضافةً إلى نمذجة البيانات التنبؤية في سياق البيانات الضخمة. نعتمد في الدراسة على التحليل القوي للمكونات الرئيسية (RPCA) لتقليل الضوضاء وإزالة القيم الشاذة بفعالية، وكذلك على تحديد مواقع الاستشعار الأمثل لضغط البيانات وتخزينها بكفاءة. تتيح هذه التقنيات ضغط البيانات دون فقدان جوهري للمعلومات مع الحدّ من متطلبات الذاكرة. وعلاوةً على ذلك، يشكل التحليل القوي للمكونات الرئيسية بديلاً أكثر متانة من التحليل التقليدي للبيانات عالية الأبعاد، ويمكن توسيعه ليشمل النمذجة في الزمن الحقيقي. ولهذا الغرض، نستخدم شبكات الذاكرة قصيرة وطويلة الأمد (LSTM)، فئة من الشبكات العصبية المتكررة، لنمذجة البيانات والتنبؤ بها استناداً إلى مجموعة فرعية منخفضة الأبعاد تحددها مواقع الاستشعار الأمثل، مما يقلل بشكل كبير من زمن التدريب. وتعدّ شبكات LSTM مناسبة لالتقاط الاعتماديات طويلة المدى في بيانات السلاسل الزمنية؛ ما يجعلها ملائمة للتنبؤ بالحالات المستقبلية للأنظمة الفيزيائية استناداً إلى البيانات التاريخية. وقد قمنا بوضع الأسس النظرية والمحاكاة لجميع الخوارزميات والتحقق من صحتها باستخدام بيانات تصوير حراري حقيقية لمحرك سفينة.</p>
<h1 id="مقدمة">مُقَدِّمَة</h1>
<p>في سياق الذكاء الاصطناعي، تتصدر البيانات المشهد في عمليات اتخاذ القرار في العديد من المجالات، من الرعاية الصحية (<span class="nodecor">raghupathi_big_2014</span>) إلى الاقتصاد القياسي (<span class="nodecor">varian_big_2014</span>) والتصنيع (<span class="nodecor">nagorny_big_2017</span>) وغيرها. ومع ذلك، ورغم الإمكانات الهائلة للبيانات الضخمة، من الضروري فهم نقاط قوتها وضعفها؛ فغالباً ما تتضمن البيانات أخطاء ناتجة عن عدم دقة المستشعرات أو أعطال النقل، مما قد يؤدي إلى تفسير خاطئ إذا لم تُعالَج هذه البيانات بشكل سليم، لا سيما عند وجود تشوهات أو قيم ناقصة (<span class="nodecor">pitici_rise_2014</span>). لذا، يُعدّ تطوير تقنيات تحليلية متينة أمراً حيوياً للتعامل بفعالية مع كميات البيانات المتزايدة وتحليلها وتفسيرها.</p>
<p>من بين الأدوات المتعددة لتحليل البيانات، حظي تحليل المكونات الرئيسية (<span class="nodecor">PCA</span>) (<span class="nodecor">jolliffe_principal_2002</span>) باهتمام كبير لما يوفره من خفض الأبعاد مع الحفاظ على معظم المعلومات (<span class="nodecor">abdi_principal_2010</span>). ومع ذلك، فإن PCA التقليدي يتأثر بشدة بالقيم الشاذة وتلف البيانات، مما يضعف أدائه ودقة الاستنتاجات اللاحقة. ولهذا ظهر التحليل القوي للمكونات الرئيسية (<span class="nodecor">RPCA</span>)، النسخة المتقدمة من PCA، ليقدم نتائج أكثر موثوقية عبر فصل المكونات منخفضة الرتبة عن المكونات المتفرقة في وجود قيم شاذة أو بيانات مفقودة (<span class="nodecor">hubert_robpca_2005</span>). وقد فصّل (<span class="nodecor">candes_robust_2011</span>) مفهوم RPCA الذي يفكك مصفوفة البيانات إلى مكون منخفض الرتبة ومكون متفرق، مستخدماً برمجة محدبة تعرف بـ«مطاردة المكونات الرئيسية». وتساهم هذه الطريقة في استعادة الهيكل الأساسي للبيانات حتى عند وجود أخطاء أو قيم مفقودة، مما يفتح آفاقاً جديدة في مجالات مراقبة الفيديو وكشف الأجسام في الخلفيات المعقدة والتعرف على الوجوه لمعالجة الظلال والانعكاسات وغيرها. كما تقدم دراسة (<span class="nodecor">scherl_robust_2019</span>) مقارنة مفصلة بين PCA وRPCA، مبينة الفوائد والقدرة الفائقة للتحليل القوي.</p>
<p>بالتوازي، ومع تصاعد حجم البيانات الضخمة، يظهر تحدٍ رئيسي في كيفية تخزينها ونقلها بفعالية. يأتي مفهوم «وضع المستشعرات الأمثل» (<span class="nodecor">OSP</span>) (<span class="nodecor">manohar_data-driven_2018</span>) كنهج مبتكر يعنى بتموضع المستشعرات استراتيجياً لالتقاط البيانات الأكثر صلة وتجنب التكرار، مما يقلل من حمل التخزين ويسهل عملية النقل. في جوهره، يهدف OSP إلى إنتاج نسخة مضغوطة من البيانات بأقل خسارة في المعلومات.</p>
<p>من خلال استعراض منهجي لـ RPCA وOSP، تهدف هذه الدراسة إلى استكشاف التكامل بين المنهجيتين وتأثيرهما على تعزيز دقة وكفاءة نمذجة البيانات الضخمة.</p>
<p>علاوةً على ذلك، نوسّع هذه الدراسة بدمج نهج تنبؤي معتمد على البيانات باستخدام شبكات الذاكرة قصيرة وطويلة الأمد (<span class="nodecor">LSTM</span>) التي قدمها (<span class="nodecor">hochreiter_long_1997</span>). تتيح بوابات LSTM تعلم الاعتماديات طويلة الأمد في البيانات (<span class="nodecor">chung_gated_2015</span>). وقد حظيت الشبكات العصبية الاصطناعية (<span class="nodecor">ANNs</span>) باهتمام واسع في التنبؤ بفضل قابليتها للتكيف وعدم خطيتها وقدرتها على تمثيل الوظائف المعقدة، رغم أنها تتطلب وقتاً حسابياً كبيراً للتدريب (<span class="nodecor">zhang_forecasting_1998</span>). لذلك نصمم نماذج LSTM استناداً إلى نقاط البيانات المختارة عبر خوارزمية OSP، مما يسرّع بشكل كبير زمن التدريب وييسر تطبيقها في نطاق واسع من التطبيقات. فعند استخدام هذه النماذج للتنبؤ بالقياسات المختارة، نعيد بعد ذلك بناء البعد الكامل للبيانات عبر مفهوم OSP، مما يمكّننا من التنبؤ بدقة بالحالات المستقبلية في الأبعاد الأصلية. يعمل دمج RPCA وOSP وLSTM على تقديم نهج مبتكر لمعالجة البيانات الضخمة يجمع بين القوة الحسابية والقدرة على التوسع في سيناريوهات واقعية متعددة.</p>
<p>طبقنا الخوارزميات في هذه الدراسة على بيانات مستخلصة من كاميرا تصوير حراري لرصد محرك سفينة. توفر الصور الحرارية رؤية فريدة لملامح درجات الحرارة وتقلباتها، مما يتيح فهماً أعمق لسلوك التشغيل وأداء المحرك. تُعد المراقبة الشرطية ضرورية للحفاظ على سلامة العمليات (<span class="nodecor">mohanty_machinery_2014</span>) وتمكّن من تقدير موثوقية المحرك ومكوناته. ومن خلال الكشف المبكر عن الشذوذ، يمكن التنبؤ بعمر المكونات ومنع الأعطال الخطيرة.</p>
<h1 id="التحديات-الأساسية">التحديات الأساسية</h1>
<p>باختصار، تتناول هذه الدراسة ثلاث تحديات أساسية:</p>
<ul>
<li><p>المعالجة المتينة لعدم اليقين في البيانات، مثل القيم الشاذة والتلف الناجم عن قياسات الكاميرا الحرارية منخفضة التكلفة وغير الملامسة.</p></li>
<li><p>الحاجة إلى تقنيات تخزين فعّالة من حيث استهلاك الذاكرة نظراً للكم الهائل من البيانات المتولدة.</p></li>
<li><p>القدرة على إجراء الصيانة الاستباقية في الزمن الحقيقي من خلال النمذجة التنبؤية المعتمدة على البيانات.</p></li>
</ul>
<p>كما أشار (<span class="nodecor">inproceedings</span>)، نادراً ما يعتمد القطاع البحري الصيانة التنبؤية، بل تميل أنشطته إلى الصيانة الوقائية، مما يؤدي غالباً إلى تكاليف أعلى جراء استبدال مكونات لا تزال صالحة.</p>
<h1 id="النظرية">النظرية</h1>
<p>يقدم هذا القسم نظرة معمقة على التقنيات الإحصائية المستخدمة في الدراسة. نشرح فيه مفهومي تحليل المكونات الرئيسية (PCA) ونظيره القوي (RPCA) لتنقية البيانات، كما نتناول فكرة تحديد مواقع الاستشعار الأمثل (OSP) لضغط البيانات وإدارة التخزين بكفاءة.</p>
<h2 id="تحليل-المكون-الرئيسي">تحليل المكون الرئيسي</h2>
<p>تحليل المكون الرئيسي (Principal Component Analysis) إجراء إحصائي يستخدم تحويلاً متعامداً لتحويل مجموعة من الملاحظات لعدة متغيرات مترابطة إلى مجموعة من المتغيرات غير المرتبطة خطياً، وتُسمى هذه المتغيرات بالمكونات الرئيسية. يسمح ذلك بتحديد الاتجاهات التي تتباين فيها البيانات بشكل أكبر. هناك نهجان رئيسيان لحساب PCA: نهج المتجه الذاتي ونهج تحليل القيمة المفردة (Singular Value Decomposition). وتُفصَّل هذه المفاهيم في (<span class="nodecor">shlens_tutorial_2014</span>). وغالباً ما يُفضَّل نهج SVD لكونه أكثر ثباتاً عدديّاً.<br />
</p>
<h3 id="نهج-تحليل-القيمة-المفردة" class="unnumbered">نهج تحليل القيمة المفردة</h3>
<p>يرتبط تحليل المكون الرئيسي ارتباطاً وثيقاً بتحليل القيمة المفردة، وهو تحليل لمصفوفة حقيقية أو مركبة. لأي مصفوفة حقيقية <span class="math inline">\(\mathbf{A}\in \mathbb{R}^{m\times n}\)</span>، حيث <span class="math inline">\(m \geq n\)</span>, يوجد تحليل من الشكل <span class="math display">\[\mathbf{A} = \mathbf{U} \mathbf{\Sigma} \mathbf{V}^T,\]</span> حيث <span class="math inline">\(\mathbf{U}\in \mathbb{R}^{m\times m}\)</span>، و<span class="math inline">\(\mathbf{\Sigma}\in \mathbb{R}^{m\times n}\)</span>، و<span class="math inline">\(\mathbf{V}\in \mathbb{R}^{n\times n}\)</span>. أعمدة <span class="math inline">\(\mathbf{U}\)</span> هي متجهات ذاتية متعامدة لـ <span class="math inline">\(\mathbf{AA}^T\)</span>، وأعمدة <span class="math inline">\(\mathbf{V}\)</span> هي متجهات ذاتية متعامدة لـ <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span>. العناصر القطرية لـ <span class="math inline">\(\mathbf{\Sigma}\)</span> هي الجذور التربيعية للقيم الذاتية لـ <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span> (أو بالمثل، <span class="math inline">\(\mathbf{AA}^T\)</span>)، وتسمى القيم المفردة لـ <span class="math inline">\(\mathbf{A}\)</span>. لرؤية ذلك، نعتبر أولاً المصفوفة <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span>، وهي مصفوفة متماثلة. بموجب نظرية الطيف، يمكننا تحليلها كما يلي: <span class="math display">\[\mathbf{A}^T\mathbf{A} = \mathbf{V} \mathbf{\Sigma}^2\mathbf{V}^T.\]</span> بالمثل، يمكننا تحليل <span class="math inline">\(\mathbf{AA}^T\)</span> كما يلي: <span class="math display">\[\mathbf{AA}^T = \mathbf{U} \mathbf{\Sigma}^2 \mathbf{U}^T.\]</span> باستخدام هاتين الهويتين، يمكن إظهار أن <span class="math display">\[\mathbf{A} = \mathbf{U} \mathbf{\Sigma} \mathbf{V}^T,\]</span> وهو تحليل القيمة المفردة لـ <span class="math inline">\(\mathbf{A}\)</span>.</p>
<p>نفترض أن لدينا مصفوفة بيانات <span class="math inline">\(\mathbf{X} \in \mathbb{R}^{m \times n}\)</span>، حيث كل صف هو ملاحظة وكل عمود هو متغير، وأن البيانات قد خضعت للتوسيط بطرح متوسطات الأعمدة.</p>
<ol>
<li><p><em>أداء تحليل القيمة المفردة ذو الرتبة المنخفضة:</em> احسب تحليل القيمة المفردة لـ <span class="math inline">\(\mathbf{X}\)</span> بواسطة <span class="math inline">\(\mathbf{X} = \mathbf{U}_r\mathbf{\Sigma}_r\mathbf{V}_r^T+\mathbf{E}\)</span>. هنا، <span class="math inline">\(\mathbf{U}_r \in \mathbb{R}^{m \times r}\)</span> و <span class="math inline">\(\mathbf{V}_r^\top \in \mathbb{R}^{r \times n}\)</span> هما مصفوفتان متعامدتان تحتويان على المتجهات الذاتية اليسرى واليمنى على التوالي، و <span class="math inline">\(r\)</span> هو عدد المكونات الرئيسية. وتحتوي المصفوفة <span class="math inline">\(\mathbf{\Sigma}_r \in \mathbb{R}^{r \times r}\)</span> على أكبر <span class="math inline">\(r\)</span> قيم مفردة بترتيب تنازلي على القطر. أما المصفوفة <span class="math inline">\(\mathbf{E}\)</span> فتمثل البقايا المتبقية بعد تقليل الأبعاد.</p></li>
<li><p><em>المكونات الرئيسية:</em> تُعطى المكونات الرئيسية لـ <span class="math inline">\(\mathbf{X}\)</span> بواسطة <span class="math inline">\(\mathbf{X}\mathbf{V}_r \approx \mathbf{U}_r \mathbf{\Sigma}_r\)</span>. العمود <span class="math inline">\(i\)</span> من <span class="math inline">\(\mathbf{X}\mathbf{V}_r\)</span> هو إسقاط البيانات على المتجه الذاتي رقم <span class="math inline">\(i\)</span>.</p></li>
</ol>
<p>يبين هذا الإجراء كيف يُستنتج PCA من تحليل القيمة المفردة لمصفوفة البيانات، مع ملاحظة أن PCA التقليدي حساس جداً للقيم الشاذة وتلف البيانات.</p>
<h2 id="sec:RPCA">تحليل المكون الرئيسي القوي</h2>
<p>الميزة الأبرز في RPCA مقارنةً بـ PCA التقليدي هي مقاومته للقيم الشاذة. فـ PCA التقليدي حساس للقيم الشاذة لكونه يحاول إيجاد تمثيل منخفض الأبعاد يفسر أكبر قدر من التباين، وقد يحرف هذا التمثيل اتجاهات البيانات الحقيقية عند وجود نقاط متطرفة. أما RPCA فينمذج هذه القيم الشاذة صراحةً، فتتحقق دقة أكبر في استعادة الهيكل الأساسي للبيانات.</p>
<p>في العديد من السيناريوهات، يستطيع RPCA استرجاع الهيكل منخفض الرتبة الحقيقي للبيانات أفضل مما يوفره PCA، خاصة عندما تسيطر التشويشات أو يكون هناك نقص كبير في العينات.</p>
<p>تعتمد الفكرة العامة على تفكيك مصفوفة البيانات <span class="math inline">\(\mathbf{X}\)</span> إلى مكونين:</p>
<span class="math display">\[\mathbf{X} = \mathbf{L} + \mathbf{S}.\]</span>
<p>حيث تصف <span class="math inline">\(\mathbf{L}\)</span> المكون منخفض الرتبة الذي يلتقط الهيكل الرئيسي للبيانات، وتصف <span class="math inline">\(\mathbf{S}\)</span> المكون المتفرق الذي يلتقط القيم الشاذة أو التشوهات. والهدف هو إيجاد <span class="math inline">\(\mathbf{L}\)</span> و<span class="math inline">\(\mathbf{S}\)</span> اللذين يحلان:</p>
<span class="math display">\[
\begin{split}
& \underset{\mathbf{L}, \mathbf{S}}{\mathrm{تصغير}}\ \mathrm{rank}(\mathbf{L}) + \|\mathbf{S}\|_0, \\
& \text{خاضع لـ} \ \mathbf{L} + \mathbf{S} = \mathbf{X},
\end{split}
\]</span>
<p>ونظراً للطبيعة غير المحدبة لرُتبة <span class="math inline">\(\mathbf{L}\)</span> وقاعدة الصفر لـ <span class="math inline">\(\mathbf{S}\)</span>، تصبح هذه المشكلة صعبة الحل عملياً (<span class="nodecor">scherl_robust_2019</span>). للتغلب على ذلك، يُستخدم الاسترخاء المحدب (<span class="nodecor">JMLR:v11:zhang10a</span>) الذي يحول المشكلة إلى:</p>
<span class="math display">\[
\begin{split}
& \underset{\mathbf{L}, \mathbf{S}}{\mathrm{تصغير}}\ \|\mathbf{L}\|_* + \lambda \|\mathbf{S}\|_1, \\
& \text{خاضع لـ} \ \mathbf{L} + \mathbf{S} = \mathbf{X},
\end{split}
\]</span>
<p>حيث يقرب تصغير القاعدة النووية <span class="math inline">\(\|\mathbf{L}\|_*\)</span> رتبة <span class="math inline">\(\mathbf{L}\)</span>، ويقرب تصغير قاعدة <span class="math inline">\(\|\mathbf{S}\|_1\)</span> قاعدة الصفر. تُعرف المشكلة الناتجة باسم «مطاردة المكونات الرئيسية» (PCP)، ويمكن حلها عبر خوارزمية مضاعف لاغرانج المعزَّز (<span class="nodecor">lin_augmented_2010</span>) الموضحة كالآتي:</p>
<span class="math display">\resizebox{.93\hsize}{!}{$
\mathcal{L}(\mathbf{L}, \mathbf{S}, \mathbf{\Lambda})=\|\mathbf{L}\|_* + \lambda \|\mathbf{S}\|_1+\langle \mathbf{\Lambda}, \mathbf{X} - \mathbf{L} - \mathbf{S} \rangle + \frac{\mu}{2}\|\mathbf{X}-\mathbf{L}-\mathbf{S}\|_{F}^2$}</span>
<p>حيث <span class="math inline">\(\mathbf{\Lambda}\)</span> هي مصفوفة مضاعفات لاغرانج و<span class="math inline">\(\mu\)</span> معامل. ثم يُحدَّث <span class="math inline">\(\mathbf{\Lambda}\)</span> عبر:</p>
<span class="math display">\[\mathbf{\Lambda}_{k+1} = \mathbf{\Lambda}_{k} + \mu(\mathbf{X}-\mathbf{L}_k-\mathbf{S}_k).\]</span>
<p>وبهذه الطريقة، يقوم RPCA بتحليل مصفوفة البيانات <span class="math inline">\(\mathbf{X}\)</span> إلى مكونات منخفضة الرتبة <span class="math inline">\(\mathbf{L}\)</span> ومتفرقة <span class="math inline">\(\mathbf{S}\)</span>.</p>
<h2 id="تحديد-مواقع-الاستشعار-الأمثل">تحديد مواقع الاستشعار الأمثل</h2>
<p>تحديد مواقع الاستشعار الأمثل هو أسلوب لاستخلاص أفضل المواقع داخل النظام لوضع المستشعرات. يهدف هذا النهج إلى تعظيم المعلومات المكتسبة (مثل الانتروبيا) مع تقليل عدد المستشعرات.</p>
<p>لتكن <span class="math inline">\(\boldsymbol{x} \in \mathbb{R}^n\)</span> نقطة بيانات في زمن معين، ويمكن تقريبها كما يلي:</p>
<span class="math display">\[\boldsymbol{x} \approx \mathbf{\Psi}_r \boldsymbol{a},\]</span>
<p>حيث <span class="math inline">\(\boldsymbol{a} \in \mathbb{R}^{r}\)</span> متجه المعاملات الزمني، وأعمدة <span class="math inline">\(\mathbf{\Psi}_r\)</span> هي الأوضاع الأرثوغونالية منخفضة الرتبة (حيث <span class="math inline">\(\mathbf{\Psi}_r = \mathbf{U}_r\)</span>). إذا اعتبرنا القياسات كالتالي:</p>
<span class="math display">\[\boldsymbol{y} = \mathbf{C}\boldsymbol{x},\]</span>
<p>حيث <span class="math inline">\(\mathbf{C}\in \mathbb{R}^{s\times n}\)</span> مصفوفة القياس المتناثرة و<span class="math inline">\(s\)</span> عدد المستشعرات، فإنها تقترب بـ:</p>
<span class="math display">\[\boldsymbol{y} \approx \mathbf{C}\mathbf{\Psi}_r \boldsymbol{a}.\]</span>
<p>إذا مثلنا <span class="math inline">\(\mathbf{\Theta} = \mathbf{C}\mathbf{\Psi}_r\)</span>، يمكن تقدير المعاملات عبر:</p>
<span class="math display">\[\boldsymbol{\hat{a}} = \mathbf{\Theta}^\dagger\boldsymbol{y}.\]</span>
<p>وبالتالي يعاد بناء النقطة كالتالي:</p>
<span class="math display">\[\boldsymbol{\hat{x}} = \mathbf{\Psi}_r\boldsymbol{\hat{a}} = \mathbf{\Psi}_r(\mathbf{C}\mathbf{\Psi}_r)^\dagger\boldsymbol{y}.\]</span>
<p>وبما أن <span class="math inline">\(\mathbf{\Psi}_r\)</span> معلوم من تحليل الأبعاد المنخفضة، يبقى <span class="math inline">\(\mathbf{C}\)</span> مجهولاً. وكما أوضح (<span class="nodecor">manohar_data-driven_2018</span>)، يُحدَّد OSP عبر تحليل QR بالتراجع العمودي على أوضاع <span class="math inline">\(\mathbf{\Psi}_r\)</span>، مع مراعاة شرط <span class="math inline">\(s \geq r\)</span>.</p>
<h1 id="المنهجية">المنهجية</h1>
<p>يصف هذا القسم سير عمل الإطار المقترح لمعالجة البيانات الضخمة، بدءاً من تنقية البيانات ثم ضغطها وصولاً إلى النمذجة المعتمدة على البيانات بكفاءة عالية. يقوم جوهر المنهجية على RPCA وOSP وشبكات LSTM.</p>
<h2 id="تنظيف-البيانات">تنظيف البيانات</h2>
<p>في خطوة تنقية البيانات، نستخدم RPCA كما عرضناه في القسم <a href="#sec:RPCA">sec:RPCA</a>. تم اختيار معاملات المزاوجة بحيث <span class="math inline">\(\lambda = 0.006\)</span> و<span class="math inline">\(\mu = 10^{-5}\)</span>. بعد تفكيك مصفوفة البيانات <span class="math inline">\(\mathbf{X}\)</span> إلى مصفوفتَي <span class="math inline">\(\mathbf{L}\)</span> (منخفضة الرتبة) و<span class="math inline">\(\mathbf{S}\)</span> (متفرقة)، نعيد بناء نسخة نظيفة من البيانات بالاعتماد على <span class="math inline">\(\mathbf{L}\)</span> التي تمثل الفيزياء الكامنة، بينما تُظهر <span class="math inline">\(\mathbf{S}\)</span> التشوهات والشوائب. وبذلك نحصل على بيانات صافية مناسبة للمراحل اللاحقة.</p>
<h2 id="ضغط-البيانات">ضغط البيانات</h2>
<p>لضغط البيانات مع الحفاظ على المعلومات الأساسية للنظام، نطبق خوارزمية OSP الموضحة في القسم <a href="#تحديد-مواقع-الاستشعار-الأمثل">تحديد مواقع الاستشعار الأمثل</a> على مصفوفة <span class="math inline">\(\mathbf{L}\)</span> الناتجة عن المرحلة السابقة. يقوم المبدأ الأساسي على اختيار مواقع حسّاسات تلتقط أكبر قدر من تباين البيانات، مما يسمح بتمثيل <span class="math inline">\(\mathbf{X}\)</span> بمجموعة أقل من القياسات <span class="math inline">\(\mathbf{Y}\)</span>، حيث تُكدس <span class="math inline">\boldsymbol{y}\)</span> في نافذة زمنية محددة. تمثل هذه المجموعة المضغوطة مصفوفة القياس النادرة <span class="math inline">\(\mathbf{C}\)</span>. بتقليل عدد الحساسات، نحد من التكاليف ومتطلبات التخزين دون المساس بدقة التمثيل.</p>
<h2 id="نمذجه-القياسات-المتناثرة-باستخدام-شبكات-lstm">نمذجة القياسات المتناثرة باستخدام شبكات LSTM</h2>
<p>في سياق النمذجة المعتمدة على البيانات، أثبتت الشبكات العصبية، ولا سيما LSTM، فعاليتها في العديد من التطبيقات. صُممت LSTM لتحمُّل المعلومات على مدى تسلسلات طويلة، مما يجعلها مثالية لمعالجة بيانات السلاسل الزمنية. غير أن تطبيقها مباشرة على البيانات الضخمة قد يكون مكلفاً حسابياً، لذا نطبق LSTM على مجموعة فرعية منخفضة الأبعاد <span class="math inline">\(\mathbf{Y}\)</span> المستخرجة من خلال OSP.</p>
<p>يسهم دمج LSTM مع OSP في خفض العبء الحسابي للتدريب بشكل كبير. عند استخدام LSTM لنمذجة هذه القياسات المختارة، نستهدف التقاط الديناميكيات الزمنية الكامنة. وبعد تدريب الشبكات، يمكنها التنبؤ بقيم القياسات المتناثرة، ومن ثم إعادة بناء البيانات بالحجم الكامل باستخدام المعادلة <span class="math inline">(\ref{eq:OSP_reconstruction})</span>. يتيح ذلك إعادة تخطيط الأبعاد الأصلية للبيانات. تجدر الإشارة إلى أنه عند أخذ العينات بتردد غير منتظم، يمكن لمرحلة الاستيفاء المسبق أن تحسّن دقة النماذج.</p>
<h2 id="تدفق-البيانات-الضخمة">تدفق البيانات الضخمة</h2>
<p>يسمح نهج التكامل السابق بتدفق عمل متسق لمعالجة البيانات الضخمة، يتكون من المراحل التالية:</p>
<ol>
<li><p><strong>تنقية البيانات:</strong> يولد RPCA نسخةً نظيفة <span class="math inline">\(\mathbf{L}\)</span> من مصفوفة البيانات <span class="math inline">\(\mathbf{X}\)</span>. بما أن <span class="math inline">\(\mathbf{L}\)</span> يحتفظ بالديناميكيات الأساسية للنظام، يمكن نقله إلى المراحل التالية من المعالجة والتحليل.</p></li>
<li><p><strong>ضغط البيانات:</strong> تمكن خوارزمية OSP من ضغط مكثف لمصفوفة البيانات النظيفة <span class="math inline">\(\mathbf{L}\)</span>. من خلال حساب أوضاع <span class="math inline">\(\mathbf{\Psi}_r\)</span> وإيجاد مصفوفة القياس النادرة <span class="math inline">\(\mathbf{C}\)</span>، تصبح مجموعة فرعية صغيرة <span class="math inline">\(\mathbf{Y}\)</span> كافية لتمثيل البيانات. يجب تخزين <span class="math inline">\(\mathbf{\Psi}_r\)</span> و<span class="math inline">\(\mathbf{C}\)</span> لإعادة البناء لاحقاً إلى <span class="math inline">\(\boldsymbol{\hat{x}}\)</span>.</p></li>
<li><p><strong>النمذجة المعتمدة على البيانات:</strong> نُنشئ نماذج LSTM للمجموعة الفرعية المنقولة <span class="math inline">\(\mathbf{Y}\)</span>. بعد التنبؤ بالمجموعة الفرعية المستقبلية، يُعاد بناء التنبؤ للأبعاد الأصلية <span class="math inline">\(\mathbf{\hat{X}_{pred}}\)</span> باستخدام <span class="math inline">\(\mathbf{\Psi}_r\)</span> و<span class="math inline">\(\mathbf{C}\)</span>.</p></li>
</ol>
<h1 id="إعداد-المحاكاة">إعداد المحاكاة</h1>
<p>اعتمدنا في هذه الدراسة على بياناتٍ حرارية تم الحصول عليها من كاميرا تصوير حراري لرصد محرك عبّارة، وزودت بها شركة Idletechs AS. ونظراً إلى صلاحية البيانات وخلوها من شوائب كبيرة، أضفنا اضطرابات اصطناعية وفقاً للسيناريوهات التالية، كما نصف إعداد شبكة LSTM المستخدمة.</p>
<h2 id="البيانات">البيانات</h2>
<p>سُحبت مجموعة البيانات من صور كاميرا حرارية لمحرك عبّارة، بهدف مراقبة السلوك الحراري خلال مراحل الإقلاع والتشغيل المستقر والتوقف. استمر جمع البيانات على مدار أربعة أيام متتالية، حيث جُمعت نحو 24 ساعة من المراقبة بمعدل أخذ عينات يقارب نصف ثانية بين القيم. تحتوي كل صورة على <span class="nodecor">19,200</span> بكسل (120×160)، يلتقط كل بكسل الإشعاعات الحرارية الصادرة عن المحرك، مما يوفر مؤشراً على الأداء الحراري وأي بقع ساخنة محتملة.</p>
<h2 id="Section: Perturbations">الاضطرابات</h2>
<p>لتقييم خوارزمياتنا تحت ظروف متباينة، نفذنا أربعة سيناريوهات محاكاة تشمل الضوضاء والشذوذ والتلوث ومزيجاً منها.</p>
<h3 id="السيناريو-1" class="unnumbered">السيناريو 1</h3>
<p>تم تعكير البيانات بضوضاء غاوسية، حيث وُلدت الضوضاء بمتوسط <span class="nodecor">0</span> وانحراف معياري <span class="nodecor">4</span>، مما يضمن اقتصار معظم القيم ضمن النطاق <span class="nodecor">[-4, 4]</span>.</p>
<h3 id="السيناريو-2" class="unnumbered">السيناريو 2</h3>
<p>تم تعكير البيانات بشذوذ، عبر اختيار عشوائي لـ <span class="nodecor">100</span> نقطة بيانات (بكسل) واستبدال قيمها الأصلية بقيم عشوائية ضمن النطاقين <span class="nodecor">[30, 40]</span> و<span class="nodecor">[-40, -30]</span> لمحاكاة شذوذ كبير في القياسات.</p>
<h3 id="السيناريو-3" class="unnumbered">السيناريو 3</h3>
<p>تم تعكير البيانات بتلوث عشوائي، حيث أضيفت ضوضاء موزعة بالتساوي إلى <span class="nodecor">10%</span> من عينات البيانات ضمن الفترة <span class="nodecor">[-15, 30]</span> لاختبار متانة خوارزميات PCA وRPCA وOSP.</p>
<h3 id="السيناريو-4" class="unnumbered">السيناريو 4</h3>
<p>تم تعكير البيانات بمزيج من السيناريوهات السابقة (1 و2 و3)، مما أدى إلى تراكب أنواع الضوضاء والشذوذ والتلوث.</p>
<h2 id="هندسة-شبكة-الذاكرة-طويلة-الأمد">هندسة شبكة الذاكرة طويلة الأمد</h2>
<p>لاختيار إعدادات شبكة LSTM، جربنا عدة توليفات للمعاملات، وأخيراً اعتمدنا القيم الموضحة في الجدول <span class="nodecor">[tab:LSTM_parameters]</span>. دربنا الشبكة باستخدام مُحسّن آدم مع معيار الجذر التربيعي للخطأ المتوسط لتقييم الأداء. للتنبؤ، استخدمنا نافذة تاريخية تتألف من <span class="nodecor">50</span> عينة واخترنا <span class="nodecor">100</span> خطوة زمنية للتنبؤ. تتكوّن بنية الشبكة من طبقة إدخال، وطبقة LSTM، وطبقة كثيفة أمامية، وطبقة إخراج. ولتفادي الإفراط في التخصيص، أضفنا طبقة إسقاط (dropout)، وهي تقنية تحذف بشكل عشوائي بعض الوحدات والروابط خلال التدريب (<span class="nodecor">nitish_srivastava_geoffrey_hinton_alex_krizhevsky_ilya_sutskever_and_ruslan_salakhutdinov_dropout_2014</span>).</p>
<h1 id="النتائج-والمناقشة">النتائج والمناقشة</h1>
<p>في ما يلي، نناقش نتائج مراحل التنقية والضغط والنمذجة المعتمدة على البيانات لكل سيناريو من السيناريوهات الأربعة.</p>
<h2 id="تنظيف-البيانات-1">تنقية البيانات</h2>
<p>تعرض نتائج تنقية البيانات لكل سيناريو من السيناريوهات المذكورة في القسم «الاضطرابات». تظهر مقارنة بين إعادة البناء باستخدام RPCA وPCA أن RPCA يفصل مصفوفة <span class="math inline">\(\mathbf{L}\)</span> التي تمثل الصورة النظيفة عن مصفوفة <span class="math inline">\(\mathbf{S}\)</span> التي تجمع التشوهات والشوائب. بينما تعاني PCA التقليدي من تأثير القيم الشاذة بوضوح، يحافظ RPCA على بنية الصورة الأساسية مع إزالة الشوائب، ما يعزز دقة تطبيقات الذكاء الاصطناعي المعتمدة على البيانات الضخمة.</p>
<h2 id="ضغط-البيانات-1">ضغط البيانات</h2>
<p>أظهر تطبيق OSP على بيانات الصور الحرارية تخفيضاً كبيراً في الأبعاد، حيث استخدمنا فقط <span class="nodecor">10</span> من أصل <span class="nodecor">19200</span> قياس بكسل. ورغم هذا الانخفاض الكبير، أمكن إعادة بناء الصور الأصلية بدقة ملحوظة. من منظور ضغط البيانات، يبرز دور OSP في خفض استهلاك الطاقة ومتطلبات الذاكرة؛ فباستخدام مجموعة صغيرة من القياسات نستطيع تمثيل البيانات الكاملة بفقدان معلوماتي ضئيل.</p>
<p>يمثل توفير الذاكرة بالنسبة للبيانات المضغوطة المعادلة التالية:</p>
<span class="math display">\[\alpha = \frac{m}{r}.\]</span>
<p>في هذه الدراسة التجريبية، نحصل على <span class="math display">\(\alpha = \frac{19200}{10} = 1920\)</span>، ما يعني أنه يمكننا تخزين 1920 مرة أكثر من الصور الحرارية بنفس سعة الذاكرة.</p>
<h2 id="نمذجه-تنبؤيه-معتمدة-على-البيانات">نمذجة تنبؤية معتمدة على البيانات</h2>
<p>دربنا شبكة <span class="nodecor">LSTM</span> على الفضاء الفرعي المتناثر <span class="math inline">\(\mathbf{Y}\)</span> المستخلص عبر OSP، مع استيفاء البيانات المسبق لمعالجة التردد غير المنتظم للعينات. لنبين أثر الاستيفاء، عرضنا قيم <span class="nodecor">RMSE</span> للنماذج مع وبدون استيفاء أولي، إضافةً إلى مقارنة زمن التدريب. تكشف النتائج عن انخفاض ملموس في الخطأ وتوفير كبير في الزمن الحسابي باستخدام النهج المقترح. تؤكد هذه السرعة المحسنة إمكانية التطبيق الفوري والتدريب عبر الإنترنت في الزمن الحقيقي، اعتماداً على عدد العصور والمعايير المختارة.</p>
<h1 id="الخلاصة">الخلاصة</h1>
<p>في الختام، يعزز تطبيق RPCA جودة بيانات الصور الحرارية بشكل ملحوظ، مما يتيح تحليلات لاحقة أكثر موثوقية. وبفضل متانته وقابليته للتوسع، يصلح هذا الإطار لمجموعة واسعة من التطبيقات المتعلقة بالبيانات الضخمة. كما يقدم OSP وسيلة فعالة لتعظيم كفاءة التخزين وضغط البيانات في البيئات ذات القيود الصارمة. وعن طريق تطبيق شبكات LSTM على فضاء منخفض الأبعاد مشتق من OSP، نحصل على كفاءة حسابية محسنة ودقة تنبؤية عالية. يعمل هذا التكامل بين التقنيات المقدمة على رفع مستويات جودة البيانات والكفاءة الحسابية والذاكرة إضافةً إلى تمكين التنبؤات في الزمن الحقيقي.</p>
</body>
</html>