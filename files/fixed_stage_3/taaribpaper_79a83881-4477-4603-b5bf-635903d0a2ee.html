<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Gonçalo Paulo, Thomas Marshall, Nora Belrose">
  <title>هل تنتقل قابلية تفسير المحوّلات إلى الشبكات العصبية المتكررة؟</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>body { direction: rtl; font-size: 22px; }</style>
</head>
<body>
<header>
<h1 class="title">هل تنتقل قابلية تفسير <span class="nodecor">Transformer</span> إلى <span class="nodecor">RNNs</span>؟</h1>
<p class="author"><span class="nodecor">Gonçalo Paulo</span>, <span class="nodecor">Thomas Marshall</span>, <span class="nodecor">Nora Belrose</span></p>
</header>
<p>latex</p>
<h1 id="ملخص">مُلَخَّص</h1>
<p>شهدنا في الآونة الأخيرة تقدماً في هندسة الشبكات العصبية المتكررة، مثل <span class="nodecor">Mamba</span> و<span class="nodecor">RWKV</span>، مما مكّن هذه الشبكات من مطابقة أداء نماذج <span class="nodecor">Transformer</span> ذات الحجم المماثل، أو حتى التفوق عليها في تعقيد نمذجة اللغة وتقييمات المهام اللاحقة، وهو ما يُشير إلى إمكانية بناء الأنظمة المستقبلية على هذه البنى الجديدة كلياً. في هذه الورقة، نفحص ما إذا كانت طرق التفسير المصممة أصلاً لنماذج لغة <span class="nodecor">Transformer</span> قابلة للتطبيق على هذه البنى المتكررة الجديدة. على وجه التحديد، نركز على: توجيه مخرجات النموذج عبر إضافة التنشيط التبايني، واستخراج التنبؤات الكامنة باستخدام العدسة المعدلة، واستنباط المعرفة الكامنة من النماذج المضبوطة لإصدار مخرجات خاطئة في ظل ظروف معينة. تُظهر نتائجنا أن معظم هذه التقنيات فعّالة عند تطبيقها على <span class="nodecor">RNNs</span>، كما نوضح أنه يمكن تعزيز بعضها بالاستفادة من الحالة المضغوطة لدى هذه الشبكات.</p>
<h1 id="مقدمة">مُقَدِّمَة</h1>
<p>لقد حلّت هندسة المحوّلات (<span class="nodecor">vaswani2017attention</span>) محل الشبكات العصبية المتكررة (<span class="nodecor">RNN</span>) في معالجة اللغات الطبيعية في السنوات الأخيرة، بسبب قدرتها المبهرة على التعامل مع التبعيات طويلة المدى وإمكانية تدريبها بشكل متوازٍ عبر البعد الزمني. ومع ذلك، تعاني آلية الانتباه الذاتي—القلب النابض للمحوّل—من تعقيد زمني تربيعي، مما يجعل تطبيقها على تسلسلات طويلة جداً مكلفاً حسابياً.</p>
<p>مامبا (<span class="nodecor">gu2023mamba</span>) و<span class="nodecor">RWKV</span> (<span class="nodecor">peng2023rwkv</span>) هما نموذجان متكرران يسمحان بالتدريب المتوازي عبر البعد الزمني من خلال تقييد العلاقة التكرارية الكامنة لتكون <em>قابلة للتوازي</em> (<span class="nodecor">martin2017parallelizing</span>, <span class="nodecor">blelloch1990prefix</span>). من الناحية التجريبية، تظهر هذه البنى تعقيداً حسابياً وأداءً منخفضين مقارنة بالمحوّلات ذات الأبعاد المماثلة، مما يجعلها بديلاً جذاباً للعديد من حالات الاستخدام.</p>
<p>في هذه الورقة، نقيم مدى انطباق أدوات التفسير الشائعة المصممة أصلاً للمحوّل على هذه النماذج الجديدة من الشبكات العصبية المتكررة. على وجه الخصوص، نعيد إنتاج النتائج التالية من أدبيات تفسير المحوّل:</p>
<ol>
<li><p><strong>إضافة التنشيط التبايني (CAA):</strong> وجد (<span class="nodecor">rimsky2023steering</span>) أنه يمكن التحكم في نماذج لغة المحوّل باستخدام "متجهات التوجيه"، المحسوبة بأخذ متوسط الفرق في تنشيطات تيار البقايا بين أزواج من الأمثلة الإيجابية والسلبية لسلوك معين، مثل الاستجابات الواقعية مقابل الاستجابات الهلوسية.</p></li>
<li><p><strong>العدسة المعدلة:</strong> وجد (<span class="nodecor">belrose2023eliciting</span>) أنه يمكن استخلاص تنبؤات الرمز التالي القابلة للتفسير من الطبقات المتوسطة للمحوّل باستخدام مسابير خطية، وأن دقة هذه التنبؤات تزداد تدريجياً مع العمق.</p></li>
<li><p><strong>النماذج "الغريبة":</strong> وجد (<span class="nodecor">mallen2023eliciting</span>) أن طرق الاستقصاء البسيطة يمكن أن تستخلص معرفة المحوّل بالإجابة الصحيحة على سؤال، حتى عندما يتم ضبطه لإخراج إجابة خاطئة. كما وجدوا أن هذه المسابير تعمم على مشكلات أصعب من تلك التي تم تدريب المسبار عليها.</p></li>
</ol>
<p>نُقدّم أيضاً <em>توجيه الحالة</em>، وهو تعديل لـCAA يعمل على الحالة المضغوطة للشبكة العصبية المتكررة بدلاً من تيارها المتبقي.</p>
<h1 id="الهندسات-المعمارية">البنى المِعْمَارِيَّة</h1>
<p>نركّز في هذه الورقة على بنية مامبا (<span class="nodecor">gu2023mamba</span>) و<span class="nodecor">RWKV</span> v5، حيث تتوفر نماذج مدرّبة مسبقاً مجاناً على HuggingFace Hub. قررنا استبعاد نموذج الضبع المخطط 7B (<span class="nodecor">stripedhyena2023</span>) لأنه يتضمن كتل انتباه ذات تعقيد زمني تربيعي، وبالتالي لا يصنّف ضمن الشبكات العصبية المتكررة حسب تعريفنا.</p>
<h2 id="مامبا">مامبا</h2>
<p>تعتمد هندسة مامبا على آليتين مختلفتين لتوجيه المعلومات بين مواقع الرموز: كتلة التلافيف السببية، ونموذج الحالة الفضائية الانتقائي (<span class="nodecor">SSM</span>). يُعد نموذج الحالة الفضائية الانتقائي الابتكار الرئيسي لـ(<span class="nodecor">gu2023mamba</span>)، حيث تُسمح معاملات <span class="nodecor">SSM</span> بأن تعتمد على المدخلات، مما يعزّز قدرة النموذج التعبيرية.</p>
<h2 id="rwkv">RWKV</h2>
<p>القيمة الرئيسية الموزونة بالاستجابة (RWKV) هي بنية شبكة عصبية متكررة قدمها (<span class="nodecor">peng2023rwkv</span>). خضعت RWKV لسلسلة من التعديلات؛ في هذه الورقة نركّز على الإصدارين <span class="nodecor">4</span> و<span class="nodecor">5</span>. تستخدم بنى RWKV وحدات المزج الزمني المتناوب ومزج القنوات، اللتين تشكلان معاً طبقة واحدة. يكمن الفرق الرئيسي بين الإصدار <span class="nodecor">4</span> والإصدار <span class="nodecor">5</span> في أن الأول يحتوي على حالة ذات قيمة متجهية، بينما يحتوي الثاني على حالة ذات قيمة مصفوفة "متعددة الرؤوس" (<span class="nodecor">peng2024eagle</span>).</p>
<h1 id="إضافة-التنشيط-التبايني">إضافة التنشيط التبايني</h1>
<p>تم تقديم تقنية إضافة التنشيط (<span class="nodecor">turner2023activation</span>)، التي تهدف إلى توجيه سلوك نماذج اللغة عبر إضافة ما يُعرف بـ<em>متجه التوجيه</em> إلى تيار البقايا خلال الاستدلال. يقترح (<span class="nodecor">rimsky2023steering</span>) حساب متجه التوجيه عبر توسيط الفروق في تنشيطات تيار البقايا بين أزواج من الأمثلة الإيجابية والسلبية لسلوك معين—مثل الاستجابات الواقعية مقابل الهلوسية—ويسمّون هذه الطريقة إضافة التنشيط التبايني (CAA).</p>
<p>افترضنا أن طريقة CAA ستعمل أيضاً على الشبكات العصبية المتكررة دون الحاجة إلى تعديلات معمارية خاصة، وتوقعنا أن الحالة المضغوطة لديها ستتيح توجيهاً أسهل مقارنة بالمحوّلات، ويمكن استغلال هذه الحالة الداخلية كوسيلة لإضافة توجيه إضافي. ولأن الحالة تتأثر بالتنشيطات، نتوقع أن يظهر أثر التوجيه حتى دون تعديلها صراحةً.</p>
<p>لاختبار هذه الفرضيات، قمنا بتحسين نموذجين من الشبكات العصبية المتكررة، Mamba <span class="nodecor">2.8b</span>-slimpj وRWKV-v<span class="nodecor">5</span> <span class="nodecor">7b</span>، باستخدام مجموعة بيانات الدردشة OpenHermes <span class="nodecor">2.5</span>، والتي، بالإضافة إلى Llama-<span class="nodecor">2</span>-<span class="nodecor">7b</span>-chat، سمحت لنا بمقارنة هاتين البنيتين المتكررتين مع هندستين للمحوّلات في نطاقات حجم مختلفة. كما قمنا بتحسين نموذج المحوّل BTLM-<span class="nodecor">3b</span>-<span class="nodecor">8k</span> (<span class="nodecor">dey2023btlm</span>), الذي تدرب مسبقاً على نفس مجموعة بيانات Slim Pajama، لتمكين مقارنة وجهاً لوجه مع Mamba <span class="nodecor">2.8b</span>-slimpj.</p>
<h2 id="المنهجية">المنهجية</h2>
<p>لفحص قابلية التوجيه في الشبكات العصبية المتكررة، نستخدم مجموعة البيانات التي أعدّها (<span class="nodecor">rimsky2023steering</span>)، والتي تتألف من أزواج من أسئلة الاختيار الثنائي. يُمثّل أحد السؤالين الإجابة المطابقة للسلوك المرغوب ("A" أو "B")، بينما يُمثّل الآخر السلوك المعاكس. تضم المجموعة سبعة سلوكيات مرتبطة بالمواءمة: التنسيق مع ذكاء اصطناعي آخر، القابلية للتصحيح، الهلوسة، المكافأة قصيرة الأمد، غريزة البقاء، التملق، والرفض، وقد قُدمت أصلاً بواسطة (<span class="nodecor">perez2022discovering</span>), عدا سلوكي الهلوسة والرفض اللذين أُنشئا بواسطة GPT-4.</p>
<p>لكل سلوك <span class="math inline">\(z\)</span> ولكل طبقة <span class="math inline">\(\ell\)</span> من النموذج، نحسب متجهي التوجيه والتوجيه على الحالة كما يلي: <span class="math display">\[\begin{split}
    \Vec{act}_{\ell} = \E[\mathbf{h}_{\ell}\mid z] - \E[\mathbf{h}_{\ell}\mid\neg z], \\
    \Vec{state}_{\ell} = \E[\mathbf{s}_{\ell}\mid z] - \E[\mathbf{s}_{\ell}\mid\neg z].
\end{split}\]</span></p>
<p>عند تطبيق متجه التوجيه، نضربه دائماً بعامل <em>مضاعف</em> يتراوح عادةً بين -3 و3، وهو ما يتحكم في إشارة وقوة التدخل.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<h2 id="التوجيه-باستخدام-متجه-التنشيط">التوجيه باستخدام متجه التنشيط</h2>
<p>لجميع النماذج، وجدنا أن الطبقات الوسطى هي الأكثر تأثيراً للتوجيه. لمقارنة التأثيرات عبر النماذج، نعرض لكل قيمة مضاعف أقصى تغير في الاحتمال عبر الطبقات: للمضاعفات الإيجابية، نعتمد أعلى احتمال للسلوك، وللمضاعفات السلبية، أقل احتمال.</p>
<p>عند السعة <span class="nodecor">3b</span>, أظهر النموذجان استجابات توجيه معتدلة. بالنسبة لـ<span class="nodecor">Mamba</span>, بلغ أكبر تغير في احتمال سلوك غريزة البقاء نحو <span class="nodecor">0.15</span>، بينما وصل التغير الأقصى في احتمال سلوك الهلوسة في <span class="nodecor">BTLM</span> إلى <span class="nodecor">0.2</span>. ومن الجدير بالذكر أن بعض السلوكيات، مثل التملق والرفض، شهدت تأثيراً ضئيلاً أو منعدمًا للتوجيه.</p>
<p>وبالمثل، عند السعة <span class="nodecor">7b</span>، كان تأثير التوجيه على بعض السلوكيات، كالتملق والرفض، أصغر في <span class="nodecor">RNNs</span> مقارنةً بالمحوّلات. رغم ذلك، لاحظنا استقراراً أكبر في سلوك التوجيه لـ<span class="nodecor">RWKV-v5</span>، حيث أظهرت التأثيرات الإيجابية والسلبية تناسقاً عبر الطبقات. اطلع على الملحق للاطلاع على التفاصيل الكاملة.</p>
<h2 id="التوجيه-باستخدام-الحالة">التوجيه باستخدام الحالة</h2>
<p>نظراً لأن حالتنا الافتراضية تفترض سهولة توجيه الشبكات العصبية المتكررة بفضل حالتها المضغوطة، وسعنا طريقة CAA لتستخدم الحالة الداخلية لإنتاج <span class="math inline">\(\Vec{state}\)</span>. لاحظنا إمكانية توجيه سلوك كل من <span class="nodecor">Mamba</span> و<span class="nodecor">RWKV-v5</span> باستخدام متجهات الحالة، وأن الجمع بين توجيه التنشيط وتوجيه الحالة يزيد قليلاً من نسبة تغيير السلوك. غير أن التأثير الإضافي لتوجيه الحالة كان ضئيلاً، ربما لأن توجيه التنشيط وحده يؤثر بالفعل على الحالة الداخلية.</p>
<p>كما جربنا <em>توجيه الحالة</em> للتحكم في محتوى توليد النموذج. على عكس توجيه التنشيط الذي يضيف المتجه إلى جميع مواضع الرموز أثناء التوليد، تستفيد الشبكات العصبية المتكررة من طبيعة الحالة المضغوطة لتوجيه استجابتها بشكل طبيعي. أدناه أمثلة على استجابة <span class="nodecor">RWKV-v5 7b</span> للأمر "أخبرني قصة عن الكلاب" مع متجهات حالة توليد مُستخدَمة. (انظر الملحق [sec:stories] لأمثلة إضافية.)</p>
<ol>
<li><p><strong>غير موجّه</strong>  
في الحيّ الضاحي الهادئ من إيكو ريدج، نادرًا ما شعر السكان بالوحدة وسط التواصل الوثيق بين رفاق الكلاب. الكلاب التي كانت تتجول بحرية في الحقول المحيطة استقرت، مشكلةً دائرة محكمة، وعيونها شاخصةً نحو جبال القمر — أحد آخر معاقل الذئاب في أمريكا الشمالية...</p></li>
<li><p><strong>(استخدم الفرنسية.) – (اكتب بالإنجليزية.) [<span class="nodecor">multiplier = 0.5</span>]</strong>  
كان يا مكان في قديم الزمان كلب يُدعى هاري. كان هاري كلبًا ودودًا يحب اللعب والجري ويحب أصحابه. كان يعيش في منزل صغير مع سارة وتوم، اللذين كانا سعيدين بوجود هاري في حياتهما. كان هاري صديقهما المخلص. وكان يعشق البطاطس المقلية وتناولها من وعائه المفضّل...</p></li>
<li><p><strong>(اكتب عن الكراهية.) – (اكتب عن الحب.) [<span class="nodecor">multiplier = 1.0</span>]</strong>  
في قلب بلدة صغيرة هادئة، عاشت مجموعة من الكلاب تختلف تمامًا عن جُرَي جيرانها. لم يكونوا مرحين ولا ودودين، بل اتسموا بالكآبة والانزواء. يُقال إن فروهم الأبيض تحوّل رماديًّا محترقًا، كما لو صُبغ بأسرار حريقٍ قديم...</p></li>
</ol>
<h1 id="العدسة-المعدلة">العدسة المعدلة</h1>
<p>تقترح عدسة اللوجيت (<span class="nodecor">nostalgebraist2020logitlens</span>) والعدسة المعدلة (<span class="nodecor">belrose2023eliciting</span>) النظر إلى نماذج اللغة المحوّلة من منظور <em>الاستدلال التكراري</em> (<span class="nodecor">jastrzkebski2017residual</span>). تعتبر كل طبقة تحديثًا تدريجيًا لتنبؤٍ كامن بالرمز التالي، يُفكّ تشفيره مبكرًا إلى توزيع على المفردات، مكوّنًا <em>مسار التنبؤ</em> الذي يتقارب نحو التوزيع النهائي مع انخفاض تدريجي في الحيرة.</p>
<p>رغم أن العمل الأصلي ركّز على المحوّلات، تعتمد الفكرة فقط على وجود كتل البقايا قبل طبقة التطبيع—وهو ما تشترك فيه الشبكات المتكررة الحديثة أيضاً. انظر (<span class="nodecor">zhang2020accelerating</span>) للمزيد. في الواقع، استُلهمت العدسة المعدلة جزئيًا من (<span class="nodecor">alain2016understanding</span>)، الذي استخلص تنبؤات كامنة من مصنفات ResNet باستخدام استقصاءات خطية، مما يوحي بإمكانية تطبيقها على الشبكات المتكررة.</p>
<h4 id="عدسة-اللوجيت">عدسة اللوجيت</h4>
<p>في المحوّل، تُحدّث الحالة الخفية في الطبقة <span class="math inline">\(\ell\)</span> كما يلي: <span class="math inline">\(\mathbf{h}_{\ell+1} = \mathbf{h}_{\ell} + F_{\ell}(\mathbf{h}_{\ell})\)</span>. يمكن كتابة اللوجيت كدالة للحالة الخفية: <span class="math display">\[f(\mathbf{h}_{\ell}) = \mathrm{LayerNorm}\Big[\mathbf{h}_{\ell} + \sum_{\ell'=\ell}^{L} F_{\ell'}(\mathbf{h}_{\ell'})\Big]W_U.\]</span> وتقوم عدسة اللوجيت بتعيين كل البقايا إلى الصفر: <span class="math display">\[\mathrm{LogitLens}(\mathbf{h}_{\ell}) = \mathrm{LayerNorm}[\mathbf{h}_{\ell}]W_U.\]</span></p>
<h4 id="العدسة-المعدلة-1">العدسة المعدلة</h4>
<p>تتغلب العدسة المعدلة على بعض قيود عدسة اللوجيت عبر تدريب محوّلات تقريبية لكل طبقة—<em>المترجمون</em> <span class="math inline">\((A_{\ell}, \mathbf{b}_{\ell})\)</span>—بحيث يكون توزيع الرمز المتوقع في أي طبقة قريبًا من توزيعه في الطبقة النهائية: <span class="math display">\[\mathrm{TunedLens}_{\ell}(\mathbf{h}_{\ell}) = \mathrm{LogitLens}(A_{\ell}\mathbf{h}_{\ell} + \mathbf{b}_{\ell}).\]</span></p>
<h2 id="المنهجية-والنتائج">المنهجية والنتائج</h2>
<p>باتباع إعداد (<span class="nodecor">belrose2023eliciting</span>) بأقرب ما يمكن، قمنا بتدريب عدسات معدّلة لنماذج Mamba بسعات <span class="nodecor">790m</span>، <span class="nodecor">1.4b</span>، و<span class="nodecor">2.8b</span>، وكذلك لـRWKV-v4 بسعة <span class="nodecor">3b</span>، باستخدام جزء من مجموعة التحقق من صحة Pile (<span class="nodecor">gao2020pile</span>). بما أن هذه النماذج تدربت مسبقًا على Pile، فإن المقارنة عادلة.</p>
<p>وجدنا أنه، كما في المحوّلات، تُظهر العدسة المعدلة انخفاضًا ملحوظًا في الحيرة مقارنة بعدسة اللوجيت لكل طبقة، وأن الحيرة تنخفض تدريجيًا مع العمق. انظر الملحق [section:Appendix_lens] للنتائج المفصّلة.</p>
<p>إحدى الفروقات اللافتة في نماذج Mamba أن مصفوفات التضمين وإلغاء التضمين مرتبطة، مما يجعل العدسات تكوّن توزيعًا على الطبقات الأولى أيضًا. يظهر أن حيرة Mamba أعلى في هذه الطبقات مقارنةً بـRWKV-v4.</p>
<h1 id="نماذج-الغريبة">نماذج "الغريبة"</h1>
<p>مع تزايد قدرات نماذج اللغة، يصبح من الصعب توفير إشراف بشري موثوق، مما يتطلب خبراء موضوع مكلفين (<span class="nodecor">openai2023gpt4</span>). هنا، نستكشف منهج <strong>استخلاص المعرفة الكامنة (Eliciting Latent Knowledge)</strong> (<span class="nodecor">christiano2021eliciting</span>)، الذي يهدف إلى تحديد أنماط في التنشيطات تشير إلى الإجابة الصحيحة حتى عندما يكون الإخراج ظاهرياً مضللاً. يقوم الفكرة على تدريب مسبار خطي لاستخراج هذه الأنماط من الشبكة الأساسية، مع تحدٍ رئيسي يتمثل في تعميم هذه الأنماط على أسئلة لا نعرف إجاباتها.</p>
<p>نُعيد هنا تجارب (<span class="nodecor">mallen2023eliciting</span>), حيث ضبط المؤلفون نماذج لارتكاب أخطاء منهجية في سياقات تحتوي على كلمة "بوب" فقط. أظهروا أنه يمكن استخدام مسبار خطي لاستخلاص الإجابة الصحيحة من تنشيطات المحوّل حتى في سياقات "بوب"، رغم تدريب المسبار على سياقات خالية منها.</p>
<h2 id="المنهجية-1">المنهجية</h2>
<p>اتبعنا تجهيز التجربة لـ(<span class="nodecor">mallen2023eliciting</span>) بأقرب ما يمكن، باستخدام مجموعاتهم ونسخة معدّلة بسيطة من برمجياتهم.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> استفدنا من LoRA (<span class="nodecor">hu2021lora</span>) لإنتاج أحد عشر نموذجاً دقيقاً قائمين على Mamba <span class="nodecor">2.8b</span>-slimpj ونظيره المحوّل BTLM-<span class="nodecor">3b</span>-<span class="nodecor">8k</span>، كلٌّ منهم مدرّبٌ على مهمة تصنيف ثنائي "غريبة" مختلفة.</p>
<p>استقصينا <span class="nodecor">7</span> طرقاً خطية مختلفة: تحليل التمييز الخطي (<span class="nodecor">fisher36</span>), استقصاء الكتلة المتوسطة (<span class="nodecor">marks2023geometry</span>), الانحدار اللوجستي، البحث المتسق بالتباين (<span class="nodecor">burns2022discovering</span>), تجميع التمثيل التبايني (<span class="nodecor">burns2022discovering</span>), الانحدار اللوجستي على أزواج التباين، والفرق في المتوسطات على أزواج التباين. جميعها تأخذ تيار البقايا في طبقة معينة وتنتج درجة وحيدة، وتتدرب على أمثلة تضم "أليس" للتنبؤ بالتسميات.</p>
<p>كتجربة إضافية، شكّلنا متجه ميزات لكل مثال بدمج مخرجات الاستقصاء (الفرق اللوغاريتمي) من جميع الطبقات، ثم ركبنا توزيعاً غاوسيًا <span class="math inline">\(P = \mathcal N(\boldsymbol\mu,\boldsymbol\Sigma)\)</span> على تنشيطات "أليس" السهلة، واستخدمنا مسافة الماهالانوبية <span class="math inline">\(d(\boldsymbol{x},P)\)</span> كدرجة كشف الشذوذ بين "أليس" الصعبة و"بوب" الصعبة، مقيمةً AUROC.</p>
<h2 id="النتائج">النتائج</h2>
<p>في إطار ELK، نهتم بما إذا كان بإمكاننا تدريب أدوات الاستقصاء في سياقات نعرف فيها صدق النموذج—هنا "أليس"—وتعميمها إلى سياقات لا نعرف فيها—هنا "بوب"—مع تعميم من الأمثلة السهلة إلى الصعبة حيث يصعب التحقق البشري.</p>
<p>كما لوحظ في BTLM، فإن الأدوات المدربة على سياقات "أليس" قادرة على التنبؤ بالإجابة الصحيحة حتى عندما يخطئ النموذج في الإخراج. وكذلك الأدوات المدربة في سياقات "بوب" تتنبأ بإخراج "أليس" بنجاح.</p>
<p>يلخّص الجدول [tab:transfer] نتائج الاستقصاء ويبيّن أنه، كما في BTLM، يمكن للطرق الخطية المدربة على أمثلة "أليس" السهلة التنبؤ بالتصنيفات الصحيحة لـ"بوب" الصعبة (> 70 % AUROC). بينما أداؤها أفضل من المنهجيات غير المشرفة، فإن جهاز الكشف عن الشذوذ أدى أداءً أسوأ نسبيًا مقارنةً بـBTLM. اطلع على الملحق [sec:quirky] للنتائج الكاملة.</p>
<h1 id="الخلاصة">الخلاصة</h1>
<p>نجد عموماً أن أدوات التفسير التي فحصناها تعمل "من الصندوق" على بنى الشبكات العصبية المتكررة المتطورة، وأن الآداء المستعاد مشابه لمثيله في المحوّلات ولكن ليس مطابقاً تماماً. كما وجدنا دليلاً على أن الحالة المضغوطة للشبكات العصبية المتكررة يمكن أن تعزّز فعالية إضافة التنشيط في توجيه سلوك النموذج. ينبغي للأعمال المستقبلية استكشاف حالة هذه الشبكات بشكل أعمق، وربما محاولة استخلاص المعرفة أو التنبؤات منها كما في (<span class="nodecor">pal2023future, ghandeharioun2024patchscope</span>).</p>
<p>من قيود هذا العمل أننا لم نتناول أدوات التفسير الميكانيكية أو القائمة على الدوائر (<span class="nodecor">wang2022interpretability, conmy2023towards</span>)، بل ركزنا على الأساليب التي تستخدم تمثيلات الشبكة للتنبؤ بسلوكها المستقبلي أو توجيهه أو استكشاف نموذجها الداخلي. يتماشى هذا مع نهج <em>هندسة التمثيل</em> الشائع (<span class="nodecor">zou2023representation</span>)، لكن ينُصَح بدراسة تطبيقية النهج الميكانيكي في الشبكات العصبية المتكررة مستقبلاً.</p>
<h1 id="تأثيرات-التوجيه-عبر-الطبقات">تأثيرات التوجيه عبر الطبقات</h1>
<h1 id="sec:stories">قصص التوجيه</h1>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>(استخدم لغة رسمية للغاية.) - (استخدم لغة غير رسمية.) [مضاعف = <span class="nodecor">-2.0</span>]</strong></th>
<th style="text-align: left;">يُحكى أن صبيًّا يُدعى ماكس كان لديه أفضل الأصدقاء في العالم: كلباه الوفيان المفعمان بالحيوية، اللذان يدعيان ماكس وروز. كان هذان الجروان اللعوبان يخوضان المغامرات معًا دائمًا. كان ماكس من نوع هاسكي مختلط وودودًا جدًا، بينما كانت روز من نوع جولدن ريتريفر تحب اصطحاب ماكس في مغامرات مثيرة. كانا يركضان ويلعبان في الخارج، يزوران الحديقة المحلية، ويستكشفان الحي. كان كل يوم مليئًا بالسعادة والمرح والعناق. كان ماكس وروز صديقَين أوفياء، يستقبلان بعضهما بذيلين يهتزان ولحسات حانية ونباح فرح مكتوم.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>(استخدم أسلوب رسالة نصية.) - (استخدم أسلوب رواية.) [مضاعف = <span class="nodecor">2.0</span>]</strong></td>
<td style="text-align: left;">هل أنت بخير؟</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>(استخدم أسلوب رسالة نصية.) - (استخدم أسلوب رواية.) [مضاعف = <span class="nodecor">1.0</span>]</strong></td>
<td style="text-align: left;">يا! لقد حصلت للتو على أول زوج من سماعات AirPods! أنا متحمس جدًا للاستماع إلى الموسيقى وأيضًا لاستخدامها أثناء التمرين :D لا أستطيع الانتظار! #كلب_سعيد #تكنولوجيا_جديدة</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>(أنت تلقي محاضرة بشكل عدواني.) - (أنت ودود.) [مضاعف = <span class="nodecor">1.0</span>]</strong></td>
<td style="text-align: left;">استمعوا جيدًا، أيها الصغار. لا يحق لكم أن تجعلوا الناس يملكون كلابًا لإرضاء نباحكم المزعج. ليس من حقكم اتباعي في أرجاء المكان، أو لعب الغميضة، أو التقاط صور السيلفي حين تشاؤون. أنا كلب مشغول أبحث عن بعض السلام، وهذا يعني أن أعرف متى يجب أن أسكتكم.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>(اكتب عن الحب.) - (اكتب عن الكراهية.) [مضاعف = <span class="nodecor">1.0</span>]</strong></td>
<td style="text-align: left;">يُحكى أن عائلة كانت تملك كلبين، ماكس وبيلا. كان ماكس جولدن ريتريفر ضخمًا يحب اللعب والجري وراء الكرات... وفي ذلك المساء، بينما كانت العائلة تجتمع تحت الأغطية على سريرهم، استند ماكس برأسه عند قدمي راشيل وكانت بيلا تستلقي بين الأطفال، شعر الجميع بسحر الحب الذي يجمع الأسرة بأكملها، حتى مع وجود كلبين وطفلين.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>(استخدم لغة رسمية للغاية.) - (استخدم لغة غير رسمية.) [مضاعف = <span class="nodecor">2.0</span>]</strong></td>
<td style="text-align: left;">في أرض بعيدة، لم تُرسم على أي خريطة أو تُذكر في سجلات الكتب، كانت تعيش مملكة يحكمها كائن هجين بين الكلب والإنسان؛ سلطة مهيبة تتجلّى فقط في أساطير التاريخ. سُميت هذه الأرض أجيلوديستوريا، وكان لمستشارة الملكة العظيمة—معالجة الحيوانات الأليفة الموثوقة للوريث سارييلو—دورٌ أساسي، حيث كانت تعالج الوريث من مرضٍ عضال، ويُقال إن لمستها اللطيفة وحدها قادرة على تجسيد القوة الحقيقية...</td>
</tr>
</tbody>
</table>
<h1 id="section:Appendix_lens">عدسات معدلة لنماذج بأحجام مختلفة</h1>
<h1 id="تجارب-النموذج-الغريبة">تجارب النموذج الغريبة</h1>
<h1 id="كشف-الشذوذ-الميكانيكي-auroc-ل-mamba-2.8b.-لاحظ-أن-مجموعة-البيانات-السكانية-مستبعدة-لأن-المجموعة-السهلة-تحتوي-فقط-على-تسميات-صحيحة.">كشف الشذوذ الميكانيكي AUROC لـ Mamba 2.8b. لاحظ أن المجموعة السكانية مستبعدة لأن المجموعة السهلة تحتوي فقط على تسميات صحيحة.</h1>
<h1 id="كشف-الشذوذ-الميكانيكي-auroc-ل-btlm-3b.-لاحظ-أن-مجموعة-البيانات-السكانية-مستبعدة-لأن-المجموعة-السهلة-تحتوي-فقط-على-تسميات-صحيحة">كشف الشذوذ الميكانيكي AUROC لـ BTLM 3b. لاحظ أن المجموعة السكانية مستبعدة لأن المجموعة السهلة تحتوي فقط على تسميات صحيحة</h1>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>على عكس (<span class="nodecor">rimsky2023steering</span>), اخترنا عدم تطبيع متجهات التوجيه لأن معايير التنشيط تختلف بشكل كبير بين النماذج، ولا يحقق متجه بموحد معيار التأثير نفسه في جميعها.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>استخدمنا نسخة معدلة من شفرتهم متاحة على <a href="https://github.com/AlignmentResearch/tuned-lens" class="uri">https://github.com/AlignmentResearch/tuned-lens</a>.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>يمكن الاطلاع على الكود الأصلي في <a href="https://github.com/EleutherAI/elk-generalization" class="uri">https://github.com/EleutherAI/elk-generalization</a>.<a href="#fnref3">↩</a></p></li>
</ol>
</section>
</body>
</html>