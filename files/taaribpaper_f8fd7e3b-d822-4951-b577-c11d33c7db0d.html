<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Sekeun Kim">
  <meta name="author" content="Hui Ren">
  <meta name="author" content="Peng Guo">
  <meta name="author" content="Abder-Rahman Ali">
  <meta name="author" content="Patrick Zhang">
  <meta name="author" content="Kyungsang Kim">
  <meta name="author" content="Quanzheng Li">
  <meta name="author" content="Xiang Li">
  <title>نموذج عالمي مُوجَّه بالمُوجِّهات لتحليل تصوير صدى القلب بغضّ النظر عن المقطع</title>
  <link href="https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap" rel="stylesheet">
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <style>
    body {
      direction: rtl;
      font-family: 'Cairo', 'Segoe UI', Tahoma, Geneva, Verdana, Arial, sans-serif;
      font-size: 20px;
      background: #f8f9fa;
      color: #222;
      margin: 0;
      padding: 0;
      line-height: 1.8;
    }
    header {
      background: linear-gradient(90deg, #3a8dde 0%, #6ed3cf 100%);
      color: #fff;
      padding: 40px 0 20px 0;
      text-align: center;
      box-shadow: 0 2px 8px rgba(58,141,222,0.08);
      margin-bottom: 40px;
    }
    h1.title {
      font-size: 2.5em;
      font-weight: 700;
      margin-bottom: 10px;
      letter-spacing: 1px;
    }
    .author {
      display: inline-block;
      margin: 0 10px;
      font-size: 1.1em;
      color: #eaf6fb;
      background: rgba(255,255,255,0.08);
      border-radius: 8px;
      padding: 4px 12px;
    }
    h1, h2, h3 {
      color: #3a8dde;
      font-weight: 700;
      margin-top: 40px;
      margin-bottom: 18px;
      letter-spacing: 0.5px;
    }
    h2 {
      font-size: 1.5em;
      border-right: 4px solid #6ed3cf;
      padding-right: 12px;
      margin-top: 32px;
    }
    h3 {
      font-size: 1.2em;
      border-right: 3px solid #3a8dde;
      padding-right: 10px;
      margin-top: 24px;
    }
    p {
      margin: 0 0 18px 0;
      text-align: justify;
    }
    ul, ol {
      margin: 0 0 18px 32px;
      padding: 0;
    }
    li {
      margin-bottom: 8px;
    }
    code, .math.inline, .math.display {
      font-family: 'Fira Mono', 'Consolas', 'monospace';
      background: #f1f3f6;
      color: #2d3a4a;
      padding: 2px 6px;
      border-radius: 4px;
      font-size: 0.95em;
      direction: ltr;
      unicode-bidi: embed;
    }
    .math.display {
      display: block;
      margin: 18px 0;
      text-align: center;
      background: #f1f3f6;
      padding: 10px 0;
      border-radius: 6px;
    }
    table {
      width: 70%;
      margin: 32px auto;
      border-collapse: collapse;
      background: #fff;
      box-shadow: 0 2px 8px rgba(58,141,222,0.07);
      border-radius: 10px;
      overflow: hidden;
    }
    caption {
      caption-side: top;
      font-size: 1.05em;
      color: #3a8dde;
      font-weight: 700;
      padding: 12px 0 8px 0;
      background: #eaf6fb;
      border-bottom: 1px solid #d1e7f7;
    }
    th, td {
      text-align: center;
      padding: 12px 16px;
      border-bottom: 1px solid #e3e3e3;
    }
    th {
      background: #f1f3f6;
      color: #3a8dde;
      font-weight: 700;
    }
    tr:last-child td {
      border-bottom: none;
    }
    strong {
      color: #2d3a4a;
      font-weight: 700;
    }
    .nodecor {
      text-decoration: none;
      color: inherit;
    }
    @media (max-width: 900px) {
      body { font-size: 18px; }
      table { width: 95%; }
      header { padding: 24px 0 12px 0; }
      h1.title { font-size: 2em; }
    }
    @media (max-width: 600px) {
      body { font-size: 16px; }
      h1.title { font-size: 1.3em; }
      h2 { font-size: 1.1em; }
      table { font-size: 0.95em; }
    }
    .MathJax_Display {
      direction: ltr !important;
      text-align: center !important;
    }
  </style>
</head>
<body>
<header>
  <h1 class="title">نموذج عالمي مُوجَّه بالمُوجِّهات لتحليل تصوير صدى القلب بغضّ النظر عن المقطع</h1>
  <div>
    <span class="author">Sekeun Kim</span>
    <span class="author">Hui Ren</span>
    <span class="author">Peng Guo</span>
    <span class="author">Abder-Rahman Ali</span>
    <span class="author">Patrick Zhang</span>
    <span class="author">Kyungsang Kim</span>
    <span class="author">Quanzheng Li</span>
    <span class="author">Xiang Li</span>
  </div>
</header>

<h1 id="ملخص">مُلخّص</h1>
<p>تُعدّ تجزئة صور تصوير صدى القلب لأغراض تحليل القلب عمليةً مُرهِقة مستهلِكة للوقت والموارد، وذلك بسبب التباين في جودة الصور والحاجة إلى معالجة الفحوصات المأخوذة من مقاطع قياسية متنوّعة. وعلى الرغم من الأداء الواعد للطرائق الآلية الحالية في تجزئة هذه الصور، فإنها تُدرَّب عادةً لكل مقطع قياسي على حدة. وللتغلب على هذه القيود، نقدّم في هذه الورقة نهجًا عالميًا مُوجَّهًا بالمُوجِّهات لتحليل تصوير صدى القلب بغضّ النظر عن المقطع. ومع مراعاة اختلافات المجال بين المقاطع القياسية، نقترح أولًا آلية مطابقة المُوجِّهات لتعلّم مُوجِّهات مُخصَّصة لكل مقطع عبر مواءمتها مع تضمينات المدخلات باستخدام نموذج رؤية مُدرَّب مُسبقًا. بعد ذلك، نستخدم نموذجًا لغويًا طبيًا مُدرَّبًا مُسبقًا لمحاذاة التمثيلات النصيّة مع بيانات البكسل، بما يضمن دقّةً عالية في التجزئة. أظهرت التجارب الواسعة على ثلاثة مقاطع قياسية تفوّق نهجنا على الطرائق العالمية الأخرى، مع أداءٍ مُعادِلٍ أو أفضل من النماذج المُخصّصة لكل مقطع.</p>

<h1 id="مقدمة">مقدمة</h1>
<p>يُعدّ التصوير بالموجات فوق الصوتية للقلب الأسلوب الأكثر شيوعًا في طب القلب، إذ يُسهم في تقييم وظائف القلب عبر فحصه من خلال مقاطع قياسية عدّة. ونظرًا لتعقيد تحليل الصور وعبء العمل على الفنيين، ازداد الاهتمام بتطوير طرائق آلية للتجزئة (<span class="nodecor">kim2022fully, kim2021automatic, leclerc2020lu</span>). وقد أظهرت هذه الطرائق أداءً متفوّقًا في تحديد البُنى التشريحية بدقّة عندما تُدرَّب على مجموعات بيانات مُخصَّصة لكل مقطع. وتشمل هذه العملية خطوةً يدويةً لتحديد المقاطع المطلوبة في دراسة المريض قبل التحليل، بما يستلزم انتقاء الملفات المناسبة من ملفات الفحص (<span class="nodecor">charton2023multi, jeon2023improving</span>). وحتى الآن لم تُستكشف بصورة كافية إمكانية تصميم نموذج عام قادر على أداء مهام التجزئة على مختلف المقاطع القياسية بشكل مستقل.<br />
الحل العملي المُتَّبع هو تدريب N نموذجًا، نموذج لكل مقطع قياسي، ومع زيادة عدد المقاطع يزداد عدد النماذج المطلوبة. ومن أبسط السبل لبناء نموذج عالمي أن ندرّب الشبكة نفسها على بيانات مأخوذة من مقاطع متعدّدة، إلا أن ذلك قد يُنقِص الأداء بسبب الخصائص البصرية المميِّزة لكل مقطع (<span class="nodecor">kim2021automatic, mitchell2019guidelines</span>). ولمعالجة هذه التحديات، ظهر عدد من النماذج العالمية (<span class="nodecor">zhang2021dodnet, butoi2023universeg, liu2023clip, ye2023uniseg</span>). يقترح نموذج <span class="nodecor">DoDNet</span> بنية مُشفِّر/مُفكِّك ترميز مع رأس ديناميكي تتحكّم فيه متجهات ثابتة ثنائية الحالة. ويطوّر النموذج العالمي المعتمد على <span class="nodecor">CLIP</span> هذه الفكرة عبر استخدام نموذج لغوي مُدرَّب مُسبقًا وتكييف رؤوس التجزئة استنادًا إلى التضمينات الدلالية للفئة. ومع أن هذه الاستراتيجية أثبتت نجاحًا في تجزئة الأعضاء في التصوير المقطعي المحوسب، فإنها تواجه تحدّيات في المجال الطبي بسبب الفجوة بين النصوص العامّة واللغة السريرية. ويرتكز <span class="nodecor">UniSeg</span> على مُوجِّهات قابلة للتعلُّم لمعالجة مهام التجزئة في التصوير المقطعي، والرنين المغناطيسي، والتصوير بالإصدار البوزيتروني، لكنه يُختبر على ثلاث مجموعات تشريحية متقاربة حيث تختلف الصور في القوام فقط بينما يظل التشريح ثابتًا؛ وبالتالي قد لا يكون مناسبًا لاختلافات المقاطع الشديدة في تصوير صدى القلب، وهو ما ينعكس على الأداء كما في الجدول [table2].<br />
للتغلّب على هذه التحدّيات، نقترح نموذجًا عالميًا مُوجَّهًا بالمُوجِّهات قادرًا على تحقيق أفضل أداء في تجزئة البُنى القلبية. ندمج في نموذجنا آلية تعلُّم مُوجِّهات قائمة على مجموعة مُوجِّهات لتحسين التكيّف مع المقاطع المختلفة، ومحاذاةً كثيفةً بين النص والبكسل للاستفادة من المعرفة اللغوية الطبية في مهام التجزئة. وبحسب علمنا، تُعدّ هذه الدراسة الأولى التي تعالج تجزئةً بنموذجٍ موحَّد في تصوير صدى القلب. تُبسِّط طريقتنا عملية التحليل القلبي بإلغاء الحاجة إلى خطوة يدوية لتحديد المقطع المطلوب من فحص المريض. وقد تمّ تقييم نهجنا على ثلاثة مقاطع قياسية من ثلاث مجموعات بيانات مختلفة وأظهر نتائج واعدة مقارنةً بالطرائق العالمية الأخرى.<br /></p>
<ul>
  <li>نُقدِّم نموذجًا عالميًا مُوجَّهًا بالمُوجِّهات يضمّ مجموعة مُوجِّهات لمعالجة المقاطع القياسية المختلفة، ويستفيد من محاذاة النص بالبكسل باستخدام نموذج لغوي طبي مُدرَّب مُسبقًا لتجزئة تصوير صدى القلب بغضّ النظر عن المقطع.</li>
  <li>نُبسِّط عملية التحليل القلبي عبر إزالة الحاجة إلى خطوة تحديد المقطع يدويًّا، مع استرجاع المقطع المطلوب تلقائيًّا من بيانات الفحص.</li>
  <li>نُبيّن من خلال تجارب واسعة على مجموعات بيانات متنوّعة أنّ نموذجنا يُحقّق أداءً متفوِّقًا في مهام تجزئة القلب مقارنةً بالنهج العالمية السابقة.</li>
</ul>

<h1 id="الطريقة">الطريقة</h1>
<p>يتكوّن نهجنا المقترح، كما هو موضَّح، من المسار النصي، ومُشفِّر الفيديو، ومجموعة مُوجِّهات قابلة للتعلُّم (مفاتيح وقِيَم)، وطبقة MLP، ووحدة مُفكِّك ترميز الفيديو. نستخدم (<span class="nodecor">alsentzer2019publicly</span>) لتعزيز استخراج التمثيلات اللغوية السريرية من النصوص. يهدف نموذجنا إلى تجزئة البُنى عبر جميع إطارات الفيديو في المقاطع القياسية المتنوّعة. ولتحقيق ذلك، نُقدّم مُكوّنين رئيسيين: 1) محاذاة كثيفة بين النص والبكسل لردم الفجوة بين نموذج اللغة المُدرَّب مُسبقًا وتمثيلات البكسل في مهام التنبؤ الكثيف، و2) تقنية مطابقة المُوجِّهات التي تستفيد من مجموعة المُوجِّهات لاختيار المُوجِّه الأمثل لكل مهمّة.</p>

<h2 id="تعريف-المشكلة">تعريف المشكلة</h2>
<p>بالنظر إلى مجموعة البيانات <em>D</em> = {D₁, …, D_N}، حيث يحتوي كل D_i على أزواج (X_{ij}, Y_{ij}) من فيديوهات بعدد إطارات F وعلاماتٍ أرضية، ويَنتمي X_{ij} إلى المقطع V_k مع وجود K مقاطع مسح قياسية. بعض مجموعات D_i موسوم بالكامل وبعضها موسوم جزئيًا. الهدف هو تدريب نموذج <span class="nodecor">F(·)</span> باستخدام هذه المجموعات ذات التوسيم الجزئي، بحيث يتمكّن من إجراء تنبؤات كثيفة لجميع الفئات عبر الإطارات F وعبر المقاطع K.</p>

<h2 id="محاذاة-كثيفة-بين-النص-والبكسل">محاذاة كثيفة بين النص والبكسل</h2>
<p>عند تكييف تمثيلات (<span class="nodecor">CLIP</span>) المُدرَّبة على الصور والنصوص العامّة للتطبيقات الطبية (<span class="nodecor">qin2022medical, liu2023clip</span>)، تضعُف قدرتها على التقاط الدلالات السريرية كما يظهر في الجدول [table3]. وللاستفادة بالكامل من المعرفة المُشفَّرة في نموذج لغوي طبي مُدرَّب مُسبقًا، اعتمدنا على (<span class="nodecor">ClinicalBERT</span>) (<span class="nodecor">alsentzer2019publicly</span>) في مهام التنبؤ الكثيف. نُحوِّل الفئات النصية إلى صيغ من نمط "مخطّط صدى القلب لـ [الفئة]" ثم نستخلص منها التضمينات <span class="math inline">𝐹(c) \in \mathbb{R}^{N\times D}</span>. نُرَمِّز فيديو الفحص بمُشفِّر الفيديو لاستخراج تضمينات محلية <span class="math inline">𝐺(x) \in \mathbb{R}^{T_i H_i W_i \times D}</span>. بعد ذلك نحسب خريطة الدرجات <span class="math inline">\mathcal{S} = \hat{G}(x) \cdot (F(c))^\top</span> مع التطبيع على طول البُعد القَنَوي. ونشتقّ من خريطة الدرجات هذه خسارةً مُساعِدةً (نص–بكسل) لدمج أولويّات النص في التضمينات المحليّة قبل فكّ الترميز.</p>

<h2 id="مطابقة-الأوامر-وتوليد-المعاملات-بناء-على-النص">مطابقة المُوجِّهات وتوليد المعاملات بناءً على النص</h2>
<p>بالنظر إلى مدخل فيديو <span class="math inline">x \in \mathbb{R}^{T\times H\times W\times C}</span> ومُشفِّر الرؤية <span class="math inline">\mathcal{Q}</span> (ViT) من <span class="nodecor">kirillov2023segment</span>، نُجزِّئ الإطار الأوّل إلى رقعات بحجم S² ثم نُنتج تضمينات الرقعات <span class="math inline">\mathcal{Q}(x) \in \mathbb{R}^{L\times D}</span>. تتألّف مجموعة المُوجِّهات من M أزواج قابلة للتعلُّم من مفاتيح <span class="math inline">k_i \in \mathbb{R}^D</span> وقِيَم <span class="math inline">P_i \in \mathbb{R}^{L\times D}</span>. نسعى لتقريب تضمينات الاستعلام ومفتاح المُوجِّه المطابق باستخدام خسارة مُقارنة قائمة على التشابه الجيبي <span class="math inline">\mathcal{L}_{pr}</span>. بعد ذلك، نستخدم تجميعًا متوسطًا عالميًا للحصول على تضمين عالمي للفيديو، ثم نستخدم تضمينات النص وقِيَم المُوجِّه لإنتاج معاملات رؤوس التجزئة <span class="math inline">\theta_N</span> في وحدة مُفكِّك ترميز الفيديو لتوليد تنبؤات ثنائية لكل فئة (<span class="nodecor">tian2020conditional</span>).</p>

<h2 id="دالة-الخسارة">دالة الخسارة</h2>
<h3 id="الانتشار-العكسي-المقنع-للفيديو">الانتشار العكسي المُقنَّع للفيديو</h3>
<p>نظرًا للتوسيم الجزئي عبر الإطارات في مجموعاتنا (<span class="nodecor">liu2023clip</span>)، صمّمنا آلية انتشارٍ عكسي مُقنَّع تحجب الإطارات غير المُوسومة عن مسار الانتشار العكسي للخسارة، ما يسمح باستغلال التسميات النادرة لتحقيق تجزئة دقيقة على مستوى الفيديو.</p>

<h3 id="الخسارة-الكلية">الخسارة الكليّة</h3>
<p>نُعرِّف دالة الخسارة الإجمالية كالتالي:<br />
<span class="math display">\[
\mathcal{L}_{seg} = \lambda_1 \mathcal{L}_{pixel-text} + \lambda_2 \mathcal{L}_{BCE}, \quad \mathcal{L}_{pr} = \langle \mathcal{Q}(X_{i0}), P_{key} \rangle
\]</span>
<span class="math display">\[
\mathcal{L}_{total} = (1 - \lambda(t)) \mathcal{L}_{seg} - \lambda(t) \mathcal{L}_{pr}
\]</span>
حيث تجمع \(\mathcal{L}_{seg}\) بين خسارة النص–البكسل وخسارة الانتروبي المُتقاطع الثنائي (BCE)، ويتم ضبط \(\lambda_1\) و\(\lambda_2\) بالتساوي. وتمثّل \(\mathcal{L}_{pr}\) تشابهًا جيبيًّا بين تضمين الاستعلام ومفتاح المُوجِّه، وتُطبَّق \(\lambda(t)\) بجدولةٍ غاوسيّة تعتمد على رقم التكرار لحساب الوزن النسبي لكل مُصطلح.</p>

<h1 id="التجارب-والنتائج">التجارب والنتائج</h1>
<p><strong>المواد.</strong> قيَّمنا الطرائق على ثلاث مجموعات بيانات عامة (<span class="nodecor">leclerc2019deep</span>, <span class="nodecor">reddy2023video</span>, <span class="nodecor">ouyang2020video</span>) تتضمّن بيانات مسح ثنائي الأبعاد لنهايتي الانبساط (ED) والانقباض (ES)، مع توفير تجزئة الحدّ الشِّغافي للبطين الأيسر (LV<sub>endo</sub>) والحدّ النِّخابي للبطين الأيسر (LV<sub>epi</sub>) في مقاطع القِمّة ثنائيّ الحجرات (A2C)، والقِمّة رباعيّ الحجرات (A4C)، والمَحور القصير بجوار القص (PSAX). اتّبعنا تقسيمًا مُعدًّا سلفًا كما في الجدول [tab1].<br />
<strong>التنفيذ ومقاييس التقييم.</strong> للحفاظ على مقارنة عادلة، استخدمنا PyTorch بدُفعةٍ حجمها 5 عبر 100 عصر على بطاقة Nvidia A100، مع شبكة UNet كهيكلٍ أساسي ومحسّن MADGRAD (<span class="nodecor">defazio2022adaptivity</span>) بمعدّل تعلّم 1e-4. قمنا بتحجيم الصور إلى 224×224×16 إطارًا وتطبيعها بمتوسط صفري وتباينٍ وحيد. ولتعزيز المتانة، طبّقنا الانعكاس العشوائي، ودوران ±30°، والاقتصاص. قَيَّمنا الأداء بمُعامل دايس (DSC) عبر مقاطع A4C وA2C وPSAX وحالتي ED وES.<br />
<strong>دراسة المقارنة.</strong> قارَنّا نهجنا في إعدادين: 1) تدريبٌ واختبار على المقطع نفسه (نهج مُخصَّص)، و2) تدريبٌ على جميع المقاطع واختبار عليها (نهج مُوحَّد). واعتمدنا كنماذج أساس SwinUNETR (<span class="nodecor">hatamizadeh2021swin</span>) وU-transformer (<span class="nodecor">petit2021u</span>) (<span class="nodecor">kim2023medivista</span>)، بالإضافة إلى النماذج العالمية DoDNet (<span class="nodecor">reddy2023video</span>)، وCLIP-driven (<span class="nodecor">liu2023clip</span>)، وUniSeg (<span class="nodecor">ye2023uniseg</span>)، وUniverSeg (<span class="nodecor">butoi2023universeg</span>).<br />
كما يُظهر الجدول [table2]، يُحقّق نموذجنا نتائج تجزئة متميّزة حتى مع إدخالٍ غير مُحدَّد المقطع. وبالمقارنة مع النماذج تحت النهج المُوحَّد، يتفوّق نموذجنا غالبًا على النماذج المُخصَّصة، باستثناء LV<sub>endo</sub> (93.2 مقابل 93.3) وLV<sub>epi</sub> (88.3 مقابل 88.5) في A2C وA4C على التوالي. ومن خلال مطابقة المُوجِّهات ديناميكيًا، نُحسن تحديد مناطق الاهتمام عبر جميع المقاطع. كما يتفوّق متوسّط أدائنا على نموذج UniverSeg القائم على التعلّم بقليلٍ من الأمثلة (89.64 مقابل 81.7).<br />
<strong>دراسة الاستئصال.</strong> لتقييم مساهمة كل مُكوّن، أزلنا مسار التضمين النصي أولًا، ولاحظنا انخفاضًا من 89.6 إلى 85.6 عند إزالة خسارة النص–البكسل، ما يُؤكّد أهميّتها. ثم قارَنّا بين نماذج اللغة CLIP وClinicalBERT، فوجدنا تفوّق الأخير (89.6 مقابل 88.8). كما قيَّمنا دقّة تصنيف المُوجِّهات عبر تصويت الأغلبيّة مُسجّلين قدرة تمييز عالية بين PSAX والمقاطع القِمّية (0.96)، وأقلّ بين A2C وA4C (0.54 و0.60) بسبب التشابه الكبير بينهما. كذلك لاحظنا أنّ توفير معلومات المقطع بصورةٍ صريحة قد يُقلِّل الأداء قليلًا (89.4 مقابل 89.6) كما في الجدول [table4].</p>

<table>
  <caption>مقارنة أداء النموذج مع أو بدون معلومات المقطع الصريحة.<span data-label="table4"></span></caption>
  <thead>
    <tr class="header">
      <th style="text-align: center;">بدون معلومات المقطع</th>
      <th style="text-align: center;">مع معلومات المقطع</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>89.6</td>
      <td>89.4</td>
    </tr>
  </tbody>
</table>

<h1 id="الخلاصة">الخلاصة</h1>
<p>قدّمنا في هذه الدراسة نموذجًا مُبتكرًا لتجزئة صور صدى القلب مُوجَّهًا بالمُوجِّهات وقادرًا على التعلّم من بيانات مُوسومة جزئيًا عبر مقاطع قياسية متعدّدة. يجمع النموذج بين محاذاة التمثيل النصّي والبصري باستخدام نموذج لغةٍ طبي مُدرَّب مُسبقًا، وتقنية مطابقة المُوجِّهات لتحقيق تجزئة متّسقة بغضّ النظر عن المقطع. وأظهر التقييم على ثلاثة مقاطع قياسية قابليةَ توسيع النموذج ليشمل مقاطع إضافية عند الضرورة، مع تبسيط سير العمل عبر إزالة الحاجة إلى تحديد المقطع يدويًا. وقد أثبتت التجارب الموسّعة تفوّق نهجنا وفائدته العالية في تجزئة صدى القلب.</p>
</body>
</html>