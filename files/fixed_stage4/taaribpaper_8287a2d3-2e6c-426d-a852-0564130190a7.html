<!DOCTYPE html>
<html lang="ar">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Rui Xie, Zhengran Zeng, Zhuohao Yu, Chang Gao, Shikun Zhang, Wei Ye">
  <title>تقرير فني CodeShell</title>

  <!-- Google Font for Arabic -->
  <link href="https://fonts.googleapis.com/css2?family=Cairo:wght@300;400;600;700&display=swap" rel="stylesheet">

  <style>
    /* Global */
    body {
      margin: 0;
      padding: 1em;
      max-width: 800px;
      margin-left: auto;
      margin-right: auto;
      background: #fafafa;
      color: #333;
      direction: rtl;
      font-family: 'Cairo', sans-serif;
      font-size: 20px;
      line-height: 1.6;
    }
    a { color: #0066cc; text-decoration: none; }
    a:hover { text-decoration: underline; }

    /* Header */
    header {
      border-bottom: 2px solid #ddd;
      padding-bottom: 1em;
      margin-bottom: 2em;
    }
    h1.title {
      font-size: 2.5em;
      margin: 0;
    }
    .author {
      margin-top: 0.5em;
      color: #555;
      font-size: 0.95em;
    }
    .author span, .author a { display: block; }

    /* Sections */
    section {
      margin-bottom: 2em;
    }
    h1, h2, h3 {
      color: #222;
      margin-top: 1.5em;
      margin-bottom: 0.5em;
      line-height: 1.3;
    }
    h1 { font-size: 2em; border-bottom: 1px solid #ddd; padding-bottom: 0.3em; }
    h2 { font-size: 1.6em; }
    h3 { font-size: 1.3em; }

    /* Paragraphs */
    p {
      margin: 0.8em 0;
      text-align: justify;
      text-justify: inter-word;
    }

    /* Lists */
    ul {
      margin: 1em 0;
      padding-inline-start: 1.2em;
    }
    li p {
      margin: 0.4em 0;
    }

    /* Table */
    figure {
      margin: 2em 0;
      overflow-x: auto;
    }
    table {
      width: 100%;
      border-collapse: collapse;
      margin: 0.5em 0;
    }
    table caption {
      caption-side: top;
      font-weight: bold;
      margin-bottom: 0.5em;
    }
    th, td {
      padding: 0.5em 0.8em;
      border: 1px solid #ccc;
      text-align: center;
    }
    tr:nth-child(odd) { background: #f7f7f7; }

    /* Inline code and highlights */
    code, .nodecor {
      background: #eef;
      padding: 0.1em 0.3em;
      border-radius: 3px;
      font-family: monospace;
    }
    .math.inline { font-style: normal; }

  </style>

  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full"></script>
</head>
<body>

<header>
  <h1 class="title">تقرير فني <code>CodeShell</code></h1>
  <p class="author">
    <span>Rui Xie, Zhengran Zeng, Zhuohao Yu, Chang Gao, Shikun Zhang, Wei Ye</span>
    <span>National Engineering Research Center for Software Engineering, Peking University, China</span>
    <span><a href="mailto:ruixie@pku.edu.cn">{ruixie, wye}@pku.edu.cn</a></span>
    <span><a href="https://github.com/WisdomShell/codeshell">https://github.com/WisdomShell/codeshell</a></span>
  </p>
</header>

<main>

  <section id="ملخص">
    <h1>مُلَخَّص</h1>
    <p>تُمثّل نماذج اللغة الكبيرة المتخصصة في البرمجة نقطة تحول رئيسية في مجال الذكاء الاصطناعي. فهي مُصمَّمة لفهم وتوليد لغات البرمجة، مما يُعزّز كفاءة سير عمل تطوير البرمجيات بشكل كبير. في هذا التقرير الفني، نقدّم نموذج <code>CodeShell-Base</code> الأساسِي المكوَّن من سبعة مليارات معلمة، وطول سياق يصل إلى <code>8K</code>، والذي يُظهر قدرات استثنائية في فهم الكود. من خلال دمج آلية الانتباه المجمع للاستعلامات (<code>GQA</code>) والـترميز الدوراني للموقع (<code>RoPE</code>) في بنية <code>GPT-2</code>، يجمع <code>CodeShell-Base</code> بين المزايا الهيكلية لـ<code>Starcoder</code> و<code>CodeLlama</code> مع تصميم معماري فريد. بعدها، اعتمدنا خط أنابيب شامل لمعالجة البيانات يتضمن إزالة التكرار، والتصفية بناءً على معيار الحيرة، والتصفية القاعدية. من خلال هذه العملية، جمعنا أكثر من <code>100</code> مليار رمز تدريبي عالي الجودة من <code>GitHub</code>. وبفضل هذه المجموعة من البيانات، يتفوّق <code>CodeShell-Base</code> على <code>CodeLlama</code> في معيار <code>HumanEval</code> بعد تدريبه على <code>500</code> مليار رمز فقط (خمس حقب). كذلك أجرينا تجارب شاملة على لغات متعددة، بينها <code>Python</code> و<code>Java</code> و<code>C++</code>، وأظهرت النتائج قوة النموذج في فهم وإنشاء الشيفرة.</p>
  </section>

  <section id="مقدمة">
    <h1>مُقَدِّمَة</h1>
    <p>أحدثت نماذج اللغة الكبيرة المخصصة للبرمجة مثل <code>CodeGen</code> و<code>CodeLlama</code> و<code>StarCoder</code> ثورة في مجال تطوير البرمجيات من خلال أتمتة المهام، وتقليل الأخطاء، وتحسين الكفاءة (<code>gpt4report</code>). بالاستفادة من التعلم العميق ومجموعات البيانات الضخمة المخصصة للكود (<code>codegen</code>, <code>thestack</code>), رفعت هذه النماذج إنتاجية المطورين ووسّعت دائرة المستخدمين القادرين على إنشاء البرمجيات.</p>
    <p>يمكن تصنيف نماذج اللغة الكبيرة للبرمجة الحالية إلى ثلاث فئات رئيسية: التدريب المسبق من الصفر (<code>starcoder</code>), والتدريب المسبق انطلاقًا من نموذج لغة كبير موجود مسبقًا (<code>codex</code>, <code>codellama</code>), والتعديل التوجيهي (<code>wizardcoder</code>). تتطلب النماذج التي تُدرب من الصفر كميات ضخمة من البيانات ووقتًا طويلًا (<code>starcoder</code>, <code>llama2</code>). من ناحية أخرى، يتيح الاستفادة من نموذج موجود تقليل زمن التدريب وتحقيق كفاءة أعلى بكمية بيانات أقل (<code>codex</code>, <code>codellama</code>). أمّا التعديل التوجيهي فيتضمن ضبط نموذج كبير باستخدام بيانات توجيهية لتحسين الأداء (<code>codellama</code>, <code>wizardcoder</code>). ومع ذلك، يبقى التحدي الأكبر أن العديد من النماذج الكبيرة تُدرّب على مجموعات بيانات ضخمة للكود دون رقابة دقيقة، ما قد يؤدي إلى إنتاج شيفرات منخفضة الجودة. ورغم بعض الاستراتيجيات لاختيار الشيفرة (<code>phi1</code>), فإن خطر خروج شيفرات دون المستوى مازال قائمًا.</p>
    <p>في هذا التقرير الفني نقدّم نموذجًا جديدًا يُسمّى <code>CodeShell</code>. يدمج CodeShell الترميز الدوراني للموقع (<code>rope</code>) وآلية الانتباه المجمع للاستعلامات (<code>gqa</code>) ضمن بنية <code>GPT-2</code> لبناء تصميم معياري وفعّال يدعم سياقات أطول. ثم طورنا خط أنابيب لاختيار الشيفرات عالية الجودة، مما أتاحت لنا حزمة بيانات تضم أكثر من <code>100</code> مليار رمز. استنادًا إلى هذه المجموعة، تدرب CodeShell على مدى خمس حقب، وأظهرت تجاربنا أنّه يستطيع مع <code>100</code> مليار رمز فريد أن يضاهي أو يتفوّق على نماذج كبيرة مثل StarCoder وCodeLlama التي دُرِّبت على <code>250</code> مليار رمز فريد. ومما يؤكد أهمية اختيار البيانات العالية الجودة، تبقى هذه العمليّة محورًا أساسيًا في تطوير نموذج فعّال. فيما يلي أبرز مساهماتنا الرئيسية:</p>
    <ul>
      <li><p>أطلقنا <code>CodeShell-7B</code>، نموذجًا أساسِيًّا جديدًا تم تدريبه من الصفر بتصميم معماري فريد، وأظهر أداءً تنافسيًا على معايير متنوعة ولغات برمجة متعددة.</p></li>
      <li><p>لتقليل تكلفة التدريب، طورنا خط أنابيب فعالًا لمعالجة البيانات يختار الشيفرات عالية الجودة من مجموعات ضخمة، وأظهرت التجارب أن نموذجنا المدرب على <code>500</code> مليار رمز فقط يتفوّق على StarCoder المدرب على تريليون رمز.</p></li>
      <li><p>للتعامل مع مهام تتطلب تحليلاً أعمق للشيفرة، مدّدنا طول السياق إلى <code>8K</code>، مما يحسّن قدرة النموذج على معالجة الشيفرات الطويلة دون التأثير على كفاءته مع المقاطع القصيرة.</p></li>
    </ul>
  </section>

  <section id="قشرة-الكود">
    <h1>قِشْرَة الكود</h1>

    <h2 id="البيانات">البَيانات</h2>
    <p>للاطّلاع على تفاصيل بناء مجموعة بيانات تدريب <code>CodeShell</code> وعمليّات التصفية والتحسين، نوضّح فيما يلي كلّ خطوة:</p>
    <p><strong>جمع البيانات:</strong> استند عملنا إلى أرشيف GitHub (<code>gharchive</code>), حيث جمعنا نحو 15 تيرابايت من المستودعات لضمان اتساع وتنوّع المجموعة. أضفنا كذلك بيانات من Stack (<code>thestack</code>) و<code>StarCoder</code> لإثراء المادة بأمثلة شيفرة ومناقشات برمجية.</p>
    <p><strong>تصفية اللغات:</strong> استبعدنا اللغات التي يقل حجم بياناتها عن 100 ميغابايت، وركزنا على سبع مجموعات رئيسية تشمل Markdown للتوثيق، وgit-commits لممارسات التطوير، وGitHub-issues لمناقشات حل المشكلات، بهدف تنويع نماذج الاستخدام.</p>
    <p><strong>القواعد الأولية للتصفية:</strong> وضَعنا قواعد لاستبعاد الشيفرات التي تحتوي على أسطر طويلة جدًا أو محتوى نصي مفصول عن الشيفرة بشكل مفرط، بهدف تركيز المُدخَلات على الأمثلة الأكثر معيارية وقابلية للقراءة.</p>
    <p><strong>إزالة التكرار:</strong> استخدمنا تجزئة MD5 للكشف عن المُكرّرات وإزالتها، وتقنيات MinHash (<code>minihash</code>) لاكتشاف المحتويات المتشابهة جدًا وتنقيتها، ما عزّز تنوّع وجودة البيانات.</p>
    <p><strong>تصفية الحيرة:</strong> اعتمدنا درجة الحيرة (<code>pplf</code>) كمقياس لجودة الشيفرة. من خلال استبعاد الأمثلة ذات درجة الحيرة العالية، رفعنا مستوى جودة المجموعة التدريبية.</p>
    <p><strong>التصفية القاعدية:</strong> وظّفنا نظام تحليل قائم على قواعد خاصة لانتقاء الشيفرات عالية الجودة، مُقيّمين مقاييس مثل عدد الأسطر، ووجود التعليقات ومدى شموليتها، ومتوسط طول السطر. فضلنا أيضًا الشيفرات التي تستخدم مكتبات طرف ثالث معروفة، وتحققنا من مدى تعقيدها المنطقي عبر تحليل الشجرة المجردة وتدفق التحكم، لضمان أنها أمثلة عملية ومتقدمة تلتزم بأفضل ممارسات البرمجة.</p>

    <figure>
      <table>
        <caption>نظرة عامة على البيانات</caption>
        <thead>
          <tr>
            <th>لغة</th>
            <th>حجم (GB)</th>
            <th>% من البيانات</th>
            <th>pplf متوسط</th>
            <th>أسطر/ملف</th>
            <th>% مكرر</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>css</td>
            <td>30.09</td>
            <td>2.38%</td>
            <td>0.13</td>
            <td>23.58</td>
            <td>0.28%</td>
          </tr>
          <!-- بقية الجدول تبقى كما هي -->
        </tbody>
      </table>
    </figure>
  </section>

  <section id="النموذج">
    <h2>النموذج</h2>

    <h3 id="محلل-الرموز">مُحلّل الرموز</h3>
    <p>لتعزيز قدرة النموذج على معالجة المحتوى الصيني في برمجة الشيفرة، قمنا بإثراء مفردات <code>StarCoder</code> بإضافة مجموعة كبيرة من المفردات الصينية. جمعنا مليون ملف برمجي صيني وبيانات باللغتين الصينية والإنجليزية حول أسئلة وأجوبة برمجية. باستخدام مكتبة Tokenizer من Hugging Face، حدّدنا <code>40,000</code> مفردة صينية ذات تكرارٍ عالٍ، و<code>30,000</code> مفردة إنجليزية من مفردات StarCoder، ودمجناهما لتكوين معجم <code>CodeShell</code> الشامل. أظهرت التجارب تفوّق معجم CodeShell في تحليل الأسئلة والأجوبة البرمجية الصينية مقارنة بمعجم StarCoder الأصلي.</p>

    <h3 id="الهندسة-المعمارية">الهندسة المعمارية</h3>
    <p>يقوم <code>CodeShell</code> على بنية <code>GPT-2</code> كأساس، ويستفيد من تقنيتين متقدمتين: آلية الانتباه المجمع للاستعلامات (<code>GQA</code>) والـ<code>RoPE</code> (الترميز الدوراني للموقع). تساعد آلية GQA في تجميع الاستعلامات المتشابهة لتحسين الكفاءة الحسابية وتقليل التكرار، بينما يوفّر الـRoPE تمثيلًا ديناميكيًا لمواقع الرموز في تسلسل الشيفرة، مما يعزّز فهم النموذج للبنية والترتيب.</p>
  </section>

  <section id="التدريب">
    <h2>التدريب</h2>

    <h3 id="التحسين">التحسين</h3>
    <p>اعتمدنا محسّن <code>AdamW</code> مع ضبط معاملات <span class="math inline">\(\beta_1\)</span> و<span class="math inline">\(\beta_2\)</span> عند <code>0.9</code> و<code>0.95</code> على التوالي. استخدمنا جدولًا زمنيًا للتعلم يبدأ بفترة تسخين مدتها <code>1000</code> خطوة، ثم يخفض معدل التعلم من <code>3e-4</code> إلى <code>3e-5</code> خلال <code>127k</code> تحديثًا. عالجنا دفعات بحجم <code>4</code> ملايين رمز، مقسمة إلى تسلسلات بطول <code>2048</code> أو <code>8192</code> رموز لكل دفعة.</p>

    <h3 id="مرحلة-التدريب-المسبق">مرحلة التدريب المسبق</h3>
    <p>للموازنة بين الكفاءة والحاجة إلى سياق أطول، بدأنا بطول سياق <code>2048</code> للأحقاب الأولى. بعد تدريب على نحو <code>450</code> مليار رمز، زدنا طول السياق إلى <code>8192</code>. نتج عن ذلك انخفاض في معدل المعالجة على وحدة المعالجة الرسومية من <code>3200</code> رمز/ثانية إلى <code>2600</code> رمز/ثانية. ومع ذلك، حافظ النموذج على استقراره أو شهد تحسنًا طفيفًا في الأداء، مع انخفاض ملحوظ في الخسارة بفضل السياق الأطول، دون أي تراجع في مقاييس التقييم.</p>
  </section>

  <section id="النتائج">
    <h1>النتائج</h1>
    <p>في هذا القسم نستعرض أداء <code>CodeShell</code> مقارنةً بالنماذج الرائدة:</p>
    <ul>
      <li><p><strong>StarCoder-7B وStarCoder-15B</strong> (<code>starcoder</code>), نموذجين بحجم <code>7</code> و<code>15</code> مليار معلمة، متوفرين علنًا ويبرعان في مهام برمجية متعددة، معتمدين على مجموعة بيانات مختارة من Stack تضم نحو <code>86</code> لغة برمجة.</p></li>
      <li><p><strong>CodeLlama</strong> (<code>codellama</code>), عائلة نماذج مبنية على بنية <code>LLaMA2</code>, تم تحسينها عبر تدريب مستمر على نحو <code>500</code> مليار رمز.</p></li>
    </ul>

    <h2 id="توليد-الشيفرة">توليد الشيفرة</h2>
    <h2 id="توليد-كود-بايثون">توليد كود بايثون</h2>
    <p>نقارن في هذا القسم أداء <code>CodeShell-7B</code> في بايثون مع نماذج مفتوحة ومغلقة. نستخدم نتائج معيار <code>HumanEval</code> (<code>codex</code>) و<code>MBPP</code>. تضم مجموعة HumanEval <code>164</code> مهمة بايثون مُصممة يدويًا مع حالات اختبار لتقييم الأداء في الوضع الصفر-شوت، بينما يتضمن معيار MBPP <code>500</code> تحديًا مع أمثلة قليلة (few-shot).</p>
    <p>أظهرت النتائج أن <code>CodeShell-7B</code> حقق دقة متوسطة تبلغ <code>34.3%</code> على HumanEval و<code>38.7%</code> على MBPP، ما يضعه في صدارة النماذج ذات الحجم المماثل، ويتفوّق على Code-LLaMA-7B وStarCoder-Base-7B، بل وعلى نماذج أكبر عددًا من المعلمات أيضًا.</p>
    <p>لا بد من الإشارة إلى أن اختيار البيانات عالية الجودة والتدريب المتكرر ساعدا <code>CodeShell</code> على تحقيق نتائج استثنائية في المهام الأساسية مثل HumanEval. ومع ذلك، قد يحتاج أداؤه في مهام أكثر تعقيدًا مثل CoderUJB إلى مزيد من التحسين لعملية اختيار البيانات والتكيف مع متطلبات الهيكل المنطقي المعقد.</p>

    <h2 id="توليد-الكود-متعدد-اللغات">توليد الكود متعدد اللغات</h2>
    <p>قيّمنا نموذجنا كذلك عبر عدة لغات باستخدام معيار <code>multiple</code> (Casano et al., 2022). أظهرت النتائج تفوّق <code>CodeShell</code> في لغات رئيسية مثل جافا سكربت، جافا، وسي++ مقارنة بـCodeLlama-7B وStarCoder-7B/15B. أما في لغات أصغر مثل دي، جوليا، ولووا، فكان الأداء أقل نظرًا لندرة البيانات عالية الجودة لتلك اللغات. ولاحظنا أن أداء <code>CodeShell</code> في بعض اللغات اقترب من مستوى StarCoder-15B، مما يدل على فعالية التصميم المعياري للنموذج الأصغر.</p>

    <h2 id="اكتمال-الكود">اكتمال الكود</h2>
    <p>أثناء التدريب المسبق، اعتمدنا تقنية Fill-In-the-Middle (<code>fim</code>) بنسبة <code>0.5</code> لتعزيز قدرة النموذج على ملء الفراغات داخل الشيفرة استنادًا إلى السياق المحيط. أوضحت تجارب مثل StarCoder-15B وCodeLlama-7B فعالية هذه التقنية. وفقًا لدراسة <code>santacoder</code>, نخفي سطرًا داخل دالة ونطلب من النموذج ملؤه، ثم نقيس الدقة المباشرة (<code>incoder</code>) باستخدام معيار <code>multiple</code> في ثلاث لغات برمجة.</p>
    <p>تظهر النتائج في الجدول [tab:results_code_completion] أن <code>CodeShell-7B</code> يتفوّق على StarCoder وCodeLlama في هذا الاختبار، مما يؤكد الدور الحاسم للبيانات عالية الجودة والتركيبة المتدرجة لطول السياق من 2048 إلى 8192 دون فقدان الكفاءة.</p>

    <h2 id="الانتباه-المتعدد-الاستعلامات-مقابل-الانتباه-المجمع-للاستعلامات">الانتباه متعدد الاستعلامات مقابل الانتباه المجمع للاستعلامات</h2>
    <p>لتقييم تأثير آليتي الانتباه متعدد الاستعلامات (MQA) والانتباه المجمع للاستعلامات (GQA)، أنشأنا نسخة صغيرة باسم “codeshell-small” مكونة من <code>24</code> طبقة، بحجم خفي <code>2048</code> ومعلمة إجمالية <code>1</code> مليار. نفذنا كل نوع انتباه كوحدة مستقلة، وأطلقنا عليهما codeshell-small-mqa وcodeshell-small-gqa. أظهرت النتائج أن الأداء كان متقاربًا في البداية، لكن مع زيادة حجم بيانات التدريب تفوّق codeshell-small-gqa على codeshell-small-mqa في مقياس الاختبار@1.</p>

    <h2 id="استبعادات-البيانات">استبعادات البيانات</h2>
    <p>لاختبار فعالية آلية التصفية، جهزنا مجموعتين: مجموعة عشوائية تضم <code>2</code> مليار رمز من البيانات غير المكررة، ومجموعة مُصفّاة تضم أعلى <code>2</code> مليار رمز تقييمًا. درّبنا نموذج “codeshell-small” على كل مجموعة، وأظهرت النتائج تفوّق المجموعة المصفاة بنسبة تقارب <code>100%</code> مقارنة بالمجموعة العشوائية، مما يؤكد الأثر الحاسم لجودة البيانات.</p>
  </section>

  <section id="الخلاصة">
    <h1>الخلاصة</h1>
    <p>في هذا التقرير الفني قدمنا نموذج الشيفرة الكبير <code>CodeShell</code>. استعرضنا تأثير التصميم المعماري واستراتيجيات التصفية على الأداء، وأثبتنا أن جودة البيانات تعتبر العامل الحاسم. بفضل اختيار بيانات عالية الجودة، حقق <code>CodeShell</code> نتائج متميزة عبر لغات برمجة متعددة. كما أظهرت آلية التصفية التي اقترحناها تحسنًا بنحو 100% مقارنة بالاختيار العشوائي، مما يؤكد فعالية نهجنا في تدريب النماذج الكبيرة.</p>
  </section>

</main>

</body>
</html>