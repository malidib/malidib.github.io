<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="author" content="Liwen Zhu, Peixi Peng, Zongqing Lu, Yonghong Tian">
  <title>MTLight: تعلم تعزيزِي متعدد المهام فعّال للتحكم في إشارات المرور</title>

  <!-- Google Font for Arabic -->
  <link href="https://fonts.googleapis.com/css2?family=Amiri&display=swap" rel="stylesheet">

  <!-- MathJax -->
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <style>
    /* Reset & Base */
    * { box-sizing: border-box; margin: 0; padding: 0; }
    body {
      font-family: 'Amiri', serif;
      font-size: 1.1rem;
      line-height: 1.8;
      color: #333;
      padding: 2em 10%;
      background: #fafafa;
    }

    /* Header */
    header {
      text-align: center;
      margin-bottom: 2em;
    }
    header h1.title {
      font-size: 2.2rem;
      margin-bottom: 0.3em;
      color: #1a237e;
    }
    .authors span {
      display: block;
      font-size: 0.95rem;
      color: #555;
    }
    .authors span.email {
      font-style: italic;
      color: #1a0dab;
    }

    /* Sections */
    section {
      margin-bottom: 2em;
    }
    h2, h1.section-title {
      font-size: 1.6rem;
      color: #303f9f;
      border-bottom: 2px solid #e0e0e0;
      padding-bottom: 0.3em;
      margin-bottom: 0.8em;
    }

    /* Paragraphs */
    p {
      margin-bottom: 1em;
      text-align: justify;
    }

    /* Lists */
    ul {
      margin: 1em 0 1em 1.5em;
      list-style-type: disc;
    }
    ul li {
      margin-bottom: 0.8em;
    }

    /* Code & Highlight */
    .nodecor {
      color: #0d47a1;
      font-weight: bold;
    }
    code {
      background: #eeeeee;
      padding: 0.2em 0.4em;
      border-radius: 4px;
      font-family: Consolas, monospace;
    }

    /* Math blocks */
    .math.display {
      display: block;
      text-align: center;
      margin: 1em 0;
    }
  </style>
</head>

<body>
  <header>
    <h1 class="title">MTLight: تعلم تعزيزِي متعدد المهام فعّال للتحكم في إشارات المرور</h1>
    <address class="authors">
      <span>Liwen Zhu، Peking University</span>
      <span class="email">liwenzhu@pku.edu.cn</span>
      <span>Peixi Peng، Peking University</span>
      <span class="email">pxpeng@pku.edu.cn</span>
      <span>Zongqing Lu، Peking University</span>
      <span class="email">zongqing.lu@pku.edu.cn</span>
      <span>Yonghong Tian، Peking University</span>
      <span class="email">yhtian@pku.edu.cn</span>
    </address>
  </header>

  <main>
    <section id="ملخص">
      <h1 class="section-title">ملخص</h1>
      <p>
        للتحكم في إشارات المرور تأثير كبير على تخفيف الازدحام المروري في المدن الحديثة. في السنوات الأخيرة، استُخدم التعلم التعزيزي العميق على نطاق واسع لهذه المهمة، حيث أظهر نتائج واعدة، لكنه واجه أيضًا عدة تحديات مثل محدودية الأداء وضعف كفاءة العينات. لمواجهة هذه التحديات، اقترحنا <span class="nodecor">MTLight</span> لتعزيز التمثيل الكامن للحالة من خلال تتبع مجموعة واسعة من مؤشرات المرور. في الوقت نفسه، بُنيت مهام مساعدة وإشرافية متعددة لتعلّم هذا التمثيل الكامن، إضافة إلى استخدام نوعين من ميزات التضمين: خاصة بالمهمة ومشتركة، لإثراء التمثيل الكامن. أظهرت التجارب الموسعة التي أُجريت على <span class="nodecor">CityFlow</span> أن <span class="nodecor">MTLight</span> يتميز بسرعة تقارب رائدة وأداء تنافسي. كما قمنا بمحاكاة ذروة حركة المرور في سيناريوهات ذات صعوبة متزايدة في التحكم، وأشارت النتائج إلى قدرة عالية على التكيف.
      </p>
    </section>

    <section id="sec:introduction">
      <h1 class="section-title">مقدمة</h1>
      <p>
        يهدف التحكم في إشارات المرور إلى تنسيق الإشارات عبر التقاطعات لتحسين كفاءة الحركة في منطقة أو مدينة، وهو عامل مهم في النقل الفعّال. ترتكز معظم الأساليب التقليدية للتحكم في الإشارات إما على جداول زمنية ثابتة (<span class="nodecor">koonce2008traffic</span>) أو على قواعد مصممة يدويًّا (<span class="nodecor">kouvelas2014maximum</span>)، وتعتمد بشكل كبير على الخبرة والتحليل المعمق للبيانات التاريخية للمرور، مما يصعّب نقلها.
      </p>
      <p>
        مؤخرًا، بدأت الأساليب المبنية على التعلم التعزيزي العميق (<span class="nodecor">DRL</span>) (<span class="nodecor">guo2021urban,jintao2020learning,pan2020spatio,he2020spatio,tong2021combinatorial,wang2020deep,gu2020exploiting,liu2021urban,xu2021hierarchically,zhang2021periodic</span>) تستخدم الشبكات العصبية العميقة لتعلم سياسات التحكم في كل تقاطع عبر التفاعل المباشر مع البيئة. ومع ذلك، تبقى المشكلة تحديًا بسبب وفرة مؤشرات المرور (عدد السيارات، طول الطابور، وقت الانتظار، السرعة، إلخ) وتعقيد الملاحظات والبيئة الديناميكية.
      </p>
      <p>
        نظرًا لأن الملاحظة والمكافأة وديناميكيات كل إشارة مرتبطة ارتباطًا وثيقًا بالإشارات الأخرى، يُمكن نمذجة التحكم في الإشارات ضمن شبكة طرق واسعة النطاق كمشكلة تعلم تعزيزي متعدد الوكلاء (<span class="nodecor">MARL</span>). اقترحت معظم الأعمال السابقة (<span class="nodecor">wei2019presslight,zhang2020generalight,chen2020toward,zheng2019learning</span>) تعلم سياسة كل وكيل بالاعتماد فقط على ملاحظات التقاطع المحلية، مع تجاهل الحالة العالمية المتاحة في المدينة الذكية.
      </p>
      <p>
        وكما ذُكر في (<span class="nodecor">zheng2019diagnosing</span>)، للمقاييس المختلفة تأثير كبير على مهمة التحكم في الإشارات. لذلك، يجب ألا يقتصر تصميم ملاحظة الوكيل على المعلومات المحلية فحسب، بل يشمل أيضًا الحالة العالمية.
      </p>
      <p>
        يمكن لتصميم ملاحظة جيد أن يستفيد بشكل كامل من العينات، محسنًا ليس فقط أداء السياسة ولكن أيضًا كفاءة العينة. ومع ذلك، توجد عدّة مؤشرات مرورية في الحالة العالمية، ويصعب اختيار ملاحظة وكيل مناسبة وغير متكررة بسبب التوازن بين الاكتفاء في التمثيل وتقليل الأبعاد.
      </p>
      <p>
        فمن ناحية، قد لا يمثل التصميم المقتصر خصائص الحالة بدقة كافية، مما يؤثر على تقدير انتقال الحالة واختيار الإجراء. ومن ناحية أخرى، إذا استخدمنا مجموعة معقدة من المؤشرات، فقد يصعب ضبط أوزانها بدقة، مما يؤدي إلى ازدواجية البيانات وزيادة الأبعاد، بالإضافة إلى استهلاك موارد حاسوبية عالية وتعقيد تعلم الوكيل.
      </p>
      <p>
        لذلك، ولتوفير تمثيل كافٍ لمهمة التحكم في الإشارات، نُقدّم مفهوم التمثيل الكامن. أولًا، نأخذ الملاحظة المحلية الأولية لكل تقاطع، ثم نُعزّز هذه الملاحظة بجزء كامن يُتعلم من الحالة العالمية. لبناء هذا الجزء الكامن، صُممت مهام مساعدة وإشرافية متعددة تتعلق بأنماط حركة المرور، حيث تعالج شبكة متكررة (<span class="nodecor">RNN</span>) تسلسلًا من إحصاءات التاريخ العالمي، ثم تتفرع لتنبؤات مختلفة مثل توزيع التدفقات ووقت السفر. ولإثراء الفضاء الكامن، تستخرج هذه البنية نوعين من ميزات التضمين: خاصة بالمهمة وعامة (مشتركة)، مما يكملهما بعضهما البعض عند تعزيز الملاحظة الأولية. أخيرًا، بناءً على الملاحظة المعززة، تُتعلم السياسة عبر (<span class="nodecor">DRL</span>) (<span class="nodecor">mnih2015human</span>)، حيث تُدرّب المهام المتعددة في آن واحد مع تعلم السياسة، مما يجعل التمثيل الكامن أكثر تكيفًا.
      </p>
    </section>

    <section id="الأعمال-ذات-الصلة">
      <h1 class="section-title">الأعمال ذات الصلة</h1>
      <p>
        يُستعرض العمل السابق في القسم <a href="#sec:related_work">[sec:related_work]</a>، ويُقدّم الأساس النظري في القسم <a href="#sec:preliminaries">[sec:preliminaries]</a>. يُوضّح القسم <a href="#sec:problem_definition">[sec:problem_definition]</a> صياغة مشكلة التعلم متعدد الوكلاء. بينما يُفصّل القسم <a href="#sec:method">[sec:method]</a> منهجية <span class="nodecor">MTLight</span>. يُقدّم القسم <a href="#sec:experiment">[sec:experiment]</a> النتائج التجريبية التي تبيّن فعالية الطريقة. وأخيرًا، يناقش القسم <a href="#sec:conclusion">[sec:conclusion]</a> الاستنتاجات والأعمال المستقبلية.
      </p>
    </section>

    <section id="sec:problem_statement">
      <h1 class="section-title">بيان المشكلة</h1>

      <h2 id="sec:problem_definition">تعريف المشكلة</h2>
      <p>
        نفترض مشكلة التحكم في إشارات المرور متعددة الوكلاء، حيث تُنمذج اللعبة كلعبة ماركوف (<span class="nodecor">Markov Game</span>) (<span class="nodecor">littman1994markov</span>)، ويمكن تمثيلها بالمعادلة
      </p>
      <div class="math display">
        \[ \mathcal{G}=\langle \mathcal{N},\mathcal{S},\mathcal{A},\mathcal{O},\mathcal{P},\mathcal{R},\mathcal{H},\gamma\rangle \]
      </div>
      <p>
        \(\mathcal{N}=\{1, \ldots, n\}\) هي مجموعة الوكلاء، بحيث يتحكم كل وكيل في تقاطع واحد. \(\mathcal{S}\) تمثل فضاء الحالة العالمي، و\(\mathcal{A}\) فضاء الأفعال لكل وكيل. يشير الفعل المشترك \(\boldsymbol{a}\in \mathbf{A}\equiv\mathcal{A}^{n}\) إلى مجموعة الأفعال الفردية \([a_i]_{i=1}^n\). في كل خطوة زمنية، يتلقى الوكيل \(i\) ملاحظة \(o_i\in\mathcal{O}\)، يختار فعلًا \(a_i\)، ثم ينتقل النظام إلى الحالة التالية \(s'\) وفقًا لدالة الانتقال \(\mathcal{P}(s'\mid s,\boldsymbol{a})\)، ويحصل كل وكيل على مكافأة \(r_i=\mathcal{R}(s,\boldsymbol{a})\). تمثل \(\mathcal{H}\) أفق الزمن و\(\gamma\in[0,1)\) عامل الخصم.
      </p>

      <h2 id="sec:agent_design">تصميم الوكيل</h2>
      <p>يتحكم في كل تقاطع وكيل مستقل. فيما يلي، نوضح تصميم الملاحظة وتصميم الفعل وتصميم المكافأة لوكيل التعلم التعزيزي:</p>
      <ul>
        <li>
          <strong>الملاحظة.</strong> تتكون ملاحظة الوكيل الأولية من جزأين: (1) عدد المركبات على كل مسار وارد \(\mathbf{f}_t^v\)؛ (2) الطور الحالي للإشارة \(\mathbf{f}_t^s\). تُعرّف الملاحظة الأولية للوكيل \(i\) بـ
          <div class="math display">
            \[ o_{i} = \{ \mathbf{f}_t^v, \mathbf{f}_t^s \}, \]
          </div>
          حيث \(\mathbf{f}_t^v = \{V_{l_{1}^{in}}, \ldots, V_{l_{m}^{in}}\}\) و\(\mathbf{f}_t^s = p_k, k\in\{1,\ldots,K\}\).
        </li>
        <li>
          <strong>الفعل.</strong> يتمثل فعل كل وكيل في اختيار الطور للفترة الزمنية التالية. يُعرّف فعل الوكيل \(i\) بـ
          <div class="math display">
            \[ a_{i} = \{ \mathbf{f}_t^s \}, \]
          </div>
          حيث \(\mathbf{f}_t^s = p_k, k\in\{1,\ldots,K\}\).
        </li>
        <li>
          <strong>المكافأة.</strong> نعّرف المكافأة بسالب مجموع أطوال الطوابير على المسارات الواردة:
          <div class="math display">
            \[ r_{i} = -\sum_{m=1}^{M} q_{l^{in}_{m}}, \]
          </div>
          حيث \(q_{l^{in}_{m}}\) طول الطابور على المسار الوارد \(l^{in}_{m}\).
        </li>
      </ul>
    </section>

    <!-- المحتوى المتبقي كما هو -->
  </main>
</body>
</html>