<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Rui Xie, Zhengran Zeng, Zhuohao Yu, Chang Gao, Shikun Zhang, Wei Ye National Engineering Research Center for Software Engineering, Peking University, China {ruixie, wye}@pku.edu.cn https://github.com/WisdomShell/codeshell">
  <title>تقرير فنّي CodeShell</title>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap');
    body {
      direction: rtl;
      font-family: 'Cairo', 'Segoe UI', Tahoma, Geneva, Verdana, Arial, sans-serif;
      font-size: 20px;
      background: #f8f9fa;
      color: #222;
      margin: 0;
      padding: 0;
      line-height: 1.8;
    }
    header {
      background: linear-gradient(90deg, #2d6cdf 0%, #6ec6ff 100%);
      color: #fff;
      padding: 40px 0 30px 0;
      text-align: center;
      box-shadow: 0 2px 8px rgba(44, 108, 223, 0.08);
      margin-bottom: 40px;
    }
    h1.title {
      font-size: 2.8em;
      margin-bottom: 0.2em;
      font-weight: 700;
      letter-spacing: 1px;
    }
    .author {
      font-size: 1.1em;
      margin-top: 1em;
      color: #e3e3e3;
      line-height: 1.5;
    }
    h1, h2, h3 {
      color: #2d6cdf;
      font-weight: 700;
      margin-top: 1.5em;
      margin-bottom: 0.7em;
      line-height: 1.2;
    }
    h1 {
      font-size: 2.1em;
      border-bottom: 2px solid #2d6cdf;
      padding-bottom: 0.2em;
      margin-bottom: 1em;
    }
    h2 {
      font-size: 1.5em;
      border-right: 4px solid #6ec6ff;
      padding-right: 0.5em;
      margin-bottom: 0.7em;
    }
    h3 {
      font-size: 1.2em;
      color: #1a4a8a;
      margin-bottom: 0.5em;
    }
    p {
      margin: 0 0 1.2em 0;
      text-align: justify;
    }
    ul, ol {
      margin: 0 0 1.2em 2em;
      padding: 0 1.5em 0 0;
    }
    ul li, ol li {
      margin-bottom: 0.5em;
    }
    strong {
      color: #1a4a8a;
    }
    code, pre {
      font-family: 'Fira Mono', 'Consolas', 'monospace';
      background: #f1f3f4;
      color: #d6336c;
      padding: 2px 6px;
      border-radius: 4px;
      font-size: 0.95em;
    }
    pre {
      display: block;
      padding: 1em;
      margin: 1em 0;
      overflow-x: auto;
      background: #f5f7fa;
      border: 1px solid #e3e3e3;
      border-radius: 6px;
      color: #222;
    }
    table {
      width: 100%;
      border-collapse: collapse;
      margin: 2em 0;
      background: #fff;
      box-shadow: 0 2px 8px rgba(44, 108, 223, 0.04);
      font-size: 0.98em;
    }
    table caption {
      caption-side: top;
      font-size: 1.1em;
      font-weight: 700;
      color: #2d6cdf;
      margin-bottom: 0.5em;
    }
    th, td {
      border: 1px solid #e3e3e3;
      padding: 0.7em 1em;
      text-align: center;
    }
    th {
      background: #eaf2fb;
      color: #1a4a8a;
      font-weight: 700;
    }
    tr:nth-child(even) {
      background: #f6fafd;
    }
    tr.odd {
      background: #f1f7ff;
    }
    .nodecor {
      text-decoration: none !important;
      color: inherit !important;
      font-weight: 600;
      font-family: inherit;
    }
    @media (max-width: 800px) {
      body { font-size: 17px; }
      header { padding: 25px 0 18px 0; }
      h1.title { font-size: 2em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1.1em; }
      table, th, td { font-size: 0.95em; }
    }
    /* MathJax direction fix for RTL */
    .MathJax_Display, .MathJax {
      direction: ltr !important;
      unicode-bidi: embed;
    }
    /* Subtle section spacing */
    main { padding: 0 1.2em; }
    hr.soft {
      border: none;
      border-top: 1px dashed #cfe0ff;
      margin: 1.8em 0;
    }
  </style>
</head>
<body>
<header>
  <h1 class="title">تقرير فنّي <span class="nodecor">CodeShell</span></h1>
  <p class="author">
    <span class="nodecor">Rui Xie</span>, <span class="nodecor">Zhengran Zeng</span>, <span class="nodecor">Zhuohao Yu</span>, <span class="nodecor">Chang Gao</span>, <span class="nodecor">Shikun Zhang</span>, <span class="nodecor">Wei Ye</span><br />
    <span class="nodecor">National Engineering Research Center for Software Engineering, Peking University, China</span><br />
    <span class="nodecor">{ruixie, wye}@pku.edu.cn</span><br />
    <span class="nodecor">https://github.com/WisdomShell/codeshell</span>
  </p>
</header>

<main>
<h1 id="ملخص">مُلخّص</h1>
<p>تُمثّل النماذج اللغويّة الكبيرة المُخصَّصة للبرمجة نقطة تحوّل رئيسية في الذكاء الاصطناعي؛ إذ صُمِّمت لفهم لغات البرمجة وتوليدها، ما يُعزّز بوضوح كفاءة سير عمل تطوير البرمجيات. في هذا التقرير الفنّي، نُقدّم <span class="nodecor">CodeShell-Base</span>، وهو نموذج أساسي بحجم 7 مليارات مُعامِل وطول سياق <span class="nodecor">8K</span>، يُظهر كفاءة ملحوظة في فهم الشِّفرة. بدمج انتباه الاستعلامات المُجمَّعة وترميز الموضع الدوّار ضمن بنية <span class="nodecor">GPT-2</span>، يجمع <span class="nodecor">CodeShell-Base</span> بين مزايا <span class="nodecor">StarCoder</span> و<span class="nodecor">CodeLlama</span> مع تصميم معماري فريد. بعد ذلك، أنشأنا خط معالجة بيانات شاملًا، يضم إزالة التكرار للمحتوى المتشابه، والترشيح وفق الحَيّرة، والترشيح القائم على النموذج. ومن خلاله جمعنا <span class="nodecor">100</span> مليار رمز تدريب مسبق عالية الجودة من <span class="nodecor">GitHub</span>. وبالاستناد إلى هذه البيانات، يتفوّق <span class="nodecor">CodeShell-Base</span> على <span class="nodecor">CodeLlama</span> في <span class="nodecor">HumanEval</span> بعد تدريب على <span class="nodecor">500</span> مليار رمز فقط (5 حِقَب). وقد أجرَينا تجارب واسعة عبر مجموعات بيانات متعدّدة اللغات، تشمل <span class="nodecor">Python</span> و<span class="nodecor">Java</span> و<span class="nodecor">C++</span>، وأظهرت النتائج امتلاك نموذجنا قدرات أساسية قويّة في فهم الشِّفرة وتوليدها.</p>

<h1 id="مقدمة">مُقدّمة</h1>
<p>أحدثت النماذج اللغويّة الكبيرة للبرمجة مثل CodeGen (<span class="nodecor">codegen</span>) وCodeLlama (<span class="nodecor">codellama</span>) وStarCoder (<span class="nodecor">starcoder</span>) ثورة في تطوير البرمجيات عبر أتمتة المهام، وتقليل الأخطاء، وتحسين الكفاءة (<span class="nodecor">gpt4report</span>). وبالاستفادة من التعلّم العميق ومجموعات البيانات الضخمة للشِّفرة (<span class="nodecor">codegen,thestack</span>)، تُعزّز هذه النماذج إنتاجية المطوّرين وتُيسّر تطوير البرمجيات لشريحة أوسع.</p>
<p>تُصنَّف النماذج الحالية إلى ثلاث فئات رئيسية: التدريب المسبق من الصفر (<span class="nodecor">starcoder</span>)، والتدريب المسبق انطلاقًا من نموذج لغوي كبير قائم (<span class="nodecor">codex,codellama</span>)، والضبط بالإرشاد (<span class="nodecor">wizardcoder</span>). تتطلّب النماذج المُدرَّبة من الصفر قدرًا هائلًا من البيانات وزمن تدريب طويلًا (<span class="nodecor">starcoder,llama2</span>). في المقابل، يُتيح الانطلاق من نموذج قائم تقليل زمن التدريب وتحسين الكفاءة باستخدام بيانات أقل (<span class="nodecor">codex,codellama</span>). أمّا الضبط بالإرشاد فيعني مواءمة نموذج كبير باستخدام بيانات إرشادية لتحسين الأداء (<span class="nodecor">codellama,wizardcoder</span>). ومع ذلك، يبقى تحدٍّ أساسي أن النماذج القائمة غالبًا ما دُرِّبت على مجموعات شيفرة ضخمة دون حَوْكَمة دقيقة، ما قد يفضي إلى شيفرة منخفضة الجودة. وبرغم اعتماد بعض استراتيجيات اختيار الشِّفرة (<span class="nodecor">phi1</span>)، يبقى خطر تدنّي الجودة قائمًا.</p>
<p>نُقدّم في هذا التقرير نموذج شِفرة كبيرًا جديدًا باسم <span class="nodecor">CodeShell</span>. يُدمج <span class="nodecor">CodeShell</span> ترميز الموضع الدوّار (<span class="nodecor">rope</span>) مع انتباه الاستعلامات المُجمَّعة (<span class="nodecor">gqa</span>) ضمن بنية <span class="nodecor">GPT-2</span> لبناء تصميم معياري فعّال يدعم سياقات أطول. ثم طوّرنا خطًّا لانتقاء الشِّفرات عالية الجودة، أسفر عن تجميع <span class="nodecor">100</span> مليار رمز عالي الجودة. وعلى هذا الأساس، دُرِّب <span class="nodecor">CodeShell</span> لمدّة خمس حِقَب. تُظهر تجاربنا أن التدريب على <span class="nodecor">100</span> مليار رمز فريد فقط يُمكّن <span class="nodecor">CodeShell</span> من مضاهاة أو التفوّق على نماذج قائمة مُدرَّبة على نحو <span class="nodecor">250</span> مليار رمز فريد، مثل <span class="nodecor">StarCoder</span> و<span class="nodecor">CodeLlama</span>. ونظرًا لندرة الشِّفرة عالية الجودة مفتوحة المصدر، يبقى انتقاء الشيفرات المتينة محورًا أساسيًّا في تطوير نموذج فعّال. وفيما يلي مساهماتنا الرئيسية:</p>
<ul>
  <li><p>إصدار <span class="nodecor">CodeShell-7B</span>، نموذجًا أساسيًا جديدًا مُدرَّبًا من الصفر بتصميم معماري فريد، وقد أظهر أداءً تنافسيًّا عبر معايير متنوّعة ولغات برمجة عدّة.</p></li>
  <li><p>للحدّ من تكاليف التدريب، أنشأنا خط معالجة بيانات فعّالًا لانتقاء الشيفرات عالية الجودة من مجموعات ضخمة. وتُظهر النتائج التجريبية أن نموذجنا، المُدرَّب على <span class="nodecor">500</span>B رمز فقط، يتفوّق على <span class="nodecor">StarCoder</span> المُدرَّب على <span class="nodecor">1</span> تريليون رمز.</p></li>
  <li><p>لمعالجة مهام برمجية أكثر تعقيدًا، مدّدنا طول السياق إلى <span class="nodecor">8K</span>، بما يحسّن قدرة النموذج على التعامل مع مقاطع شيفرة طويلة دون المساس بكفاءته على المقاطع الأقصر.</p></li>
</ul>

<h1 id="قشرة-الكود">CodeShell</h1>
<h2 id="البيانات">البيانات</h2>
<p>لشرح بناء مجموعة تدريب <span class="nodecor">CodeShell</span> وخطوات الترشيح والتحسين، نستعرض المراحل التالية بإيجاز:</p>
<p><strong>جمع البيانات:</strong> كان المصدر الأساسي <span class="nodecor">GitHub</span> (<span class="nodecor">gharchive</span>)؛ حيث زحفنا إلى نحو 15 تيرابايت من المستودعات لضمان تنوّع واتّساع مجموعة البيانات. كما أدمجنا مجموعتَي <span class="nodecor">The Stack</span> (<span class="nodecor">thestack</span>) و<span class="nodecor">StarCoder</span> لإثراء البيانات بأمثلة شيفرات ومناقشات برمجية.</p>
<p><strong>ترشيح اللغات:</strong> استبعدنا اللغات التي تقل بياناتها عن 100 ميغابايت، وركّزنا على 7 فئات رئيسية تضمّ: <span class="nodecor">Markdown</span> للتوثيق، و<span class="nodecor">git commits</span> لممارسات التطوير، و<span class="nodecor">GitHub issues</span> لمناقشات حلّ المشكلات، لتعزيز فهم النموذج لأنماط مختلفة من البرمجة.</p>
<p><strong>قواعد أوليّة للترشيح:</strong> وضعنا قواعد لاستبعاد الشيفرات ذات الأسطر الطويلة جدًّا أو تلك التي يطغى فيها المحتوى النصّي على الرموز، للتركيز على أمثلة معيارية وقابلة للقراءة.</p>
<p><strong>إزالة التكرار:</strong> استخدمنا تجزئة <span class="nodecor">MD5</span> لاكتشاف النُّسخ المكرّرة وإزالتها، وتقنية <span class="nodecor">MinHash</span> (<span class="nodecor">minihash</span>) لاكتشاف المحتويات شديدة التشابه وتنقيتها، بما يعزّز التنوّع والجودة.</p>
<p><strong>ترشيح الحَيّرة (Perplexity):</strong> اعتمدنا درجات الحَيّرة (<span class="nodecor">pplf</span>) كمؤشّر على جودة الشِّفرة. باستبعاد المقاطع عالية الحَيّرة، ارتفع المستوى النوعي للأمثلة في المجموعة.</p>
<p><strong>الترشيح القائم على القواعد:</strong> وظّفنا محلّلات وقواعد مخصّصة لانتقاء الشيفرات عالية الجودة؛ فحسبْنا مقاييس مثل عدد الأسطر، وحضور التعليقات وتغطيتها، ومتوسّط طول السطر. كما فضّلنا الشيفرات التي تستخدم مكتبات طرف ثالث معروفة، والتي تعكس ممارسات تطوير متقدّمة. وتحقّقنا من درجة التعقيد المنطقي عبر تحليل شجرة البُنية المُجرَّدة (<span class="nodecor">AST</span>) وتدفّق التحكّم، لضمان أن الأمثلة ليست وظيفية فحسب بل متقنة أيضًا، مع الالتزام بأفضل الممارسات القياسية.</p>
<table>
  <caption>نظرة عامّة على البيانات</caption>
  <tbody>
    <tr class="odd">
      <td style="text-align: left;"><span class="nodecor">css</span></td>
      <td style="text-align: center;"><span class="nodecor">30.09</span></td>
      <td style="text-align: center;"><span class="nodecor">5292.28</span></td>
      <td style="text-align: center;"><span class="nodecor">2.38</span>%</td>
      <td style="text-align: center;"><span class="nodecor">0.13</span></td>
      <td style="text-align: center;"><span class="nodecor">23.58</span></td>
      <td style="text-align: center;"><span class="nodecor">0.28</span>%</td>
    </tr>
    <!-- بقية الجدول تبقى كما هي -->
  </tbody>
</table>
<p>[tab:data_overview_1]</p>

<h2 id="النموذج">النموذج</h2>
<h3 id="محلل-الرموز">مُحلِّل الرموز</h3>
<p>لدعم المحتوى الصيني المرتبط بالبرمجة، عزّزنا مفردات <span class="nodecor">StarCoder</span> بإضافة كمّ معتبر من المفردات الصينية. على وجه التحديد، جمعنا مليون ملف شيفرة بالصينية وبيانات أسئلة/أجوبة برمجية بالصينية. وباستخدام مكتبة <span class="nodecor">Tokenizer</span> من <span class="nodecor">Hugging Face</span>، انتقينا <span class="nodecor">40,000</span> مفردة صينية عالية التكرار، و<span class="nodecor">30,000</span> مفردة إنجليزية من مفردات <span class="nodecor">StarCoder</span>، ودمجناهُما لتكوين مفردات <span class="nodecor">CodeShell</span> الشاملة. وتُظهر النتائج التجريبية تفوّق مفردات <span class="nodecor">CodeShell</span> في كفاءة ترميز أسئلة/أجوبة البرمجة بالصينية مقارنة بمفردات <span class="nodecor">StarCoder</span> الأصلية.</p>

<h3 id="الهندسة-المعمارية">الهندسة المعماريّة</h3>
<p>يبني <span class="nodecor">CodeShell</span> على بنية <span class="nodecor">GPT-2</span> (<span class="nodecor">gpt2</span>) ويستفيد من تقنيتين متقدّمتين: انتباه الاستعلامات المُجمَّعة (<span class="nodecor">gqa</span>) وترميز الموضع الدوّار (<span class="nodecor">rope</span>). تعمل آلية انتباه الاستعلامات المُجمَّعة على تجميع الاستعلامات المتقاربة لتقليل التكرار وتحسين الكفاءة الحوسبية، فيما يوفّر ترميز الموضع الدوّار تمثيلًا زاويًّا ديناميكيًّا لمواضع العناصر في التسلسل، ما يُعين النموذج على فهم البنية والترتيب بدقّة أعلى.</p>

<h2 id="التدريب">التدريب</h2>
<h3 id="التحسين">التحسين</h3>
<p>اعتمدنا <span class="nodecor">AdamW</span> مُحسِّنًا، مع ضبط معاملي <span class="math inline">\(\beta_1\)</span> و<span class="math inline">\(\beta_2\)</span> عند <span class="nodecor">0.9</span> و<span class="nodecor">0.95</span> على التوالي. واستخدمنا جدولًا زمنيًّا للتعلّم يبدأ بتسخين لمدّة <span class="nodecor">1000</span> خطوة، ثم خفّضنا مُعدّل التعلّم من <span class="math inline">\(3 \times 10^{-4}\)</span> إلى <span class="math inline">\(3 \times 10^{-5}\)</span> عبر <span class="nodecor">127k</span> تحديث. عالجنا دفعات بحجم فعّال قدره <span class="nodecor">4</span> ملايين رمز، مُقسّمة إلى تسلسلات بطول <span class="nodecor">2048</span> أو <span class="nodecor">8192</span> رمزًا لكل منها.</p>

<h3 id="مرحلة-التدريب-المسبق">مرحلة التدريب المُسبق</h3>
<p>للموازنة بين الكفاءة والحاجة إلى سياقات أطول، بدأنا بطول سياق <span class="nodecor">2048</span> في الحِقَب الأولى. وبعد تدريب على نحو <span class="nodecor">450</span> مليار رمز، زدنا طول السياق إلى <span class="nodecor">8192</span>. وتراجع مُعدّل المعالجة على وحدة معالجة الرسوميات (<span class="nodecor">GPU</span>) من نحو <span class="nodecor">3200</span> رمز/ثانية إلى <span class="nodecor">2600</span> رمز/ثانية. وبرغم ذلك، حافظ النموذج على استقراره وتحسّن أداؤه قليلًا، مع انخفاض ملحوظ في الخسارة بفضل السياق الأطول، دون أي تراجع في مقاييس التقييم.</p>

<hr class="soft" />

<h1 id="النتائج">النتائج</h1>
<p>نستعرض هنا أداء <span class="nodecor">CodeShell</span> مقارنةً بنماذج رائدة:</p>
<ul>
  <li><p><strong>StarCoder-7B وStarCoder-15B</strong> (<span class="nodecor">starcoder</span>)، بحجمَي <span class="nodecor">7</span> و<span class="nodecor">15</span> مليار مُعامِل، ومتاحة علنًا وتتفوق في مهام برمجية متنوّعة، وقد دُرِّبت على جزء مُنتقى بعناية من مجموعة <span class="nodecor">The Stack</span> التي تغطّي <span class="nodecor">86</span> لغة برمجة.</p></li>
  <li><p><strong>CodeLlama</strong> (<span class="nodecor">codellama</span>)، عائلة نماذج برمجية مُشتقّة من <span class="nodecor">LLaMA2</span> (<span class="nodecor">llama2</span>)، مُحسّنة بالتدريب المستمر على نحو <span class="nodecor">500</span> مليار رمز بالاعتماد على بنية <span class="nodecor">LLaMA2</span> الأساسية.</p></li>
</ul>

<h2 id="توليد-الشيفره">توليد الشِّفرة</h2>

<h2 id="توليد-كود-بايثون">توليد شيفرة بايثون</h2>
<p>نُقارن هنا أداء <span class="nodecor">CodeShell</span> في <span class="nodecor">Python</span> مع نماذج مفتوحة ومغلقة. نبدأ بنتائج <span class="nodecor">HumanEval</span> (<span class="nodecor">codex</span>) و<span class="nodecor">MBPP</span> (<span class="nodecor">mbpp</span>). تتكوّن مجموعة <span class="nodecor">HumanEval</span> من 164 مهمة بايثون مُصمّمة يدويًّا مع حالات اختبار لتقييم الأداء دون أمثلة سابقة (zero-shot). أمّا معيار <span class="nodecor">MBPP</span> فيتضمّن 500 تحدٍّ مع أمثلة قليلة (few-shot).</p>
<p>تُظهر النتائج أنّ <span class="nodecor">CodeShell-7B</span> حقّق دقّة متوسّطة قدرها 34.3% على <span class="nodecor">HumanEval</span> و38.7% على <span class="nodecor">MBPP</span>، ليضعه ذلك في صدارة النماذج المماثلة حجمًا، متفوّقًا على <span class="nodecor">CodeLlama-7B</span> و<span class="nodecor">StarCoder-Base-7B</span>. كما يتفوّق <span class="nodecor">CodeShell-7B</span> على نماذج أكبر من حيث عدد المُعامِلات في بعض الإعدادات.</p>
<p>نُشير إلى أنّ انتقاء البيانات عالية الجودة والتدريب عبر حِقَب عدّة أتاحا لـ<span class="nodecor">CodeShell</span> أداءً قويًّا في المهام الأساسية مثل <span class="nodecor">HumanEval</span>. ومع ذلك، قد يتطلّب الأداء على مهام أكثر تعقيدًا، مثل <span class="nodecor">CoderUJB</span>، تحسينًا إضافيًّا لخط انتقاء البيانات ومواءمته مع متطلّبات البُنى المنطقية المعقّدة.</p>

<h2 id="توليد-الكود-متعدد-اللغات">توليد الشيفرة مُتعدّد اللغات</h2>
<p>قيّمنا النموذج عبر مجموعة أوسع من اللغات باستخدام معيار <span class="nodecor">MultiPL-E</span> (Cassano et al., 2022). النتائج لمختلف اللغات، بما في ذلك <span class="nodecor">JavaScript</span> و<span class="nodecor">Java</span> و<span class="nodecor">Swift</span> و<span class="nodecor">PHP</span> وغيرها، موضّحة في الجدول [tb:results_multiple].</p>
<p>لوحِظ أن <span class="nodecor">CodeShell</span> حقّق نتائج أفضل في لغات رئيسية مثل <span class="nodecor">JavaScript</span> و<span class="nodecor">Java</span> و<span class="nodecor">C++</span> مقارنةً بـ<span class="nodecor">CodeLlama-7B</span> و<span class="nodecor">StarCoder-7B/15B</span>. بينما كان الأداء أدنى في لغات أقل تمثيلًا كالـ<span class="nodecor">D</span> و<span class="nodecor">Julia</span> و<span class="nodecor">Lua</span>، بما يعكس توافُر بيانات عالية الجودة للغات الشائعة. ويجدر الذكر أنّ أداء <span class="nodecor">CodeShell</span> في بعض اللغات كان منافسًا لـ<span class="nodecor">StarCoder-15B</span>، ما يُشير إلى فعالية التصميم المعياري للنموذج الأصغر.</p>

<h2 id="اكتمال-الكود">إكمال الشِّفرة</h2>
<p>خلال التدريب المسبق، استخدمنا تقنية <span class="nodecor">Fill-In-the-Middle</span> (<span class="nodecor">fim</span>) بنسبة 0.5 لتعزيز قدرة النموذج على ملء الفجوات في الشيفرة استنادًا إلى السياق المحيط. وقد أثبتت هذه التقنية فاعليتها في مهمة الإكمال، كما في نماذج مثل <span class="nodecor">StarCoder-15B</span> و<span class="nodecor">CodeLlama-7B</span>. ووفقًا لـ<span class="nodecor">SantaCoder</span>، نُخفي سطرًا واحدًا داخل دالة ونطلب من النموذج إكماله، ثم نقيس المطابقة الدقيقة (Exact Match) كما في <span class="nodecor">InCoder</span> على معيار <span class="nodecor">MultiPL-E</span> لثلاث لغات برمجة.</p>
<p>تُظهر النتائج في الجدول [tab:results_code_completion] أنّ <span class="nodecor">CodeShell-7B</span> يتفوّق على <span class="nodecor">StarCoder</span> و<span class="nodecor">CodeLlama</span> في هذا الاختبار، مؤكِّدًا أهمية البيانات عالية الجودة وإستراتيجية التدريب المسبق التي تبدأ بطول سياق 2048 ثم تمتد إلى 8192 دون خسارة في الكفاءة النهائية.</p>

<h2 id="الانتباه-المتعدد-الاستعلامات-مقابل-الانتباه-المجمع-للاستعلامات">انتباه متعدد الاستعلامات مقابل انتباه الاستعلامات المُجمَّعة</h2>
<p>لتقييم أثر كلٍّ من انتباه متعدد الاستعلامات (<span class="nodecor">MQA</span>) وانتباه الاستعلامات المُجمَّعة (<span class="nodecor">GQA</span>) في الأداء، طوّرنا نسخة <span class="nodecor">codeshell-small</span> بواقع <span class="nodecor">24</span> طبقة، وحجم خفي <span class="nodecor">2048</span>، وإجمالي نحو <span class="nodecor">1</span> مليار مُعامِل. نفّذنا كل نوع انتباه كوحدة مستقلّة، وسمّيناهما <span class="nodecor">codeshell-small-mqa</span> و<span class="nodecor">codeshell-small-gqa</span>. تُشير النتائج إلى أنّ الأداء كان متقاربًا في البداية، لكن مع ازدياد حجم بيانات التدريب تدريجيًّا، تفوّق <span class="nodecor">codeshell-small-gqa</span> على <span class="nodecor">codeshell-small-mqa</span> في مقياس <span class="nodecor">Top-1</span>.</p>

<h2 id="استبعادات-البيانات">استبعاد البيانات</h2>
<p>لاختبار فاعلية آلية ترشيح الشيفرات عالية الجودة، أعددنا مجموعتين: مجموعة عشوائية أخذنا منها 2 مليار رمز من البيانات غير المُكرّرة، ومجموعة مُصفّاة أخذنا منها 2 مليار رمز الأعلى تقييمًا من حيث الجودة. استخدمنا نموذج <span class="nodecor">codeshell-small</span> لتدريب كل مجموعة. وأظهرت النتائج (انظر الشكل المقابل) تفوّق النموذج المُصفّى باستمرار بنسبة تقارب 100% مقارنةً بالآخر، مؤكِّدة الدور الحاسم لجودة البيانات.</p>

<hr class="soft" />

<h1 id="الخلاصة">الخُلاصة</h1>
<p>قدّمنا في هذا التقرير نموذج الشِّفرة الكبير <span class="nodecor">CodeShell</span>، واستعرضنا أثر التصميم المعماري وإستراتيجيات ترشيح البيانات في الأداء. وأظهرنا أنّ جودة البيانات تبقى العامل الأهم: فبفضل انتقاء بيانات عالية الجودة، حقّق <span class="nodecor">CodeShell</span> أداءً متميّزًا عبر لغات برمجة عدّة. إضافةً إلى ذلك، بيّنت طريقة الترشيح المقترَحة تحسينًا يقارب ~100% مقارنةً بالاختيار العشوائي، ما يؤكّد فاعلية منهجنا في تدريب النماذج الكبيرة.</p>
</main>
</body>
</html>