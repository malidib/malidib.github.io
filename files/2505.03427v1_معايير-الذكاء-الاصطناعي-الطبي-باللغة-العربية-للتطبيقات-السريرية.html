<!DOCTYPE html>
<html lang="ar">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MedArabiQ: تقييم النماذج اللغوية الضخمة في المهام الطبية العربية</title>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        body {
            font-family: 'Times New Roman', serif;
            line-height: 1.7;
            color: #333;
            background-color: #fafafa;
            direction: rtl;
        }
        .container {
            max-width: 920px;
            background-color: #fff;
            box-shadow: 0 0 12px rgba(0,0,0,0.08);
            padding: 42px;
            margin: 24px auto;
            border-radius: 8px;
        }
        h1 {
            text-align: center;
            font-size: 2.15em;
            margin-bottom: 28px;
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 14px;
        }
        h2 {
            color: #34495e;
            font-size: 1.5em;
            margin-top: 34px;
            margin-bottom: 14px;
            border-right: 4px solid #3498db;
            padding-right: 10px;
        }
        h3 {
            color: #5d6d7e;
            font-size: 1.25em;
            margin-top: 24px;
            margin-bottom: 10px;
        }
        p {
            text-align: justify;
            margin-bottom: 14px;
        }
        .abstract {
            background-color: #f8f9fa;
            border-right: 4px solid #007bff;
            padding: 20px;
            margin: 28px 0;
            font-style: italic;
            border-radius: 6px;
        }
        .keywords {
            background-color: #e9ecef;
            padding: 12px 14px;
            margin: 18px 0;
            border-radius: 5px;
        }
        .equation {
            text-align: center;
            margin: 18px 0;
            padding: 14px;
            background-color: #f8f9fa;
            border-radius: 5px;
        }
        .figure, .figure* {
            text-align: center;
            margin: 26px 0;
            padding: 18px;
            background-color: #f8f9fa;
            border-radius: 6px;
            border: 1px solid #dee2e6;
        }
        .table, .table* {
            margin: 22px 0;
            padding: 10px 12px;
            background-color: #fdfdfd;
            border: 1px dashed #e1e5ea;
            border-radius: 6px;
        }
        .reference {
            font-size: 0.9em;
            margin-bottom: 8px;
        }
        .meta-info {
            background-color: #e7f3ff;
            padding: 14px;
            margin-bottom: 28px;
            border-radius: 6px;
            font-size: 0.9em;
            direction: ltr;
            text-align: left;
        }
        nav#TOC ul {
            list-style: none;
            padding-right: 0;
        }
        nav#TOC ul li {
            margin: 6px 0;
        }
        nav#TOC a {
            text-decoration: none;
            color: #2c3e50;
        }
        nav#TOC a:hover {
            color: #0d6efd;
        }
        code {
            background-color: #f8f9fa;
            padding: 2px 4px;
            border-radius: 3px;
        }
        pre {
            background-color: #f8f9fa;
            padding: 14px;
            border-radius: 5px;
            overflow-x: auto;
        }
        blockquote {
            border-right: 4px solid #6c757d;
            padding-right: 18px;
            font-style: italic;
            color: #6c757d;
            background: #fcfcfc;
            border-radius: 6px;
        }
        .theorem, .lemma, .proposition, .corollary {
            background-color: #fff3cd;
            border: 1px solid #ffeaa7;
            padding: 14px;
            margin: 18px 0;
            border-radius: 6px;
        }
        .proof {
            border-right: 2px solid #28a745;
            padding-right: 14px;
            margin: 14px 0;
            background: #f9fffa;
            border-radius: 6px;
        }
        hr {
            border-top: 1px solid #e9ecef;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="meta-info">
            <strong>ArXiv ID:</strong> 2505.03427v1<br>
            <strong>LaTeX الأصلي:</strong> <code>./nyuad_arxiv_papers/nyuad_papers_comprehensive/source_code/2505.03427v1_extracted/main_arxiv_version.tex</code><br>
            <strong>تاريخ التحويل:</strong> 2025-06-06 13:15:53
        </div>
        <header id="title-block-header">
            <h1 class="title">MedArabiQ: تقييم النماذج اللغوية الضخمة في المهام الطبية العربية</h1>
            <p class="author">
            جامعة نيويورك أبوظبي، الإمارات العربيّة المتّحدة<br>
            <span class="math inline">\(^\dagger\)</span> مُساهماتٌ متساوية
            </p>
            <p class="date">نوفمبر 2024</p>
            <div class="abstract">
                <div class="abstract-title">الملخّص</div>
                <p>
النماذج اللغوية الضخمة (LLMs) أظهرت إمكاناتٍ كبيرة في تطبيقات الرعاية الصحيّة المتنوّعة. غير أنّ فاعليتها في المجال الطبي العربي لا تزال غير مُستكشفةٍ بما يكفي بسبب نقص مجموعات البيانات المتخصّصة عالية الجودة والمعايير المرجعية الملائمة. نقدّم في هذه الدراسة MedArabiQ، وهو معيارٌ مرجعي جديد يتألّف من سبع مهام طبية باللغة العربية، تغطّي تخصّصاتٍ متعدّدة وتشمل أسئلة اختيارٍ من متعدّد، وأسئلة إكمال الفراغ، وحوارات تفاعلية بين المريض والطبيب. قمنا أوّلاً ببناء مجموعة البيانات بالاعتماد على اختباراتٍ طبية سابقة ومصادر عامة متاحة. ثم أعدنا صياغة جزءٍ منها بطرائق مختلفة لتقييم قدرات النماذج، بما في ذلك تقنيات الحدّ من التحيّز. أجرينا تقييماً شاملاً باستخدام خمسةٍ من أحدث النماذج اللغوية المفتوحة والمملوكة، من بينها GPT-4o وClaude 3.5-Sonnet وGemini 1.5. تؤكّد نتائجُنا الحاجةَ إلى تطوير معايير مرجعية عالية الجودة ومتعدّدة اللغات لضمان عدالة النشر وتوسيع استخدام النماذج اللغوية في الرعاية الصحيّة. ومن خلال إنشاء هذا المعيار وإتاحة مجموعة البيانات، نوفر أساساً لأبحاثٍ مستقبلية تُعنى بتقييم وتعزيز القدرات مُتعدّدة اللغات للنماذج اللغوية من أجل استخدامٍ عادلٍ للذكاء الاصطناعي التوليدي في القطاع الصحي.
                </p>
            </div>
        </header>
        <nav id="TOC" role="doc-toc">
            <ul>
                <li><a href="#sec:intro">المقدّمة</a></li>
                <li><a href="#related-work">الأعمال ذات الصلة</a></li>
                <li><a href="#methodology">المنهجيّة</a>
                    <ul>
                        <li><a href="#tasks-and-datasets">المهام ومجموعات البيانات</a>
                            <ul>
                                <li><a href="#multiple-choice-questions">أسئلة اختيار من متعدّد</a></li>
                                <li><a href="#multiple-choice-questions-with-bias">أسئلة اختيار من متعدّد مع تحيّز</a></li>
                                <li><a href="#fill-in-the-blank-with-choices">إكمال الفراغ مع خيارات</a></li>
                                <li><a href="#fill-in-the-blank-without-choices">إكمال الفراغ من دون خيارات</a></li>
                                <li><a href="#patient-doctor-qa">أسئلة وأجوبة بين المريض والطبيب</a></li>
                                <li><a href="#qa-with-grammatical-error-correction-gec">أسئلة وأجوبة مع تصحيح الأخطاء النحوية</a></li>
                                <li><a href="#qa-with-llm-modifications">أسئلة وأجوبة مع تعديلات النماذج اللغوية</a></li>
                            </ul>
                        </li>
                        <li><a href="#models">النماذج</a></li>
                        <li><a href="#evaluation">التقييم</a></li>
                        <li><a href="#bias-assessment-and-mitigation">تقييم التحيّز والحدّ منه</a></li>
                    </ul>
                </li>
                <li><a href="#experimental-setup">إعداد التجارب</a></li>
                <li><a href="#results">النتائج</a></li>
                <li><a href="#discussion">المناقشة</a></li>
                <li><a href="#ethical-considerations">اعتبارات أخلاقية</a></li>
                <li><a href="#limitations-and-future-work">القيود والعمل المستقبلي</a></li>
                <li><a href="#conclusion">الخلاصة</a></li>
                <li><a href="#related-work-1">الأعمال ذات الصلة</a></li>
                <li><a href="#appendix-b">نظرة عامة على مجموعة البيانات</a></li>
                <li><a href="#model-overview">نظرة عامة على النماذج</a></li>
                <li><a href="#prompts-by-task">المحفّزات حسب المهمة</a></li>
                <li><a href="#bias-evaluation">تقييم التحيّز</a></li>
                <li><a href="#performance-by-bias-category">الأداء حسب فئة التحيّز</a></li>
                <li><a href="#performance-by-question-category">الأداء حسب فئة السؤال</a></li>
            </ul>
        </nav>
        <section id="data-and-code-availability" class="level4 unnumbered">
            <h4 class="unnumbered">توفر البيانات والكود البرمجي</h4>
            <p>
في هذا العمل، نقدّم مجموعة بياناتٍ معيارية جديدة باسم MedArabiQ ونقيّم أداء أحدث النماذج اللغوية الضخمة. نوفر بياناتنا لضمان إمكانيّة إعادة التجارب وتحقيق تقييمٍ عادل للنماذج مستقبلاً: <a href="https://github.com/nyuad-cai/MedArabiQ" class="uri">https://github.com/nyuad-cai/MedArabiQ</a>
            </p>
        </section>
        <section id="institutional-review-board-irb" class="level4 unnumbered">
            <h4 class="unnumbered">موافقة لجنة الأخلاقيات (IRB)</h4>
            <p>
لا تتضمّن هذه الدراسة مشاركين بشريين، لذا لم تكن هناك حاجةٌ للحصول على موافقة لجنة الأخلاقيات.
            </p>
        </section>
        <section id="sec:intro" class="level1">
            <h1>المقدّمة</h1>
            <p>
شهدت السنواتُ الأخيرة ثورةً في معالجة اللغة الطبيعية بفضل ظهور النماذج اللغوية الضخمة (LLMs)، حيث أظهرت أداءً استثنائياً في مهام عديدة مثل الترجمة والكتابة الإبداعية <span class="citation" data-cites="mdpi2023"></span>. ورغم أنّ هذه النماذج صُمِّمت في البداية لفهم اللغة عموماً، فقد جرى تقييمُها لاحقاً في تطبيقاتٍ متخصّصة كالتعليم والبرمجة والفنون والطب، كما تم تكييفُها لمهامّ تخصصية عبر استراتيجيات الضبط الدقيق ومجموعات بياناتٍ متخصّصة <span class="citation" data-cites="arxiv2023"></span>.
            </p>
            <p>
أثار استخدامُ النماذج اللغوية الضخمة في الرعاية الصحيّة اهتماماً واسعاً نظراً لإمكاناتها في تحسين التشخيص واتخاذ القرار السريري وجودة رعاية المرضى <span class="citation" data-cites="mdpi2023 sciencedirect2024"></span>. ومن التطبيقات البارزة كذلك التعليمُ الطبي، حيث يمكن لهذه النماذج توليدُ ملخصاتٍ دقيقة ودعمُ التعلّم التفاعلي <span class="citation" data-cites="oup2023"></span>. ولهذا الغرض، اقتُرحت معاييرُ مرجعية لتقييم قدرات النماذج في المعرفة الطبية والاستدلال. ومع ذلك، ما تزال تحدياتٌ قائمة مثل المسائل الأخلاقية، ومخاطر إنتاج محتوى مُتحيّز أو ضار، وتفاوت الأداء بين اللغات والسياقات الثقافية <span class="citation" data-cites="wiley2024 mdpi2023"></span>.
            </p>
            <p>
تستهدف المعايير المرجعية الحالية مثل GLUE وMedQA اللغة الإنجليزية بالدرجة الأولى، مما يترك فجوةً كبيرة في تقييم النماذج اللغوية للمهام الطبية العربية <span class="citation" data-cites="nature2024"></span>. ويعود ذلك إلى أسبابٍ عدّة، منها قلّة توافر مجموعات بياناتٍ عربية عالية الجودة للتطبيقات السريرية، بالإضافة إلى التعقيد اللغوي للعربية وتعدّد لهجاتها (الخليج، المغرب العربي، مصر، الشام، وغيرها) إلى جانب العربية الفصحى <span class="citation" data-cites="acl2018"></span>. كما أنّ أداء النماذج متعدّدة اللغات التي تتضمّن العربية في بيانات تدريبها غالباً ما يكون دون المستوى في السياقات الطبية بسبب نقص الموارد المتخصّصة والمعايير المرجعية المناسبة <span class="citation" data-cites="mdpi2023 arxiv2024"></span>. إنّ معالجة هذه الفجوات أمرٌ ضروري لتحقيق الاستفادة الكاملة من النماذج اللغوية لصالح المرضى ومقدّمي الرعاية الناطقين بالعربية وضمان عدالة الوصول إلى تقنيات الذكاء الاصطناعي في الصحّة.
            </p>
            <p>
استجابةً لهذه التحديات، تبرز الحاجة إلى أُطر عملٍ لتقييم أداء النماذج اللغوية في المهام السريرية الخاصة بالمجتمعات الناطقة بالعربية. ومن خلال تطوير معايير تعكس التفاعلات السريرية الواقعية، يمكن ضمان نشرٍ أكثر موثوقيّة وملاءمةٍ ثقافية لهذه النماذج في أنظمة الرعاية الصحية مُتعدّدة اللغات. في هذه الدراسة، نقدّم عدّة مساهمات رئيسية عبر طرح MedArabiQ (انظر الشكل <a href="#fig:overview" data-reference-type="ref" data-reference="fig:overview">[fig:overview]</a>). أولاً، طوّرنا سبع مجموعات بياناتٍ معيارية لتقييم النماذج في تطبيقات الرعاية الصحيّة العربية، مع مراعاة التعقيد اللغوي والتحدّيات التخصّصية. ركّزنا على مهام طبية حاسمة مثل الإجابة عن الأسئلة الطبية، والحوار السريري، واتخاذ القرار الأخلاقي. ثانياً، حلّلنا أداء النماذج متعدّدة اللغات والنماذج العربية، مع إبراز أثر التغطية اللغوية وشفافية بيانات التدريب على التطبيقات الصحية. وقد أجرينا تقييماً شاملاً يقدّم أساساً متيناً لتطوير حلول الذكاء الاصطناعي في المهام الطبية العربية.
            </p>
            <div class="figure*">
                <p><img src="figures/fig1-arx.png" style="width:92.0%" alt="مخطط نظرة عامة على معيار MedArabiQ" /></p>
            </div>
        </section>
        <section id="related-work" class="level1">
            <h1>الأعمال ذات الصلة</h1>
            <p>
اقتُرحت معاييرُ مرجعية عديدة لتقييم أداء النماذج اللغوية في المهام الطبية، وغالباً ما تركّز على الإنجليزية. على سبيل المثال، قدّم <span class="citation" data-cites="GAO2023104286"></span> معيار Dr. Bench، وهو معيارٌ للاستدلال التشخيصي في معالجة اللغة السريرية يركّز على فهم النصوص الطبية واستدلال المعرفة الطبية وتوليد التشخيصات. يجمع هذا المعيار بياناتٍ بالإنجليزية من مصادر متنوّعة، لكنه يعتمد أساساً على ملاحظاتٍ سريرية داخل المستشفيات. ولتقييم أداء النماذج في مهام الإجابة عن الأسئلة الطبية، جرى تضمين عينات من اختبارات المجالس الطبية مثل MedQA، الذي يدعم التقييم متعدّد اللغات عبر إدراج أسئلة بالصينية التقليدية والمبسّطة والإنجليزية <span class="citation" data-cites="jin2020diseasedoespatienthave"></span>. كما يستخدم معيار MMLU أسئلةً من اختبار الترخيص الطبي الأمريكي <span class="citation" data-cites="hendrycks2021measuringmassivemultitasklanguage"></span>، بينما يوسّع MedMCQA هذه المعايير إلى إطار تقييمٍ متعدّد اللغات <span class="citation" data-cites="pal2022medmcqa"></span>.
            </p>
            <p>
رغم الاهتمام المتزايد بمعالجة اللغة العربية، تبقى المعايير الطبية العربية محدودة. فقد ترجم <span class="citation" data-cites="achiam2023gpt"></span> معيار MMLU إلى 14 لغة من بينها العربية بمساعدة مترجمين محترفين. ويركّز AraSTEM على مهمة الإجابة عن الأسئلة وله جزءٌ طبي <span class="citation" data-cites="mustapha2024arastemnativearabicmultiple"></span>. كما يقدّم AraMed مجموعةَ بياناتٍ طبية عربية مُشَرَّحة <span class="citation" data-cites="alasmari2024"></span>. ومعظم هذه المجموعات تركّز على مهمة الإجابة عن الأسئلة الطبية وغالباً ما تعاني قصوراً أخرى، كما هو موضّح في الجدول <a href="#table:dataset_comparison" data-reference-type="ref" data-reference="table:dataset_comparison">[table:dataset_comparison]</a>. وعلى الرغم من فائدتها، إلا أنها لا تغطّي طيف المهام الطبية العربية بشكلٍ شامل، مما يبرز الحاجة إلى جهودٍ معيارية مُتخصّصة.
            </p>
            <p>
في ما يتعلّق بالتقييم، اقتُرحت أُطرٌ متعدّدة لتقييم نماذج الذكاء الاصطناعي السريرية. يتكوّن "نموذج الحوكمة للذكاء الاصطناعي في الرعاية الصحيّة" من أربع ركائز رئيسية: العدالة، الشفافية، الموثوقيّة، والمساءلة <span class="citation" data-cites="Reddy2020491"></span>. كما اقترح <span class="citation" data-cites="dada2024doesbiomedicaltraininglead"></span> إطارَ تقييمٍ لفهم اللغة السريرية يقيّم النماذج باستخدام بيانات مرضى حقيقية لمهامّ متنوّعة مثل الإجابة عن الأسئلة، واستخلاص الفرضيات، وتلخيص المشكلات والاستفسارات. وقدّم <span class="citation" data-cites="kanithi2024"></span> إطار "MEDIC" لتقييم النماذج عبر خمس فئاتٍ سريرية: الاستدلال الطبي، القضايا الأخلاقية والتحيّز، فهم البيانات واللغة، التعلّم في السياق، والسلامة السريرية وتقييم المخاطر. ورغم التقدّم الكبير في هذا المجال، فإنّ معظم التقييمات أُجرِيَت على بياناتٍ باللغة الإنجليزية، ولا يوجد معيارٌ واحد لتقييم النماذج العربية في أكثر من مهمةٍ طبية ومقياس أداءٍ واحد. ومع وجود أكثر من 380 مليون ناطقٍ أصلي بالعربية <span class="citation" data-cites="Eberhard2024"></span>، كثيرٌ منهم أحاديّ اللغة، يصبح من الضروري تلبية احتياجات المرضى الناطقين بالعربية لضمان عدالة النشر.
            </p>
        </section>
        <section id="methodology" class="level1">
            <h1>المنهجيّة</h1>
            <p>
نستعرض هنا تفاصيل الإطار المنهجي لبناء مجموعات البيانات وتقييم أحدث النماذج اللغوية الضخمة. يقدّم الشكل <a href="#fig:overview" data-reference-type="ref" data-reference="fig:overview">[fig:overview]</a> نظرةً عامة على MedArabiQ.
            </p>
            <section id="tasks-and-datasets" class="level2">
                <h2>المهام ومجموعات البيانات</h2>
                <p>
لتطوير إطارٍ موثوق لتقييم النماذج اللغوية في تطبيقات الرعاية الصحيّة العربية، ركّزنا على الاستشارات الطبية عن بُعد والإجابة عن الأسئلة كحالات استخدامٍ رئيسية. تتطلّب هذه المهام ليس فقط القدرة على الاستدلال الطبي، بل أيضاً حواراً طبيعياً بين المريض والطبيب. يجب أن يُحاكي النموذجُ دورَ الطبيب قدر الإمكان، بما في ذلك امتلاك المعرفة الطبية وتوظيفها وفق احتياجات المرضى. ومع ذلك، ينبغي ألّا يؤدّي هذا التخصيص إلى تحيّزٍ أو تمييزٍ في إجابات النموذج بناءً على ملفّ المريض. في الواقع، يُفترض أن يُظهر النموذج مقاومةً للمحفّزات المتحيّزة، وأن يستجيب بعدالةٍ وموضوعيّة. استمددنا مجموعات البيانات من مصدرين رئيسيين: <span>اختبارات سابقة وملاحظات من كليات طب عربية</span>، و<span>مجموعة بيانات AraMed</span> <span class="citation" data-cites="alasmari2024"></span>. وقد اخترنا مصادر بياناتٍ يُستبعد بدرجةٍ كبيرة أن تكون قد استُخدمت ضمن مجموعات تدريب النماذج السابقة.
                </p>
                <section id="multiple-choice-questions" class="level3">
                    <h3>أسئلة اختيار من متعدّد</h3>
                    <p>
لتقييم الفهم الطبي للنماذج، أنشأنا مجموعةَ بياناتٍ معيارية من أزواج أسئلةٍ وأجوبة تغطّي موضوعاتٍ طبية أساسية ومتقدمة مثل علم وظائف الأعضاء (الفسيولوجيا)، والتشريح، وجراحة الأعصاب. جمعنا اختباراتٍ ورقية وملاحظات محاضرات من مستودع أكاديمي كبير تُديره منصّات طلابية في كليات الطب الإقليمية. لم تتضمّن البيانات أيّ معلوماتٍ تعريفية أو بياناتٍ حقيقية للمرضى، وبالتالي لم تكن هناك حاجةٌ لإخفاء الهوية. لم تكن هذه الاختبارات متاحةً بصيغٍ رقمية منظَّمة، ما تطلّب جهداً يدوياً كبيراً لضمان الدقة والوضوح. ونظراً لأن التعليم الطبي العربي غير مُرقمَن إلى حدّ كبير، فإنّ هذه الاختبارات ليست متاحةً للعامة بشكلٍ منظّم. وحتى إن وُجدت بعض الأسئلة بشكلٍ فردي على الإنترنت، فإنّ الجهد الكبير المطلوب لتجميعها وهيكلتها يُقلّل احتمال تلوّث البيانات. وقد جرى انتقاءُ الأسئلة لتعكس تدرّج الصعوبة عبر السنوات الأكاديمية، لضمان تقييم أداء النماذج على مستوياتٍ مختلفة من الخبرة الطبية. اخترنا عيّنةً عشوائية من 100 سؤال اختيارٍ من متعدّد، وقمنا برقمنتها والتحقّق منها يدوياً. ويتراوح متوسّط طول السؤال بين 15 و30 كلمة.
                    </p>
                </section>
                <section id="multiple-choice-questions-with-bias" class="level3">
                    <h3>أسئلة اختيار من متعدّد مع تحيّز</h3>
                    <p>
تماشياً مع الأعمال الحديثة <span class="citation" data-cites="schmidgall2024addressing"></span>، قمنا بحقنِ التحيّز في مجموعة أسئلة الاختيار من متعدّد لتقييم كيفية تعامل النماذج مع السيناريوهات الأخلاقية أو الثقافية الحسّاسة. استخدمنا فئات تحيّز مُحدّدة مسبقاً مثل: (1) التحيّز التأكيدي، (2) تحيّز الحداثة، (3) تحيّز التكرار، (4) التحيّز الثقافي، (5) تحيّز الإجماع الزائف، (6) تحيّز الوضع القائم، و(7) تحيّز التشخيص الذاتي. ومن خلال الحقن اليدوي للانحياز، ضمِنّا ملاءمة الأسئلة للتحدّيات اللغوية والسريرية الفريدة في السياق العربي. نتج عن ذلك مجموعةُ بياناتٍ مؤلّفة من 100 عيّنة.
                    </p>
                </section>
                <section id="fill-in-the-blank-with-choices" class="level3">
                    <h3>إكمال الفراغ مع خيارات</h3>
                    <p>
لتقييم استرجاع المعرفة والتعلّم في السياق، أنشأنا يدوياً أسئلةَ إكمالِ فراغ، كلٌّ منها مُصحوبٌ بمجموعةٍ من الخيارات المحدّدة مسبقاً. كان على النموذج اختيار الإجابة الأنسب من بين هذه الخيارات. يقيس هذا النهج قدرة النموذج على التعرف إلى الإجابة الصحيحة ضمن مجموعةٍ محصورة، ويُقلّل من الاعتماد على قدرات التوليد الحرّ. تتكوّن مجموعةُ البيانات من 100 عيّنة.
                    </p>
                </section>
                <section id="fill-in-the-blank-without-choices" class="level3">
                    <h3>إكمال الفراغ من دون خيارات</h3>
                    <p>
في هذا الإعداد، قُدِّمت أسئلةُ إكمال الفراغ من دون خياراتٍ مُسبقة، ما يتطلّب من النموذج توليدَ الإجابة بشكلٍ مستقل. يقيس هذا التقييم قدرة النموذج على استرجاع وتوليد المعرفة الطبية الدقيقة دون معلوماتٍ إضافية، مع التركيز على الاستدلال وقدرات التوليد اللغوي. تتكوّن مجموعةُ البيانات لهذه المهمة أيضاً من 100 عيّنة.
                    </p>
                </section>
                <section id="patient-doctor-qa" class="level3">
                    <h3>أسئلة وأجوبة بين المريض والطبيب</h3>
                    <p>
تُعدّ AraMed مجموعةَ بياناتٍ طبية عربية للإجابة عن الأسئلة، جُمعت أصلاً من منصّة "الطبي"، وهي منتدى إلكتروني للنقاشات الطبية بين المرضى والأطباء <span class="citation" data-cites="alasmari2024"></span>. تتكوّن المجموعة الأصلية من 400 زوج سؤالٍ وجواب، جميعها مصاغةٌ بالعربية الفصحى لضمان الاتساق. اخترنا يدوياً 100 عيّنة، مع إعطاء الأولوية للأسئلة ذات الصياغة الجيّدة والإجابات المفيدة، وتجنّبنا الحالات التي كانت الإجابات فيها عامّة جداً (مثل "استشر طبيباً" أو "راجِع أخصائياً")، مع الاحتفاظ ببعض الأمثلة لتعكس سلوك المستخدمين في الواقع.
                    </p>
                    <p>
حرصنا أيضاً على الحفاظ على التوزيع النسبي للفئات الطبية، خصوصاً في مجالات الصحّة الإنجابية والجنسية التي غالباً ما تكون ناقصة التمثيل في الأبحاث الطبية العربية رغم أهميتها. ونظراً لحساسية هذه الموضوعات، أدرجناها لتوفير تقييمٍ أكثر واقعية وتوازناً لقدرة النماذج على التعامل مع استفساراتٍ طبية متنوّعة. ولضمان توزيعٍ عادل، اخترنا 100 سؤال، وخصّصنا نسبةً متساوية لكلّ تخصّص: أمراض القلب، التوليد وأمراض النساء، الجراحة، طب الأطفال، الأعصاب، الأورام، الغدد الصمّاء، طب الأسنان، الأنف والأذن والحنجرة، الصحّة العامة، الأمراض الجلدية، الرعاية الأولية، أمراض الرئة، وعلم النفس.
                    </p>
                    <p>
أضفنا أيضاً معلوماتٍ عن المريض مثل العمر والجنس عند توافرها في السؤال. وإذا كانت هذه المعلومات غير معروفة أو غير منطقية (مثلاً عمرٌ غير واقعي)، جرى استبعادُها. أحياناً يَرِد السؤال من قريبٍ للمريض، فلا تتوافر معلوماتٌ عنه. عادةً ما تُذكَر هذه المعلومات في بداية السؤال أو بعد التحية، بصيغة "أنا رجل/امرأة وعمري [س] سنة". أضفى ذلك واقعيةً وتخصيصاً على السيناريوهات، مما يجعل المعيار أكثر ملاءمةً لتقييم أداء النماذج في الحالات الطبية الواقعية.
                    </p>
                </section>
                <section id="qa-with-grammatical-error-correction-gec" class="level3">
                    <h3>أسئلة وأجوبة مع تصحيح الأخطاء النحوية</h3>
                    <p>
نظراً لاستخدام اللهجات في مجموعة أسئلة وأجوبة المرضى، أنشأنا نسخةً إضافيةً ذات جودةٍ لغوية أعلى. طَبَّقنا سلسلةَ تصحيحِ أخطاءٍ نحوية مُخصّصة للنصوص الطبية العربية. ونظراً لتعقيد العربية صرفياً ونحوياً، كان هذا الإجراء ضرورياً. استخدمنا cameltools، وهي مكتبةٌ مفتوحة المصدر لمعالجة اللغة العربية، لتفكيك الكلمات وإزالة التشكيل <span class="citation" data-cites="obeid2020"></span>. ثم استخدمنا نموذج كشف الأخطاء النحوية (GED) القائم على BERT لكشف أخطاء التطابق والترتيب والصرف <span class="citation" data-cites="alhafni-etal-2023-advancements"></span>. وتم تصحيح الأخطاء تلقائياً باستخدام نموذج GEC مبنيّ على mBART، مُدرّب على مجموعات QALB-2015 وQALB-2014 وZAEBUC <span class="citation" data-cites="mohit-etal-2014-first rozovskaya-etal-2015-second habash-palfreyman-2022-zaebuc"></span>.
                    </p>
                </section>
                <section id="qa-with-llm-modifications" class="level3">
                    <h3>أسئلة وأجوبة مع تعديلات النماذج اللغوية</h3>
                    <p>
لتقليل احتمالية حفظ النماذج للأسئلة، خصوصاً أنّ بعضها قد يكون تدَرّب على بياناتٍ من "الطبي"، قمنا بتعديل مجموعة البيانات باستخدام نموذجٍ لغويٍّ ضخم لإعادة صياغة الأسئلة مع الحفاظ على معناها <span class="citation" data-cites="dong2024"></span>. استخدمنا GPT-4o لإعادة الصياغة عبر مُحفّز: "أنت مساعدٌ مُفيد تعيد صياغة النص مع الحفاظ على معناه." وقد ضمنت هذه الطريقة بقاء المفاهيم الطبية الأساسية مع تقليل الاعتماد على الحفظ.
                    </p>
                    <p>
باختصار، أنشأنا سبع مجموعات بياناتٍ جديدة انطلاقاً من مصدرين رئيسيين (AraMed واختباراتٍ طبية سابقة) عبر تحقّقٍ بشريٍّ مُكثّف لبناء معيار MedArabiQ.
                    </p>
                    <div class="table*">
                        <p><span>tab:benchmark_results</span></p>
                        <p><span id="table:results" label="table:results"></span></p>
                    </div>
                </section>
            </section>
            <section id="models" class="level2">
                <h2>النماذج</h2>
                <p>
غالباً ما تُواجِه المعايير المرجعية المُستخدمة لتقييم النماذج اللغوية تحدّي تلوّث البيانات، إذ إنّ العديد من النماذج الحديثة تدَرّبت على مجموعاتٍ ضخمة من الإنترنت قد تتضمّن أسئلةً من المعايير نفسها، مما يُؤدي إلى تضخيم نتائج الأداء وجعل التقييم غير عادل <span class="citation" data-cites="deng2024 yihong2024"></span>. إنّ معالجة هذه المشكلة ضرورية لضمان أن تعكس نتائج التقييم قدرات النماذج الحقيقية دون تحيّز ناتج عن التعرّض المُسبق للبيانات.
                </p>
                <p>
ولتقليل هذه المخاوف، صنّفنا النماذج إلى مجموعتين رئيسيتين: نماذج ذات <strong>بيانات تدريبٍ معروفة</strong> ونماذج ذات <strong>بيانات تدريبٍ غير معروفة</strong>. يسمح هذا التمييز بتقييم مخاطر التلوّث بشكلٍ أكثر موثوقية للنماذج ذات المصادر الموثّقة، مع الإقرار بصعوبة استبعاد التلوّث في النماذج غير الشفّافة.
                </p>
                <p>
بالإضافة إلى ذلك، صنّفنا النماذج حسب التغطية اللغوية: نماذج <strong>متعدّدة اللغات عموماً</strong> ونماذج <strong>تركّز على العربية</strong>. ورغم أنّ العديد من النماذج تتضمّن بياناتٍ من لغاتٍ عديدة، إلا أنّ التعرّض للغة لا يعني بالضرورة إتقانَها <span class="citation" data-cites="bender2021"></span>. على سبيل المثال، من المعروف أن GPT-4 تدَرّب على لغاتٍ متنوّعة <span class="citation" data-cites="achiam2023gpt"></span>. ومن خلال تقييم النماذج متعدّدة اللغات والنماذج العربية بشكلٍ منفصل، يمكننا تحديد أثر التغطية والتخصّص اللغوي على الأداء في المهام الطبية العربية. يوضّح الجدول <a href="#table:models" data-reference-type="ref" data-reference="table:models">[table:models]</a> النماذج المختارة.
                </p>
            </section>
            <section id="evaluation" class="level2">
                <h2>التقييم</h2>
                <p>
يتطلّب تقييم النماذج اللغوية في تطبيقات الرعاية الصحية العربية إطاراً شاملاً يُوازِن بين الأداء التقني والملاءمة الواقعية <span class="citation" data-cites="sallam2024"></span>. يُقيّم إطارُنا الاستدلال الطبي، واتخاذ القرار، والإجابة الحوارية عن الأسئلة <span class="citation" data-cites="kanithi2024 guo2023"></span>. وقد مُنِحت أسئلةُ الاختيار من متعدّد دقّةً بوصفها المقياس، بينما جرى تقييم الأسئلة المفتوحة مثل إكمال الفراغ وأسئلة المريض-الطبيب باستخدام BERTScore لقياس التقارب الدلالي <span class="citation" data-cites="bert-score"></span>.
                </p>
            </section>
            <section id="bias-assessment-and-mitigation" class="level2">
                <h2>تقييم التحيّز والحدّ منه</h2>
                <p>
لضمان إمكانيّة نشر النماذج اللغوية في الرعاية الصحيّة بشكلٍ فعّال، من الضروري معالجة احتمالية تكرارها لتحيّزاتٍ بشرية. ومن شبه المستحيل إزالة التحيّز تماماً من النماذج، إذ إنّ مجموعات البيانات المستخدمة في التدريب متأثرةٌ حكماً بالأحكام البشرية. إدراكاً لهذا التحدّي، طوّرنا إطار تقييمٍ منهجيّاً لقياس مقاومة النماذج للانحيازات المحقونة في أسئلة الاختيار من متعدّد، وقياس قابليتها للتأثّر، واختبار استراتيجيات الحدّ من التحيّز. يستند الإطار إلى منهجياتٍ حديثة <span class="citation" data-cites="schmidgall2024addressing"></span> مع تكييفها للسياق العربي الطبي، بما في ذلك فئات تحيّز ملائمة ثقافياً، ومُحفّزاتٍ مُصمّمة للسيناريوهات السريرية، ومقاييس تقييم إضافية.
                </p>
                <p>
أنشأنا إطاراً مُنظّماً لتقييم مقاومة النماذج للانحيازات المعرفية:
                </p>
                <ol>
                    <li><p><strong>الاختبار الأساسي:</strong> تُقيَّم النماذج باستخدام مجموعة البيانات الأصلية غير المتحيّزة لتحديد خطّ الأساس للأداء.</p></li>
                    <li><p><strong>اختبار التحيّز:</strong> تُختبَر النماذج مع نسخٍ مُتحيّزة من المُحفّزات، ونحسب التغيّر في الدقّة لقياس أثر التحيّز.</p></li>
                    <li><p><strong>تقييم الحدّ من التحيّز:</strong> تُختبَر تقنيات الحدّ من التحيّز وتُقاس آثارُها على الدقّة، وتشمل:</p>
                        <ul>
                            <li><p><strong>التثقيف حول التحيّز:</strong> إضافة تحذيرات في المُحفّزات تُؤكّد الاستدلال القائم على الأدلة (مثلاً: "قيِّم كل مريضٍ على حدة دون الاعتماد على الاتجاهات أو الحالات الأخيرة").</p></li>
                            <li><p><strong>مثالٌ واحد توضيحي:</strong> تقديم مثالٍ سلبي واحد يُظهر الاستدلال الخاطئ الناتج عن التحيّز.</p></li>
                            <li><p><strong>عدّة أمثلة توضيحية:</strong> تقديم أمثلةٍ إيجابية وسلبية توضّح التعامل الصحيح والخاطئ مع التحيّز.</p></li>
                        </ul>
                    </li>
                </ol>
                <p>
يوفّر هذا الإطار منهجيةً واضحة وقابلةً للتكرار لتقييم ومعالجة التحيّزات المعرفية في النماذج اللغوية، بما يضمن نشرَها في السياقات الصحية بشكلٍ فعّال وأخلاقي.
                </p>
                <div class="figure*">
                    <p><img src="figures/fig2-lasr.png" alt="مخطط سير العمل لتقييم التحيّز والحدّ منه" /></p>
                </div>
                <div class="figure*">
                    <p><img src="figures/samples-arx.png" style="width:97.0%" alt="عينات من المهام والأسئلة" /></p>
                </div>
            </section>
        </section>
        <section id="experimental-setup" class="level1">
            <h1>إعداد التجارب</h1>
            <p>
<strong>التقييم.</strong> استخدمنا أسلوب التحفيز الصفري (zero-shot) لجميع النماذج والمهام، مع ضبط "درجة الحرارة" بحسب طبيعة كلّ معيار بعد مرحلة اختبارٍ أولية. في النماذج المغلقة، ثُبِّتت درجة الحرارة عند 0.2 لجميع المهام. أمّا في النماذج مفتوحة المصدر، فحُدِّدت بـ 0 في المهام المُغلَقة لضمان إجاباتٍ حتمية، وبـ 0.4 في المهام المفتوحة. وفي تقييم BERTScore، استخدمنا نموذج XLM-RoBERTa-Large المدعوم بلغاتٍ متعددة ومنها العربية، مما يجعله أنسب من النماذج أحادية اللغة.
            </p>
            <p>
<strong>النماذج المضبوطة بالتعليمات.</strong> استخدمنا نسخاً مضبوطةً بالتعليمات من النماذج السابقة نظراً لقدرتها الأفضل على فهم وتنفيذ التعليمات الخاصة بالمهام. أمّا النسخ الأساسية فقد أظهرت قصوراً كبيراً في اتّباع المُحفّزات حتى مع تحسينها، وهو ما يتوافق مع الأدبيات <span class="citation" data-cites="chung2022scaling zhang2023instruction"></span> التي تؤكّد أنّ ضبط التعليمات يُحسّن الأداء والالتزام بالمُحفّزات عبر المهام والأحجام المختلفة.
            </p>
            <p>
<strong>محفّزات التعليمات.</strong> تُعدّ هندسة المُحفّزات أمراً محورياً في تقييم النماذج. في تجاربنا، اختبرنا المُحفّزات بالإنجليزية والعربية، ووجدنا أنّ المُحفّزات الإنجليزية كانت أكثر فاعليةً عموماً، باستثناء مهام AraMed حيث تفوّقت المُحفّزات العربية في النماذج مفتوحة المصدر. بناءً على ذلك، استخدمنا المُحفّزات الإنجليزية لجميع المهام باستثناء أسئلة المريض-الطبيب، وتصحيح الأخطاء النحوية، وتعديلات النماذج. يوضح الجدول التكميلي <a href="#table:prompts" data-reference-type="ref" data-reference="table:prompts">[table:prompts]</a> المُحفّزات المستخدمة.
            </p>
            <p>
<strong>معالجة الإجابات.</strong> في مهام الأسئلة والأجوبة، والأسئلة مع التحيّز، وإكمال الفراغ مع خيارات، تولّد النماذج كلاً من مؤشّر الخيار الصحيح والنصّ الكامل للإجابة. إلا أنّ بعض النماذج، خصوصاً مفتوحة المصدر، تُظهر تفاوتاً في التهجئة. ولضمان الدقّة، قمنا بتقييم أول حرفٍ بعد عبارة "الحرف الصحيح هو:" ومقارنته بالخيارات المتاحة. إذا لم يتطابق الحرف مع خيارٍ صحيح، تُعتبر الإجابة غير صالحة. وفي المهام المفتوحة، يُقيَّم النص الكامل الذي يولّده النموذج.
            </p>
            <div class="figure*">
                <p><img src="figures/bias_figure.png" style="width:95.0%" alt="تصوير لسيناريوهات الحقن والتحكّم في التحيّز" /></p>
            </div>
        </section>
        <section id="results" class="level1">
            <h1>النتائج</h1>
            <p>
نعرض نتائج جميع التجارب على المعايير الستة في الجدول <a href="#table:results" data-reference-type="ref" data-reference="table:results">[table:results]</a>. تُظهر النتائج أنه لا يوجد نموذجٌ واحد يتفوّق على جميع النماذج في كلّ المعايير. في المهام المُغلَقة (الاختيار من متعدّد وإكمال الفراغ مع/من دون خيارات)، تتفوّق النماذج المغلقة كما هو متوقّع. يحقّق Gemini 1.5 Pro أعلى دقّة في ثلاثٍ من أصل ست مهام، مع أداءٍ مماثل لـ Claude 3.5 Sonnet في إحداها. في أسئلة الاختيار من متعدّد وإكمال الفراغ مع خيارات، يتفوّق Gemini بدقّة 57.5 و72.7 على التوالي. أمّا في المهام المفتوحة (أسئلة المريض-الطبيب، التصحيح النحوي، وتعديلات النماذج)، فيتفوّق Qwen محققاً 85.2 في أسئلة المريض-الطبيب، بينما يُحقّق LLaMa أفضل نتيجة في التصحيح النحوي بـ 85.5. ومع ذلك، لا تتفوّق النماذج نفسها في جميع أنواع المهام، إذ إنّ Qwen وLLaMa أداؤهما ضعيف في المهام المُغلَقة.
            </p>
            <p>
يقارن الشكل <a href="#fig:results_overall" data-reference-type="ref" data-reference="fig:results_overall">[fig:results_overall]</a> (أ) أداء النماذج مفتوحة المصدر والمبنية على واجهات برمجة التطبيقات عبر جميع المهام. يحقّق <strong>Gemini 1.5 Pro</strong> <strong>أعلى متوسّط أداء</strong>، يليه GPT-4 وClaude 3.5، مما يعزّز تفوّق النماذج المملوكة في مهام معالجة اللغة. وتُظهر النماذج مفتوحة المصدر مثل Llama 3.1 وQwen 2.5 أداءً تنافسياً لكن متغيّراً، مع تفوّق Qwen 2.5 بينها. وتُشير أشرطة الخطأ إلى أنّ النماذج المغلقة أكثر استقراراً، بينما تُظهر النماذج مفتوحة المصدر تبايناً أكبر بسبب اعتمادها على تدريبٍ عامّ بدلاً من ضبطٍ تخصّصي. وتؤكّد هذه النتائج تفوّق النماذج المملوكة حالياً، مع إمكان تحسين النماذج مفتوحة المصدر عبر الضبط التخصّصي.
            </p>
            <p>
يوضح الشكل <a href="#fig:results_overall" data-reference-type="ref" data-reference="fig:results_overall">[fig:results_overall]</a> (ب) تباين الأداء حسب نوع المهمة، حيث تُحقّق النماذج المغلقة نتائج مرتفعة في جميع المعايير، خاصةً في مهام الأسئلة والأجوبة بما في ذلك التصحيح النحوي وتعديلات النماذج. ويشير ذلك إلى قدرةٍ قوية على التعامل مع الاستفسارات الطبية المعقّدة، وهو أمرٌ حاسم في التطبيقات الواقعية. ومع ذلك، تُظهر مهام إكمال الفراغ والاختيار من متعدّد تبايناً أكبر، مع تأخّر النماذج مفتوحة المصدر عن المغلقة. وتؤكّد هذه الفجوات الحاجة إلى ضبطٍ تخصّصي للنماذج مفتوحة المصدر لتحسين الدقّة في المهام المعرفية. يوضّح الشكل <a href="#fig:samples" data-reference-type="ref" data-reference="fig:samples">[fig:samples]</a> أمثلةً من إجابات النماذج في المهام المُغلَقة والمفتوحة.
            </p>
            <p>
يستعرض الشكل <a href="#fig:bias" data-reference-type="ref" data-reference="fig:bias">[fig:bias]</a> أثر التحيّز واستراتيجيات الحدّ منه على أداء النماذج. في الشكل (أ)، نقارن دقّة GPT-4o وGemini 1.5 Pro وClaude 3.5 Sonnet-20240620 في الأسئلة الأصلية مقابل الأسئلة المحقونة بالتحيّز عبر فئات التحيّز المختلفة. تُظهر النتائج انخفاضاً عاماً في الدقّة عند إدخال التحيّز، مع تباين الانخفاض حسب نوع التحيّز. يُظهر Gemini 1.5 Pro مقاومةً أعلى خاصةً في تحيّز الوضع القائم والإجماع الزائف، بينما يُظهر Claude 3.5 Sonnet انخفاضاً أكبر في تحيّز التشخيص الذاتي والتحيّز الثقافي. وفي الشكل (ب)، يتّضح تحسّن الدقّة مع استراتيجياتٍ مثل التحفيز بعدّة أمثلة مقارنةً بالأسئلة المُتحيّزة دون تدخّل. ويتفوّق Gemini 1.5 Pro باستمرارٍ في جميع الاستراتيجيات، مما يعزّز متانته في مواجهة التحيّز.
            </p>
            <p>
يعرض الشكل (ج) مخططاً رادارياً يُلخّص أداء النماذج عبر استراتيجيات الحدّ من التحيّز. يُظهر Gemini أداءً ثابتاً، بينما يُظهر GPT-4o وClaude 3.5 Sonnet تبايناً أكبر عبر الاستراتيجيات مثل التثقيف حول التحيّز والتحفيز بمثالٍ واحد. وتُؤكّد هذه النتائج أهمية استراتيجيات الحدّ من التحيّز في تعزيز موثوقيّة النماذج. ويمكن الاطّلاع على تفاصيل إضافية حول الأداء حسب فئة التحيّز والتخصّص الطبي في الأشكال <a href="#fig:bias accuracy1" data-reference-type="ref" data-reference="fig:bias accuracy1">[fig:bias accuracy1]</a> و<a href="#fig:bias accuracy2" data-reference-type="ref" data-reference="fig:bias accuracy2">[fig:bias accuracy2]</a> في الملحق.
            </p>
        </section>
        <section id="discussion" class="level1">
            <h1>المناقشة</h1>
            <p>
تتّسق نتائجُنا مع أبحاثٍ سابقة في تقييم النماذج الطبية، حيث تتفوّق النماذج المغلقة في المهام المنظّمة بينما تتقارب النتائج في المهام التوليدية. أظهر <span class="citation" data-cites="chen2025benchmarkinglargelanguagemodels"></span> أنّ النماذج المملوكة مثل GPT-4 وMed-PaLM 2 تتفوّق في مهام الاختيار من متعدّد واسترجاع الحقائق بفضل تدريبها على مجموعات بياناتٍ منظّمة ودمج المعرفة التخصّصية. كما وجد <span class="citation" data-cites="Alonso_2024"></span> أنّ النماذج المملوكة تُحقّق دقّةً أعلى في مهام الأسئلة الطبية بعدّة لغات، مما يعزّز فكرة أنّ النماذج المغلقة أكثر رسوخاً في المعرفة الطبية. وتدعم نتائجُنا هذا الاتجاه، إذ يتصدّر Gemini 1.5 Pro وClaude 3.5 Sonnet في مهام الاختيار من متعدّد وإكمال الفراغ، ما يُشير إلى أنّ النماذج المبنية على واجهات برمجة التطبيقات أكثر ملاءمةً لدعم القرار السريري والمهام المنظّمة.
            </p>
            <p>
يوضح الشكل <a href="#fig:bias" data-reference-type="ref" data-reference="fig:bias">[fig:bias]</a> أيضاً تباين أداء النماذج عند التعرّض للانحياز وفاعلية استراتيجيات الحدّ منه لأفضل ثلاثة نماذج (GPT-4o، Gemini 1.5 Pro، وClaude 3.5 Sonnet-20240620). جميع النماذج تشهد انخفاضاً في الدقّة عند إدخال التحيّز، مع تراجُعٍ أكبر في Claude 3.5 Sonnet عبر عدّة فئات. وأظهرت تقنيات الحدّ من التحيّز مثل التحفيز بعدّة أمثلة تحسّناً ملحوظاً، خصوصاً في Gemini 1.5 Pro الذي أظهر أكبر مقاومة. ومع ذلك، لا توجد استراتيجية واحدة فعّالة دائماً عبر جميع النماذج والفئات، مما يبرز تعقيد التحيّز في معالجة اللغة الطبية والحاجة إلى مزيدٍ من البحث.
            </p>
            <p>
في المهام التوليدية، لا تعكس مقاييس التقييم التلقائي مثل BERTScore الأداءَ الفعلي للنماذج بشكلٍ كامل. فرغم أنّ GPT-4 وClaude 3.5 يُنتجان إجاباتٍ ذات صلةٍ وسياقٍ دقيق كما هو موضّح في الشكل 3، فإنّ طول الإجابات يؤدي في الغالب إلى انخفاض BERTScore مقارنةً بالإجابات المرجعية. وأشار <span class="citation" data-cites="liu-etal-2025-interactive"></span> سابقاً إلى أنّ مقاييس مثل ROUGE وBERTScore تعجز عن تقييم النماذج الطبية بدقّة بسبب تعقيد التشخيصات وتعدّد الخيارات العلاجية. وتؤكّد نتائجُنا هذا القصور، إذ إنّ النماذج ذات BERTScore المنخفض قد تُنتِج إجاباتٍ عالية الجودة لكنها تُعاقَب على الإطناب لا على عدم الدقّة. ويبرز ذلك الحاجة إلى أساليب تقييمٍ أكثر دقّة، مثل التقييم البشري أو التقييم الحواري المُوجَّه بالمهام، لتعكس الاستخدام الواقعي في الاستشارات الطبية وتحدّ من هلوسة الحقائق.
            </p>
        </section>
        <section id="ethical-considerations" class="level1">
            <h1>اعتبارات أخلاقية</h1>
            <p>
نظراً لحساسية تطبيقات الرعاية الصحيّة، تُعدّ الاعتبارات الأخلاقية أساسيةً عند تطوير ونشر النماذج اللغوية الضخمة. وقد بُنِي معيار MedArabiQ بعناية من مصادر تعليمية عامة ومجهولة الهوية، مع الالتزام بمعايير الخصوصية عبر استبعاد أيّ معلوماتٍ تعريفية للمرضى. كما نُقِرّ بعدّة قضايا أخلاقية مرتبطةٍ بنشر النماذج في السياق السريري، مثل مخاطر المعلومات المُضلِّلة، وتضخيم التحيّزات (الثقافية، التأكيدية، أو تحيّز الوضع القائم)، ومحدودية تفسير النماذج. ولمعالجة هذه المخاطر، نؤكّد أهمية التحقّق الشامل عبر أُطرٍ هجينة تجمع بين التقييم التلقائي ومراجعة الخبراء. ونوصي بالمراقبة المستمرة، وإشراف الأطباء، ووضع إرشادات تشغيلية واضحة للحدّ من الأضرار والتحيّزات. ومن خلال توضيح هذه الاعتبارات، نهدف إلى تعزيز تبنّيٍ مسؤول وشفّاف للنماذج، والمساهمة في حلولٍ صحية أكثر أماناً وعدلاً.
            </p>
        </section>
        <section id="limitations-and-future-work" class="level1">
            <h1>القيود والعمل المستقبلي</h1>
            <p>
رغم أنّ دراستنا تُقدّم تقييماً شاملاً للنماذج الطبية العربية، إلا أنّ هناك مجالاتٍ تستحقّ مزيداً من البحث. أولاً، هناك احتمال لتلوّث البيانات. ورغم أنّ اختبارات الطب السابقة لم تكن متاحةً رقمياً وتتطلّب جهداً كبيراً لرقمنتها وتنظيفها، لا يمكننا استبعاد التلوّث تماماً. ومع ذلك، يمكن لتحسين أداء النماذج أن يبرز أهمية المعايير المرجعية. وبالنسبة لـ AraMed، أجرينا تعديلاتٍ لاختبار الحفظ المحتمل نظراً لأنها مجموعة بياناتٍ عامة. وللتحقّق من صلاحية البيانات، أجرينا تقييماً أولياً بالتعاون مع طلاب طب لتقييم الحقائق والملاءمة والوضوح والتعقيد على مقياسٍ من 1 إلى 5. أظهرت النتائج (الملاءمة: 4.99، الحقائق: 4.97، الدقّة: 4.88، الوضوح: 4.89) موثوقيةً وفائدةً مبدئية. ويتطلّب تقييمٌ موسّع مستقبلاً مع توسيع نطاق المعيار.
            </p>
            <p>
اتباعاً للممارسات القياسية في معالجة اللغة الطبية، اعتمدنا على مجموعات بياناتٍ معيارية بدلاً من التفاعلات السريرية الحيّة لضمان القابلية للتكرار والامتثال الأخلاقي. وجديرٌ بالذكر أنّ مجموعة أسئلة المريض-الطبيب مُستمدّة من AraMed <span class="citation" data-cites="alasmari2024"></span>، والتي تتضمّن استشاراتٍ حقيقية من منصّة "الطبي"، مما يضمن الواقعية. ورغم أنّ الاختبار السريري الحي قد يُوفّر رؤى إضافية، إلا أنه يواجه تحدّيات الخصوصية والتنظيم، خصوصاً في المنطقة العربية حيث تفرض لوائح مثل GDPR وHIPAA قيوداً صارمة على مشاركة بيانات المرضى <span class="citation" data-cites="theodos2020"></span>. كما أنّ العديد من المؤسسات الصحية لا تزال تعتمد على السجلات الورقية <span class="citation" data-cites="aljawarneh2024"></span>، مما يُصعّب جمع البيانات الحية على نطاقٍ واسع. ويمكن مستقبلاً استكشاف استراتيجياتٍ مُحافظة على الخصوصية لدمج التقييمات السريرية الواقعية بشكلٍ آمنٍ وأخلاقي.
            </p>
            <p>
من القيود الأخرى الحاجة إلى تقنياتٍ أكثر فاعلية للحدّ من التحيّز. ورغم تقييمنا لقابلية التحيّز عبر مهامّ متعددة، تؤكّد النتائج أنّ الاستراتيجيات الحالية لا تقضي عليه تماماً، خصوصاً في سياقات اتخاذ القرار السريري الحسّاسة <span class="citation" data-cites="alyafeai2024 omar2024"></span>. لذا ينبغي أن يركّز البحث المستقبلي على تطوير أساليب مُتخصّصة تُراعي العوامل اللغوية والثقافية الفريدة للغة العربية الطبية.
            </p>
            <p>
ركّزنا في هذه الدراسة على تقييم الأداء الصفري (zero-shot)، لتقديم تقييمٍ غير مُتحيّز لقدرة النماذج على المهام الطبية العربية دون ضبطٍ مُسبق <span class="citation" data-cites="kojima2022"></span>. ورغم أنّ ذلك يوفّر خطَّ أساسٍ قويّاً، يمكن مستقبلاً استكشافُ ضبطِ النماذج على مجموعات بياناتٍ طبية عربية لتحسين الفهم التخصّصي. ويتطلّب ذلك مراعاة توافر البيانات، وتكاليف الحوسبة، ومخاطر فقدان التعميم.
            </p>
            <p>
علاوةً على ذلك، اعتمدت معاييرُنا على العربية الفصحى لضمان الاتساق، غير أنّ ذلك لا يعكس التنوع اللهجي المُستخدَم في التفاعلات الواقعية. ويمكن مستقبلاً دمج بياناتٍ لهجية لتعزيز قدرة النماذج على التكيّف مع السياقات الصحية العربية المتنوّعة. كما أنّ الدراسة تركّز على النصوص فقط، ويمكن توسيع المعايير لدعم الذكاء الاصطناعي متعدّد الوسائط مثل الصور الطبية ونتائج المختبرات.
            </p>
            <p>
نخطّط مستقبلاً لتوسيع MedArabiQ من حيث العمق والتخصّص، عبر تغطية مجالاتٍ سريرية إضافية مثل الصحّة النفسية، والأمراض المُعدية، والأمراض المزمنة، بالتعاون مع أطباء وخبراء لضمان ملاءمة الأسئلة للمعايير السريرية الحديثة. وسنُصنّف الأسئلة حسب نوع الاستدلال السريري، ونُقيّم تعقيدها، ونُجري تقييماتٍ لاتساق المُقيّمين. سيُعزّز هذا التوسّع شمولية وموثوقية المعيار، ويدعم ضبط النماذج العربية ومتعدّدة اللغات، مما ينعكس إيجاباً على الرعاية الصحيّة للناطقين بالعربية.
            </p>
        </section>
        <section id="conclusion" class="level1">
            <h1>الخلاصة</h1>
            <p>
في هذا العمل، قدّمنا أول معيارٍ مُنظَّم لتقييم النماذج اللغوية في الرعاية الصحيّة العربية، لمعالجة فجوةٍ كبيرة في معالجة اللغة الطبية بالعربية. يتكوّن معيارُنا من 700 عيّنةٍ سريريةٍ متنوّعة، تغطّي التقييمات المعرفية المنظّمة والتفاعلات الواقعية بين المريض والطبيب. ويتجاوز معيارُنا حدود الرعاية الصحية العربية، إذ يضع أساساً لتطوير معايير بلغاتٍ طبية أخرى غير مخدومة، مما يُسهم في تطوير تطبيقات الذكاء الاصطناعي الطبية عالمياً.
            </p>
            <p>
تكشف نتائجُنا عن قيودٍ حرِجة في النماذج الحالية، مثل هلوسة الحقائق في المهام المفتوحة وقابلية التحيّز في اتخاذ القرار السريري، مما يعزّز الحاجة إلى استراتيجياتٍ فعّالة للحدّ من التحيّز. وينبغي أن يستكشف العملُ المستقبلي ضبط النماذج على بياناتٍ طبية عربية، وتوسيع المعايير لتشمل التنوع اللهجي، وتطوير استراتيجياتٍ متخصّصة للحدّ من التحيّز في السياق الطبي العربي. ومن خلال إتاحة معاييرنا، نهدف إلى دعم البحث في معالجة اللغة الطبية العربية، وتوفير أساسٍ لحلولٍ صحيةٍ موثوقةٍ وعادلةٍ وفعّالة مدعومةٍ بالذكاء الاصطناعي.
            </p>
        </section>
        <section id="related-work-1" class="level1">
            <h1>الأعمال ذات الصلة</h1>
            <p>
توجد عدّة مجموعات بياناتٍ طبية عربية، غير أنها جميعاً تعاني قصوراً ما وغالباً ما تركز على مهمة الإجابة عن الأسئلة الطبية. يُلخّص الجدول <a href="#table:dataset_comparison" data-reference-type="ref" data-reference="table:dataset_comparison">[table:dataset_comparison]</a> هذه المجموعات وقيودها وكيفية تجاوز معيارنا لهذه القيود. باختصار، تتلخّص مساهمتنا في أربع نقاط:
            </p>
            <ol>
                <li><p>تقديم مجموعة بياناتٍ تتكوّن تقريباً بالكامل من بياناتٍ جديدة غير معروضةٍ سابقاً على النماذج، مما يُقلّل خطر التلوّث.</p></li>
                <li><p>توسيع البيانات من الإجابة التقليدية إلى حالات استخدامٍ متنوّعة مثل الاختيار من متعدّد وإكمال الفراغ، لاختبار المعرفة والاستدلال الطبي.</p></li>
                <li><p>ضمان جودة البيانات عبر مراجعة بشريةٍ يدوية دقيقة.</p></li>
                <li><p>عكس روح التفاعلات الواقعية بين المريض والطبيب باستخدام بياناتٍ من منصّة "الطبي".</p></li>
            </ol>
            <div class="table*">
                <p><span> </span> <span id="table:dataset_comparison" label="table:dataset_comparison"></span></p>
            </div>
        </section>
        <section id="appendix-b" class="level1">
            <h1>نظرة عامة على مجموعة البيانات</h1>
            <p>
يُلخّص الجدول <a href="#table:datasets" data-reference-type="ref" data-reference="table:datasets">[table:datasets]</a> مجموعات البيانات المستخدمة في التقييم، مع توضيح المصدر ومحتوى كلّ مجموعة.
            </p>
            <div class="table*">
                <p><span>tab:datasets</span></p>
                <p><span id="table:datasets" label="table:datasets"></span></p>
            </div>
        </section>
        <section id="model-overview" class="level1">
            <h1>نظرة عامة على النماذج</h1>
            <p>
تم تصنيف النماذج في الجدول <a href="#table:models" data-reference-type="ref" data-reference="table:models">[table:models]</a> بناءً على شفافية بيانات التدريب، مما يؤثّر في احتمال تلوّث التقييم، وعلى التغطية اللغوية التي تؤثّر في الأداء في العربية.
            </p>
            <div class="table*">
                <p><span>tab:model_summary</span></p>
                <p><span id="table:models" label="table:models"></span></p>
            </div>
        </section>
        <section id="prompts-by-task" class="level1">
            <h1>المحفّزات حسب المهمة</h1>
            <p>
تلعب هندسة المُحفّزات دوراً محورياً في استجابة النموذج. استخدمنا المُحفّز نفسه لكل نموذج، مع تخصيصه حسب فئة المهمة كما هو موضّح في الجدول <a href="#table:prompts" data-reference-type="ref" data-reference="table:prompts">[table:prompts]</a>. وقد كان ذلك ضرورياً لضمان واقعية المُحفّزات وملاءمتها لحالات الاستخدام المختلفة.
            </p>
            <div class="table*">
                <p><span>tab:task_prompts</span></p>
                <p><span id="table:prompts" label="table:prompts"></span></p>
            </div>
        </section>
        <section id="bias-evaluation" class="level1">
            <h1>تقييم التحيّز</h1>
            <p>
يقارن الجدول <a href="#table:bias" data-reference-type="ref" data-reference="table:bias">[table:bias]</a> أداء النماذج في أسئلة الاختيار من متعدّد والأسئلة المحقونة بالتحيّز، مع استراتيجيات الحدّ من التحيّز مثل التثقيف، المثال الواحد، وعدّة أمثلة. عموماً، تنخفض الدقّة مع التحيّز وتتحسّن مع استراتيجيات الحدّ منه. وبشكلٍ خاص، أدّى التثقيف إلى انخفاض الدقّة، بينما حسّنت استراتيجيتا المثال الواحد وعدّة أمثلة الأداء في جميع النماذج، مع أكبر تحسّنٍ في Claude 3.5 Sonnet عند استخدام المثال الواحد.
            </p>
            <div class="table*">
                <p><span>tab:bias_evaluation_results</span></p>
                <p><span id="table:bias" label="table:bias"></span></p>
            </div>
        </section>
        <section id="performance-by-bias-category" class="level1">
            <h1>الأداء حسب فئة التحيّز</h1>
            <p>
يجمع الشكل <a href="#fig:bias accuracy1" data-reference-type="ref" data-reference="fig:bias accuracy1">[fig:bias accuracy1]</a> أداءَ النماذج حسب فئة التحيّز للأسئلة من دون تحيّز، ومع التحيّز، ومع الحدّ من التحيّز. وقد أظهرت الأسئلةُ المحقونة بالتحيّز التأكيدي والإجماع الزائف أكبر تحسّنٍ مع استراتيجيات الحدّ، خصوصاً المثال الواحد وعدّة أمثلة. وكان التثقيف أقلّ فاعلية، وأحياناً أدّى لانخفاض الدقّة. وكانت الأسئلة ذات التحيّز الثقافي أكثر مقاومةً للاستراتيجيات، مع تحسّنٍ طفيف أو معدوم. ولم يتحسّن أيّ نموذجٍ باستمرارٍ مع الحدّ من التحيّز عبر جميع الفئات.
            </p>
            <div class="figure*">
                <p><img src="figures/accuracy_by_bias.png" style="width:60.0%" alt="الأداء بحسب فئات التحيّز" /></p>
            </div>
        </section>
        <section id="performance-by-question-category" class="level1">
            <h1>الأداء حسب فئة السؤال</h1>
            <p>
يمكن تصنيف الأسئلة حسب التخصّص الطبي عند دراسة الأداء مع التحيّز واستراتيجيات الحدّ منه، كما في الشكل <a href="#fig:bias accuracy2" data-reference-type="ref" data-reference="fig:bias accuracy2">[fig:bias accuracy2]</a>. وأحياناً حسّنت استراتيجيتا المثال الواحد وعدّة أمثلة الأداء، لكن ليس دائماً. وغالباً ما أدّى التثقيف إلى انخفاض الدقّة أو عدم التغيير. ولم تكن التحسينات في الدقّة متسقة. وكان أبرز تحسّنٍ في تخصّص الأورام على Gemini عند استخدام عدّة أمثلة.
            </p>
            <div class="figure*">
                <p><img src="figures/accuracy_by_bias.png" style="width:70.0%" alt="الأداء بحسب فئة السؤال الطبي" /></p>
            </div>
        </section>
        <hr style="margin: 40px 0;">
        <div class="text-muted text-center">
            <small>
                تم تحويل هذه النسخة تلقائياً من LaTeX.<br>
                تُعرض المعادلات الرياضية باستخدام MathJax.
            </small>
        </div>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>