<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Daniel Menges">
  <meta name="author" content="Adil Rasheed">
  <title>تحليلات تنبؤية قوية وفعّالة من حيث الحساب والذاكرة باستخدام البيانات الضخمة</title>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap');
    html, body {
      font-family: 'Cairo', 'Segoe UI', Tahoma, Geneva, Verdana, Arial, sans-serif;
      background: #f8f9fa;
      color: #222;
      font-size: 20px;
      line-height: 1.8;
      margin: 0;
      padding: 0;
      direction: rtl;
    }
    body {
      max-width: 900px;
      margin: 40px auto 40px auto;
      padding: 32px 24px 32px 24px;
      background: #fff;
      border-radius: 18px;
      box-shadow: 0 4px 32px 0 rgba(0,0,0,0.08);
    }
    header {
      text-align: center;
      margin-bottom: 40px;
    }
    h1.title {
      font-size: 2.3em;
      font-weight: 700;
      color: #1a237e;
      margin-bottom: 0.2em;
      margin-top: 0.2em;
      letter-spacing: 0.01em;
    }
    .author {
      font-size: 1.1em;
      color: #374151;
      margin: 0.2em 0;
    }
    h1, h2, h3 {
      color: #0d47a1;
      font-weight: 700;
      margin-top: 2.2em;
      margin-bottom: 0.7em;
      line-height: 1.3;
    }
    h2 {
      font-size: 1.4em;
      border-right: 4px solid #1976d2;
      padding-right: 12px;
      background: #e3f2fd;
      border-radius: 8px 0 0 8px;
      margin-top: 2em;
    }
    h3 {
      font-size: 1.15em;
      color: #1976d2;
      margin-top: 1.5em;
      margin-bottom: 0.5em;
    }
    p {
      margin: 1.1em 0;
      text-align: justify;
    }
    ul, ol {
      margin: 1.2em 2em 1.2em 0;
      padding-right: 1.5em;
    }
    ul li, ol li {
      margin-bottom: 0.7em;
      font-size: 1em;
    }
    strong {
      color: #0d47a1;
    }
    code, pre {
      font-family: 'Fira Mono', 'Consolas', 'Courier New', monospace;
      background: #f1f3f4;
      color: #b71c1c;
      padding: 2px 6px;
      border-radius: 5px;
      font-size: 0.95em;
    }
    pre {
      display: block;
      padding: 16px;
      overflow-x: auto;
      background: #f1f3f4;
      border-radius: 8px;
      margin: 1.5em 0;
    }
    blockquote {
      border-right: 4px solid #1976d2;
      background: #e3f2fd;
      color: #374151;
      margin: 1.5em 0;
      padding: 1em 1.5em;
      border-radius: 8px 0 0 8px;
      font-size: 1.05em;
    }
    table {
      border-collapse: collapse;
      width: 100%;
      margin: 1.5em 0;
      background: #fafbfc;
      border-radius: 8px;
      overflow: hidden;
    }
    th, td {
      border: 1px solid #e0e0e0;
      padding: 10px 14px;
      text-align: center;
    }
    th {
      background: #e3f2fd;
      color: #0d47a1;
      font-weight: 700;
    }
    .math.display, .math.inline {
      direction: ltr;
      unicode-bidi: embed;
      font-size: 1.05em;
      background: #f1f3f4;
      padding: 2px 8px;
      border-radius: 5px;
      margin: 0 0.2em;
      display: inline-block;
      vertical-align: middle;
    }
    .math.display {
      display: block;
      margin: 1.2em auto;
      text-align: center;
      font-size: 1.1em;
    }
    .nodecor {
      text-decoration: none;
      color: #374151;
    }
    h1:not(.title) {
      border-bottom: 2px solid #1976d2;
      padding-bottom: 0.2em;
      margin-bottom: 1.2em;
      margin-top: 2.5em;
    }
    @media (max-width: 600px) {
      body {
        padding: 10px 2vw;
        font-size: 17px;
      }
      h1.title {
        font-size: 1.3em;
      }
      h2 {
        font-size: 1.1em;
        padding-right: 7px;
      }
    }
    .MathJax_Display {
      direction: ltr !important;
      text-align: center !important;
    }
  </style>
</head>
<body>
<header>
  <h1 class="title">تحليلات تنبؤية قوية وفعّالة من حيث الحساب والذاكرة باستخدام البيانات الضخمة</h1>
  <p class="author"><span class="nodecor">Daniel Menges</span></p>
  <p class="author"><span class="nodecor">Adil Rasheed</span></p>
</header>

<h1 id="ملخص">مُلخّص</h1>
<p>في العصر الراهن، غدت البيانات الضخمة ركيزةً أساسيةً للذكاء الاصطناعي، إذ تُستخدم قاعدةً لتطوير نماذج مُعتمِدة على البيانات وتوليد رؤى في مجالات متنوّعة. تتناول هذه الدراسة التحدّيات المرتبطة بشكوك البيانات، وقيود التخزين، والنمذجة التنبؤية عبر البيانات الضخمة. نعتمد تحليل المكوّنات الرئيسية المتين لتقليل الضوضاء بفعالية والتخلّص من القيم الشاذّة، إضافةً إلى تحديد مواقع الاستشعار الأمثل من أجل ضغط البيانات وتخزينها بكفاءة عالية. تتيح هذه التقنية ضغط البيانات دون فقدان جوهري للمعلومات مع تقليل الحاجة إلى السعة التخزينية. وبالموازاة، يوفّر تحليل المكوّنات الرئيسية المتين بديلاً أشدّ صلابةً من التحليل التقليدي لإدارة البيانات عالية الأبعاد، مع توسيع نطاقه ليشمل النمذجة المتينة للبيانات الضخمة في الزمن الحقيقي. لهذا الغرض، نُطبّق شبكات الذاكرة طويلة وقصيرة الأمد (LSTM)، وهي فئة من الشبكات العصبية المتكرّرة، لنمذجة البيانات والتنبّؤ بها استناداً إلى مجموعة فرعية منخفضة الأبعاد مُستخلصة عبر تحديد مواقع الاستشعار الأمثل، ما يُسرّع بصورة ملحوظة مرحلة التدريب. تُعدّ شبكات LSTM مناسبة لالتقاط الاعتماديات طويلة المدى في بيانات السلاسل الزمنية، ما يجعلها ملائمةً للتنبؤ بالحالات المستقبلية للأنظمة الفيزيائية اعتماداً على البيانات التاريخية. وقد قمنا بصياغة ومحاكاة جميع الخوارزميات والتحقّق من صحّتها باستخدام بيانات تصوير حراري حقيقية لمحرك سفينة.</p>

<h1 id="مقدمة">مُقَدِّمة</h1>
<p>في سياق الذكاء الاصطناعي، تتصدّر البيانات المشهد، إذ تؤثّر في عمليات اتخاذ القرار في مجالات عدّة، من الرعاية الصحية (<span class="nodecor">raghupathi_big_2014</span>) إلى الاقتصاد القياسي (<span class="nodecor">varian_big_2014</span>) والتصنيع (<span class="nodecor">nagorny_big_2017</span>) وغيرها. ومع ذلك، ورغم الإمكانات الهائلة للبيانات الضخمة، من الضروري فهم نقاط قوتها وضعفها؛ فهي غالباً ما تتضمّن أخطاء ناتجة عن عدم دقّة المستشعرات أو أعطال النقل، ما قد يؤدّي إلى تفسير خاطئ للبيانات إذا لم تُعالَج على نحو سليم، لا سيّما عند وجود تشوّهات أو بيانات ناقصة (<span class="nodecor">pitici_rise_2014</span>). لذا، فإن القدرة على التعامل بفعالية مع كميات البيانات المتزايدة وتحليلها وتفسيرها تُعدّ أمراً حيوياً، وتستدعي تطوير تقنيات تحليلية متينة.</p>
<p>من بين الأدوات المتعددة لتحليل البيانات، حظي تحليل المكوّنات الرئيسية (<span class="nodecor">PCA</span>) (<span class="nodecor">jolliffe_principal_2002</span>) باهتمام كبير لما يوفّره من تقليل أبعاد مجموعات البيانات مع الحفاظ على معظم المعلومات (<span class="nodecor">abdi_principal_2010</span>). ومع ذلك، فإن PCA التقليدي يتأثر بشدّة بالقيم الشاذّة وتلف البيانات، ما ينعكس على أدائه ودقّة الاستنتاجات اللاحقة. ولهذا برزت تقنيات أشدّ متانة قادرة على التعامل مع هذه الاختلالات. يقدّم تحليل المكوّنات الرئيسية المتين (<span class="nodecor">RPCA</span>)، وهو نسخة متقدمة من PCA، نتائج أكثر موثوقية عبر فصل المكوّن منخفض الرتبة والمكوّن المتناثر في البيانات، حتى في وجود قيم شاذّة أو بيانات مفقودة (<span class="nodecor">hubert_robpca_2005</span>). وقد شُرح مفهوم RPCA لتفكيك مصفوفة البيانات إلى مكوّن منخفض الرتبة وآخر متناثر بتفصيل في (<span class="nodecor">candes_robust_2011</span>)، حيث يُنفَّذ عبر برمجة محدّبة تُعرف بـ «مطاردة المكوّنات الرئيسية» (PCP). تُتيح هذه الطريقة استعادة المكوّنات الرئيسية حتى عند وجود أخطاء أو قيَم مفقودة في البيانات، الأمر الذي يفتح آفاقاً جديدةً في مجالات مراقبة الفيديو وكشف الأجسام في الخلفيات المعقّدة والتعرّف على الوجوه لمعالجة الظلال والانعكاسات وغيرها. وتقدّم دراسة (<span class="nodecor">scherl_robust_2019</span>) مقارنة مفصّلة بين PCA وRPCA، مبيّنةً الفوائد والقدرة العالية لتحليل المكوّنات الرئيسية المتين.</p>
<p>بالتوازي مع ذلك، ومع تصاعد حجم البيانات الضخمة، يبرز تحدٍّ رئيسي في كيفية تخزينها ونقلها بفعالية. يأتي مفهوم «تحديد مواقع الاستشعار الأمثل» (<span class="nodecor">OSP</span>) (<span class="nodecor">manohar_data-driven_2018</span>) كنهج مبتكر يُعنى بتموضع المستشعرات استراتيجياً لالتقاط البيانات الأكثر صلة وتجنّب التكرار، مما يقلّل حمل التخزين ويُيسّر عملية النقل. في جوهره، يهدف OSP إلى إنتاج تمثيل مضغوط للبيانات بأقل خسارة معلوماتية.</p>
<p>من خلال استعراض منهجي لـ RPCA وOSP، تهدف هذه الدراسة إلى استكشاف التكامل بين المنهجيتين وتأثيرهما في تعزيز دقّة وكفاءة نمذجة البيانات الضخمة.</p>
<p>علاوةً على ذلك، نُوسّع هذه الدراسة بدمج نهج تنبّئي معتمد على البيانات باستخدام شبكات الذاكرة طويلة وقصيرة الأمد (<span class="nodecor">LSTM</span>)، التي قدّمها (<span class="nodecor">hochreiter_long_1997</span>). تتيح آليات البوابات في LSTM تعلّم الاعتماديات طويلة الأمد في البيانات (<span class="nodecor">chung_gated_2015</span>). وقد حظيت الشبكات العصبية الاصطناعية (<span class="nodecor">ANNs</span>) باهتمام واسع في التنبؤ بفضل قابليتها للتكيّف ولاخطيّتها وقدرتها على تمثيل الوظائف المعقّدة، رغم أنها تتطلّب وقتاً حسابياً كبيراً للتدريب (<span class="nodecor">zhang_forecasting_1998</span>). لذلك، نصمّم نماذج LSTM استناداً إلى عدد قليل من نقاط البيانات المختارة عبر خوارزمية OSP، مما يُعجّل بصورة كبيرة زمن التدريب ويُيسّر التطبيق واسع النطاق. فعند استخدام هذه النماذج للتنبؤ بالقياسات المختارة، نُعيد بعد ذلك بناء البعد الكامل للبيانات عبر مفهوم OSP، مما يمكّننا من التنبؤ بدقّة بالحالات المستقبلية في الأبعاد الأصلية. إن دمج RPCA وOSP وLSTM يوفّر نهجاً مبتكراً لمعالجة البيانات الضخمة يجمع بين المتانة والكفاءة الحسابية وقابلية التوسّع عبر سيناريوهات واقعية متعددة.</p>
<p>في هذه الدراسة، طبّقنا الخوارزميات على بياناتٍ مُستخلصة من كاميرا حرارية تُصوّر محرك سفينة. توفّر الصور الحرارية رؤية فريدة لملامح درجات الحرارة وتقلباتها، مما يُتيح فهماً أعمق لسلوك التشغيل وأداء المحرك. تُعد المراقبة الشرطية ضروريةً للحفاظ على سلامة العمليات (<span class="nodecor">mohanty_machinery_2014</span>) وتمكّن من تقدير موثوقيّة المحرك ومكوّناته. ومن خلال الكشف المبكّر عن الشذوذ، يمكن التنبّؤ بعمر المكونات ومنع الأعطال الجسيمة.</p>

<h1 id="التحديات-الأساسية">التحدّيات الأساسية</h1>
<p>باختصار، تتناول هذه الدراسة ثلاثة تحدّيات أساسية:</p>
<ul>
  <li>المعالجة المتينة للشكوك مثل القيم الشاذّة وتلف البيانات النابع من قياسات كاميرا حرارية منخفضة الكلفة وغير متطفّلة.</li>
  <li>الحاجة إلى تقنيات تخزين فعّالة من حيث استهلاك الذاكرة نظرًا للكمّ الهائل من البيانات المتولّدة.</li>
  <li>القدرة على إجراء صيانة استباقية في الزمن الحقيقي عبر نمذجة تنبّؤية معتمدة على البيانات.</li>
</ul>
<p>كما أشار المرجع (<span class="nodecor">inproceedings</span>)، نادراً ما يعتمد القطاع البحري الصيانة التنبّؤية، بل تميل أنشطته إلى الصيانة الوقائية، مما يؤدّي غالباً إلى تكاليف أعلى نتيجة استبدال مكوّنات لا تزال صالحة.</p>

<h1 id="النظرية">النظرية</h1>
<p>يقدّم هذا القسم نظرة معمّقة على التقنيات الإحصائية المستخدمة في الدراسة. نشرح فيه مفهومي تحليل المكوّنات الرئيسية (PCA) ونظيره المتين (RPCA) لتنقية البيانات، كما نتناول فكرة تحديد مواقع الاستشعار الأمثل (OSP) لضغط البيانات وإدارة التخزين بكفاءة.</p>

<h2 id="تحليل-المكونات-الرئيسية">تحليل المكوّنات الرئيسية</h2>
<p>تحليل المكوّنات الرئيسية (Principal Component Analysis) إجراء إحصائي يستخدم تحويلاً متعامداً لتحويل مجموعة من الملاحظات لعدّة متغيّرات مترابطة إلى مجموعة من المتغيّرات غير المرتبطة خطّياً تُسمّى المكوّنات الرئيسية. يسمح ذلك بتحديد الاتجاهات ذات التباين الأكبر في البيانات. هناك نهجان رئيسيان لحساب PCA: نهج المتجه الذاتي ونهج تحليل القيمة المفردة (Singular Value Decomposition). وتُفصَّل هذه المفاهيم في (<span class="nodecor">shlens_tutorial_2014</span>). وغالباً ما يُفضَّل نهج SVD لكونه أكثر ثباتاً عدديّاً.</p>

<h3 id="نهج-تحليل-القيمة-المفردة" class="unnumbered">نهج تحليل القيمة المفردة</h3>
<p>يرتبط تحليل المكوّنات الرئيسية ارتباطاً وثيقاً بتحليل القيمة المفردة، وهو تحليل لمصفوفة حقيقية أو مركّبة. لأي مصفوفة حقيقية <span class="math inline">\(\mathbf{A}\in \mathbb{R}^{m\times n}\)</span>، حيث <span class="math inline">\(m \geq n\)</span>، يوجد تحليل من الشكل <span class="math display">\[\mathbf{A} = \mathbf{U} \mathbf{\Sigma} \mathbf{V}^T,\]</span> حيث <span class="math inline">\(\mathbf{U}\in \mathbb{R}^{m\times m}\)</span>، و<span class="math inline">\(\mathbf{\Sigma}\in \mathbb{R}^{m\times n}\)</span>، و<span class="math inline">\(\mathbf{V}\in \mathbb{R}^{n\times n}\)</span>. أعمدة <span class="math inline">\(\mathbf{U}\)</span> هي متجهات ذاتية متعامدة لـ <span class="math inline">\(\mathbf{AA}^T\)</span>، وأعمدة <span class="math inline">\(\mathbf{V}\)</span> هي متجهات ذاتية متعامدة لـ <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span>. العناصر القُطرية لـ <span class="math inline">\(\mathbf{\Sigma}\)</span> هي الجذور التربيعية للقيم الذاتية لـ <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span> (أو بالمثل، <span class="math inline">\(\mathbf{AA}^T\)</span>)، وتُسمّى القيمَ المفردة لـ <span class="math inline">\(\mathbf{A}\)</span>. لرؤية ذلك، نعتبر أولاً المصفوفة <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span>، وهي مصفوفة متماثلة. وبموجب نظرية الطيف، يمكننا تحليلها كما يلي: <span class="math display">\[\mathbf{A}^T\mathbf{A} = \mathbf{V} \mathbf{\Sigma}^2\mathbf{V}^T.\]</span> بالمثل، يمكننا تحليل <span class="math inline">\(\mathbf{AA}^T\)</span> كما يلي: <span class="math display">\[\mathbf{AA}^T = \mathbf{U} \mathbf{\Sigma}^2 \mathbf{U}^T.\]</span> باستخدام هاتين الهويتين، يمكن إظهار أن <span class="math display">\[\mathbf{A} = \mathbf{U} \mathbf{\Sigma} \mathbf{V}^T\]</span> وهو تحليل القيمة المفردة لـ <span class="math inline">\(\mathbf{A}\)</span>.</p>
<p>لننظر إلى مصفوفة بيانات <span class="math inline">\(\mathbf{X} \in \mathbb{R}^{m \times n}\)</span>، حيث كل صفّ هو ملاحظة وكل عمود هو متغيّر. نفترض أن البيانات قد تم توسيطها، أي تم طرح متوسطات الأعمدة.</p>
<ol>
  <li><em>تحليل قيمة مفردة منخفض الرتبة:</em> احسب تحليل القيمة المفردة لـ <span class="math inline">\(\mathbf{X}\)</span> بواسطة <span class="math inline">\(\mathbf{X} = \mathbf{U}_r\mathbf{\Sigma}_r\mathbf{V}_r^T+\mathbf{E}\)</span>. هنا، <span class="math inline">\(\mathbf{U}_r \in \mathbb{R}^{m \times r}\)</span> و<span class="math inline">\(\mathbf{V}_r \in \mathbb{R}^{n \times r}\)</span> مصفوفتان بعموديات متعامدة تحتويان على المتجهات الذاتية اليسرى واليمنى، و<span class="math inline">\(r\)</span> هو عدد المكوّنات الرئيسية. المصفوفة <span class="math inline">\(\mathbf{\Sigma}_r \in \mathbb{R}^{r \times r}\)</span> تحتوي على أكبر <span class="math inline">\(r\)</span> قيَم مفردة بترتيب تنازلي على القطر. بالإضافة إلى ذلك، تحتوي المصفوفة <span class="math inline">\(\mathbf{E}\)</span> على البواقي غير الممثّلة بسبب تقليل الأبعاد.</li>
  <li><em>المكوّنات الرئيسية:</em> تُعطى المكوّنات الرئيسية لـ <span class="math inline">\(\mathbf{X}\)</span> بواسطة <span class="math inline">\(\mathbf{X}\mathbf{V}_r \approx \mathbf{U}_r \mathbf{\Sigma}_r\)</span>. العمود <span class="math inline">\(i\)</span> من <span class="math inline">\(\mathbf{X}\mathbf{V}_r\)</span> هو إسقاط البيانات على الاتجاه الرئيسي <span class="math inline">\(i\)</span> (أي المتجه الذاتي <span class="math inline">\(i\)</span>).</li>
</ol>
<p>يُظهر هذا الإجراء كيف يمكن استنتاج PCA من تحليل القيمة المفردة لمصفوفة البيانات. ومع ذلك، فإن PCA التقليدي شديد الحساسية للقيم الشاذّة وتلف البيانات.</p>

<h2 id="sec:RPCA">تحليل المكوّنات الرئيسية المتين</h2>
<p>الميزة الأبرز في RPCA مقارنةً بـ PCA التقليدي هي متانته حيال القيم الشاذّة. فـ PCA التقليدي حسّاس للقيم الشاذّة لكونه يحاول إيجاد تمثيل منخفض البعد يفسّر أكبر قدر من التباين، وقد يُحرّف هذا التمثيل اتجاهات البيانات الحقيقية عند وجود نقاط متطرّفة. أمّا RPCA فينمذج هذه القيم الشاذّة صراحةً، فتتحقّق دقّة أكبر في استعادة الهيكل الأساسي للبيانات.</p>
<p>في العديد من السيناريوهات، يستطيع RPCA استرجاع الهيكل منخفض الرتبة الحقيقي للبيانات أفضل ممّا يوفّره PCA، خاصةً عندما تَسود التشويشات أو يكون هناك نقص كبير في العينات.</p>
<p>تعتمد الفكرة العامة على تفكيك مصفوفة البيانات <span class="math inline">\(\mathbf{X}\)</span> إلى مكوّنين:</p>
<span class="math display">\[\mathbf{X} = \mathbf{L} + \mathbf{S}.\]</span>
<p>حيث تصف <span class="math inline">\(\mathbf{L}\)</span> المكوّن منخفض الرتبة الذي يلتقط الهيكل الرئيسي للبيانات، وتصف <span class="math inline">\(\mathbf{S}\)</span> المكوّن المتناثر الذي يلتقط القيم الشاذّة أو التشوّهات. والهدف هو إيجاد <span class="math inline">\(\mathbf{L}\)</span> و<span class="math inline">\(\mathbf{S}\)</span> اللذين يحلّان:</p>
<span class="math display">\[
\begin{aligned}
& \underset{\mathbf{L}, \mathbf{S}}{\mathrm{تصغير}}\ \mathrm{rank}(\mathbf{L}) + \|\mathbf{S}\|_0, \\
& \text{خاضع لـ}\ \ \mathbf{L} + \mathbf{S} = \mathbf{X},
\end{aligned}
\]</span>
<p>نظراً للطبيعة غير المحدّبة لرُتبة <span class="math inline">\(\mathbf{L}\)</span> و«شبه-المعيار» <span class="math inline">\(\|\mathbf{S}\|_0\)</span>، تُصبح هذه المشكلة صعبة الحل عملياً (<span class="nodecor">scherl_robust_2019</span>). للتغلّب على ذلك، يُستخدم «الاسترخاء المحدّب» (<span class="nodecor">JMLR:v11:zhang10a</span>) الذي يحوّل المشكلة إلى:</p>
<span class="math display">\[
\begin{aligned}
& \underset{\mathbf{L}, \mathbf{S}}{\mathrm{تصغير}}\ \|\mathbf{L}\|_* + \lambda \|\mathbf{S}\|_1, \\
& \text{خاضع لـ}\ \ \mathbf{L} + \mathbf{S} = \mathbf{X},
\end{aligned}
\]</span>
<p>حيث يُمثّل تصغير «المعيار النووي» <span class="math inline">\(\|\mathbf{L}\|_*\)</span> استبدالاً محدّباً لتصغير الرتبة، ويُمثّل تصغير «معيار» <span class="math inline">\(\|\mathbf{S}\|_1\)</span> استبدالاً محدّباً لـ <span class="math inline">\(\|\mathbf{S}\|_0\)</span>. تُعرَف المشكلة الناتجة باسم «مطاردة المكوّنات الرئيسية» (PCP)، ويمكن حلّها عبر خوارزمية مُضاعِف لاغرانج المُعزَّز (<span class="nodecor">lin_augmented_2010</span>)، التي تُصاغ كالآتي:</p>
<span class="math display">\[
\mathcal{L}(\mathbf{L}, \mathbf{S}, \mathbf{\Lambda})=\|\mathbf{L}\|_* + \lambda \|\mathbf{S}\|_1+\langle \mathbf{\Lambda}, \mathbf{X} - \mathbf{L} - \mathbf{S} \rangle + \frac{\mu}{2}\|\mathbf{X}-\mathbf{L}-\mathbf{S}\|_{F}^2
\]</span>
<p>حيث <span class="math inline">\(\mathbf{\Lambda}\)</span> مصفوفة مُضاعِفات لاغرانج و<span class="math inline">\(\mu\)</span> معامل الضبط. ثم يُحدَّث <span class="math inline">\(\mathbf{\Lambda}\)</span> عبر:</p>
<span class="math display">\[\mathbf{\Lambda}_{k+1} = \mathbf{\Lambda}_{k} + \mu(\mathbf{X}-\mathbf{L}_k-\mathbf{S}_k).\]</span>
<p>وبهذه الطريقة، يُحلّل RPCA مصفوفة البيانات <span class="math inline">\(\mathbf{X}\)</span> إلى مكوّنات منخفضة الرتبة <span class="math inline">\(\mathbf{L}\)</span> ومتناثرة <span class="math inline">\(\mathbf{S}\)</span>.</p>

<h2 id="تحديد-مواقع-الاستشعار-الأمثل">تحديد مواقع الاستشعار الأمثل</h2>
<p>تحديد مواقع الاستشعار الأمثل أسلوب لاستخلاص أفضل المواضع داخل النظام لوضع المستشعرات. يهدف هذا النهج إلى تعظيم المعلومات المُكتسَبة (مثل الإنتروبيّا) مع تقليل عدد المستشعرات.</p>
<p>لتكن <span class="math inline">\(\boldsymbol{x} \in \mathbb{R}^n\)</span> نقطة بيانات في زمن معيّن، ويمكن تقريبها كما يلي:</p>
<span class="math display">\[\boldsymbol{x} \approx \mathbf{\Psi}_r \boldsymbol{a},\]</span>
<p>حيث <span class="math inline">\(\boldsymbol{a} \in \mathbb{R}^{r}\)</span> متجه المعاملات الزمني، وأعمدة <span class="math inline">\(\mathbf{\Psi}_r\)</span> هي الأوضاع الأرثوغونالية منخفضة الرتبة (حيث <span class="math inline">\(\mathbf{\Psi}_r = \mathbf{U}_r\)</span>). إذا اعتبرنا القياسات:</p>
<span class="math display">\[\boldsymbol{y} = \mathbf{C}\boldsymbol{x},\]</span>
<p>حيث <span class="math inline">\(\mathbf{C}\in \mathbb{R}^{s\times n}\)</span> مصفوفة قياس متناثرة و<span class="math inline">\(s\)</span> عدد المستشعرات، فإنها تقرّب بـ:</p>
<span class="math display">\[\boldsymbol{y} \approx \mathbf{C}\mathbf{\Psi}_r \boldsymbol{a}.\]</span>
<p>إذا مثّلنا <span class="math inline">\(\mathbf{\Theta} = \mathbf{C}\mathbf{\Psi}_r\)</span>، يمكن تقدير المعاملات عبر:</p>
<span class="math display">\[\boldsymbol{\hat{a}} = \mathbf{\Theta}^\dagger\boldsymbol{y}.\]</span>
<p>ومن ثمّ تُعاد بناء النقطة كالتالي:</p>
<span class="math display">\[\boldsymbol{\hat{x}} = \mathbf{\Psi}_r\boldsymbol{\hat{a}} = \mathbf{\Psi}_r(\mathbf{C}\mathbf{\Psi}_r)^\dagger\boldsymbol{y}.\]</span>
<p>وبما أن <span class="math inline">\(\mathbf{\Psi}_r\)</span> معلوم من تحليل الأبعاد المنخفضة، يبقى <span class="math inline">\(\mathbf{C}\)</span> مجهولاً. وكما أوضح (<span class="nodecor">manohar_data-driven_2018</span>)، يُحدَّد OSP عبر تحليل QR مع تبديل الأعمدة على <span class="math inline">\(\mathbf{\Psi}_r^T\)</span>، مع مراعاة شرط <span class="math inline">\(s \geq r\)</span>.</p>

<h1 id="المنهجية">المنهجية</h1>
<p>يصف هذا القسم سير عمل الإطار المقترَح لمعالجة البيانات الضخمة، بدءاً من تنقية البيانات ثم ضغطها وصولاً إلى النمذجة المعتمدة على البيانات بكفاءة حسابية عالية. يقوم جوهر المنهجية على RPCA وOSP وشبكات LSTM.</p>

<h2 id="تنظيف-البيانات">تنقية البيانات</h2>
<p>في خطوة تنقية البيانات، نستخدم RPCA كما عُرض في قسم <a class="nodecor" href="#sec:RPCA">تحليل المكوّنات الرئيسية المتين</a>. تم اختيار ثوابت الضبط بحيث <span class="math inline">\(\lambda = 0.006\)</span> و<span class="math inline">\(\mu = 10^{-5}\)</span>. بعد تفكيك مصفوفة البيانات <span class="math inline">\(\mathbf{X}\)</span> إلى مصفوفتَي <span class="math inline">\(\mathbf{L}\)</span> (منخفضة الرتبة) و<span class="math inline">\(\mathbf{S}\)</span> (متناثرة)، نُعيد بناء نسخة نظيفة من البيانات بالاعتماد على <span class="math inline">\(\mathbf{L}\)</span> التي تمثّل الفيزياء الكامنة، بينما تُظهر <span class="math inline">\(\mathbf{S}\)</span> التشوّهات والشوائب. وبذلك نحصل على بيانات مُصقَّاة مناسبة للمراحل اللاحقة.</p>

<h2 id="ضغط-البيانات">ضغط البيانات</h2>
<p>لضغط البيانات مع الحفاظ على المعلومات الأساسية للنظام، نُطبّق خوارزمية OSP الموضّحة في قسم <a class="nodecor" href="#تحديد-مواقع-الاستشعار-الأمثل">تحديد مواقع الاستشعار الأمثل</a> على مصفوفة <span class="math inline">\(\mathbf{L}\)</span> الناتجة عن المرحلة السابقة. يقوم المبدأ الأساسي على اختيار مواقع مستشعرات تلتقط أكبر قدر من تباين البيانات، مما يسمح بتمثيل <span class="math inline">\(\mathbf{X}\)</span> بمجموعة أقل من القياسات <span class="math inline">\(\mathbf{Y}\)</span>، حيث تُكدّس <span class="math inline">\(\boldsymbol{y}\)</span> في نافذة زمنية محدّدة. تُمثَّل هذه المجموعة المضغوطة بمصفوفة قياس متناثرة <span class="math inline">\(\mathbf{C}\)</span>. بتقليل عدد المستشعرات، نحدّ من التكاليف وسعة التخزين المطلوبة دون المساس بدقّة التمثيل.</p>

<h2 id="نمذجة-القياسات-المتناثرة-باستخدام-شبكات-lstm">نمذجة القياسات المتناثرة باستخدام شبكات LSTM</h2>
<p>في سياق النمذجة المعتمدة على البيانات، أثبتت الشبكات العصبية، ولا سيّما LSTM، فعاليتها في العديد من التطبيقات. صُمّمت LSTM لتحمّل المعلومات على مدى تسلسلات طويلة، مما يجعلها مثالية لمعالجة بيانات السلاسل الزمنية. غير أن تطبيقها مباشرةً على البيانات الضخمة قد يكون مُكلِفاً حسابياً، لذا نُطبّق LSTM على مجموعة فرعية منخفضة الأبعاد <span class="math inline">\(\mathbf{Y}\)</span> المُستخرجة عبر OSP.</p>
<p>يسهم دمج LSTM مع OSP في خفض العبء الحسابي للتدريب بصورة كبيرة. عند استخدام LSTM لنمذجة هذه القياسات المختارة، نستهدف التقاط الديناميكيات الزمنية الكامنة. وبعد تدريب الشبكات، يمكنها التنبؤ بقِيَم القياسات المتناثرة، ومن ثم إعادة بناء البيانات بالحجم الكامل باستخدام المعادلة <span class="math inline">\(\boldsymbol{\hat{x}} = \mathbf{\Psi}_r(\mathbf{C}\mathbf{\Psi}_r)^\dagger\boldsymbol{y}\)</span>. يتيح ذلك إعادة إسقاط التنبؤات على الأبعاد الأصلية للبيانات. وتجدر الإشارة إلى أنه عند أخذ العينات بفواصل زمنية غير منتظمة، قد تُحسّن مرحلةُ الاستيفاء المُسبق دقّة النماذج.</p>

<h2 id="تدفق-البيانات-الضخمة">تدفق البيانات الضخمة</h2>
<p>يسمح نهج التكامل السابق بتدفّق عمل متّسق لمعالجة البيانات الضخمة، يتكوّن من المراحل التالية:</p>
<ol>
  <li><strong>تنقية البيانات:</strong> يُولّد RPCA نسخةً نظيفة <span class="math inline">\(\mathbf{L}\)</span> من مصفوفة البيانات <span class="math inline">\(\mathbf{X}\)</span>. وبما أنّ <span class="math inline">\(\mathbf{L}\)</span> يحافظ على الديناميكيات الأساسية للنظام، يمكن نقلها إلى المراحل اللاحقة من المعالجة والتحليل.</li>
  <li><strong>ضغط البيانات:</strong> تُتيح خوارزمية OSP ضغطاً مكثّفاً لمصفوفة البيانات النظيفة <span class="math inline">\(\mathbf{L}\)</span>. عبر حساب أوضاع <span class="math inline">\(\mathbf{\Psi}_r\)</span> وإيجاد مصفوفة القياس <span class="math inline">\(\mathbf{C}\)</span>، تُصبح مجموعة فرعية صغيرة <span class="math inline">\(\mathbf{Y}\)</span> كافية لتمثيل البيانات. يجب تخزين <span class="math inline">\(\mathbf{\Psi}_r\)</span> و<span class="math inline">\(\mathbf{C}\)</span> لإعادة البناء لاحقاً إلى <span class="math inline">\(\boldsymbol{\hat{x}}\)</span>.</li>
  <li><strong>النمذجة المعتمدة على البيانات:</strong> نُنشئ نماذج LSTM للمجموعة الفرعية المُقاسة <span class="math inline">\(\mathbf{Y}\)</span>. بعد التنبؤ بالمجموعة الفرعية المستقبلية، يُعاد بناء التنبؤ للأبعاد الأصلية <span class="math inline">\(\mathbf{\hat{X}_{pred}}\)</span> باستخدام <span class="math inline">\(\mathbf{\Psi}_r\)</span> و<span class="math inline">\(\mathbf{C}\)</span>.</li>
</ol>

<h1 id="إعداد-المحاكاة">إعداد المحاكاة</h1>
<p>في هذه الدراسة، اعتَمَدنا بياناتٍ مُلتقطة بكاميرا حرارية لرصد محرك سفينة، وقد زوّدتنا بها شركة Idletechs AS. ونظراً لجودة البيانات وخلوّها من شوائب كبيرة، قمنا بإضافة اضطرابات اصطناعية وفق السيناريوهات التالية. كما نصف إعداد شبكة LSTM المستخدمة.</p>

<h2 id="البيانات">البيانات</h2>
<p>سُحِبت مجموعة البيانات من صور كاميرا حرارية تُظهر محرك سفينة عَبّارة، بهدف مراقبة السلوك الحراري خلال مراحل الإقلاع والتشغيل المستقر والتوقّف. استمر جمع البيانات على مدار أربعة أيام متتالية، إذ جُمعت نحو 24 ساعة من المراقبة بفاصل زمني وسطي قدره <span class="nodecor">0.5</span> ثانية بين القياسات. تحتوي كل صورة على <span class="nodecor">19,200</span> بكسل (120×160)، حيث يلتقط كل بكسل الإشعاعات الحرارية الصادرة عن المحرك، مما يوفّر مؤشراً على الأداء الحراري وأي بقع ساخنة محتملة.</p>

<h2 id="Section: Perturbations">الاضطرابات</h2>
<p>لتقييم خوارزمياتنا تحت ظروف متباينة، نفّذنا أربعة سيناريوهات محاكاة تشمل الضوضاء، والشذوذ، والتلوّث، ومزيجاً منها.</p>

<h3 id="السيناريو-1" class="unnumbered">السيناريو 1</h3>
<p>تم تشويش البيانات بضوضاء غاوسيّة ذات متوسّط <span class="nodecor">0</span> وانحراف معياري <span class="nodecor">4</span>، مما يضمن انحصار معظم القيم ضمن النطاق <span class="nodecor">[-4, 4]</span>.</p>

<h3 id="السيناريو-2" class="unnumbered">السيناريو 2</h3>
<p>تم إدخال شذوذات عبر اختيار عشوائي لـ <span class="nodecor">100</span> نقطة بيانات (بكسل) واستبدال قيمها الأصلية بقيم عشوائية ضمن النطاقين <span class="nodecor">[30, 40]</span> و<span class="nodecor">[-40, -30]</span>، لمحاكاة شذوذ كبير في القياسات.</p>

<h3 id="السيناريو-3" class="unnumbered">السيناريو 3</h3>
<p>تم تلويث البيانات عشوائياً، حيث أُضيفت ضوضاء موزّعة بانتظام إلى <span class="nodecor">10%</span> من عينات البيانات ضمن الفترة <span class="nodecor">[-15, 30]</span>، لاختبار متانة خوارزميات PCA وRPCA وOSP.</p>

<h3 id="السيناريو-4" class="unnumbered">السيناريو 4</h3>
<p>تم تشويش البيانات بمزيج من السيناريوهات السابقة (1 و2 و3)، مما أدّى إلى تراكب أنواع الضوضاء والشذوذ والتلوّث.</p>

<h2 id="هندسة-شبكة-الذاكرة-طويلة-الأمد">هندسة شبكة الذاكرة طويلة الأمد</h2>
<p>لاختيار إعدادات شبكة LSTM، جُرّبت عدّة توليفات للمعاملات، واعتمدنا في النهاية مُحسِّن «آدم» لتدريب الشبكة، مع استخدام مقياس الجذر التربيعي للخطأ المتوسط (RMSE) لتقييم الأداء. للتنبؤ، استخدمنا نافذة تاريخية مكوّنة من <span class="nodecor">50</span> عيّنة، مع أفق تنبّؤي قدره <span class="nodecor">100</span> خطوة زمنية. تتكوّن بنية الشبكة من طبقة إدخال، وطبقة LSTM، وطبقة كثيفة (Dense)، وطبقة إخراج. ولتفادي الإفراط في التخصيص، أُضيفت طبقة إسقاط (dropout)، وهي تقنية تحذف بشكل عشوائي بعض الوحدات والوصلات أثناء التدريب (<span class="nodecor">nitish_srivastava_geoffrey_hinton_alex_krizhevsky_ilya_sutskever_and_ruslan_salakhutdinov_dropout_2014</span>).</p>

<h1 id="النتائج-والمناقشة">النتائج والمناقشة</h1>
<p>فيما يلي، نعرض نتائج مراحل التنقية والضغط والنمذجة المعتمدة على البيانات لكل سيناريو من السيناريوهات الأربعة.</p>

<h2 id="تنظيف-البيانات-1">تنقية البيانات</h2>
<p>تُظهر نتائج تنقية البيانات لكل سيناريو من السيناريوهات الواردة في قسم «الاضطرابات» أن RPCA يفصل مصفوفة <span class="math inline">\(\mathbf{L}\)</span> التي تمثّل الصورة النظيفة عن مصفوفة <span class="math inline">\(\mathbf{S}\)</span> التي تجمع التشوّهات والشوائب. وبينما يُعاني PCA التقليدي من تأثير القيم الشاذّة بصورة واضحة، يحافظ RPCA على بنية الصورة الأساسية مع إزالة الشوائب، ما يعزّز دقّة تطبيقات الذكاء الاصطناعي المعتمدة على البيانات الضخمة.</p>

<h2 id="ضغط-البيانات-1">ضغط البيانات</h2>
<p>أظهر تطبيق OSP على بيانات الصور الحرارية تخفيضاً كبيراً في الأبعاد، حيث استُخدم فقط <span class="nodecor">10</span> قياسات بكسل من أصل <span class="nodecor">19200</span>. ورغم هذا الانخفاض الكبير، أمكن إعادة بناء الصور الأصلية بدقّة ملحوظة. من منظور ضغط البيانات، يتّضح دور OSP في خفض استهلاك الطاقة ومتطلّبات الذاكرة؛ فباستخدام مجموعة صغيرة من القياسات يمكن تمثيل البيانات الكاملة بفقدان معلوماتي ضئيل.</p>
<p>ويُمثَّل توفير الذاكرة بالنسبة للبيانات المضغوطة بالمعادلة:</p>
<span class="math display">\[\alpha = \frac{m}{s}.\]</span>
<p>في هذه الدراسة التجريبية، نحصل على <span class="math display">\[\alpha = \frac{19200}{10} = 1920\]</span>، ما يعني إمكان تخزين عدد صور أكبر بنحو 1920 مرّة ضمن السعة نفسها.</p>

<h2 id="نمذجه-تنبؤيه-معتمدة-على-البيانات">نمذجة تنبؤية معتمدة على البيانات</h2>
<p>دُرِّبت شبكة <span class="nodecor">LSTM</span> على الفضاء الفرعي منخفض الأبعاد <span class="math inline">\(\mathbf{Y}\)</span> المُستخلص عبر OSP، مع استيفاء البيانات المُسبق لمعالجة عدم انتظام الفواصل الزمنية للعينات. ولإبراز أثر الاستيفاء، عُرضت قيم <span class="nodecor">RMSE</span> للنماذج مع وبدون استيفاء أولي، إلى جانب مقارنة زمن التدريب. تكشف النتائج عن انخفاض ملموس في الخطأ وتوفير كبير في الزمن الحسابي باستخدام النهج المقترح. وتؤكّد هذه السرعة المحسّنة إمكانية التطبيق الفوري والتدريب عبر الإنترنت في الزمن الحقيقي، اعتماداً على عدد العصور ومعايير التدريب المختارة.</p>

<h1 id="الخلاصة">الخلاصة</h1>
<p>في الختام، يُحسّن تطبيق RPCA جودة بيانات الصور الحرارية بصورة ملحوظة، مما يُتيح تحليلات لاحقة أكثر موثوقية. وبفضل متانته وقابليته للتوسّع، يصلح هذا الإطار لمجموعة واسعة من التطبيقات المرتبطة بالبيانات الضخمة. كما يقدّم OSP وسيلة فعّالة لتعظيم كفاءة التخزين وضغط البيانات في البيئات ذات القيود الصارمة. وعن طريق تطبيق شبكات LSTM على فضاء منخفض الأبعاد مُشتق من OSP، نحصل على كفاءة حسابية مُحسّنة ودقّة تنبؤية عالية. إن هذا التكامل بين التقنيات المقدّمة يرفع مستويات جودة البيانات والكفاءة الحسابية والذاكرة، ويُمكّن من تحقيق تنبؤات في الزمن الحقيقي.</p>
</body>
</html>