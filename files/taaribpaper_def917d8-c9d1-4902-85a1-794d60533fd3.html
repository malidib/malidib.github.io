<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Bin Luo">
  <meta name="author" content="Susan Halabi">
  <title>شَبَكَة عَصَبِيَّة ذات مدخلات مُتَناثِرَة باستخدام تَنْظِيم مُقَعَّر جَماعِيّ</title>
  <link href="https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap" rel="stylesheet">
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>
    body {
      direction: rtl;
      font-family: 'Cairo', 'Segoe UI', 'Tahoma', 'Geneva', 'Verdana', sans-serif;
      font-size: 22px;
      background: #f8f9fa;
      color: #222;
      margin: 0;
      padding: 0;
      line-height: 1.7;
    }
    header {
      background: linear-gradient(90deg, #3a6073 0%, #16222a 100%);
      color: #fff;
      padding: 2.5rem 1.5rem 1.5rem 1.5rem;
      text-align: center;
      border-bottom-left-radius: 30px;
      border-bottom-right-radius: 30px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.08);
      margin-bottom: 2.5rem;
    }
    h1.title {
      font-size: 2.5rem;
      font-weight: 700;
      margin-bottom: 0.5rem;
      letter-spacing: 1px;
      line-height: 1.3;
    }
    .author {
      font-size: 1.2rem;
      margin: 0.2rem 0;
      color: #e0e0e0;
      font-weight: 400;
    }
    main {
      max-width: 900px;
      background: #fff;
      margin: 0 auto 2.5rem auto;
      padding: 2.5rem 2.5rem 2rem 2.5rem;
      border-radius: 24px;
      box-shadow: 0 4px 24px rgba(60,60,60,0.08);
    }
    h1, h2, h3, h4 {
      font-family: 'Cairo', 'Segoe UI', sans-serif;
      font-weight: 700;
      color: #2a3b4c;
      margin-top: 2.2rem;
      margin-bottom: 1rem;
      line-height: 1.4;
    }
    h1 {
      font-size: 2rem;
      border-bottom: 2px solid #e0e0e0;
      padding-bottom: 0.3rem;
      margin-bottom: 1.5rem;
    }
    h2 {
      font-size: 1.5rem;
      color: #3a6073;
      margin-top: 1.8rem;
      margin-bottom: 1rem;
    }
    h3 {
      font-size: 1.2rem;
      color: #4e5d6c;
      margin-top: 1.5rem;
      margin-bottom: 0.8rem;
    }
    p {
      margin: 1.1rem 0;
      text-align: justify;
    }
    ul, ol {
      margin: 1.2rem 2.5rem 1.2rem 0;
      padding-right: 1.5rem;
    }
    li {
      margin-bottom: 0.7rem;
    }
    code, pre {
      font-family: 'Fira Mono', 'Consolas', 'Monaco', monospace;
      background: #f3f3f3;
      color: #c7254e;
      padding: 0.2em 0.4em;
      border-radius: 4px;
      font-size: 0.95em;
    }
    .math.inline {
      font-size: 1.05em;
      color: #1a237e;
      background: #f0f4ff;
      padding: 0.1em 0.3em;
      border-radius: 4px;
    }
    .math.display {
      display: block;
      margin: 1.2em auto;
      background: #f0f4ff;
      border-radius: 8px;
      padding: 1em 1.5em;
      font-size: 1.1em;
      direction: ltr;
      text-align: left;
      overflow-x: auto;
    }
    .nodecor {
      text-decoration: none;
      color: #2a3b4c;
      font-weight: 600;
    }
    blockquote {
      border-right: 4px solid #3a6073;
      background: #f6fafd;
      margin: 1.5em 0;
      padding: 1em 1.5em;
      color: #444;
      border-radius: 8px;
    }
    @media (max-width: 700px) {
      main {
        padding: 1.2rem 0.7rem;
        border-radius: 0;
      }
      header {
        padding: 1.5rem 0.5rem 1rem 0.5rem;
        border-radius: 0;
      }
      h1.title {
        font-size: 1.5rem;
      }
    }
    table {
      border-collapse: collapse;
      width: 100%;
      margin: 1.5em 0;
      background: #f9f9f9;
      border-radius: 8px;
      overflow: hidden;
    }
    th, td {
      border: 1px solid #e0e0e0;
      padding: 0.7em 1em;
      text-align: center;
    }
    th {
      background: #e3eaf2;
      color: #2a3b4c;
      font-weight: 700;
    }
    h1[id^="القسم-"], h1[id^="section-"] {
      color: #1a237e;
      background: #e3eaf2;
      border-radius: 8px;
      padding: 0.5em 1em;
      border-bottom: none;
      margin-top: 2.5em;
    }
  </style>
</head>
<body>
<header>
  <h1 class="title">شَبَكَة عَصَبِيَّة ذات مدخلات مُتَناثِرَة باستخدام تَنْظِيم مُقَعَّر جَماعِيّ</h1>
  <p class="author"><span class="nodecor">Bin Luo</span></p>
  <p class="author"><span class="nodecor">Susan Halabi</span></p>
</header>
<main>
<h1 id="ملخص">مُلَخَّص</h1>
<p>تُعَدّ عمليّة اختيار الميزات وتقدير الدوالّ غير الخطيّة في آنٍ واحد تحدّياً، ولا سيّما في سياقات الأبعاد العالية حيث يفوق عددُ المتغيّرات حجمَ العيّنة المتاحة في دراسات الترصيد. في هذه المقالة نستكشف مشكلة اختيار الميزات في الشبكات العصبيّة. على الرغم من استخدام <span class="nodecor">group LASSO</span> لاختيار المتغيّرات مع الشبكات العصبيّة، فإنّه يميلُ إلى اختيار متغيّرات غير مهمّة لتعويض الانكماش الزائد. للتغلّب على هذا القيد، نقترح إطاراً للشبكات العصبيّة ذات المدخلات المتناثرة باستخدام تنظيم مُقَعَّر جَماعي لاختيار الميزات في الإعدادات المنخفضة والعالية الأبعاد. الفكرة الرئيسة هي تطبيقُ عقوبةٍ مُقَعَّرة مناسبة على معيار <span class="math inline">\(l_2\)</span> لأوزان جميع الوصلات الخارجة من كلّ عُقدة إدخال، بما يؤول إلى شبكةٍ عصبيّة تستخدم مجموعةً فرعيّة صغيرة من المتغيّرات الأصليّة. بالإضافة إلى ذلك، نُطوِّر خوارزميّةً فعّالةً قائمةً على التحسين المَسَاريّ العكسي لإنتاج مسارات حلٍّ مُستقرّة، لمواجهة التحدّيات الناجمة عن الطبيعة المعقّدة لمسألة التحسين. تُظهِر دراساتُ المحاكاة الواسعة وأمثلةُ البيانات الحقيقيّة التي أجريناها أداءً قويّاً في ظلّ عيناتٍ محدودة للمُقدِّر المقترَح، سواء في اختيار الميزات أو دقّة التنبّؤ لنمذجة النتائج المستمرّة والثنائيّة ووقت الحدث.</p>

<h1 id="مقدمة">مُقَدِّمَة</h1>
<p>في العقد الماضي، أدّت التطوّراتُ في الاختبارات الجزيئيّة والتصوير وسواهما من التقنيات المخبريّة إلى زيادة الاهتمام بتحليل البيانات عالية الأبعاد. تشير هذه البيانات إلى مجموعاتٍ تحتوي على عددٍ هائلٍ من المتغيّرات مقارنةً بحجم العيّنة المحدود، ما يشكّل تحدّياً كبيراً في بناء نماذج دقيقة وقابلة للتفسير. على سبيل المثال، في علم الأحياء الحيوي تُستخدم مئات الآلاف من قياسات تعبير الحمض النووي الريبي وبيانات دراسات الارتباط على مستوى الجينوم وشرائح الميكروأري لفهم بيولوجيا الأمراض، مع إشراك مئات المرضى فقط (<span class="nodecor">visscher2012five, hertz2016pharmacogenetic, kim2016high, beltran2017impact</span>). ولمعالجة لعنة الأبعاد، أصبح اختيارُ الميزات خطوةً حاسمةً في تحليل البيانات عالية الأبعاد. فمن خلال تحديد الخصائص الأكثر تمثيلاً لبيولوجيا المرض أو للنتائج، يمكن لأساليب اختيار الميزات زيادةُ قابليّة تفسير النموذج وتعزيزُ قدرته على التعميم.</p>
<p>هناك استراتيجياتٌ متعدّدة لاختيار الميزات، تشمل أساليب الفِلترة (<span class="nodecor">koller1996toward, guyon2003introduction, gu2012generalized</span>)، وطرائق التغليف (<span class="nodecor">kohavi1997wrappers, inza2004filter, tang2014feature</span>)، والطرائق المُضمّنة (<span class="nodecor">tibshirani1996regression, zou2006adaptive, fan2001variable, zhang2010nearly</span>). من بينها، أصبحت طرائق الانحدار المُعاقَب شائعةً جدّاً في تحليل البيانات عالية الأبعاد منذ تقديم مُشغِّل الانكماش والاختيار لأصغر مجموع مطلق القيم (<span class="nodecor">LASSO</span>) (<span class="nodecor">tibshirani1996regression</span>). تُتيح هذه الطرائقُ تقديرَ المعاملات واختيارَ الميزات معاً عبر تصفير بعض المعاملات تماماً. ومع أنّ <span class="nodecor">LASSO</span> يُستَخدم على نطاق واسع للحصول على تمثيلاتٍ متناثرة في التعلّم الآلي والإحصاء، فإنّه يعاني ميلاً إلى اختيار متغيّرات غير مهمّة لتعويض الانكماش الزائد في المتغيّرات ذات الأثر الحقيقي (<span class="nodecor">zou2006adaptive</span>). وللتغلّب على التحيّز وعدم اتّساق اختيار الميزات في <span class="nodecor">LASSO</span>، قُدِّمت عدّةُ توسعات، مثل <span class="nodecor">LASSO</span> التكيّفي (<span class="nodecor">zou2006adaptive</span>)، وعقوبة <span class="nodecor">MCP</span> (<span class="nodecor">zhang2010nearly</span>)، و<span class="nodecor">SCAD</span> (<span class="nodecor">fan2001variable</span>).</p>
<p>لكنّ معظم هذه الطرائق تفترض علاقةً خطيّة بين المتغيّرات والنتائج، بينما قد تكون العلاقةُ الفعليّة غيرَ خطيّة في كثيرٍ من التطبيقات. طُرِحت بعضُ التوسعات اللامعلَميّة (<span class="nodecor">cosso, ravikumar2009sparse, meier2009high</span>)، غير أنّ نماذجها ترتكز على مجموعات دوالّ أحاديّة أو قليلة الأبعاد، ما قد يُعيق قدرتها على التقاط التفاعلات المعقّدة بين المتغيّرات. كما اقترحت أعمالٌ مثل (<span class="nodecor">yamada2014high</span>) منهج <span class="nodecor">HSIC-LASSO</span> الذي يستفيد من تعلّم النواة لكشف التفاعلات غير الخطيّة للميزات، لكنّه يُعاني تعقيداً حسابيّاً تربيعيّاً في عدد المشاهدات.</p>
<p>تُعَدّ الشبكاتُ العصبيّة أدواتٍ قويّةً لنمذجة العلاقات المعقّدة في تطبيقاتٍ عدّة، من التعرّف على الصور (<span class="nodecor">krizhevsky2017imagenet, he2016deep</span>) والكلام (<span class="nodecor">graves2013speech, chan2016listen</span>) إلى معالجة اللغة الطبيعيّة (<span class="nodecor">young2018recent, devlin2018bert</span>) والتنبّؤ المالي (<span class="nodecor">fischer2018deep</span>). ويُعزَى أداؤها المتفوّق إلى الموارد الحسابيّة الكبيرة وأحجام العينات الضخمة. مع ذلك، قد تؤدّي البياناتُ عاليةُ الأبعاد إلى الإفراط في التخصيص وضعف قدرة الشبكات العصبيّة على التعميم (<span class="nodecor">liu2017deep</span>). ومؤخّراً برزت أساليبُ تعتمد على تنظيم الشبكات العصبيّة لاختيار الميزات في سياق البيانات عالية الأبعاد، مع تركيزٍ خاص على <span class="nodecor">group LASSO</span> لتعزيز تقلّص الوصلات الخارجة من عُقد الإدخال (<span class="nodecor">liu2017deep, scardapane2017group, feng2017sparse</span>). تنظر هذه الأساليب إلى الوصلات الخارجة من كلّ عصبونِ إدخالٍ كمجموعة، وتُطبّق عقوبة <span class="nodecor">LASSO</span> على معيار <span class="math inline">\(l_2\)</span> لمتجهات الوزن. وفي أعمالٍ أخرى (<span class="nodecor">li2016deep, lemhadri2021lassonet</span>) جرى دمجُ هذه الفكرة لاختيار الميزات في الشبكات العصبيّة. غير أنّ التنظيمَ القائمَ على <span class="nodecor">LASSO</span> يُعاني انكماشاً مفرطاً للأوزان الحقيقيّة ويولِّد إيجابيّاتٍ كاذبة. ولتخفيف هذه المشكلة استُخدم <span class="nodecor">LASSO</span> التكيّفي (<span class="nodecor">dinh2020consistent</span>)، لكنه ظلّ محدوداً بحالات النتائج المستمرّة ويفترض أنّ المتوسّط الشرطي مُعبَّرٌ عنه بشبكةٍ عصبيّة دقيقة. كما حاولت دراساتٌ أخرى (<span class="nodecor">yamada2020feature</span>) إدخال بوّابات عشوائيّة لتقريب تنظيم <span class="math inline">\(l_0\)</span>، غير أنّها تتطلّب قيمةَ قطعٍ لتمييز الإشارات الضعيفة، ولا تستبعد بعضَ المتغيّرات تماماً خلال التدريب والتنبّؤ.</p>
<p>في هذه الورقة نقترح إطاراً جديداً للشبكات العصبيّة ذات المدخلات المتناثرة باستخدام تنظيم مُقَعَّر جَماعي لتجاوز قيود أساليب اختيار الميزات الراهنة. وعلى الرغم من أنّ عقوبات التقعّر مثل <span class="nodecor">MCP</span> و<span class="nodecor">SCAD</span> أظهرت أداءً جيّداً في الإعدادات النظريّة والعدديّة لاختيار الميزات والتنبّؤ، إلّا أنّها لم تحظَ بالاهتمام نفسِه مقارنةً بـ<span class="nodecor">LASSO</span> في أوساط التعلّم الآلي. يهدف إطارُنا إلى تسليط الضوء على الإمكانات غير المستثمَرة للعقوبات المُقَعَّرة لاختيار الميزات في الشبكات العصبيّة، عبر تقديم مقاربةٍ شاملة تجمع بين اختيار الميزات وتقدير الدوالّ في الإعدادات منخفضة وعالية الأبعاد. وبوجهٍ خاص، نعدّ الوصلات الخارجة من كلّ عصبونِ إدخالٍ مجموعةً واحدة ونُطبّق عقوبةً مُقَعَّرة على معيار <span class="math inline">\(l_2\)</span> لمتجه الوزن في كلّ مجموعة. فعند تقليص أوزان مجموعاتٍ معيّنة إلى الصفر تماماً، نحصل على شبكةٍ عصبيّة تُشغَّل على مجموعةٍ محدودة من المتغيّرات. وإضافةً إلى ذلك طوّرنا خوارزميّةً فعّالةً قائمةً على التحسين المَسَاريّ العكسي لإنتاج مساراتِ حلٍّ مُستقرّة، نظراً لوعورةِ المشهدِ الأمثلِيّ لمسألة التحسين. وتُظهِر دراساتُ المحاكاة وأمثلةُ البيانات الحقيقيّة أداءً مُتميّزاً للمُقدِّر المقترح، متفوّقاً على الأساليب الحالية في اختيار الميزات ودقّة التنبّؤ لنمذجة النتائج المستمرّة والثنائيّة ووقت الحدث.</p>
<p>تُنظَّم بقيّةُ المقالة كما يلي: في القسم <span class="nodecor">2</span> نصوغُ مشكلةَ اختيار الميزات لنموذجٍ لا معلَمي عام، ونقدّم طريقتنا المقترحة. ويأتي تنفيذُ الطريقة، بما في ذلك خوارزميّةُ الانحدار التدرّجي المُركَّب والتحسين المَسَاريّ العكسي، في القسم <span class="nodecor">3</span>.</p>

<h1 id="القسم-4">القسم <span class="nodecor">4</span></h1>
<p>نجري دراساتِ محاكاةٍ واسعةَ النطاق لإظهار أداء الطريقة المقترحة.</p>

<h1 id="القسم-5">القسم <span class="nodecor">5</span></h1>
<p>نُقدِّم تطبيقَ الطريقة على مجموعات بياناتٍ واقعيّةٍ متنوّعة.</p>

<h1 id="القسم-6">القسم <span class="nodecor">6</span></h1>
<p>وأخيراً، نناقش النتائجَ واستنتاجاتِها وتأثيراتِها المحتملة.</p>

<h1 id="الطريقة">الطريقة</h1>
<h2 id="إعداد-المشكلة">إعداد المشكلة</h2>
<p>لنفترض أنّ <span class="math inline">\(X \in \mathbb{R}^d\)</span> متجهٌ عشوائيّ ذو بُعد <span class="math inline">\(d\)</span> و<span class="math inline">\(Y\)</span> متغيّرُ الاستجابة. نفترض أنّ التوزيعَ الشرطي <span class="math inline">\(P_{Y|X}\)</span> يعتمد على الشكل <span class="math inline">\(f(X_S)\)</span> حيث <span class="math inline">\(f \in F\)</span> ومجموعةٌ فرعيّة من المتغيّرات <span class="math inline">\(S \subseteq \{1, \dots, d\}\)</span>. نبتغي تحديد المجموعة الحقيقيّة <span class="math inline">\(S\)</span> للمتغيّرات المؤثِّرة وتقدير الدالّة <span class="math inline">\(f\)</span> بحيث يمكن التنبّؤ بـ<span class="math inline">\(Y\)</span> اعتماداً على المتغيّرات المختارة <span class="math inline">\(X_S\)</span>.</p>
<p>على مستوى المجتمع، نهدف إلى تقليل الخسارة
<span class="math display">\[
\min_{f\in F, S} \mathbb{E}_{X, Y} \,\ell\bigl(f(X_S), Y\bigr)
\]</span>
حيث تمثّل <span class="math inline">\(\ell\)</span> دالّةَ خسارةٍ مناسبةً للمهمّة. عمليّاً، غالباً لا يُعرَف توزيع <span class="math inline">\( (X, Y)\)</span>، ويُتاح بدلاً منه عيّناتٌ مستقلةٌ ومُتطابقة التوزيع بحجم <span class="math inline">\(n\)</span>، مكوّنة من أزواج <span class="math inline">\(\{(X_i, Y_i)\}_{i=1}^n\)</span>. وعندما يكون <span class="math inline">\(d\)</span> كبيراً، يصبح البحثُ على جميع المجموعات الفرعيّة متعذّراً عمليّاً. وإضافةً إلى ذلك لا نفترض شكلاً محدّداً للدالة المجهولة <span class="math inline">\(f\)</span>، بل نسعى إلى تمثيلها على نحوٍ لا معلَمي باستخدام الشبكات العصبيّة. وبناءً عليه، هدفُنا تطويرُ طريقةٍ فعّالة تختار في الوقت نفسه مجموعةً فرعيّة من المتغيّرات <span class="math inline">\(S\)</span> وتقرّب الدالّة <span class="math inline">\(f\)</span> باستخدام شبكةٍ عصبيّة ذات مدخلاتٍ مُتناثرة.</p>

<h2 id="الإطار-المقترح">الإطار المقترح</h2>
<p>نفترض شبكةً عصبيّةً أماميّة تنتمي إلى الفئة <span class="math inline">\(\mathcal{F}_n\)</span>، إذ يُمثَّل كلُّ نموذجٍ فيها بالتابع <span class="math inline">\(f_\mathbf{w}: \mathbb{R}^d \to \mathbb{R}\)</span> بمعاملات <span class="math inline">\(\mathbf{w}\)</span>. وتتكوّن الشبكةُ متعدّدةُ الطبقات (MLP) من تركيب دوالّ خطيّة وتنشيط:</p>
<p>
<span class="math display">\[
f_\mathbf{w}(x) = L_D \circ \sigma \circ L_{D-1} \circ \sigma \circ \cdots \circ \sigma \circ L_1 \circ \sigma \circ L_0(x),
\]</span>
</p>
<p>حيث <span class="math inline">\(L_i(x) = \mathbf{W}_i x + b_i\)</span>، و<span class="math inline">\(\mathbf{W}_i \in \mathbb{R}^{d_{i+1} \times d_i}\)</span> مصفوفةُ الأوزان، و<span class="math inline">\(b_i \in \mathbb{R}^{d_{i+1}}\)</span> متّجهُ الانحياز للطبقة <span class="math inline">\(i\)</span>، ودالّةُ التنشيط <span class="math inline">\(\sigma(\cdot)\)</span>. وتجمع <span class="math inline">\(\mathbf{w}\)</span> جميعَ المعاملات <span class="math inline">\(\{\mathbf{W}_i, b_i: i=0,\dots,D\}\)</span> بحيث يكون البُعدُ الكُلّي <span class="math inline">\(P\)</span>. نُعرِّف الخسارةَ التجريبيّة:</p>
<p>
<span class="math display">\[
\mathcal{L}_n(\mathbf{w}) = \frac{1}{n} \sum_{i=1}^n \ell\bigl(f_\mathbf{w}(X_i), Y_i\bigr).
\]</span>
</p>
<p>السيناريو المثالي وجودُ شبكةٍ ذات مدخلاتٍ متناثرة <span class="math inline">\(f_\mathbf{w}\)</span> تقرأ إشاراتٍ فقط من المتغيّرات المهمّة، أي أنّ <span class="math inline">\(\mathbf{W}_{0,j} = \mathbf{0}\)</span> لكل <span class="math inline">\(j \notin S\)</span>، حيث <span class="math inline">\(\mathbf{W}_{0,j}\)</span> العمودُ رقم <span class="math inline">\(j\)</span> من <span class="math inline">\(\mathbf{W}_0\)</span>. ولتحفيز الندرة في <span class="math inline">\(\mathbf{W}_0\)</span> مع تقليل الخسارة التجريبيّة، نُدرِّب الشبكةَ بحلّ المسألة:</p>
<p>
<span class="math display">\[
\hat{\mathbf{w}} = \arg\min_{\mathbf{w} \in \mathbb{R}^P} \left\{ \mathcal{L}_n(\mathbf{w}) + \sum_{j=1}^d \rho_\lambda\!\left(\,\|\mathbf{W}_{0,j}\|_2\,\right) + \alpha \|\mathbf{w}\|_2^2 \right\},
\]
</span>
</p>
<p>حيث يدلّ <span class="math inline">\(\|\cdot\|_2\)</span> على المعيار الإقليدي.</p>
<p>تتكوّن الدالةُ الهدف في المعادلة أعلاه من ثلاثة مكوّنات:</p>
<ul>
  <li><p><span class="math inline">\(\mathcal{L}_n(\mathbf{w})\)</span> الخسارةُ التجريبيّة، مثل متوسِّط مربّعات الخطأ للانحدار، وخسارة الإنتروبيا المتقاطعة للتصنيف، والاحتمال الجزئيّ السلبيّ في نموذج المخاطر النسبيّة. انظر الملحق لمزيدٍ من التفاصيل.</p></li>
  <li><p><span class="math inline">\(\rho_\lambda\)</span> دالّةُ عقوبةٍ مُقَعَّرة بمعامل <span class="math inline">\(\lambda \ge 0\)</span>. نعدّ الوصلاتِ الخارجة من كلّ عصبونِ إدخالٍ مجموعةً واحدة، ونُطبّق <span class="math inline">\(\rho_\lambda\)</span> على معيار <span class="math inline">\(l_2\)</span> لمتّجه الوزن لتقليص مجموعاتٍ معيّنة من الأوزان إلى الصفر، ما يؤدّي إلى اختيارٍ فرعيّ لمجموعة المتغيّرات الأصليّة.</p></li>
  <li><p><span class="math inline">\(\alpha \|\mathbf{w}\|_2^2\)</span> مع <span class="math inline">\(\alpha > 0\)</span> تمثّل تنظيماً تربيعيّاً (Ridge) للحيلولة دون الإفراط في التخصيص. تعتمدُ عمليّةُ اختيار الميزات فقط على <span class="math inline">\(\rho_\lambda\)</span> في طبقة الإدخال، بينما يُوازِن التنظيمُ التربيعيّ الأوزانَ عبر الطبقات ويُعزِّز ثبات النموذج.</p></li>
</ul>
<p>عندما يكون عددُ الطبقات المخفيّة <span class="math inline">\(D=0\)</span>، ينحصر النموذجُ في دالّةٍ خطيّة، ويصير الإطارُ أعلاه هو إطارَ «الشبكة المرنة» (<span class="nodecor">Elastic Net</span>) (<span class="nodecor">zou2005regularization</span>)، و<span class="nodecor">SCAD</span>-<span class="math inline">\(L_2\)</span> (<span class="nodecor">zeng2014group</span>)، و<span class="nodecor">Mnet</span> (<span class="nodecor">huang2016mnet</span>) تبعاً لاختيار عقوبة <span class="math inline">\(\rho_\lambda\)</span> لتكون على التوالي: <span class="nodecor">LASSO</span>، و<span class="nodecor">SCAD</span>، و<span class="nodecor">MCP</span>.</p>

<h2 id="تنظيم-التقعر">تنظيمُ التقعُّر</h2>
<p>هناك عقوباتٌ شائعة لتعزيز الندرة، منها ما هو مُحدَّب مثل <span class="nodecor">LASSO</span> (<span class="nodecor">tibshirani1996regression</span>)، ومنها ما هو مُقَعَّر مثل <span class="nodecor">SCAD</span> (<span class="nodecor">fan2001variable</span>) و<span class="nodecor">MCP</span> (<span class="nodecor">zhang2010nearly</span>). وعند تطبيق أيٍّ منها على معيار <span class="math inline">\(l_2\)</span> لمعاملات كلّ مجموعة متغيّرات، نحصل على نسخٍ جماعيّة (بالِغَةِ الأثر على اختيار الميزات) مثل:</p>
<ul>
  <li><p><strong>تنظيم المجموعات بـ LASSO</strong> (<span class="nodecor">group LASSO</span>) (<span class="nodecor">yuan2006model</span>): 
<span class="math display">\[
\rho_\lambda(t) = \lambda\, t, \qquad t \ge 0.
\]</span>
</p></li>
  <li><p><strong>تنظيم المجموعات بـ SCAD</strong> (<span class="nodecor">group SCAD</span>) (<span class="nodecor">guo2015model</span>): 
<span class="math display">\[
\rho_\lambda(t) =
\begin{cases}
\lambda\, t, & 0 \le t \le \lambda, \\
\dfrac{-\bigl(t^2 - 2a\lambda\, t + \lambda^2\bigr)}{2(a-1)}, & \lambda < t \le a\lambda, \\
\dfrac{(a+1)\lambda^2}{2}, & t > a\lambda,
\end{cases}
\qquad a>2.
\]</span>
</p></li>
  <li><p><strong>تنظيم المجموعات بـ MCP</strong> (<span class="nodecor">group MCP</span>) (<span class="nodecor">huang2012selective</span>): 
<span class="math display">\[
\rho_\lambda(t) = \lambda \int_{0}^{t} \left(1 - \frac{z}{\lambda a}\right)_+ \, dz, \qquad t \ge 0,\ a>1,
\]</span>
حيث <span class="math inline">\((u)_+ = \max(u,0)\)</span>.
</p></li>
</ul>
<p>أظهرت دراساتٌ نظريّة وتجريبيّة أنّ العقوبات المُقَعَّرة مثل <span class="nodecor">SCAD</span> و<span class="nodecor">MCP</span> تتفوّق على <span class="nodecor">LASSO</span> في دقّة اختيار الميزات والتنبّؤ (<span class="nodecor">fan2001variable</span>, <span class="nodecor">zhang2010nearly</span>). فبعكس <span class="nodecor">LASSO</span> المُحدَّبة التي تتحيّز نحو تقليلٍ مفرط للمعاملات الكبيرة وتُفضي إلى اختيارٍ غير متّسقٍ للميزات، تُقلِّل العقوباتُ المُقَعَّرة من التحيّز وتُحسِّن دقّة النموذج عبر خفضٍ تدريجيّ في مُشتقّ العقوبة حتى ينعدمَ عندما <span class="math inline">\(t > a\lambda\)</span>. لذلك نقترح استخدامَ تنظيمِ المجموعات المُقَعَّر ضمن إطارنا لاختيار الميزات وتقدير الدالّة في آنٍ واحد.</p>

<!-- قد تُستكمل الأقسام اللاحقة هنا عند اللزوم -->
</main>
</body>
</html>