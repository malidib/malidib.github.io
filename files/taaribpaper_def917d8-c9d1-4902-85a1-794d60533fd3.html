<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Bin Luo">
  <meta name="author" content="Susan Halabi">
  <title>شَبَكَة عَصَبِيَّة ذات مدخلات مُتَناثِرَة باستخدام تَنْظِيم مُقَعَّر جَماعِيّ</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>body { direction: rtl; font-size: 22px; }</style>
</head>
<body>
<header>
<h1 class="title">شَبَكَة عَصَبِيَّة ذات مدخلات مُتَناثِرَة باستخدام تَنْظِيم مُقَعَّر جَماعِيّ</h1>
<p class="author"><span class="nodecor">Bin Luo</span></p>
<p class="author"><span class="nodecor">Susan Halabi</span></p>
</header>
<p>latex</p>
<h1 id="ملخص">مُلَخَّص</h1>
<p>تُعَدّ عَمَلِيَّة اختيار الميزات وتقدير الدوال غير الخطية في آنٍ واحد تحديًا، خاصة في السياقات ذات الأبعاد العالية حيث يتجاوز عدد المتغيرات حجم العينة المتاحة في التنميط. في هذه المقالة، نستكشف مشكلة اختيار الميزات في الشبكات العصبية. على الرغم من استخدام <span class="nodecor">LASSO</span> الجماعي لاختيار المتغيرات في التعلم مع الشبكات العصبية، إلا أنه يميل إلى اختيار متغيرات غير مهمة في النموذج لتعويض تقليصه الزائد. للتغلب على هذا القيد، نقترح إطارًا للشبكات العصبية ذات المدخلات المتناثرة باستخدام تنظيم مقعر جماعي لاختيار الميزات في الإعدادات ذات الأبعاد المنخفضة والعالية. الفكرة الرئيسية هي تطبيق عقوبة مقعرة مناسبة على قاعدة <span class="math inline">\(l_2\)</span> للأوزان من جميع الاتصالات الخارجة لكل عقدة إدخال، وبالتالي الحصول على شبكة عصبية تستخدم فقط مجموعة فرعية صغيرة من المتغيرات الأصلية. بالإضافة إلى ذلك، نطور خوارزمية فعالة تعتمد على التحسين المساري العكسي لإنتاج مسارات حل مستقرة، من أجل التعامل مع تحدي المناظر الطبيعية المعقدة للتحسين. تظهر دراسات المحاكاة الواسعة وأمثلة البيانات الحقيقية التي أجريناها أداءً مرضيًا للعينات المحدودة للمقدر المقترح، في اختيار الميزات والتنبؤ لنمذجة النتائج المستمرة والثنائية ووقت الحدث.</p>
<h1 id="مقدمة">مُقَدِّمَة</h1>
<p>في العقد الماضي، أدت التطورات في الاختبارات الجزيئية والتصوير وغيرها من الاختبارات المخبرية إلى زيادة الاهتمام بتحليل البيانات ذات الأبعاد العالية. تشير البيانات ذات الأبعاد العالية إلى مجموعة بيانات تحتوي على عدد كبير من المتغيرات الملحوظة مقارنة بحجم العينة الصغير، مما يشكل تحديًا كبيرًا في بناء نماذج دقيقة وقابلة للتفسير. على سبيل المثال، في علم الأحياء الحيوي، يتم استخدام مئات الآلاف من تعبيرات الحمض النووي الريبي وبيانات دراسة الارتباط الجيني الواسعة وبيانات الميكروأري لفهم بيولوجيا الأمراض، مع مشاركة مئات المرضى فقط (<span class="nodecor">visscher2012five, hertz2016pharmacogenetic, kim2016high, beltran2017impact</span>). لمعالجة لعنة الأبعاد، أصبح اختيار الميزات خطوة حاسمة في تحليل البيانات ذات الأبعاد العالية. من خلال تحديد الميزات الأكثر تمثيلاً لوصف بيولوجيا الأمراض أو النتائج، يمكن لطرق اختيار الميزات زيادة قابلية تفسير النموذج وتحسين تعميم النموذج.</p>
<p>هناك طرق مختلفة لاختيار الميزات، بما في ذلك طرق الفلترة (<span class="nodecor">koller1996toward, guyon2003introduction, gu2012generalized</span>)، وطرق التغليف (<span class="nodecor">kohavi1997wrappers, inza2004filter, tang2014feature</span>)، والطرق المضمنة (<span class="nodecor">tibshirani1996regression,zou2006adaptive, fan2001variable,zhang2010nearly</span>). من بينها، أصبحت طرق الانحدار المعاقب شائعة جدًا في تحليل البيانات ذات الأبعاد العالية منذ تقديم مشغل الانكماش والاختيار المطلق الأدنى (<span class="nodecor">LASSO</span>) (<span class="nodecor">tibshirani1996regression</span>). يمكن لطريقة الانحدار المعاقب أن تؤدي تقدير المعاملات واختيار الميزات في آن واحد من خلال تقليص بعض معاملات المعلمات إلى أصفار دقيقة. بينما تم استخدام <span class="nodecor">LASSO</span> على نطاق واسع للحصول على تقديرات متناثرة في التعلم الآلي والإحصاء، فإنه يميل إلى اختيار متغيرات غير مهمة لتعويض الانكماش الزائد للمتغيرات ذات الصلة (<span class="nodecor">zou2006adaptive</span>). لمعالجة التحيز وعدم اتساق اختيار الميزات لـ <span class="nodecor">LASSO</span>، تم اقتراح عدة طرق، بما في ذلك <span class="nodecor">LASSO</span> التكيفي (<span class="nodecor">zou2006adaptive</span>)، وعقوبة الحد الأدنى المقعر (<span class="nodecor">MCP</span>) (<span class="nodecor">zhang2010nearly</span>)، وانحراف الانقطاع المطلق السلس (<span class="nodecor">SCAD</span>) (<span class="nodecor">fan2001variable</span>).</p>
<p>ومع ذلك، فإن معظم هذه الطرق المعاقبة تفترض خطية في العلاقة بين المتغيرات والنتائج، بينما قد لا تكون الصيغة الوظيفية الفعلية للعلاقة متاحة في العديد من التطبيقات. تم اقتراح بعض التوسعات غير البارامترية الإضافية لحل هذه المشكلة (<span class="nodecor">cosso,ravikumar2009sparse,meier2009high</span>)، ولكن نماذجها تعتمد على مجموعات الدوال أحادية البعد أو منخفضة البعد وقد لا تكون قادرة على التقاط التفاعلات المعقدة بين المتغيرات المتعددة. يقترح (<span class="nodecor">yamada2014high</span>) نهج <span class="nodecor">HSIC-LASSO</span> الذي يستفيد من تعلم النواة لاختيار الميزات مع كشف التفاعلات غير الخطية للميزات. ومع ذلك، فإنه يعاني من التوسع التربيعي في التعقيد الحسابي بالنسبة لعدد الملاحظات.</p>
<p>تُعَدّ الشبكات العصبية أدوات قوية لنمذجة العلاقات المعقدة في مجموعة واسعة من التطبيقات، من التعرف على الصور (<span class="nodecor">krizhevsky2017imagenet, he2016deep</span>) والتعرف على الكلام (<span class="nodecor">graves2013speech, chan2016listen</span>) إلى معالجة اللغة الطبيعية (<span class="nodecor">young2018recent, devlin2018bert</span>) والتنبؤ المالي (<span class="nodecor">fischer2018deep</span>). تم تحقيق أدائها المتقدم من خلال الموارد الحسابية القوية واستخدام أحجام عينات كبيرة. على الرغم من ذلك، فإن البيانات ذات الأبعاد العالية لا تزال يمكن أن تؤدي إلى التركيب الزائد وضعف أداء التعميم للشبكات العصبية (<span class="nodecor">liu2017deep</span>). مؤخرًا، كانت هناك تطورات جديدة في استخدام الشبكات العصبية المنتظمة لاختيار الميزات أو تحليل البيانات ذات الأبعاد العالية. تركز سلسلة من الأبحاث على استخدام الشبكات العصبية المنتظمة، وخاصة باستخدام تقنية <span class="nodecor">LASSO</span> الجماعية لتعزيز التفرق بين عقد الإدخال (<span class="nodecor">liu2017deep, scardapane2017group, feng2017sparse</span>). تعتبر هذه الطرق جميع الاتصالات الصادرة من عصبون إدخال واحد كمجموعة وتطبق عقوبة <span class="nodecor">LASSO</span> على قاعدة <span class="math inline">\(l_2\)</span> لمتجهات الوزن لكل مجموعة. يمكن العثور على شبكات عصبية أخرى منتظمة بـ <span class="nodecor">LASSO</span> في اختيار الميزات في أعمال (<span class="nodecor">li2016deep</span>) و(<span class="nodecor">lemhadri2021lassonet</span>). ومع ذلك، فإن الشبكات العصبية المنتظمة التي تدمج <span class="nodecor">LASSO</span> تعاني من ميل إلى الانكماش الزائد لوزن المتغيرات ذات الصلة غير الصفرية وتضم العديد من الإيجابيات الخاطئة في النموذج المختار. تم استخدام <span class="nodecor">LASSO</span> التكيفي لتخفيف هذه المشكلة (<span class="nodecor">dinh2020consistent</span>)، ومع ذلك، فإن نتائجهم محدودة بالنتائج المستمرة وتفترض أن وظيفة الوسيط الشرطي هي بالضبط شبكة عصبية. تجاوز العمل في (<span class="nodecor">yamada2020feature</span>) تنظيم <span class="math inline">\(l_1\)</span> من خلال إدخال بوابات عشوائية إلى طبقة الإدخال للشبكات العصبية. اعتبروا تنظيمًا شبيهًا بـ <span class="math inline">\(l_0\)</span> استنادًا إلى استرخاء مستمر لتوزيع برنولي. ومع ذلك، تتطلب طريقتهم قيمة قطع لاختيار المتغيرات ذات الإشارات الضعيفة، ولا تستطيع البوابة العشوائية استبعاد المتغيرات غير المختارة بشكل كامل خلال مراحل التدريب والتنبؤ للنموذج.</p>
<p>في هذه الورقة، نقترح إطارًا جديدًا للشبكات العصبية ذات الإدخال المتناثر باستخدام تنظيم مقعر جماعي للتغلب على قيود طرق اختيار الميزات الحالية. على الرغم من أن العقوبات المقعرة مثل <span class="nodecor">MCP</span> و<span class="nodecor">SCAD</span> قد أظهرت أداءً جيدًا في الإعدادات النظرية والعددية لاختيار الميزات والتنبؤ، إلا أنها لم تتلق نفس مستوى الاهتمام مثل <span class="nodecor">LASSO</span> في سياق التعلم الآلي. يهدف إطارنا المقترح إلى لفت الانتباه إلى الإمكانات غير المستغلة للعقوبة المقعرة لاختيار الميزات في الشبكات العصبية، من خلال توفير نهج شامل لاختيار الميزات وتقدير الدوال في كل من الإعدادات منخفضة الأبعاد وذات الأبعاد العالية. على وجه الخصوص، تعتبر طريقتنا المقترحة جميع الاتصالات الصادرة من عصبون إدخال واحد كمجموعة وتطبق عقوبة مقعرة مناسبة على قاعدة <span class="math inline">\(l_2\)</span> للأوزان لكل مجموعة. من خلال تقليص جميع الأوزان لمجموعات معينة إلى أصفار دقيقة، فإنه يحصل على شبكة عصبية تستخدم مجموعة صغيرة فقط من المتغيرات. بالإضافة إلى ذلك، طورنا خوارزمية فعالة استنادًا إلى التحسين المساري العكسي الذي ينتج مسارات حل مستقرة، لمواجهة تحدي المناظر الطبيعية المعقدة للتحسين. تظهر دراسات المحاكاة لدينا وأمثلة البيانات الحقيقية أداء العينة المحدودة المرضي للتنظيم المقعر الجماعي، والذي يتفوق على الطرق الحالية من حيث اختيار الميزات ودقة التنبؤ لنمذجة النتائج المستمرة والثنائية ووقت الحدث.</p>
<p>يتم تنظيم بقية هذه المقالة على النحو التالي. في القسم <span class="nodecor">2</span>، نصيغ مشكلة اختيار الميزات لنموذج غير بارامتري عام ونقدم طريقتنا المقترحة. يتم تقديم تنفيذ الطريقة، بما في ذلك خوارزمية الانحدار التدرجي المركب والتحسين المساري العكسي، في القسم <span class="nodecor">3</span>.</p>
<h1 id="القسم-4">القسم <span class="nodecor">4</span></h1>
<p>نجري دراسات محاكاة واسعة النطاق لإظهار أداء الطريقة المقترحة.</p>
<h1 id="القسم-5">القسم <span class="nodecor">5</span></h1>
<p>يتم تقديم تطبيق الطريقة على مجموعات بيانات واقعية.</p>
<h1 id="القسم-6">القسم <span class="nodecor">6</span></h1>
<p>أخيرًا، نناقش النتائج وتأثيراتها.</p>
<h1 id="الطريقة">الطريقة</h1>
<h2 id="إعداد-المشكلة">إعداد المشكلة</h2>
<p>لنفترض أن <span class="math inline">\(X \in \RR^d\)</span> هو متجه عشوائي ذو بعد <span class="math inline">\(d\)</span> و<span class="math inline">\(Y\)</span> هو متغير الاستجابة. نفترض أن التوزيع الشرطي <span class="math inline">\(P_{Y|X}\)</span> يعتمد على شكل <span class="math inline">\(f(X_S)\)</span> بدالة <span class="math inline">\(f \in F\)</span> ومجموعة فرعية من المتغيرات <span class="math inline">\(S \subseteq \{1, \cdots, d\}\)</span>. نحن مهتمون بتحديد المجموعة الحقيقية <span class="math inline">\(S\)</span> للمتغيرات الهامة وتقدير الدالة <span class="math inline">\(f\)</span> بحيث يمكننا التنبؤ بـ<span class="math inline">\(Y\)</span> استنادًا إلى المتغير المختار <span class="math inline">\(X_S\)</span>.</p>
<p>على مستوى السكان، نهدف إلى تقليل الخسارة <span class="math display">\[\min_{f\in F, S} \EE_{X, Y} \ell(f(X_S), Y)\]</span> حيث <span class="math inline">\(\ell\)</span> هي دالة خسارة مصممة لمشكلة محددة. في الإعدادات العملية، غالبًا ما يكون توزيع <span class="math inline">\((X, Y)\)</span> غير معروف، وبدلاً من ذلك يتوفر عينة عشوائية مستقلة ومتطابقة التوزيع (i.i.d.) بحجم <span class="math inline">\(n\)</span>، تتكون من أزواج من الملاحظات <span class="math inline">\({(X_i, Y_i)}_{i=1}^n\)</span>. بالإضافة إلى ذلك، إذا كان عدد المتغيرات <span class="math inline">\(d\)</span> كبيرًا، فإن البحث الشامل عن جميع المجموعات الفرعية الممكنة <span class="math inline">\(S\)</span> يصبح غير قابل للتطبيق من الناحية الحسابية. علاوة على ذلك، لا نفترض أي شكل محدد للدالة المجهولة <span class="math inline">\(f\)</span> ونهدف إلى تقريب <span class="math inline">\(f\)</span> بطريقة غير معلمية باستخدام الشبكات العصبية. وبالتالي، هدفنا هو تطوير طريقة فعالة يمكنها في الوقت نفسه اختيار مجموعة فرعية من المتغيرات <span class="math inline">\(S\)</span> وتقريب الحل <span class="math inline">\(f\)</span> لأي فئة معينة من الدوال باستخدام شبكة عصبية ذات مدخلات متناثرة.</p>
<h2 id="الإطار-المقترح">الإطار المقترح</h2>
<p>ننظر في مقدرات الدوال المبنية على الشبكات العصبية الأمامية. لنفترض أن <span class="math inline">\(\mathcal{F}_n\)</span> هي فئة من الشبكات العصبية الأمامية <span class="math inline">\(f_\bw: \RR^d \mapsto \RR\)</span> بمعامل <span class="math inline">\(\bw\)</span>. يمكن التعبير عن بنية الشبكة العصبية متعددة الطبقات (MLP) كتركيب لسلسلة من الدوال <span class="math display">\[f_\bw(x)=L_D \circ \sigma  \circ L_{D-1} \circ \sigma \circ \cdots  \circ \sigma \circ L_{1} \circ \sigma \circ L_{0}(x), x \in \RR^d,\]</span> حيث يشير <span class="math inline">\(\circ\)</span> إلى تركيب الدوال و<span class="math inline">\(\sigma(x)\)</span> هي دالة التنشيط المحددة لكل مكون من <span class="math inline">\(x\)</span>. بالإضافة إلى ذلك، <span class="math display">\[L_i(x) = \bW_ix + b_i, i=0, 1, \dots, \mD,\]</span> حيث <span class="math inline">\(\bW_i \in \RR^{d_{i+1} \times d_{i} }\)</span> هي مصفوفة الوزن، <span class="math inline">\(D\)</span> هو عدد الطبقات المخفية، <span class="math inline">\(d_i\)</span> هو العرض المحدد كعدد الخلايا العصبية للطبقة <span class="math inline">\(i\)</span>-th بحيث <span class="math inline">\(d_0=d\)</span>، و<span class="math inline">\(b_i \in \RR^{d_{i+1}}\)</span> هو متجه الانحياز في التحويل الخطي <span class="math inline">\(i\)</span>-th <span class="math inline">\(L_i\)</span>. لاحظ أن المتجه <span class="math inline">\(\bw \in \RR^P\)</span> هو تجميع الأعمدة لجميع المعاملات في <span class="math inline">\(\{\bW_i, b_i: i=0, 1, \dots, \mD\}\)</span>. نعرف الخسارة التجريبية لـ <span class="math inline">\(f_\bw\)</span> كما يلي <span class="math display">\[\mL_n(\bw)= \frac{1}{n} \sum_{i=1}^n \ell(f_\bw(X_i), Y_i).\]</span></p>
<p>السيناريو المثالي هو أن يكون لدينا شبكة عصبية بمدخلات متناثرة <span class="math inline">\(f_\bw\)</span> تأخذ الإشارات فقط من المتغيرات المهمة، بمعنى أن <span class="math inline">\(\bW_{0,j}=\b0\)</span> لـ <span class="math inline">\(j \notin S\)</span>، حيث <span class="math inline">\(\bW_{0,j}\)</span> يشير إلى المتجه العمودي <span class="math inline">\(j\)</span>-th من <span class="math inline">\(\bW_0\)</span>. من أجل تقليل الخسارة التجريبية <span class="math inline">\(\mL_n(\bw)\)</span> مع تحفيز التفرقة في <span class="math inline">\(\bW_0\)</span>، نقترح تدريب الشبكة العصبية بتقليل الخسارة التجريبية المنتظمة للمجموعة التالية</p>
<p><span class="math display">\[\label{eq:obj}
  \hat{\bw} = \argmin_{\bw \in \RR^P} \left \{\mL_n(\bw) + \sum_{j=1}^d \rho_\lambda(\|\bW_{0,j}\|_2)+ \alpha \|\bw\|_2^2 \right\},\]</span></p>
<p>حيث <span class="math inline">\(\|\cdot\|_2\)</span> تشير إلى القاعدة الإقليدية لمتجه.</p>
<p>تتكون الدالة الهدف في المعادلة ([eq:obj]) من ثلاثة مكونات:</p>
<ul>
<li><p><span class="math inline">\(\mL_n(\bw)\)</span> هي دالة الخسارة التجريبية مثل خسارة متوسط الأخطاء المربعة لمهام الانحدار، خسارة الانتروبيا المتقاطعة لمهام التصنيف، والاحتمال الجزئي السلبي لنماذج الأخطار المتناسبة. يمكن العثور على تفاصيل إضافية في الملحق [appendix:loss].</p></li>
<li><p><span class="math inline">\(\rho_\lambda\)</span> هي دالة عقوبة مقعرة معلمة بواسطة <span class="math inline">\(\lambda \ge 0\)</span>. لاختيار المتغيرات وتعلم الشبكة العصبية في نفس الوقت، نجمع الاتصالات الخارجة من كل خلية عصبية مدخلة تتوافق مع كل متغير. تم تصميم دالة العقوبة المقعرة <span class="math inline">\(\rho_\lambda\)</span> لتقليص متجهات الوزن لمجموعات محددة إلى أصفار دقيقة، مما يؤدي إلى شبكة عصبية تستخدم فقط مجموعة صغيرة من المتغيرات الأصلية.</p></li>
<li><p><span class="math inline">\(\alpha \|\bw\|_2^2\)</span>، حيث <span class="math inline">\(\alpha &gt; 0\)</span>، يمثل مصطلح التنظيم الشائك المستخدم لمنع التخصيص الزائد في الشبكات العصبية. لاحظ أن اختيار الميزات، باستخدام <span class="math inline">\(\rho_\lambda\)</span>، يعتمد حصريًا على مقادير الأوزان في طبقة الإدخال. ومع ذلك، من الممكن تقليل تأثير <span class="math inline">\(\rho_\lambda\)</span> بتقليل جميع الأوزان في طبقة الإدخال بينما يسمح بأوزان أكبر في طبقات أخرى، دون التأثير على إخراج الشبكة. يعالج التنظيم الشائك هذه المشكلة من خلال تعزيز الأوزان الأصغر والمتوازنة جيدًا، مما يحسن استقرار النموذج ويقلل من التخصيص الزائد.</p></li>
</ul>
<p>لاحظ أنه عندما يكون عدد الطبقات المخفية <span class="math inline">\(D=0\)</span>، تتقلص الدالة <span class="math inline">\(f_\bw\)</span> إلى دالة خطية، ويصبح مشكلة التحسين في المعادلة ([eq:obj]) إطار عمل الشبكة المرنة (<span class="nodecor">zou2005regularization</span>)، SCAD-<span class="math inline">\(L_2\)</span> (<span class="nodecor">zeng2014group</span>)، وMnet (<span class="nodecor">huang2016mnet</span>)، مع اختيار <span class="math inline">\(\rho_{\lambda}\)</span> ليكون LASSO، SCAD، وMCP، على التوالي.</p>
<h2 id="تنظيم-التقعر">تنظيم التقعر</h2>
<p>هناك العديد من دوال العقوبة المستخدمة بشكل شائع والتي تشجع على الندرة في الحل، مثل الانتقاء المطلق الأقل شمولاً (<span class="nodecor">Least Absolute Shrinkage and Selection Operator</span>) (<span class="nodecor">tibshirani1996regression</span>)، والانتقاء المطلق المتقارب (<span class="nodecor">Smoothly Clipped Absolute Deviation</span>) (<span class="nodecor">fan2001variable</span>)، والانتقاء المطلق المتعدد (<span class="nodecor">Minimax Concavity Penalty</span>) (<span class="nodecor">zhang2010nearly</span>). عند تطبيقها على قاعدة <span class="math inline">\(l_2\)</span> للمعاملات المرتبطة بكل مجموعة من المتغيرات، تؤدي هذه دوال العقوبة إلى طرق تنظيم المجموعات، بما في ذلك تنظيم المجموعات للانتقاء المطلق الأقل شمولاً (<span class="nodecor">group Least Absolute Shrinkage and Selection Operator</span>) (<span class="nodecor">yuan2006model</span>)، وتنظيم المجموعات للانتقاء المطلق المتقارب (<span class="nodecor">group Smoothly Clipped Absolute Deviation</span>) (<span class="nodecor">guo2015model</span>)، وتنظيم المجموعات للانتقاء المطلق المتعدد (<span class="nodecor">group Minimax Concavity Penalty</span>) (<span class="nodecor">huang2012selective</span>). على وجه التحديد، يتم تعريف الانتقاء المطلق الأقل شمولاً، والانتقاء المطلق المتقارب، والانتقاء المطلق المتعدد كما يلي.</p>
<ul>
<li><p><span><strong>الانتقاء المطلق الأقل شمولاً</strong></span> <span class="math display">\[\rho_\lambda(t)=\lambda |t|.\]</span></p></li>
<li><p><span><strong>الانتقاء المطلق المتقارب</strong></span> <span class="math display">\[\rho_{\lambda}(t)=\begin{cases}
\lambda |t| \quad &amp;  {\rm for~} |t| \le \lambda,\\
-\frac{t^2-2a\lambda|t|+\lambda^2}{2(a-1)} \quad &amp; {\rm for~} \lambda &lt; |t| \le a\lambda,\\
\frac{(a+1)\lambda^2}{2} \quad &amp;  {\rm for~}|t| &gt; a\lambda,
\end{cases}\]</span> حيث <span class="math inline">\(a&gt;2\)</span> ثابت.</p></li>
<li><p><span><strong>الانتقاء المطلق المتعدد</strong></span> <span class="math display">\[\rho_\lambda(t)={\rm sign}(t) \lambda \int_{0}^{|t|}\left(1-\frac{z}{\lambda a}\right)_+ dz,\]</span> حيث <span class="math inline">\(a&gt;0\)</span> ثابت.</p></li>
</ul>
<p>لقد تم إثبات، نظريًا وعدديًا، أن طرق تنظيم التقعر مثل الانتقاء المطلق المتقارب والانتقاء المطلق المتعدد تظهر أداءً قويًا من حيث اختيار الميزات والتنبؤ (<span class="nodecor">fan2001variable</span>, <span class="nodecor">zhang2010nearly</span>). على عكس عقوبة الانتقاء المطلق الأقل شمولاً المحدبة، التي تميل إلى التنظيم الزائد للمصطلحات الكبيرة وتوفير اختيار ميزات غير متسق، يمكن للتنظيم التقعري تقليل تحيز الانتقاء المطلق الأقل شمولاً وتحسين دقة اختيار النموذج. الأساس وراء العقوبة التقعرية يكمن في سلوك مشتقاتها. على وجه التحديد، يُطبق الانتقاء المطلق المتقارب والانتقاء المطلق المتعدد في البداية نفس مستوى العقوبة كما في الانتقاء المطلق الأقل شمولاً، ولكن يقلل تدريجيًا من معدل العقوبة حتى ينخفض إلى الصفر عندما <span class="math inline">\(t &gt; a\lambda\)</span>. نظرًا لفوائد العقوبة التقعرية، نقترح استخدام تنظيم المجموعات التقعري في إطار عملنا لاختيار الميزات وتقدير الدالة في آن واحد.</p>
<!-- ... باقي النص كما هو ... -->
</body>
</html>
