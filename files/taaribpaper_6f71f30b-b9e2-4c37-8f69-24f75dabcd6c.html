<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Gengming Zhang, Hao Cao, Kewei Hu, Yaoqiang Pan, Yuqin Deng, Hongjun Wang, Hanwen Kang">
  <title>تقدير نقاط القطع الدقيقة لحصاد الليتشي الآلي من خلال التعلّم المُدرِك للهندسة</title>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap');
    body {
      direction: rtl;
      font-family: 'Cairo', 'Segoe UI', Tahoma, Geneva, Verdana, Arial, sans-serif;
      font-size: 22px;
      background: #f8f9fa;
      color: #222;
      margin: 0;
      padding: 0;
      line-height: 1.8;
    }
    header {
      background: linear-gradient(90deg, #e0eafc 0%, #cfdef3 100%);
      padding: 2.5rem 1rem 1.5rem 1rem;
      text-align: center;
      border-bottom: 2px solid #b2bec3;
      margin-bottom: 2rem;
    }
    .container {
      max-width: 1000px;
      margin: 0 auto;
      padding: 0 1rem 3rem 1rem;
    }
    h1.title {
      font-size: 2.5rem;
      font-weight: 700;
      color: #2d3436;
      margin-bottom: 1rem;
      letter-spacing: 0.02em;
    }
    .author {
      font-size: 1.2rem;
      color: #636e72;
      margin-bottom: 0.5rem;
    }
    h1, h2, h3 {
      color: #0984e3;
      font-weight: 700;
      margin-top: 2.2rem;
      margin-bottom: 1rem;
      line-height: 1.3;
    }
    h1 {
      font-size: 2rem;
      border-bottom: 2px solid #dfe6e9;
      padding-bottom: 0.3rem;
    }
    h2 {
      font-size: 1.5rem;
      border-right: 4px solid #74b9ff;
      padding-right: 0.7rem;
      background: #f1f2f6;
      border-radius: 0.3rem;
    }
    h3 {
      font-size: 1.15rem;
      color: #636e72;
      margin-top: 1.5rem;
      margin-bottom: 0.7rem;
    }
    p {
      margin: 0 0 1.2em 0;
      text-align: justify;
    }
    ul, ol {
      margin: 1em 2em 1em 0;
      padding-right: 1.5em;
    }
    ul li, ol li {
      margin-bottom: 0.7em;
      line-height: 1.7;
    }
    li p { margin-bottom: 0; }
    code, pre {
      font-family: 'Fira Mono', 'Consolas', 'Courier New', monospace;
      background: #f1f2f6;
      color: #d35400;
      padding: 0.2em 0.4em;
      border-radius: 0.2em;
      font-size: 0.95em;
    }
    .math.display, .math.inline {
      direction: ltr;
      unicode-bidi: embed;
      background: #f1f2f6;
      padding: 0.3em 0.7em;
      border-radius: 0.3em;
      display: block;
      margin: 1em auto;
      font-size: 1.1em;
      overflow-x: auto;
      text-align: left;
    }
    .math.inline {
      display: inline;
      padding: 0.1em 0.3em;
      margin: 0 0.2em;
      font-size: 1em;
    }
    .nodecor {
      color: #636e72;
      font-weight: 500;
      font-family: inherit;
      text-decoration: none;
    }
    table {
      border-collapse: collapse;
      width: 100%;
      margin: 1.5em 0;
      background: #fff;
      border-radius: 0.4em;
      overflow: hidden;
      box-shadow: 0 2px 8px #dfe6e9;
    }
    th, td {
      border: 1px solid #dfe6e9;
      padding: 0.7em 1em;
      text-align: center;
    }
    th {
      background: #dfe6e9;
      color: #0984e3;
      font-weight: 700;
    }
    blockquote {
      border-right: 5px solid #74b9ff;
      background: #f1f2f6;
      margin: 1.5em 2em;
      padding: 1em 1.5em;
      color: #636e72;
      font-style: italic;
      border-radius: 0.3em;
    }
    @media (max-width: 700px) {
      body { font-size: 18px; }
      header { padding: 1.2rem 0.5rem 1rem 0.5rem; }
      h1.title { font-size: 1.5rem; }
      h1 { font-size: 1.2rem; }
      h2 { font-size: 1rem; padding-right: 0.4rem; }
    }
  </style>
</head>
<body>
<header>
  <h1 class="title">تقدير نقاط القطع الدقيقة لحصاد الليتشي الآلي من خلال التعلّم المُدرِك للهندسة</h1>
  <p class="author">
    <span class="nodecor">Gengming Zhang</span>, 
    <span class="nodecor">Hao Cao</span>, 
    <span class="nodecor">Kewei Hu</span>, 
    <span class="nodecor">Yaoqiang Pan</span>, 
    <span class="nodecor">Yuqin Deng</span>,<br />
    <span class="nodecor">Hongjun Wang</span>, 
    <span class="nodecor">Hanwen Kang</span>
  </p>
</header>

<main class="container">
  <h1 id="ملخص">مُلَخَّص</h1>
  <p>يُعَدّ تحديد نقاط قَطْع عناقيد الليتشي بدقّة في بيئات البساتين غير المنظَّمة واستخراج إحداثياتها أمرًا حاسمًا لنجاح روبوتات الحصاد. ومع ذلك، كثيرًا ما تواجه طرائق الكشف عن الأجسام المعتمدة على الصور ثنائية الأبعاد (2D) صعوبات بسبب البُنى الهندسية المعقّدة للفروع والأوراق والثمار، ما يُفضي إلى أخطاء في تحديد مواقع القَطْع. في هذه الدراسة، نقترح نموذج الشبكة <span class="nodecor">Fcaf3d-lychee</span> المصمَّم خصيصًا للكشف الدقيق عن نقاط القَطْع. تُكتسب بيانات سحابة النقاط لنقاط القَطْع في البيئات الطبيعية باستخدام كاميرا <span class="nodecor">Microsoft Azure Kinect DK</span> العاملة بآلية قياس زمن الطيران (<span class="nodecor">TOF</span>) عبر تصوير متعدّد الزوايا. نعزّز نموذج الكشف ثلاثي الأبعاد الخالي من المراسي والتامّ الالتفاف (<span class="nodecor">Fcaf3d</span>) بوحدة الضغط والإثارة (<span class="nodecor">SE</span>)، المستلهمة من آليات الانتباه البصري البشري لتعزيز استخراج السمات الخاصة بنقاط القَطْع. تمّ تقييم النموذج على مجموعة اختبار لمناطق القَطْع، محقِّقًا قيمة <span class="nodecor"><span class="math inline">F_{1}</span></span> بلغت <span class="nodecor">88.57%</span>، متفوِّقًا بوضوح على النماذج الراهنة. كما يضمن الكشف ثلاثي الأبعاد لمواضع نقاط القَطْع في بساتين الليتشي الحقيقية دقّة عالية حتى في ظروف الاحتجاب الكثيف. لا تتجاوز أخطاء التموضع ± 1.5 سم على جميع المحاور، بما يبرهن على متانة النموذج وعموميته.</p>

  <h1 id="مقدمة">مُقَدِّمَة</h1>
  <p>الزراعة الدقيقة (أو الزراعة الذكية) هي مفهوم حديث لإدارة المزرعة الشامل، وتستخدم طيفًا من التقنيات يبدأ بالاستشعار عن بُعد وجمع البيانات القريبة، وصولًا إلى الأتمتة والروبوتات. في هذه الدراسة نُركِّز على حصاد الليتشي الطازج، وهو تحدٍّ ليس فقط من ناحية التصميم الميكانيكي للروبوت، بل أيضًا من حيث نظام الرؤية وخوارزميات التنقّل وآليات التحكّم ونُظُم التلاعب (<span class="nodecor">r65</span>). وينصبّ اهتمامنا هنا على اكتشاف نقاط القَطْع في بيانات السحابة النقطية لتعزيز قدرات القطف الذاتي لروبوتات الحصاد.</p>
  <p>يمكن قطف الفواكه الفردية مثل التفاح والبرتقال مباشرة، بينما تتطلّب الفواكه العنقودية مثل الليتشي والعنب قطف العنقود كاملًا. ولحصاد الليتشي، يجب أولًا تحديد نقطة القَطْع الرئيسة للفرع الرئيسي الحامل للثمار (MFBB) ثم قَطْع الفرع بدقّة لتفادي تلف الثمار (<span class="nodecor">r2</span>). إذا كانت منطقة العمل خالية من العوائق وكان الوصول إليها يسيرًا، فلن تمثّل إزالة العناقيد صعوبة كبيرة (<span class="nodecor">r63</span>). غير أنّ الحقل غير منظَّم؛ إذ تختلف عناقيد الليتشي في الحجم والشكل وتظهر على ارتفاعات ومواقع متعددة، وقد تتعرّض نقاط القَطْع للازدحام الشديد أو يكون الهدف غير واضح بما يكفي. كما تُعقّد الأهداف الصغيرة عملية الكشف، ما ينعكس سلبًا على الدقّة. لذا أصبح تحديد نقاط قَطْع عناقيد الليتشي بدقّة وبانتقائية محطّ تركيز رئيس في الأبحاث. ويتطلّب ذلك تقنيتَين أساسيتَين: (1) بيانات سحابة نقطية ثلاثية الأبعاد (3D) تتحمّل الاحتجاب والازدحام، و(2) نموذج كشف ثلاثي الأبعاد قائم على الشبكات التلافيفية قادر على التحديد الدقيق.</p>
  <p>خلال السنوات الأخيرة، اتّسعت تطبيقات الرؤية الحاسوبية في تحديد نقاط القَطْع (<span class="nodecor">r3,r42,r4</span>)، حيث تُستَخدم خصائص الهدف —كاللون والشكل والنسيج— لاكتشاف الليتشي عبر معالجة الصور (الترشيح، التجزئة، المعالجة المورفولوجية) وخوارزميات التعلّم الآلي (<span class="nodecor">r5,r43,r6,r7,r44</span>). ومع تقدّم التعلّم العميق، لا سيّما الشبكات الالتفافية (CNN)، تحوّلت دراسات عديدة إلى أساليب الكشف ثنائية الأبعاد المعتمدة على التعلّم مثل YOLO (<span class="nodecor">r11,r12,r45,r46,r47</span>) وسلسلة R-CNN (<span class="nodecor">r50</span>). وعلى الرغم من النتائج المشجّعة، ما تزال تقلبات الإضاءة والاحتجاب الناجم عن الأوراق والفروع عائقًا كبيرًا.</p>
  <p>تتميّز بيانات السحابة النقطية ثلاثية الأبعاد بقدرتها على تمثيل الأشكال الهندسية بدقّة وتوفير معلومات العمق مباشرة، كما تُتيح إعادة البناء ثلاثي الأبعاد بما يعزّز متانة الكشف ودقّته. ومع تطوّر الشبكات العصبية الالتفافية ثلاثية الأبعاد، استُخدمت أساليب قائمة على السحابة النقطية في حصاد الفاكهة وكشف نقاط القَطْع (<span class="nodecor">r51,r16,r52,r53,r14,r54,r66,r57</span>). وبرغم النتائج الجيّدة، لا تزال هناك فجوات في تحديد نقاط قَطْع الليتشي بصورة مباشرة.</p>
  <p>في هذا العمل، نقترح نهجًا متكاملًا يدمج بيانات سحابة النقاط متعدّدة الزوايا من كاميرا قياس زمن الطيران مع نموذج <span class="nodecor">Fcaf3d-lychee</span> لاكتشاف نقاط قَطْع الليتشي وتحديد مواقعها بدقّة في بيئة البستان الطبيعية، مع اختبار ميداني. يدمج النهج بيانات الاستشعار المرئي متعدّد الزوايا، ثم يكتشف الموضع الدقيق لنقطة القَطْع عبر خوارزمية كشف ثلاثية الأبعاد. وتُظهر النتائج تفوُّق طريقتنا على نماذج الكشف التقليدية للسحابة النقطية ثلاثية الأبعاد. يمكن تلخيص المساهمات الرئيسية كما يلي:</p>
  <ul>
    <li><p>اقتراح نموذج <span class="nodecor">Fcaf3d-lychee</span> للكشف عن نقاط قَطْع الليتشي، بما يُحسِّن دقّة التموضع بدرجة كبيرة.</p></li>
    <li><p>استخدام كاميرا قياس زمن الطيران لخياطة البيانات النقطية متعدّدة الزوايا، لمعالجة مشكلة الاحتجاب أحادي الزاوية وشُحّ المعلومات الحسية.</p></li>
    <li><p>إظهار قدرة روبوت قطف الليتشي، المُجهَّز بنموذج <span class="nodecor">Fcaf3d-lychee</span>، على التعرّف إلى نقاط القَطْع وتحديد مواقعها في بيئات البستان الطبيعية.</p></li>
  </ul>
  <p>يُنظَّم هيكل الورقة كما يلي: يستعرض القسم [section: review] الأعمال ذات الصلة. يقدّم القسم [section: method] نظرة عامة على النظام والمنهجية. تُعرض نتائج التجارب ومناقشتها في القسم [section: experiment]، ثم الخاتمة في القسم [section: conclusion].</p>

  <h1 id="section: review">الأعمال ذات الصلة</h1>
  <h2 id="مراجعة-عن-الكشف-عن-الأهداف-ثنائية-الأبعاد-المبنية-على-الصور-في-الليتشي">مراجعة حول الكشف عن الأهداف ثنائية الأبعاد المبنية على الصور في الليتشي</h2>
  <p>يغطي مجال تطبيق الروبوتات حاليًّا تقنيات أساسية ومتنوّعة (<span class="nodecor">r17</span>). وفي تطوير روبوتات الحصاد الذكية، تشكّل خوارزميات الرؤية عاملًا حاسمًا في الأداء. تشمل مهمّتا الرؤية الرئيسيتان تحديد موقع الثمرة واستخراج نقطة القَطْع، مع تحديات مثل تشوّه اللون الناتج عن تغيّر الإضاءة وتداخل أعضاء النبات والتشوّهات داخل الفئة للثمار (<span class="nodecor">r18</span>). سعت خوارزميات الرؤية الآلية إلى تحسين الكفاءة والدقّة والذكاء وإتاحة التفاعل عن بُعد خلال عمليات الحصاد (<span class="nodecor">r19</span>). وتُصنَّف الأساليب إلى تحليل السمة المفردة ودمج السمات المتعدّدة والتعرّف إلى الأنماط (<span class="nodecor">r20</span>, <span class="nodecor">r21</span>). اقترح (<span class="nodecor">r24</span>) مُصنِّفًا يعتمد على تحليل التمييز الخطي المحسَّن (LDA) لمعالجة انخفاض معدل النجاح في التعرف إلى الليتشي الأخضر بسبب تداخل الخلفية. تستخرج طريقة LDA سمات التحويل الصوري، ويُقدَّم مفهوم “الهامش الأقصى” في خوارزمية SVM لتحديد العتبة المناسبة، ثم يُدمَج ذلك في مُصنِّف LDA متعدد عبر Adaboost. أظهرت التجارب دقّة بلغت <span class="nodecor">80.4%</span> لليتشي غير الناضج، كما يمكن استخدام الخوارزمية في تصنيف نضج الفاكهة. غير أن الأساليب المعتمدة على الصور تتطلّب إضاءة مناسبة ومعالجة إضافية للتعامل مع التموضع ثلاثي الأبعاد، ما يُضعِف كفاءة عملية القطف ومتانتها.</p>

  <h2 id="مراجعة-على-طرق-الكشف-عن-الأهداف-ثنائية-الأبعاد-لثمره-الليتشي-باستخدام-التعلم-العميق">مراجعة حول طرق الكشف ثنائية الأبعاد لثمرة الليتشي باستخدام التعلّم العميق</h2>
  <p>اعتمدت بعض الأبحاث تقنيات الرؤية المجسّمة وتقنيات معالجة الصور التقليدية، بينما قدّم التطوّر في التعلّم العميق حلولًا متقدّمة لتمييز الفواكه في بيئات البساتين المعقّدة (<span class="nodecor">r25</span>). على سبيل المثال، اقترح (<span class="nodecor">r26</span>) خوارزمية لكشف ثمار الليتشي وسيقانها في البيئات الليلية باستخدام YOLOv3 وU-Net تحت شدّات ضوء صناعية مختلفة، محقّقًا دقّة كشف متوسّطة قدرها <span class="nodecor">99.57%</span> وتجزئة MIoU بلغت <span class="nodecor">84.33%</span>. ومع ذلك، تعتمد الطريقة أولًا على YOLOv3 ثم على منطقة ROI لتمييز السيقان، ما يُقلّل الفاعلية في التنفيذ. و(<span class="nodecor">r28</span>) حسّن بنية YOLOv5s لسيناريوهات الاحتجاب الخلفي وتداخل الفواكه أثناء قطف التفاح، لكنه يقتصر على الفواكه الفردية ولا يغطّي سيناريوهات حصاد الليتشي. وبرغم التقدّم الكبير في تحديد نقاط القَطْع عبر الصور ثنائية الأبعاد، لم تتناول معظم الدراسات الكشف المباشر عن نقاط قَطْع الفرع الأم.</p>

  <h2 id="مراجعة-على-طرق-الكشف-عن-الأهداف-ثلاثية-الأبعاد-باستخدام-التعلم-العميق-للفواكه">مراجعة حول طرق الكشف ثلاثية الأبعاد باستخدام التعلّم العميق للفواكه</h2>
  <p>على الرغم من التقدّم الملحوظ في الكشف ثنائي الأبعاد، يفتقر هذا النمط إلى التوزيع المكاني التفصيلي. توفّر السحب النقطية ثلاثية الأبعاد تمثيلًا شاملًا لتوزيع الأجسام في المشاهد المعقّدة، ما أدّى إلى ظهور أساليب جديدة للكشف. اقترح (<span class="nodecor">r33</span>) استراتيجية لتحديد نقاط القَطْع بدقّة لعناقيد العنب الصناعية عبر دمج البيانات القريبة والبعيدة من السحب النقطية، محقّقًا نجاحًا بنحو <span class="nodecor">95%</span> من <span class="nodecor">100</span> عيّنة ودقّة <span class="nodecor">95%</span>. كذلك، اقترح (<span class="nodecor">r36</span>) طريقة لمعالجة أعضاء شجرة الرمان وعدّ الفواكه عبر دمج السمات واستخدام SVM؛ إذ يُحصَل أولًا على السحابة النقطية ثلاثية الأبعاد ثم تُستخرَج سمات اللون والشكل للتصنيف، وقد أظهرت التجارب قدرة عالية على اكتشاف معظم الثمار على الشجرة. ومع ذلك، لم تُدرَس طرائق الكشف المباشر على السحب النقطية الخاصة بنقاط القَطْع.</p>
  <p>يبني عملنا على نموذج <span class="nodecor">Fcaf3d</span>، حيث استحدثنا نموذج <span class="nodecor">Fcaf3d-lychee</span> لتحديد نقاط قَطْع الليتشي مباشرة من تدفّق السحب النقطية لكاميرا العمق، بما يسرّع عملية الاكتشاف ويزيد فاعليتها ويوفّر الإحداثيات ثلاثية الأبعاد بدقّة.</p>

  <h1 id="section: method">المواد والطرق</h1>
  <h2 id="نظرة-عامة-على-النظام">نظرة عامة على النظام</h2>
  <p>يوضح الشكل [fig:graph1] عملية اكتشاف نقطة قَطْع الليتشي المقترحة، وهي تنقسم إلى مرحلتين: (1) اكتساب السحابة النقطية وخياطتها متعددة الزوايا، و(2) استخدام نموذج <span class="nodecor">Fcaf3d-lychee</span> للتحديد الدقيق للموقع. أولًا، يتجوّل الروبوت القاطف —المزوّد بخريطة للبستان— ذاتيًّا للحصول على تقدير أولي لموضع الهدف من تدفّق السحابة النقطية. بعدها، ينتقل الروبوت لجمع سحابة نقطية حول الهدف من ثلاث زوايا متقاربة، ثم يُجري الخياطة والتنقية. تُغذّى السحابة المُعالَجة إلى نموذج <span class="nodecor">Fcaf3d-lychee</span> لاكتشاف النقطة بدقّة، ويعقب ذلك توجيه المشبك/الملحق القاطِع لأداء حركة القطف.</p>

  <h2 id="نموذج-الرؤية-اليد-عين-وطريقة-المعايرة-المغلقة">نموذج الرؤية يد–عين وطريقة المعايرة المغلقة الحلقة</h2>
  <p>تُحمَل الكاميرا على ذراع روبوت Aubo بستّ درجات حريّة لجمع البيانات، ثم تُحوَّل في النهاية إحداثيات نقطة القَطْع ثلاثية الأبعاد بدقّة إلى نظام إحداثيات قاعدة الذراع. قبل ذلك، أُجرِيَت معايرة الكاميرا ومعايرة يد–عين. أُنجزت الأولى بطريقة Zhang الكلاسيكية (<span class="nodecor">r59</span>). وفي دراساتنا السابقة، اقترح (<span class="nodecor">r60</span>) طريقة معايرة يد–عين مغلقة الحلقة لتحديد العلاقة الإحداثية بين نهاية الذراع وحسّاس الكاميرا. وتُحسب مصفوفة اليد–عين كما في المعادلة (1).</p>
  <p class="math display">\[
\widehat{{_{C}^{F}}T} =\frac{1}{N_c} \sum_{i=1}^{N_c} \left({_{B}^{C}}T^{(i)} {_{R}^{B}}T {_{F}^{R}}T^{(i)}\right)^{-1}
\]</p>
  <p>حيث <span class="math inline">\(_R^B T\)</span> مصفوفة التحويل الثابتة بين {R} و{B}، و<span class="math inline">\(_B^C T^{(i)}\)</span> بين {C} و{B} للوضع i، و<span class="math inline">\(_F^R T^{(i)}\)</span> بين {F} و{R} للوضع i. يمثّل <span class="math inline">N_c</span> عدد الوضعيات المختلفة، وهنا <span class="nodecor">16</span>. عند تحريك الذراع إلى المواقع المختارة (<span class="nodecor">r64</span>)، تُحوَّل السمات المحلية لكل نقطة إلى نظام الإحداثيات الأساسي لتشكيل سمة عالمية.</p>

  <h2 id="اكتساب-سحابه-النقاط">اكتساب سحابة النقاط</h2>
  <h3 id="التصفية">التصفية</h3>
  <p>تتأثر دقّة السحب النقطية الخام المُجمَّعة من نظام الرؤية متعدّد الزوايا بعوامل عدّة كالتغيّرات الضوئية والاهتزازات وأخطاء المعايرة وأخطاء الأجهزة. تولِّد هذه العوامل ضوضاء وتبعثر نقاط خارج البنية الرئيسية. للتعامل معها، دمجنا مُرشِّحًا إحصائيًا ومُرشِّحًا لونيًا لتنقية الشوائب المنعزلة والنقاط الشاذة، وتوفير حالة أولية صالحة لخياطة السحب لاحقًا.</p>
  <p>كما اقترح (<span class="nodecor">r62</span>) في إعادة بناء ثلاثي الأبعاد (3D) لأشجار الفاكهة، نُطبِّق مُرشِّحًا لونيًا بسيطًا على السحابة النقطية للحدّ من عدد الأوراق الخضراء الظاهرة وإعداد بيئة أولية مناسبة للكشف اللاحق.</p>
  <p class="math display">\[
\left\{
\begin{aligned}
    R_s &\leq \sigma_1 \\
    G_s &> \sigma_2
\end{aligned}
\right.
\]</p>
  <p>حيث <span class="math inline">R_s</span> و<span class="math inline">G_s</span> قناتَا الأحمر والأخضر لكل نقطة. إذا تحقّق الشرط، تُزال النقطة من السحابة.</p>
  <p>أمّا المُرشِّح الإحصائي، فيبحث لكل نقطة عن جيرانها، ويحسب متوسّط المسافات <span class="math inline">\(\mu\)</span> والانحراف المعياري <span class="math inline">\(\sigma\)</span>، ويستبعد النقاط خارج الفترة:</p>
  <p class="math display">\[
\left[ 
    \mu-\alpha_v\times\sigma,\ \mu+\alpha_v\times\sigma
\right]
\]</p>
  <p>حيث <span class="math inline">\(\alpha_v<3\)</span>.</p>

  <h3 id="الخياطة">الخياطة</h3>
  <p>استنادًا إلى معايرة اليد–عين، تُحوَّل كل مجموعة من السحب النقطية الثلاث إلى نظام إحداثيات قاعدة الذراع، ما يوفّر توجيهًا أوليًا جيّدًا لخياطة السحب التالية.</p>
  <p>لنفترض أن عدد نقاط السحابة في الزوايا A وB وC هو <span class="nodecor"><span class="math inline">n_1</span></span> و<span class="nodecor"><span class="math inline">n_2</span></span> و<span class="nodecor"><span class="math inline">n_3</span></span> على التوالي، وأن إحداثياتها في النظام الأساسي هي <span class="nodecor"><span class="math inline">{^R}P_A^{(k)}</span></span> و<span class="nodecor"><span class="math inline">{^R}P_B^{(k)}</span></span> و<span class="nodecor"><span class="math inline">{^R}P_C^{(k)}</span></span>، بينما إحداثياتها في نظام الكاميرا هي <span class="nodecor"><span class="math inline">{^{CA}}P^{(k)}</span></span> و<span class="nodecor"><span class="math inline">{^{CB}}P^{(k)}</span></span> و<span class="nodecor"><span class="math inline">{^{CC}}P^{(k)}</span></span> على التوالي. بتطبيق التحويل <span class="nodecor"><span class="math inline">_{C}^{R}T</span></span> كما استُنتِج في القسم III-B، نحصل على:</p>
  <p class="math display">\[
\begin{aligned}
\left[
\begin{array}{c}
    {^R}P_A^{(1)} \\
    {^R}P_A^{(2)} \\
    \vdots \\
    {^R}P_A^{(n_1)} 
\end{array}
\right]
&= \ 
^{R}_{CA}T
\left[
\begin{array}{c}
    ^{CA}P^{(1)} \\
    ^{CA}P^{(2)} \\
    \vdots \\
    ^{CA}P^{(n_1)} 
\end{array}
\right], \\
^{R}_{CA}T
&= 
^{R}_{CB}T
=
^{R}_{CC}T
=
\widehat{{_{C}^{F}}T}
\end{aligned}
\]</p>
  <p>وبالتالي تتجمّع السحابة النقطية الموحَّدة <span class="nodecor"><span class="math inline">P_s</span></span> كما يلي:</p>
  <p class="math display">\[
P_s
=
\left[
\begin{array}{c|c|c}
    \Bigl[{^R}P_A^{(1)},\dots,{^R}P_A^{(n_1)}\Bigr] &
    \Bigl[{^R}P_B^{(1)},\dots,{^R}P_B^{(n_2)}\Bigr] &
    \Bigl[{^R}P_C^{(1)},\dots,{^R}P_C^{(n_3)}\Bigr]
\end{array}
\right]^T
\]</p>

  <!-- ... يمكن أن تُستكمل الأقسام اللاحقة بالطريقة نفسها ... -->
</main>
</body>
</html>