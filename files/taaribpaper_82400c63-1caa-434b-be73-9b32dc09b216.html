<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Aayush Dhakal, Subash Khanal, Srikumar Sastry, Adeel Ahmad, Nathan Jacobs">
  <title>GeoBind: ربط النصّ والصور والصوت عبر صور الأقمار الصناعيّة</title>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap');
    html, body {
      font-family: 'Cairo', 'Segoe UI', 'Tahoma', 'Geneva', 'Verdana', sans-serif;
      background: #f8fafc;
      color: #222;
      font-size: 20px;
      line-height: 1.8;
      margin: 0;
      padding: 0;
      direction: rtl;
    }
    body {
      max-width: 900px;
      margin: 40px auto 40px auto;
      padding: 32px 24px 32px 24px;
      background: #fff;
      border-radius: 18px;
      box-shadow: 0 4px 32px 0 rgba(0,0,0,0.08);
    }
    header {
      text-align: center;
      margin-bottom: 36px;
    }
    h1.title {
      font-size: 2.3em;
      font-weight: 700;
      color: #1e3a8a;
      margin-bottom: 0.2em;
      margin-top: 0;
      letter-spacing: 0.01em;
    }
    .author {
      font-size: 1.05em;
      color: #555;
      margin-bottom: 0.5em;
    }
    h1, h2 {
      color: #2563eb;
      font-weight: 700;
      margin-top: 2.2em;
      margin-bottom: 0.7em;
      border-bottom: 2px solid #e0e7ef;
      padding-bottom: 0.2em;
      letter-spacing: 0.01em;
    }
    h2 {
      font-size: 1.25em;
      margin-top: 1.7em;
    }
    p {
      margin-top: 0.7em;
      margin-bottom: 0.7em;
      text-align: justify;
    }
    .abstract {
      background: #f1f5f9;
      border-right: 4px solid #2563eb;
      padding: 1em 1.2em;
      border-radius: 10px;
    }
    code, pre, .math.display {
      background: #f3f4f6;
      color: #1e293b;
      border-radius: 6px;
      padding: 0.2em 0.5em;
      font-size: 1em;
      font-family: 'Cairo', 'Consolas', 'monospace';
      direction: ltr;
      unicode-bidi: embed;
    }
    pre {
      padding: 1em;
      overflow-x: auto;
      font-size: 0.95em;
    }
    .math.display {
      display: block;
      margin: 1.2em auto;
      text-align: center;
      font-size: 1.1em;
      direction: ltr;
      unicode-bidi: embed;
    }
    span.nodecor {
      text-decoration: none;
      color: #0e7490;
      font-weight: 500;
    }
    ul, ol {
      margin: 1em 2em 1em 0;
      padding-right: 1.5em;
    }
    table {
      border-collapse: collapse;
      width: 100%;
      margin: 1.5em 0;
      background: #f9fafb;
      border-radius: 8px;
      overflow: hidden;
      font-size: 0.98em;
    }
    th, td {
      border: 1px solid #e5e7eb;
      padding: 0.7em 1em;
      text-align: center;
    }
    th {
      background: #e0e7ef;
      color: #1e3a8a;
      font-weight: 700;
    }
    a {
      color: #0e7490;
      text-decoration: underline dotted;
      transition: color 0.2s;
    }
    a:hover {
      color: #1e3a8a;
    }
    @media (max-width: 600px) {
      body {
        padding: 10px 2vw 10px 2vw;
        font-size: 17px;
      }
      h1.title {
        font-size: 1.5em;
      }
    }
  </style>
</head>
<body>
<header>
  <h1 class="title">GeoBind: ربط النصّ والصور والصوت عبر صور الأقمار الصناعيّة</h1>
  <p class="author">
    <span class="nodecor">Aayush Dhakal</span>,
    <span class="nodecor">Subash Khanal</span>,
    <span class="nodecor">Srikumar Sastry</span>,
    <span class="nodecor">Adeel Ahmad</span>,
    <span class="nodecor">Nathan Jacobs</span>
  </p>
</header>

<h1 id="ملخص">مُلخَّص</h1>
<div class="abstract">
<p>في الاستشعار عن بُعد، نهتمّ بنمذجة وسائط متعدِّدة لموقعٍ جغرافيٍّ مُعيَّن. ركّزت أعمال كثيرة على تعلُّم العلاقة بين الموقع وأنواع المناظر الطبيعيّة، وقابليّة السُّكنى، والصوت، والأوصاف النصّية، وغيرها. حديثاً، صار النهج الشائع لمعالجة هذه المشكلات هو تدريب نموذج تعلُّم عميق يستند إلى صور الأقمار الصناعيّة لاستنتاج خصائص فريدة للموقع. في هذا العمل، نقدِّم نموذج تعلُّم عميق، <span class="nodecor">GeoBind</span>، يمكنه الاستدلال على وسائط متعدِّدة—وتحديداً النصّ والصور والصوت—انطلاقاً من صورة قَمَريّة لموقعٍ ما. لتحقيق ذلك، نعتمد صور الأقمار الصناعيّة كعنصر ربط، ونُحاذي تباينيّاً بين وسائطنا المختلفة وتضمينات صور الأقمار الصناعيّة. يفضي تدريبُنا إلى إنشاء فضاء تضمين مُشترَك يضمّ بيانات صور الأقمار الصناعيّة، وصور مستوى الأرض، والصوت، والنصّ. علاوة على ذلك، لا يتطلّب نهجُنا مجموعة بيانات واحدة كاملة تحتوي على جميع هذه الوسائط، بل يكتفي ببيانات مرتبطة بصور الأقمار الصناعيّة. وعلى الرغم من أنّنا نقوم بمحاذاة ثلاث وسائط فقط في هذه الورقة، فإنّنا نقدِّم إطاراً عامّاً يمكن تطبيقه لإنشاء فضاء تضمين لأيّ عددٍ من الوسائط باستخدام صور الأقمار الصناعيّة كعنصر ربط. تُظهر نتائجُنا أنّ نموذج <span class="nodecor">GeoBind</span> مُتعدِّد الاستخدامات ويمكنه التعامل مع وسائط متعدِّدة عند إدخال صورة قَمَريّة.</p>
</div>

<h1 id="sec:intro">مُقَدِّمة</h1>
<p>إنّ استنتاج الخصائص المختلفة المرتبطة بمواقع جغرافيّة محدَّدة مهمّة بالغة الأهمِّيّة في الاستشعار عن بُعد. تركزت الجهود البحثية السابقة أساساً على إقامة علاقات بين الموقع ووسيط واحد مثل استخدامات الأراضي، أو مقاييس قابليّة السُّكنى، أو خصائص الصوت، أو مناظر مستوى الأرض، أو الوصف النصّي (<span class="nodecor">yurui2020towards</span>, <span class="nodecor">zhu2022land</span>, <span class="nodecor">khanal2023learning</span>, <span class="nodecor">basu2021investigating</span>, <span class="nodecor">dhakal2023sat2cap</span>). وقد أدّى ذلك إلى تطوير نماذج تعلُّم عميق تستنتج خصائص فريدة اعتماداً على صورة قَمَريّة معيَّنة (<span class="nodecor">greenwell2018goes</span>, <span class="nodecor">zang2021land</span>, <span class="nodecor">9323706</span>, <span class="nodecor">sastry2024birdsat</span>, <span class="nodecor">klemmer2023satclip</span>).</p>
<p>تهدف هذه الدراسة إلى توسيع هذا النهج عبر إنشاء فضاء تضمين مُشترَك يربط الوسائط المتعدِّدة بالموقع الجغرافي بسلاسة. تتمثّل مساهمتنا الرئيسة في بناء فضاء واحد مُشترَك للتضمين يمكن استخدامه لاستنتاج خصائص مختلفة للموقع اعتماداً على صور الأقمار الصناعيّة فقط. غير أنّ تدريب مثل هذا النموذج يواجه تحدّياً في تجميع بيانات مُتكاملة تُغطّي جميع الوسائط. فعلى سبيل المثال، لإنشاء فضاء يربط صور الأقمار الصناعيّة بالنصوص والصوت وصور مستوى الأرض، سنحتاج إلى مجموعة بيانات رباعيّة كاملة، وهو ما يزداد تعقيداً وصعوبةً مع زيادة عدد الوسائط.</p>
<p>تناولت أعمال حديثة (مثل <span class="nodecor">girdhar2023imagebind</span>) هذه المشكلة بإثبات إمكانيّة تعلُّم فضاء تضمين مُشترَك للوسائط المتعدِّدة باستخدام الصور كعنصر ربط. يستخدم ImageBind مجموعات بيانات متعدِّدة مرتبطة بالصور، ثم يقوم بمحاذاة تضمينات كل وسيط مع تضمينات الصور، ما يُنتج فضاء تمثيل مُشترَكاً يغطي جميع الوسائط. استلهاماً من ذلك، نقترح إطار عمل يعتمد على بيانات متعدِّدة مرتبطة بصور الأقمار الصناعيّة لتعلُّم فضاء تضمين مُشترَك يربط الوسائط المتعدِّدة عبر الجغرافيا، وهو فضاء مفيد لطيفٍ واسع من المهام المكانيّة. في هذا الإطار، نعتمد على نوعين من البيانات: تسجيلات صوتيّة مُقترنة بصور الأقمار الصناعيّة، وصور مستوى الأرض المُقترنة بصور الأقمار الصناعيّة. نعدّ صور الأقمار الصناعيّة نقطة الارتكاز لربط هذه الوسائط المختلفة. يتكوّن التدريب من مرحلتين: الأولى لمحاذاة تضمينات صور الأقمار الصناعيّة مع تضمينات صور مستوى الأرض (ومن ثمّ الوصف النصّي) وفقاً لأسلوب Sat2Cap (<span class="nodecor">dhakal2023sat2cap</span>)، والثانية لمحاذاة تضمينات الصوت مع تضمينات الصور القَمَريّة الناجمة عن المرحلة الأولى.</p>

<h1 id="sec:method">الطريقة</h1>
<h2 id="مجموعة-البيانات">مجموعة البيانات</h2>
<p>نستخدم مجموعتَيْ بيانات مرتبطتَيْن بصور الأقمار الصناعيّة. أوّلاً، مجموعة (<span class="nodecor">dhakal2023sat2cap</span>) التي تضمّ 6.1 مليون زوج من صور الأقمار الصناعيّة وصور مستوى الأرض. دقّة صور الأقمار الصناعيّة 0.6 م/بكسل، مأخوذة من خرائط Bing، وبحجم 800×800 بكسل لكل صورة. ثانياً، بيانات SoundingEarth (<span class="nodecor">wu2023large</span>) التي تحتوي على 50 ألف تسجيل صوتي مُحدَّد الموقع جغرافيّاً، مُقترن بصور أقمار صناعيّة مُتمركزة على الإحداثيّات بدقّة 0.6 م/بكسل وبحجم 800×800 بكسل، مأخوذة أيضاً من خرائط Bing.</p>

<h2 id="المنهج">المنهج</h2>
<p>يتكوّن منهجُنا من خطوتَيْن أساسيتَيْن. الأولى لمحاذاة تضمينات صور الأقمار الصناعيّة مع تضمينات صور مستوى الأرض في فضاء <span class="nodecor">CLIP</span>، والثانية لمحاذاة تضمينات الصوت مع تضمينات الصور القَمَريّة الناتجة.</p>
<p>في الخطوة الأولى، نتّبع إجراء Sat2Cap (<span class="nodecor">dhakal2023sat2cap</span>) لمحاذاة دفعة من الصور القَمَريّة \(S_i\) وتضميناتها \(O_i\) مع تضمينات CLIP لصور مستوى الأرض \(C_i\). نستخدم خسارة InfoNCE:</p>
<p><span class="math display">\[
L = \frac{1}{k}\sum_{i=0}^{k} -\log\frac{\exp(o_i \cdot c_i / \tau)}{\sum_{j=0}^{k} \exp(o_i \cdot c_j / \tau) }
\]</span></p>
<p>حيث \(\tau\) معامل الحرارة وk حجم الدُّفعة. وبما أنّ فضاء CLIP يُسقِط الصور والنصوص في فضاء دلاليٍّ مُشترَك، فإنّ محاذاة الصور القَمَريّة مع تضمينات CLIP لصور مستوى الأرض تُحاذي ضمنيّاً الأوصاف النصّية لهذه المشاهد.</p>
<p>في المرحلة الثانية، نستخدم بيانات SoundingEarth لتهيئة مُشفِّر الصوت. لدفعة من الصور القَمَريّة \(S_i\)، نحصل أوّلاً على تضميناتها \(O_i\) باستخدام المُشفِّر القَمَري المُدرَّب. ثم ندرّب مُشفِّر الصوت على دفعة من التسجيلات \(H_i\) لإخراج تضمينات \(A_i\)، مع تجميد المُشفِّر القَمَري، وذلك عبر خسائر تباينيّة مزدوجة:</p>
<p><span class="math display">\[
L_1 = \frac{1}{k}\sum_{i=0}^{k} -\log\frac{\exp(o_i \cdot a_i / \tau)}{\sum_{j=0}^{k} \exp(o_i \cdot a_j / \tau) }
\]</span></p>
<p><span class="math display">\[
L_2 = \frac{1}{k}\sum_{i=0}^{k} -\log\frac{\exp(a_i \cdot o_i / \tau)}{\sum_{j=0}^{k} \exp(a_i \cdot o_j / \tau) }
\]</span></p>
<p><span class="math display">\[
L = \frac{L_1 + L_2}{2}
\]</span></p>
<p>وبتقريب تضمينات الصوت من تضمينات الصور القَمَريّة المقابلة، فإنّها تتماشى أيضاً مع صور مستوى الأرض والنصوص ذات الصلة الدلاليّة، فتتشكّل لدينا مساحة تضمين موحَّدة تُمكِّن الوسائط المختلفة من التفاعل ضمنها.</p>

<h1 id="sec:exp">التجارب والنتائج</h1>
<h2 id="تفاصيل-التنفيذ">تفاصيل التنفيذ</h2>
<p>نستخدم نموذج CLIP ViT-B/32 المُدرَّب مُسبقاً لتوليد تضمينات CLIP. كما نستخدم ViT-B/32 كمُشفِّر لصور الأقمار الصناعيّة، مُتهيِّئاً بمعاملات نموذج CLIP، ومُشفِّر الصوت CLAP من Hugging Face. نعتمد RandAugment (<span class="nodecor">cubuk2020randaugment</span>) بثلاث عمليات لزيادة صور الأقمار الصناعيّة أثناء التدريب. نستخدم المُحسِّن AdamW (<span class="nodecor">loshchilov2017decoupled</span>) بمعدّل تعلُّم 5e-05، \(\beta_1=0.99\)، \(\beta_2=0.98\)، وجدولة CosineAnnealing مع إعادة تشغيل دافئة (<span class="nodecor">loshchilov2016sgdr</span>). معامل الحرارة \(\tau\) قابل للتعلُّم ويُبتدَأ بقيمة 0.07.</p>

<h2 id="استرجاع-متعدد-الوسائط">استرجاع متعدِّد الوسائط</h2>
<p>لإثبات أنّ فضاء التضمين المُشترَك يجمع البيانات ذات الصلة الدلاليّة، نجري تجارب استرجاع على مجموعة اختبار محجوزة من 10000 عيّنة. أوّلاً، نُظهر أنّ الفضاء يربط الصور القَمَريّة بصور مستوى الأرض من المواقع نفسها. نحسب تضمينات الصور القَمَريّة بمُشفِّرنا وتضمينات صور مستوى الأرض بمُشفِّر CLIP، ثم نحسب تشابه جيب التمام لجميع الأزواج ونستخلص مقاييس أعلى-k. ونظراً لأنّ التدريب الأوّلي مُطابق لـ Sat2Cap (<span class="nodecor">dhakal2023sat2cap</span>)، نلاحظ في (<span class="nodecor">table:image_retrieval</span>) أداء استرجاع مُتوافقاً، مع وقوع الصورة الحقيقيّة ضمن الأعلى-10 في نحو 56% من الحالات. يدلّ ذلك على توافق الصور القَمَريّة والأرضيّة دلاليّاً في فضاء التضمين المُشترَك.</p>
<p>ثانياً، نُقيِّم استرجاع الصوت استناداً إلى الصور القَمَريّة. نحسب تضمينات الصور القَمَريّة بمُشفِّرنا وتضمينات الصوت بمُشفِّر الصوت، ثم نستخلص مقاييس أعلى-k كما في (<span class="nodecor">table:sound_retrieval</span>). نلاحظ أنّ النتائج أدنى من استرجاع صور مستوى الأرض، وهو متوقّع لطبيعة المهمّة الأكثر صعوبة (<span class="nodecor">heidler2023self</span>). ومع ذلك، فإنّ نتائجنا قريبة من النماذج الراهنة لهذه المهمّة. يُشير ذلك إلى أنّ إطار عمل GeoBind يخلق فضاء تضمين مُشترَكاً يربط الصور القَمَريّة بالأرضيّة والصوت (وبالتالي النصّ عبر محاذاة CLIP)، ما يتيح استخدام مُشفِّرات متعدِّدة لوضع وسائط مختلفة في فضاء واحد دون الحاجة إلى نموذجٍ مُتخصِّص لكلّ مهمّة.</p>

<h1 id="المناقشة-والخلاصة">المناقشة والخلاصة</h1>
<p>قدّمنا إطار عمل يُمكِّن صور الأقمار الصناعيّة من التفاعل مع أنواع متعدِّدة من البيانات. وبربط الوسائط المتعدِّدة بصور الأقمار الصناعيّة، أنشأنا فضاء تضمين مُشترَكاً يجمع النصوص الدلاليّة، وصور مستوى الأرض، والصوت، والصور القَمَريّة. ويمكن توجيه هذه الوسائط إلى فضاء واحد لحلّ مشكلات متعدِّدة دون الحاجة إلى نماذج مُخصَّصة لكلّ وضع.</p>
<p>يهدف هذا الإطار إلى تشجيع تطوير نماذج تعلُّم عميق عامّة ومتعدِّدة الاستخدامات للبيانات القَمَريّة. ورغم اعتمادنا على تدريب ذي مرحلتَيْن، يمكن إضافة مراحل جديدة لأيّ عددٍ من الوسائط عبر محاذاتها بصور الأقمار الصناعيّة. يفتح عملُنا الطريق لنماذج أكثر تكاملاً وكفاءةً عِوضاً عن طرُز أحاديّة الوضع ضيّقة النطاق. في الأعمال المستقبليّة، نعتزم استكشاف إضافة وسائط جديدة ودراسة الخصائص الناشئة في فضاء التضمين المُشترَك.</p>
</body>
</html>