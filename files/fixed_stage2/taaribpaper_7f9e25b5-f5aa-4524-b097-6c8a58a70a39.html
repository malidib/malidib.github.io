<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Daniel Menges">
  <meta name="author" content="Adil Rasheed">
  <title>تحليلات تنبؤية قوية وفعالة من حيث الحساب والذاكرة باستخدام البيانات الضخمة</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>body { direction: rtl; font-size: 22px; }</style>
</head>
<body>
<header>
<h1 class="title">تحليلات تنبؤية قوية وفعالة من حيث الحساب والذاكرة باستخدام البيانات الضخمة</h1>
<p class="author"><span class="nodecor">Daniel Menges</span></p>
<p class="author"><span class="nodecor">Adil Rasheed</span></p>
</header>
<p>معادلات LaTeX</p>
<h1 id="ملخص">مُلَخَّص</h1>
<p>في عصر البيانات الضخمة الحالي، أصبحت البيانات الضخمة ركيزة أساسية للذكاء الاصطناعي، حيث تُستخدم كأساس لتطوير نماذج تعتمد على البيانات وتوليد رؤى في مجالات متنوعة. تتناول هذه الدراسة التحديات المرتبطة بشكوك البيانات، وقيود التخزين، ونمذجة البيانات التنبؤية عبر البيانات الضخمة. نعتمد على تحليل المكونات الرئيسية القوي لتقليل الضوضاء بفعالية والتخلص من القيم الشاذة، إضافةً إلى تحديد مواقع الاستشعار الأمثل لضغط البيانات وتخزينها بكفاءة عالية. تتيح هذه التقنية ضغط البيانات دون فقدان جوهري للمعلومات مع تقليل الاحتياج إلى السعة التخزينية. وبالموازاة، يقدم تحليل المكونات الرئيسية القوي بديلاً أكثر متانة من التحليل التقليدي لإدارة البيانات عالية الأبعاد، مع توسيع نطاقه ليشمل النمذجة القوية للبيانات الضخمة في الزمن الحقيقي. لهذا الغرض، نطبق شبكات الذاكرة قصيرة وطويلة الأمد (LSTM)، وهي فئة من الشبكات العصبية المتكررة، لنمذجة البيانات والتنبؤ بها استناداً إلى مجموعة فرعية منخفضة الأبعاد مستخلصة من خلال تحديد مواقع الاستشعار الأمثل، مما يسرع بشكل كبير مرحلة التدريب. تُعتبر شبكات LSTM مناسبة لالتقاط الاعتماديات طويلة المدى في بيانات السلاسل الزمنية، مما يجعلها ملائمة بشكل خاص للتنبؤ بالحالات المستقبلية للأنظمة الفيزيائية استناداً إلى البيانات التاريخية. وقد قمنا بتنظير ومحاكاة جميع الخوارزميات والتحقق من صحتها باستخدام بيانات تصوير حراري حقيقية لمحرك سفينة.</p>
<h1 id="مقدمة">مُقَدِّمَة</h1>
<p>في سياق الذكاء الاصطناعي، تتصدر البيانات المشهد، حيث تؤثر في عمليات اتخاذ القرار في العديد من المجالات، من الرعاية الصحية (<span class="nodecor">raghupathi_big_2014</span>) إلى الاقتصاد القياسي (<span class="nodecor">varian_big_2014</span>) والتصنيع (<span class="nodecor">nagorny_big_2017</span>) وغيرها. ومع ذلك، ورغم الإمكانات الهائلة للبيانات الضخمة، من الضروري فهم نقاط القوة والضعف فيها؛ فغالباً ما تتضمن أخطاء ناتجة عن عدم دقة المستشعرات أو أعطال النقل، مما قد يؤدي إلى تفسير خاطئ للبيانات إذا لم تُعالَج بشكل سليم، لا سيما عند وجود تشوهات أو بيانات ناقصة (<span class="nodecor">pitici_rise_2014</span>). لذا، فإن القدرة على التعامل بفعالية مع كميات البيانات المتزايدة وتحليلها وتفسيرها تُعدّ أمراً حيوياً، ويستدعي تطوير تقنيات تحليلية متينة.</p>
<p>من بين الأدوات المتعددة لتحليل البيانات، حظي تحليل المكونات الرئيسية (<span class="nodecor">PCA</span>) (<span class="nodecor">jolliffe_principal_2002</span>) باهتمام كبير لما يوفره من تقليل أبعاد مجموعات البيانات مع الحفاظ على معظم المعلومات (<span class="nodecor">abdi_principal_2010</span>). ومع ذلك، فإن PCA التقليدي يتأثر بشدة بالقيم الشاذة وتلف البيانات، مما يؤثر في أدائه ودقة الاستنتاجات اللاحقة. ولهذا، ظهرت تقنيات أكثر متانة قادرة على التعامل مع هذه الاختلالات. يقدم تحليل المكونات الرئيسية القوي (<span class="nodecor">RPCA</span>)، النسخة المتقدمة من PCA، نتائج أكثر موثوقية من خلال فصل المكونات منخفضة الرتبة والمعزولة في البيانات، حتى في وجود قيم شاذة أو بيانات مفقودة (<span class="nodecor">hubert_robpca_2005</span>). وقد تم شرح مفهوم RPCA لتفكيك مصفوفة البيانات إلى مكون منخفض الرتبة ومكون متفرق بالتفصيل في (<span class="nodecor">candes_robust_2011</span>)، حيث تُنفَّذ عبر برمجة محدبة تُعرف بـ «مطاردة المكونات الرئيسية». وتَسهم هذه الطريقة في استعادة المكونات الرئيسية حتى عند وجود أخطاء أو قيم مفقودة في البيانات، الأمر الذي يفتح آفاقاً جديدةً في مجالات مراقبة الفيديو وكشف الأجسام في الخلفيات المعقدة والتعرف على الوجوه لمعالجة الظلال والانعكاسات وغيرها. وتقدم دراسة (<span class="nodecor">scherl_robust_2019</span>) مقارنة مفصلة بين PCA وRPCA، مبيّنةً الفوائد والقدرة العالية لتحليل المكونات الرئيسية القوي.</p>
<p>بالتوازي مع ذلك، ومع تصاعد حجم البيانات الضخمة، يظهر تحدٍ رئيسي في كيفية تخزينها ونقلها بفعالية. يأتي مفهوم «وضع المستشعرات الأمثل» (<span class="nodecor">OSP</span>) (<span class="nodecor">manohar_data-driven_2018</span>) كنهج مبتكر يعنى بتموضع المستشعرات استراتيجياً لالتقاط البيانات الأكثر صلة وتجنب التكرار، مما يقلل من حمل التخزين ويسهل عملية النقل. في جوهره، يهدف OSP إلى إنتاج نسخة مضغوطة من البيانات بأقل خسارة في المعلومات.</p>
<p>من خلال استعراض منهجي لـ RPCA وOSP، تهدف هذه الدراسة إلى استكشاف التكامل بين المنهجيتين وتأثيرهما في تعزيز دقة وكفاءة نمذجة البيانات الضخمة.</p>
<p>علاوةً على ذلك، نُوسّع هذه الدراسة بدمج نهج تنبؤي معتمد على البيانات باستخدام شبكات الذاكرة قصيرة وطويلة الأمد (<span class="nodecor">LSTM</span>)، التي قدمها (<span class="nodecor">hochreiter_long_1997</span>). تتيح آليات بوابات LSTM تعلم الاعتماديات طويلة الأمد في البيانات (<span class="nodecor">chung_gated_2015</span>). وقد حظيت الشبكات العصبية الاصطناعية (<span class="nodecor">ANNs</span>) باهتمام واسع في التنبؤ بفضل قابليتها للتكيف وعدم خطيتها وقدرتها على تمثيل الوظائف المعقدة، رغم أنها تتطلب وقتاً حسابياً كبيراً للتدريب (<span class="nodecor">zhang_forecasting_1998</span>). لذلك، نقوم بتصميم نماذج LSTM استناداً إلى عدد قليل من نقاط البيانات المختارة عبر خوارزمية OSP، مما يعجل بشكل كبير من زمن التدريب ويُيسر تطبيقها في نطاق واسع من التطبيقات. فعند استخدام هذه النماذج للتنبؤ بالقياسات المختارة، نعيد بعد ذلك بناء البعد الكامل للبيانات عبر مفهوم OSP، مما يمكّننا من التنبؤ بدقة بالحالات المستقبلية في الأبعاد الأصلية. إن دمج RPCA وOSP وLSTM يوفر نهجاً مبتكراً لمعالجة البيانات الضخمة يجمع بين القوة الحسابية والقدرة على التوسع عبر سيناريوهات واقعية متعددة.</p>
<p>في هذه الدراسة، طبقنا الخوارزميات على بياناتٍ مستخلصة من كاميرا حرارية ترسم خريطةً لمحرك سفينة. تقدم الصور الحرارية رؤية فريدة لملامح درجات الحرارة وتقلباتها، مما يتيح فهماً أعمق لسلوك التشغيل وأداء المحرك. تُعد المراقبة الشرطية ضروريةً للحفاظ على سلامة العمليات (<span class="nodecor">mohanty_machinery_2014</span>) وتمكّن من تقدير موثوقية المحرك ومكوناته. ومن خلال الكشف المبكر عن الشذوذ، يمكن التنبؤ بعمر المكونات ومنع الأعطال الخطيرة.</p>
<h1 id="التحديات-الأساسية">التحديات الأساسية</h1>
<p>باختصار، تتناول هذه الدراسة ثلاث تحديات أساسية:</p>
<ul>
<li><p>المعالجة المتينة للشكوك مثل القيم الشاذة والتلف في البيانات الناجم عن قياسات الكاميرا الحرارية منخفضة التكلفة وغير المتطفلة.</p></li>
<li><p>الحاجة إلى تقنيات تخزين فعّالة من حيث الاستخدام الذاكري نظرًا للكم الهائل من البيانات المتولدة.</p></li>
<li><p>القدرة على إجراء الصيانة الاستباقية في الزمن الحقيقي من خلال النمذجة التنبؤية المعتمدة على البيانات.</p></li>
</ul>
<p>كما أشار (<span class="nodecor">inproceedings</span>)، نادرًا ما يعتمد القطاع البحري الصيانة التنبؤية، بل تميل أنشطته إلى الصيانة الوقائية، مما يؤدي غالبًا إلى تكاليف أعلى نتيجة استبدال مكونات لا تزال صالحة.</p>
<h1 id="النظرية">النظرية</h1>
<p>يقدم هذا القسم نظرة معمقة على التقنيات الإحصائية المستخدمة في الدراسة. نشرح فيه مفهومي تحليل المكونات الرئيسية (PCA) ونظيره القوي (RPCA) لتنقية البيانات، كما نتناول فكرة تحديد مواقع الاستشعار الأمثل (OSP) لضغط البيانات وإدارة التخزين بكفاءة.</p>
<h2 id="تحليل-المكون-الرئيسي">تحليل المكون الرئيسي</h2>
<p>تحليل المكون الرئيسي (Principal Component Analysis) إجراء إحصائي يستخدم تحويلًا متعامدًا لتحويل مجموعة من الملاحظات لعدة متغيرات مترابطة إلى مجموعة من المتغيرات غير المرتبطة خطيًا، وتُسمى هذه المتغيرات المكونات الرئيسية. يسمح ذلك بتحديد الاتجاهات التي تتباين فيها البيانات بشكل أكبر. هناك نهجان رئيسيان لحساب PCA: نهج المتجه الذاتي ونهج تحليل القيمة المفردة (Singular Value Decomposition). وتُفصَّل هذه المفاهيم في (<span class="nodecor">shlens_tutorial_2014</span>). وغالبًا ما يُفضَّل نهج SVD لكونه أكثر ثباتًا عدديًا.<br />
</p>
<h3 id="نهج-تحليل-القيمة-المفردة" class="unnumbered">نهج تحليل القيمة المفردة</h3>
<p>يرتبط تحليل المكون الرئيسي ارتباطًا وثيقًا بتحليل القيمة المفردة، وهو تحليل لمصفوفة حقيقية أو مركبة. لأي مصفوفة حقيقية <span class="math inline">\(\mathbf{A}\in \mathbb{R}^{m\times n}\)</span>، حيث <span class="math inline">\(m \geq n\)</span>، يوجد تحليل من الشكل <span class="math display">\[\mathbf{A} = \mathbf{U} \mathbf{\Sigma} \mathbf{V}^T,\]</span> حيث <span class="math inline">\(\mathbf{U}\in \mathbb{R}^{m\times m}\)</span>، و<span class="math inline">\(\mathbf{\Sigma}\in \mathbb{R}^{m\times n}\)</span>، و<span class="math inline">\(\mathbf{V}\in \mathbb{R}^{n\times n}\)</span>. أعمدة <span class="math inline">\(\mathbf{U}\)</span> هي متجهات ذاتية متعامدة لـ <span class="math inline">\(\mathbf{AA}^T\)</span>، وأعمدة <span class="math inline">\(\mathbf{V}\)</span> هي متجهات ذاتية متعامدة لـ <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span>. العناصر القطرية لـ <span class="math inline">\(\mathbf{\Sigma}\)</span> هي الجذور التربيعية للقيم الذاتية لـ <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span> (أو بالمثل، <span class="math inline">\(\mathbf{AA}^T\)</span>)، وتسمى القيم المفردة لـ <span class="math inline">\(\mathbf{A}\)</span>. لرؤية ذلك، نعتبر أولاً المصفوفة <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span>، وهي مصفوفة متماثلة. بموجب نظرية الطيف، يمكننا تحليلها كما يلي: <span class="math display">\[\mathbf{A}^T\mathbf{A} = \mathbf{V} \mathbf{\Sigma}^2\mathbf{V}^T.\]</span> بالمثل، يمكننا تحليل <span class="math inline">\(\mathbf{AA}^T\)</span> كما يلي: <span class="math display">\[\mathbf{AA}^T = \mathbf{U} \mathbf{\Sigma}^2 \mathbf{U}^T.\]</span> باستخدام هاتين الهويتين، يمكن إظهار أن <span class="math display">\[\mathbf{A} = \mathbf{U} \mathbf{\Sigma} \mathbf{V}^T,\]</span> وهو تحليل القيمة المفردة لـ <span class="math inline">\(\mathbf{A}\)</span>.</p>
<p>ننظر إلى مصفوفة بيانات <span class="math inline">\(\mathbf{X} \in \mathbb{R}^{m \times n}\)</span>، حيث كل صف هو ملاحظة وكل عمود هو متغير. نفترض أن البيانات قد تم توسيطها، أي تم طرح متوسطات الأعمدة.</p>
<ol>
<li><p><em>أداء تحليل القيمة المفردة ذو الرتبة المنخفضة:</em> احسب تحليل القيمة المفردة لـ <span class="math inline">\(\mathbf{X}\)</span> بواسطة <span class="math inline">\(\mathbf{X} = \mathbf{U}_r\mathbf{\Sigma}_r\mathbf{V}_r^T+\mathbf{E}\)</span>. هنا، <span class="math inline">\(\mathbf{U}_r \in \mathbb{R}^{m \times r}\)</span> و <span class="math inline">\(\mathbf{V}_r^\top \in \mathbb{R}^{r \times n}\)</span> هما مصفوفتان متعامدتان تحتويان على المتجهات الذاتية اليسرى واليمنى و <span class="math inline">\(r\)</span> هو عدد المكونات الرئيسية، على التوالي. المصفوفة <span class="math inline">\(\mathbf{\Sigma}_r \in \mathbb{R}^{r \times r}\)</span> تحتوي على أكبر <span class="math inline">\(r\)</span> قيم مفردة بترتيب تنازلي على القطر. بالإضافة إلى ذلك، تحتوي المصفوفة <span class="math inline">\(\mathbf{E}\)</span> على البقايا غير الممثلة بسبب تقليل الأبعاد.</p></li>
<li><p><em>المكونات الرئيسية:</em> أخيرًا، تُعطى المكونات الرئيسية لـ <span class="math inline">\(\mathbf{X}\)</span> بواسطة <span class="math inline">\(\mathbf{X}\mathbf{V}_r \approx \mathbf{U}_r \mathbf{\Sigma}_r\)</span>. العمود <span class="math inline">\(i\)</span> من <span class="math inline">\(\mathbf{X}\mathbf{V}_r\)</span> هو إسقاط البيانات على الاتجاه الرئيسي <span class="math inline">\(i\)</span> (أي المتجه الذاتي <span class="math inline">\(i\)</span>).</p></li>
</ol>
<p>يُظهر هذا الإجراء كيف يمكن استنتاج PCA من تحليل القيمة المفردة لمصفوفة البيانات. ومع ذلك، فإن PCA التقليدي حساس للغاية للقيم الشاذة وتلف البيانات.</p>
<h2 id="sec:RPCA">تحليل المكون الرئيسي القوي</h2>
<p>الميزة الأبرز في RPCA مقارنةً بـ PCA التقليدي هي مقاومته للقيم الشاذة. فـ PCA التقليدي حساس للقيم الشاذة لكونه يحاول إيجاد تمثيل منخفض البعد يفسر أكبر قدر من التباين، وقد يحرف هذا التمثيل اتجاهات البيانات الحقيقية عند وجود نقاط متطرفة. أما RPCA فينمذج هذه القيم الشاذة صراحةً، فتتحقق دقة أكبر في استعادة الهيكل الأساسي للبيانات.</p>
<p>في العديد من السيناريوهات، يستطيع RPCA استرجاع الهيكل منخفض الرتبة الحقيقي للبيانات أفضل مما يوفره PCA، خاصة عندما تسيطر التشويشات أو يكون هناك نقص كبير في العينات.</p>
<p>تعتمد الفكرة العامة على تفكيك مصفوفة البيانات <span class="math inline">\(\mathbf{X}\)</span> إلى مكونين:</p>
<span class="math display">\[\mathbf{X} = \mathbf{L} + \mathbf{S}.\]</span>
<p>حيث تصف <span class="math inline">\(\mathbf{L}\)</span> المكون منخفض الرتبة الذي يلتقط الهيكل الرئيسي للبيانات، وتصف <span class="math inline">\(\mathbf{S}\)</span> المكون المتفرق الذي يلتقط القيم الشاذة أو التشوهات. والهدف هو إيجاد <span class="math inline">\(\mathbf{L}\)</span> و<span class="math inline">\(\mathbf{S}\)</span> اللذين يحلان:</p>
<span class="math display">\[
\begin{split}
& \underset{\mathbf{L}, \mathbf{S}}{\mathrm{تصغير}}\ \mathrm{rank}(\mathbf{L}) + \|\mathbf{S}\|_0, \\
& \text{خاضع لـ} \ \mathbf{L} + \mathbf{S} = \mathbf{X},
\end{split}
\]</span>
<p>نظرًا للطبيعة غير المحدبة لرُتبة <span class="math inline">\(\mathbf{L}\)</span> وقاعدة الصفر لـ <span class="math inline">\(\mathbf{S}\)</span>، تصبح هذه المشكلة صعبة الحل عمليًا (<span class="nodecor">scherl_robust_2019</span>). للتغلب على ذلك، يُستخدم الاسترخاء المحدب (<span class="nodecor">JMLR:v11:zhang10a</span>) الذي يحول المشكلة إلى:</p>
<span class="math display">\[
\begin{split}
& \underset{\mathbf{L}, \mathbf{S}}{\mathrm{تصغير}}\ \|\mathbf{L}\|_* + \lambda \|\mathbf{S}\|_1, \\
& \text{خاضع لـ} \ \mathbf{L} + \mathbf{S} = \mathbf{X},
\end{split}
\]</span>
<p>حيث يُقرب تصغير القاعدة النووية <span class="math inline">\(\|\mathbf{L}\|_*\)</span> تصغير الرتبة، ويُقرب تصغير قاعدة <span class="math inline">\(\|\mathbf{S}\|_1\)</span> تصغير قاعدة الصفر. تُعرف المشكلة الناتجة باسم «مطاردة المكون الرئيسي» (PCP)، ويمكن حلها عبر خوارزمية مضاعف لاغرانج المعزز (<span class="nodecor">lin_augmented_2010</span>)، التي تُصاغ كالآتي:</p>
<span class="math display">\resizebox{.93\hsize}{!}{$
\mathcal{L}(\mathbf{L}, \mathbf{S}, \mathbf{\Lambda})=\|\mathbf{L}\|_* + \lambda \|\mathbf{S}\|_1+\langle \mathbf{\Lambda}, \mathbf{X} - \mathbf{L} - \mathbf{S} \rangle + \frac{\mu}{2}\|\mathbf{X}-\mathbf{L}-\mathbf{S}\|_{F}^2$}</span>
<p>حيث <span class="math inline">\(\mathbf{\Lambda}\)</span> هي مصفوفة مضاعفات لاغرانج و<span class="math inline">\(\mu\)</span> معامل. ثم يُحدَّث <span class="math inline">\(\mathbf{\Lambda}\)</span> عبر:</p>
<span class="math display">\[\mathbf{\Lambda}_{k+1} = \mathbf{\Lambda}_{k} + \mu(\mathbf{X}-\mathbf{L}_k-\mathbf{S}_k).\]</span>
<p>وبهذه الطريقة، يقوم RPCA بتحليل مصفوفة البيانات <span class="math inline">\(\mathbf{X}\)</span> إلى مكونات منخفضة الرتبة <span class="math inline">\(\mathbf{L}\)</span> ومتفرقة <span class="math inline">\(\mathbf{S}\)</span>.</p>
<h2 id="تحديد-مواقع-الاستشعار-الأمثل">تحديد مواقع الاستشعار الأمثل</h2>
<p>تحديد مواقع الاستشعار الأمثل هو أسلوب لاستخلاص أفضل المواقع داخل النظام لوضع المستشعرات. يهدف هذا النهج إلى تعظيم المعلومات المكتسبة (مثل الانتروبيا) مع تقليل عدد المستشعرات.</p>
<p>لتكن <span class="math inline">\(\boldsymbol{x} \in \mathbb{R}^n\)</span> نقطة بيانات في زمن معين، ويمكن تقريبها كما يلي:</p>
<span class="math display">\[\boldsymbol{x} \approx \mathbf{\Psi}_r \boldsymbol{a},\]</span>
<p>حيث <span class="math inline">\(\boldsymbol{a} \in \mathbb{R}^{r}\)</span> متجه المعاملات الزمني، وأعمدة <span class="math inline">\(\mathbf{\Psi}_r\)</span> هي الأوضاع الأرثوغونالية منخفضة الرتبة (حيث <span class="math inline">\(\mathbf{\Psi}_r = \mathbf{U}_r\)</span>). إذا اعتبرنا القياسات كالتالي:</p>
<span class="math display">\[\boldsymbol{y} = \mathbf{C}\boldsymbol{x},\]</span>
<p>حيث <span class="math inline">\(\mathbf{C}\in \mathbb{R}^{s\times n}\)</span> مصفوفة القياس المتناثرة و<span class="math inline">\(s\)</span> عدد المستشعرات، فإنها تقترب بـ:</p>
<span class="math display">\[\boldsymbol{y} \approx \mathbf{C}\mathbf{\Psi}_r \boldsymbol{a}.\]</span>
<p>إذا مثلنا <span class="math inline">\(\mathbf{\Theta} = \mathbf{C}\mathbf{\Psi}_r\)</span>، يمكن تقدير المعاملات عبر:</p>
<span class="math display">\[\boldsymbol{\hat{a}} = \mathbf{\Theta}^\dagger\boldsymbol{y}.\]</span>
<p>وبالتالي يعاد بناء النقطة كالتالي:</p>
<span class="math display">\[\boldsymbol{\hat{x}} = \mathbf{\Psi}_r\boldsymbol{\hat{a}} = \mathbf{\Psi}_r(\mathbf{C}\mathbf{\Psi}_r)^\dagger\boldsymbol{y}.\]</span>
<p>وبما أن <span class="math inline">\(\mathbf{\Psi}_r\)</span> معلوم من تحليل الأبعاد المنخفضة، يبقى <span class="math inline">\(\mathbf{C}\)</span> مجهولاً. وكما وضح (<span class="nodecor">manohar_data-driven_2018</span>)، يُحدَّد OSP عبر تحليل QR بالتراجع العمودي على أوضاع <span class="math inline">\(\mathbf{\Psi}_r\)</span>، مع مراعاة شرط <span class="math inline">\(s \geq r\)</span>.</p>
<h1 id="المنهجية">المنهجية</h1>
<p>يصف هذا القسم سير عمل الإطار المقترح لمعالجة البيانات الضخمة، بدءًا من تنقية البيانات ثم ضغطها وصولاً إلى النمذجة المعتمدة على البيانات بكفاءة حسابية عالية. يقوم جوهر المنهجية على RPCA وOSP وشبكات LSTM.</p>
<h2 id="تنظيف-البيانات">تنظيف البيانات</h2>
<p>في خطوة تنقية البيانات، نستخدم RPCA كما عرضناه في القسم [sec:RPCA]. تم اختيار معاملات المزاوجة بحيث <span class="math inline">\(\lambda = 0.006\)</span> و<span class="math inline">\(\mu = 10^{-5}\)</span>. بعد تفكيك مصفوفة البيانات <span class="math inline">\(\mathbf{X}\)</span> إلى مصفوفتَي <span class="math inline">\(\mathbf{L}\)</span> (منخفضة الرتبة) و<span class="math inline">\(\mathbf{S}\)</span> (متفرقة)، نعيد بناء نسخة نظيفة من البيانات بالاعتماد على <span class="math inline">\(\mathbf{L}\)</span> التي تمثل الفيزياء الكامنة، بينما تُظهر <span class="math inline">\(\mathbf{S}\)</span> التشوهات والشوائب. وبذلك نحصل على بيانات مُصقَّاة مناسبة للمراحل اللاحقة.</p>
<h2 id="ضغط-البيانات">ضغط البيانات</h2>
<p>لضغط البيانات مع الحفاظ على المعلومات الأساسية للنظام، نطبق خوارزمية OSP الموضحة في القسم [sec:OSP] على مصفوفة <span class="math inline">\(\mathbf{L}\)</span> الناتجة عن المرحلة السابقة. يقوم المبدأ الأساسي على اختيار مواقع حسّاسات تلتقط أكبر قدر من تباين البيانات، مما يسمح بتمثيل <span class="math inline">\(\mathbf{X}\)</span> بمجموعة أقل من القياسات <span class="math inline">\(\mathbf{Y}\)</span>، حيث تُكدس <span class="math inline">\(\boldsymbol{y}\)</span> في نافذة زمنية محددة. تمثل هذه المجموعة المضغوطة بمصفوفة القياس النادرة <span class="math inline">\(\mathbf{C}\)</span>. بتقليل عدد الحساسات، نحد من التكاليف وسعة التخزين المطلوبة دون المساس بدقة التمثيل.</p>
<h2 id="نمذجه-القياسات-المتناثرة-باستخدام-شبكات-lstm">نمذجة القياسات المتناثرة باستخدام شبكات LSTM</h2>
<p>في سياق النمذجة المعتمدة على البيانات، أثبتت الشبكات العصبية، ولا سيما LSTM، فعاليتها في العديد من التطبيقات. صُممت LSTM لتحمُّل المعلومات على مدى تسلسلات طويلة، مما يجعلها مثالية لمعالجة بيانات السلاسل الزمنية. غير أن تطبيقها مباشرةً على البيانات الضخمة قد يكون مكلفًا حسابيًا، لذا نطبق LSTM على مجموعة فرعية منخفضة الأبعاد <span class="math inline">\(\mathbf{Y}\)</span> المستخرجة من خلال OSP.</p>
<p>يسهم دمج LSTM مع OSP في خفض العبء الحسابي للتدريب بشكل كبير. عند استخدام LSTM لنمذجة هذه القياسات المختارة، نستهدف التقاط الديناميكيات الزمنية الكامنة. وبعد تدريب الشبكات، يمكنها التنبؤ بقيم القياسات المتناثرة، ومن ثم إعادة بناء البيانات بالحجم الكامل باستخدام المعادلة <span class="math inline">(\ref{eq:OSP_reconstruction})</span>. يتيح ذلك إعادة تخطيط الأبعاد الأصلية للبيانات. تجدر الإشارة إلى أنه عند أخذ العينات بتردد غير منتظم، يمكن لمرحلة الاستيفاء المسبق أن تحسّن من دقة النماذج.</p>
<h2 id="تدفق-البيانات-الضخمة">تدفق البيانات الضخمة</h2>
<p>يسمح نهج التكامل السابق بتدفق عمل متسق لمعالجة البيانات الضخمة، يتكون من المراحل التالية:</p>
<ol>
<li><p><strong>تنقية البيانات:</strong> يولد RPCA نسخةً نظيفة <span class="math inline">\(\mathbf{L}\)</span> من مصفوفة البيانات <span class="math inline">\(\mathbf{X}\)</span>. بما أن <span class="math inline">\(\mathbf{L}\)</span> يحافظ على الديناميكيات الأساسية للنظام، يمكن نقلها إلى المراحل اللاحقة من المعالجة والتحليل.</p></li>
<li><p><strong>ضغط البيانات:</strong> تمكن خوارزمية OSP من ضغط مكثف لمصفوفة البيانات النظيفة <span class="math inline">\(\mathbf{L}\)</span>. من خلال حساب أوضاع <span class="math inline">\(\mathbf{\Psi}_r\)</span> وإيجاد مصفوفة القياس النادرة <span class="math inline">\(\mathbf{C}\)</span>, تصبح مجموعة فرعية صغيرة <span class="math inline">\(\mathbf{Y}\)</span> كافية لتمثيل البيانات. يجب تخزين <span class="math inline">\(\mathbf{\Psi}_r\)</span> و<span class="math inline">\(\mathbf{C}\)</span> لإعادة البناء لاحقًا إلى <span class="math inline">\(\boldsymbol{\hat{x}}\)</span>.</p></li>
<li><p><strong>النمذجة المعتمدة على البيانات:</strong> نُنشئ نماذج LSTM للمجموعة الفرعية المنقولة <span class="math inline">\(\mathbf{Y}\)</span>. بعد التنبؤ بالمجموعة الفرعية المستقبلية، يُعاد بناء التنبؤ للأبعاد الأصلية <span class="math inline">\(\mathbf{\hat{X}_{pred}}\)</span> باستخدام <span class="math inline">\(\mathbf{\Psi}_r\)</span> و<span class="math inline">\(\mathbf{C}\)</span>.</p></li>
</ol>
<h1 id="إعداد-المحاكاة">إعداد المحاكاة</h1>
<p>في هذه الدراسة، اعتمدنا على بياناتٍ تم الحصول عليها من كاميرا حرارية لرصد محرك سفينة، وقد زودت هذه البيانات شركة Idletechs AS. نظرًا لصلاحية البيانات وخلوها من شوائب كبيرة، قمنا بإضافة اضطرابات اصطناعية وفق السيناريوهات التالية. كما نصف إعداد شبكة LSTM المستخدمة.</p>
<h2 id="البيانات">البيانات</h2>
<p>سُحب مجموعة البيانات من صور الكاميرا الحرارية التي تُظهر محرك سفينة عبارة، بهدف مراقبة السلوك الحراري خلال مراحل الإقلاع والتشغيل المستقر والتوقف. استمر جمع البيانات على مدار أربعة أيام متتالية، إذ جُمعت نحو 24 ساعة من المراقبة بمتوسط تردد أخذ عينات يقارب <span class="nodecor">0.5</span> ثانية بين القيم. تحتوي كل صورة على <span class="nodecor">19,200</span> بكسل (120×160)، حيث يلتقط كل بكسل الإشعاعات الحرارية الصادرة عن المحرك، مما يوفر مؤشراً على الأداء الحراري وأي بقع ساخنة محتملة.</p>
<h2 id="Section: Perturbations">الاضطرابات</h2>
<p>لتقييم خوارزمياتنا تحت ظروف متباينة، نفذنا أربعة سيناريوهات محاكاة تشمل الضوضاء، والشذوذ، والتلوث، ومزيجاً منها.</p>
<h3 id="السيناريو-1" class="unnumbered">السيناريو 1</h3>
<p>تم تعكير البيانات بواسطة ضوضاء غاوسية، حيث وُلدت الضوضاء بمتوسط <span class="nodecor">0</span> وانحراف معياري <span class="nodecor">4</span>، مما يضمن اقتصار معظم القيم ضمن النطاق <span class="nodecor">[-4, 4]</span>.</p>
<h3 id="السيناريو-2" class="unnumbered">السيناريو 2</h3>
<p>تم تعكير البيانات بواسطة شذوذ، من خلال اختيار عشوائي لـ <span class="nodecor">100</span> نقطة بيانات (بكسل) واستبدال قيمها الأصلية بقيم عشوائية ضمن النطاقين <span class="nodecor">[30, 40]</span> و<span class="nodecor">[-40, -30]</span>، لمحاكاة شذوذ كبير في القياسات.</p>
<h3 id="السيناريو-3" class="unnumbered">السيناريو 3</h3>
<p>تم تعكير البيانات بواسطة تلوث عشوائي، حيث أُضيفت ضوضاء موزعة بالتساوي إلى <span class="nodecor">10%</span> من عينات البيانات ضمن الفترة <span class="nodecor">[-15, 30]</span>، لاختبار متانة خوارزميات PCA وRPCA وOSP.</p>
<h3 id="السيناريو-4" class="unnumbered">السيناريو 4</h3>
<p>تم تعكير البيانات بمزيج من السيناريوهات السابقة (1 و2 و3)، مما أدى إلى تراكب أنواع الضوضاء والشذوذ والتلوث.</p>
<h2 id="هندسة-شبكة-الذاكرة-طويلة-الأمد">هندسة شبكة الذاكرة طويلة الأمد</h2>
<p>لاختيار إعدادات شبكة LSTM، جربنا عدة توليفات للمعاملات، وأخيرًا اعتمدنا المعاملات الموضحة في الجدول [tab:LSTM_parameters]. دربنا الشبكة باستخدام مُحسّن آدم مع معيار الجذر التربيعي للخطأ المتوسط لتقييم الأداء. للتنبؤ، استخدمنا نافذة تاريخية تتألف من <span class="nodecor">50</span> عينة واخترنا <span class="nodecor">100</span> خطوة زمنية للتنبؤ. تتكوّن بنية الشبكة من طبقة إدخال وطبقة LSTM وطبقة كثيفة أمامية وطبقة إخراج. ولتفادي الإفراط في التخصيص، أضفنا طبقة إسقاط (dropout)، وهي تقنية تحذف بشكل عشوائي بعض الوحدات والروابط خلال التدريب (<span class="nodecor">nitish_srivastava_geoffrey_hinton_alex_krizhevsky_ilya_sutskever_and_ruslan_salakhutdinov_dropout_2014</span>).</p>
<h1 id="النتائج-والمناقشة">النتائج والمناقشة</h1>
<p>في ما يلي، نناقش نتائج مراحل التنقية والضغط والنمذجة المعتمدة على البيانات لكل سيناريو من السيناريوهات الأربعة.</p>
<h2 id="تنظيف-البيانات-1">تنقية البيانات</h2>
<p>تعرض نتائج تنقية البيانات لكل سيناريو من السيناريوهات المذكورة في القسم «الاضطرابات». تظهر مقارنة بين إعادة البناء باستخدام RPCA وPCA أن RPCA يفصل مصفوفة <span class="math inline">\(\mathbf{L}\)</span> التي تمثل الصورة النظيفة عن مصفوفة <span class="math inline">\(\mathbf{S}\)</span> التي تجمع التشوهات والشوائب. بينما تعاني PCA التقليدي من تأثير القيم الشاذة بوضوح، يحافظ RPCA على بنية الصورة الأساسية مع إزالة الشوائب، ما يعزز دقة تطبيقات الذكاء الاصطناعي المعتمدة على البيانات الضخمة.</p>
<h2 id="ضغط-البيانات-1">ضغط البيانات</h2>
<p>أظهر تطبيق OSP على بيانات الصور الحرارية تخفيضًا كبيرًا في الأبعاد، حيث استخدمنا فقط <span class="nodecor">10</span> من أصل <span class="nodecor">19200</span> قياس بكسل. ورغم هذا الانخفاض الكبير، أمكن إعادة بناء الصور الأصلية بدقة ملحوظة. من منظور ضغط البيانات، يبرز دور OSP في خفض استهلاك الطاقة ومتطلبات الذاكرة؛ فباستخدام مجموعة صغيرة من القياسات نستطيع تمثيل البيانات الكاملة بفقدان معلوماتي ضئيل.</p>
<p>يمثل توفير الذاكرة بالنسبة للبيانات المضغوطة المعادلة التالية:</p>
<span class="math display">\[\alpha = \frac{m}{r}.\]</span>
<p>في هذه الدراسة التجريبية، نحصل على <span class="math display">\(\alpha = \frac{19200}{10} = 1920\)</span>، ما يعني أنه يمكننا تخزين 1920 مرة أكثر من الصور الحرارية بنفس سعة الذاكرة.</p>
<h2 id="نمذجه-تنبؤيه-معتمدة-على-البيانات">نمذجة تنبؤية معتمدة على البيانات</h2>
<p>دربنا شبكة <span class="nodecor">LSTM</span> على الفضاء الفرعي المتناثر <span class="math inline">\(\mathbf{Y}\)</span> المستخلص عبر OSP، مع استيفاء البيانات المسبق لمعالجة التردد غير المنتظم للعينات. لنبين أثر الاستيفاء، عرضنا قيم <span class="nodecor">RMSE</span> للنماذج مع وبدون استيفاء أولي، إضافةً إلى مقارنة زمن التدريب. تكشف النتائج عن انخفاض ملموس في الخطأ وتوفير كبير في الزمن الحسابي باستخدام النهج المقترح. تؤكد هذه السرعة المحسنة إمكانية التطبيق الفوري والتدريب عبر الإنترنت في الزمن الحقيقي، اعتماداً على عدد العصور والمعايير المختارة.</p>
<h1 id="الخلاصة">الخلاصة</h1>
<p>في الختام، يعزز تطبيق RPCA جودة بيانات الصور الحرارية بشكل ملحوظ، مما يتيح تحليلات لاحقة أكثر موثوقية. وبفضل متانته وقابليته للتوسع، يصلح هذا الإطار لمجموعة واسعة من التطبيقات المتعلقة بالبيانات الضخمة. كما يقدم OSP وسيلة فعّالة لتعظيم كفاءة التخزين وضغط البيانات في البيئات ذات القيود الصارمة. وعن طريق تطبيق شبكات LSTM على فضاء منخفض الأبعاد مشتق من OSP، نحصل على كفاءة حسابية محسنة ودقة تنبؤية عالية. يعمل هذا التكامل بين التقنيات المقدمة على رفع مستويات جودة البيانات والكفاءة الحسابية والذاكرة إضافةً إلى تمكين التنبؤات في الزمن الحقيقي.</p>
</body>
</html>