<!DOCTYPE html>
<html lang="ar">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MedFuse - الدَّمج المُتعدِّد الوسائط للبيانات السريرية وصور الأشعَّة لتنبُّؤ الوفيّات</title>
    <!-- MathJax for LaTeX math rendering -->
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true,
                packages: {'[+]': ['ams', 'amssymb', 'amsmath', 'amsthm', 'newcommand', 'boldsymbol']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            }
        };
    </script>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        body {
            font-family: 'Times New Roman', serif;
            line-height: 1.7;
            color: #333;
            background-color: #fafafa;
            direction: rtl;
        }
        .container {
            max-width: 900px;
            background-color: #fff;
            box-shadow: 0 0 12px rgba(0,0,0,0.08);
            padding: 40px;
            margin: 20px auto;
            border-radius: 6px;
        }
        h1 {
            text-align: center;
            font-size: 2.1em;
            margin-bottom: 25px;
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 12px;
        }
        h2 {
            color: #34495e;
            font-size: 1.45em;
            margin-top: 32px;
            margin-bottom: 14px;
            border-right: 4px solid #3498db;
            padding-right: 10px;
        }
        h3 {
            color: #5d6d7e;
            font-size: 1.25em;
            margin-top: 24px;
            margin-bottom: 10px;
        }
        p {
            text-align: justify;
            margin-bottom: 14px;
        }
        .abstract {
            background-color: #f8f9fa;
            border-right: 4px solid #007bff;
            padding: 18px 20px;
            margin: 28px 0;
            font-style: italic;
            border-radius: 4px;
        }
        .keywords {
            background-color: #eef5ff;
            padding: 12px 15px;
            margin: 18px 0 8px;
            border-radius: 5px;
            font-size: 0.95em;
        }
        .equation {
            text-align: center;
            margin: 18px 0;
            padding: 12px 15px;
            background-color: #f8f9fa;
            border-radius: 5px;
        }
        figure, .figure, .figure* {
            text-align: center;
            margin: 26px 0;
            padding: 14px;
            background-color: #f8f9fa;
            border-radius: 5px;
            border: 1px solid #e6e9ed;
        }
        figcaption {
            margin-top: 10px;
            color: #555;
            font-size: 0.95em;
        }
        .table, .table* {
            margin: 22px 0;
            padding: 10px 12px;
            background-color: #fcfcfc;
            border: 1px dashed #dee2e6;
            border-radius: 4px;
            color: #666;
            font-size: 0.95em;
        }
        .reference {
            font-size: 0.9em;
            margin-bottom: 8px;
        }
        .meta-info {
            background-color: #e7f3ff;
            padding: 12px 15px;
            margin-bottom: 28px;
            border-radius: 5px;
            font-size: 0.92em;
        }
        code {
            background-color: #f8f9fa;
            padding: 2px 4px;
            border-radius: 3px;
        }
        pre {
            background-color: #f8f9fa;
            padding: 14px;
            border-radius: 5px;
            overflow-x: auto;
        }
        blockquote {
            border-right: 4px solid #6c757d;
            padding-right: 16px;
            font-style: italic;
            color: #6c757d;
            background-color: #f9f9f9;
            border-radius: 4px;
        }
        .theorem, .lemma, .proposition, .corollary {
            background-color: #fff3cd;
            border: 1px solid #ffeaa7;
            padding: 14px 15px;
            margin: 18px 0;
            border-radius: 5px;
        }
        .proof {
            border-right: 2px solid #28a745;
            padding-right: 14px;
            margin: 14px 0;
        }
        .footnotes {
            font-size: 0.92em;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="meta-info">
            <strong>معرّف ArXiv:</strong> 2207.07027v2<br>
            <strong>LaTeX الأصلي:</strong> <code>./nyuad_arxiv_papers/nyuad_papers_comprehensive/source_code/2207.07027v2_extracted/main.tex</code><br>
            <strong>تمّ التحويل:</strong> 2025-06-06 13:13:48
        </div>
        <header id="title-block-header">
            <h1 class="title">MedFuse - الدَّمج المُتعدِّد الوسائط للبيانات السريرية وصور الأشعَّة لتنبُّؤ الوفيّات</h1>
            <p class="author">
                <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a><br>
                قسم الهندسة<br>
                جامعة نيويورك أبوظبي<br>
                أبوظبي، الإمارات العربية المتحدة<br>
                قسم الأشعّة<br>
                كلية الطب بجامعة نيويورك جروسمان<br>
                نيويورك، الولايات المتحدة الأمريكية<br>
                قسم الهندسة<br>
                جامعة نيويورك أبوظبي<br>
                أبوظبي، الإمارات العربية المتحدة
            </p>
            <div class="abstract">
                <div class="abstract-title"><strong>الملخّص</strong></div>
                <p>تستهدف تقنيات الدَّمج المُتعدِّد الوسائط تكامل المعلومات المُستخلَصة من مصادر بيانات مُتنوِّعة. وعلى خلاف مجموعات البيانات الطبيعيّة (كالصوت والصورة) حيث تتكوّن العيّنات عادةً من وسائط «مُقترَنة»، فإنّ بيانات الرعاية الصحيّة غالبًا ما تُجمَع على نحوٍ غير مُتزامِن. لذا فإنّ الاشتراط على توافُر جميع الوسائط لكلّ عيّنة أمر غير واقعي في المهامّ السريريّة، ويحدّ بصورة كبيرة من حجم البيانات المُتاحة أثناء التدريب. نقترح في هذا البحث <code>MedFuse</code>، وهي وحدة دَمج قائمة على LSTM بسيطة من حيث الفكرة وقويّة من حيث الأداء، وقادرة على التعامُل مع المُدخلات الأحاديّة أو المُتعدِّدة الوسائط. نقوم بتقييم منهجيّة الدمج هذه ونقدّم نتائج معياريّة جديدة لتنبُّؤ الوفيّات داخل المستشفى وتصنيف الأنماط المرضيّة، بالاستفادة من بيانات سريريّة طوليّة من مجموعة MIMIC-IV وصور أشعّة صدريّة من MIMIC-CXR. مقارنةً باستراتيجيات الدَّمج المُتعدِّد الوسائط الأكثر تعقيدًا، يُقدّم <code>MedFuse</code> تحسُّنًا ملحوظًا على مجموعة الاختبار المُقترَنة بالكامل، كما يبقى مُتماسِك الأداء عند اختبار عيّنات تفتقد صور الأشعّة السينيّة للصدر. نُتيح الشيفرة البرمجيّة خاصّتنا دعمًا لإعادة إنتاج النتائج وتمكين تقييم نماذج منافسة مستقبلًا.</p>
            </div>
            <div class="keywords">
                <strong>الكلمات المفتاحيّة:</strong>
                التعلُّم المُتعدِّد الوسائط؛ دَمج الوسائط؛ السجلات الصحيّة الإلكترونيّة (EHR)؛ صور الأشعّة السينيّة للصدر (CXR)؛ تنبُّؤ الوفيّات داخل المستشفى؛ تصنيف الأنماط المرضيّة؛ LSTM؛ MIMIC-IV؛ MIMIC-CXR.
            </div>
        </header>
        <nav id="TOC" role="doc-toc">
            <ul>
                <li><a href="#introduction">المقدّمة</a>
                    <ul>
                        <li><a href="#generalizable-insights-about-machine-learning-in-the-context-of-healthcare">رؤى عامّة حول تعلُّم الآلة في سياق الرعاية الصحيّة</a></li>
                    </ul>
                </li>
                <li><a href="#related-work">الأعمال ذات الصلة</a>
                    <ul>
                        <li><a href="#multi-modal-learning">التعلُّم المُتعدِّد الوسائط</a></li>
                        <li><a href="#multi-modal-fusion-with-medical-images">دَمج الوسائط المُتعدِّدة مع الصور الطبيّة</a></li>
                        <li><a href="#multi-modal-fusion-with-clinical-data-and-medical-images">دَمج البيانات السريريّة مع الصور الطبيّة</a></li>
                    </ul>
                </li>
                <li><a href="#sec:method">المنهجيّة</a>
                    <ul>
                        <li><a href="#encoders">المُشفِّرات الخاصّة بكلّ وسيط</a></li>
                        <li><a href="#fusion">وحدة <code>MedFuse</code></a></li>
                    </ul>
                </li>
                <li><a href="#sec:exp">التجارب</a>
                    <ul>
                        <li><a href="#datasets-and-benchmark-tasks">مجموعات البيانات والمهام المعياريّة</a>
                            <ul>
                                <li><a href="#pre-processing-of-clinical-time-series-data">معالجة البيانات الزمنيّة السريريّة</a></li>
                                <li><a href="#data-splits">تقسيمات البيانات</a></li>
                            </ul>
                        </li>
                        <li><a href="#training-strategy-with-the-medfuse-module">استراتيجيّة التدريب مع وحدة <code>MedFuse</code></a></li>
                        <li><a href="#baseline-models">النماذج الأساسيّة</a></li>
                        <li><a href="#model-training-and-selection">تدريب النماذج واختيارها</a></li>
                    </ul>
                </li>
                <li><a href="#sec:res">النتائج</a>
                    <ul>
                        <li><a href="#performance-results-in-the-uni-modal-multi-modal-settings">نتائج الأداء في السيناريوَين الأحاديّ والمُتعدِّد الوسائط</a></li>
                        <li><a href="#performance-results-in-the-paired-setting">نتائج الأداء في الإعداد المُقترَن</a></li>
                        <li><a href="#performance-results-in-the-partially-paired-setting">نتائج الأداء في الإعداد المُقترَن جزئيًّا</a></li>
                        <li><a href="#phenotype-wise-analysis">تحليل بحسب الأنماط المرضيّة</a></li>
                        <li><a href="#in-hospital-mortality-age-wise-analysis">تحليل تنبُّؤ الوفيّات داخل المستشفى بحسب الفئات العمريّة</a></li>
                    </ul>
                </li>
                <li><a href="#discussion">المناقشة</a></li>
                <li><a href="#appendix-a">الملحق</a>
                    <ul>
                        <li><a href="#image-aug">تحسينات الصور</a></li>
                        <li><a href="#hyperparameter">نتائج البحث عن القِيَم الفائقة</a></li>
                        <li><a href="#unimodalpercentagetraining">نسبة العيّنات أحاديّة الوسيط ضمن مجموعة التدريب</a></li>
                        <li><a href="#unimodalpercPAIRED">نسبة العيّنات أحاديّة الوسيط ضمن مجموعة الاختبار المُقترَن</a></li>
                        <li><a href="#missingtoken">التعامُل مع الوسيط المفقود في الدمج المُبكِّر والمُشترك</a></li>
                        <li><a href="#unimodalpercPARTIAL">نسبة العيّنات أحاديّة الوسيط ضمن مجموعة الاختبار المُقترَن جزئيًّا</a></li>
                        <li><a href="#ensemble">تجميع النماذج الأحاديّة والمُتعدِّدة الوسائط</a></li>
                    </ul>
                </li>
            </ul>
        </nav>
        <section id="introduction" class="level1">
            <h1>المقدّمة</h1>
            <p>يُدرِك الإنسان العالم من حوله عبر بيانات مُتعدِّدة الوسائط <span class="citation" data-cites="ngiam2011multimodal"></span>. حتى الآن، تعتمد معظم النماذج الناجحة في تعلُّم البيانات الإدراكيّة في الرعاية الصحيّة على وسيطٍ واحد فقط <span class="citation" data-cites="Huang2020_survey"></span>. ورغم أن التعلُّم المُتعدِّد الوسائط قد استُكشف على نطاقٍ واسع في سياقات الصوت والصورة <span class="citation" data-cites="vaezi20mmtm"></span> وعلى مجموعات الصور الطبيعيّة <span class="citation" data-cites="zellers2021merlot zsd"></span>، لا تزال تطبيقاته في الرعاية الصحيّة محدودة. الهدف الرئيس من الدَّمج المُتعدِّد الوسائط هو استغلال المعلومات ذات الصلة من وسائط مختلفة لتعزيز الأداء في المهامّ اللاحقة <span class="citation" data-cites="baltruvsaitis2018multimodal"></span>. ويمكن تصنيف استراتيجيات الدَّمج إلى: دَمج مُبكِّر، ودَمج مُشترك، ودَمج مُتأخِّر <span class="citation" data-cites="Huang2020_survey"></span>؛ ويُعدّ الدَّمج المُشترك أكثر وعودًا إذ يُنمذج التفاعلات بين تمثيلات الوسائط المُدخلة.</p>
            <p>نُبرز هنا تحدّيَين رئيسين يواجهان الدَّمج المُشترك المُتعدِّد الوسائط في الرعاية الصحيّة. أولًا، تفترض كثير من الأساليب الحديثة توافُر جميع الوسائط لكلّ عيّنة أثناء التدريب أو الاستدلال أو كليهما <span class="citation" data-cites="daft"></span>. وبرغم أن بعض الدراسات السريريّة تستوفي هذا الافتراض <span class="citation" data-cites="Huang2020_survey"></span>، فإن الحصول على بيانات مُقترَنة على الدوام غير عمليّ لأن الممارسة السريريّة اليوميّة تُنتِج بيانات غير مُتجانسة وبكثافات زمنيّة متفاوتة. فعلى سبيل المثال، تُجمَع القياسات الفسيولوجيّة بوتيرة أعلى بكثير من صور الأشعّة السينيّة للصدر في وحدات العناية المركّزة. وهاتان الوسيطتان هما محور دراستنا لما لهما من أهميّة في مهامّ التنبؤ السريري <span class="citation" data-cites="benchhmark Lohan2019"></span>. كما أن تطوير نموذج دَمج موحّد لهاتين الوسيطتين يطرح تحدّيات إضافيّة، من أبرزها: (1) اختلاف أبعاد المُدخلات على نحوٍ كبير، (2) الحاجة إلى مُستخلِص ميزات خاصّ بكلّ وسيط نظرًا لاختلاف طبيعة المعلومات والضجيج <span class="citation" data-cites="nagrani2021attention"></span>، و(3) عدم التزامُن الزمني بين الوسائط، ما يُصعِّب اقترانها. بناءً على ذلك، هدفنا الأساسي هو اقتراح بنية دَمج قادرة على التعامُل مع البيانات المُقترَنة جزئيًّا مع تحقيق أداءٍ قويّ في المهامّ التنبّؤية.</p>
            <p>التحدّي الثاني هو غياب معايير عامّة مُتعدِّدة الوسائط مُتاحة علنًا في المجال السريري. لذا تعتمد معظم الدراسات على وسيط بيانات واحد <span class="citation" data-cites="benchhmark"></span>، أو على مجموعات بيانات مُتعدِّدة الوسائط خاصّة <span class="citation" data-cites="Huang2020_survey"></span>. هنا، هدفنا الثانوي هو تقديم نتائج معياريّة جديدة لمهمّتَين سريريّتَين شائعتَين باستخدام مجموعتَي البيانات المتاحتَين للجمهور MIMIC-IV <span class="citation" data-cites="mimic4"></span> وMIMIC-CXR <span class="citation" data-cites="mimiccxrjpg"></span>، مع إتاحة الشيفرة البرمجيّة لضمان إمكانيّة إعادة الإنتاج. نقارن منهجيّتنا بالدَّمج المُبكِّر والمُشترك التقليديَّين، إضافةً إلى أحدث الأساليب مفتوحة المصدر <span class="citation" data-cites="vaezi20mmtm daft"></span>. وإجمالًا، نقدّم المساهمات التالية:</p>
            <ul>
                <li><p>نقترح <code>MedFuse</code>، وهو نهج دَمج مُتعدِّد الوسائط قائم على LSTM <span class="citation" data-cites="hochreiter1997long"></span>. بخلاف الاستراتيجيات التقليديّة للدَّمج المُشترك التي تَجمع تمثيلات الميزات من عدّة وسائط في تمثيلٍ واحد ثم تُمرِّره إلى مهمّة لاحقة، فإننا نتعامل مع التمثيلات مُتعدِّدة الوسائط على أنّها سلسلة من تمثيلات أحاديّة الوسيط (أو «رموز»)، بحيث يتولّى نموذج الدَّمج تجميع هذه التمثيلات عبر آليّة التكرار في LSTM. نفترض بنية تسلسليّة للاستفادة من التحيّز الاستقرائي في LSTM وللتعامُل مع تسلسلات مُدخلات بطولٍ مُتغيِّر في حال غياب وسيطٍ ما. وحدة الدَّمج غير مُقيّدة بهندسة مُستخلِصات الميزات الخاصّة بكلّ وسيط، ويمكنها التعامُل مع البيانات المفقودة أثناء التدريب والاستدلال.</p></li>
                <li><p>لتقييم النهج المقترح، قمنا بربط مجموعتَي بيانات واقعيّتَين مفتوحتَين: MIMIC-IV <span class="citation" data-cites="mimic4"></span> التي تحتوي على بيانات سريريّة طوليّة من وحدات العناية المركّزة، وMIMIC-CXR <span class="citation" data-cites="mimiccxrjpg"></span> التي تحتوي على صور أشعّة سينيّة للصدر. عالجنا البيانات وقدّمنا نتائج معياريّة جديدة لمهمّتَين: تنبُّؤ الوفيّات داخل المستشفى وتصنيف الأنماط المرضيّة <span class="citation" data-cites="benchhmark"></span>. أظهرت النتائج أنّ أداء النموذج يبقى قويًّا في العيّنات أحاديّة الوسيط ويتحسّن في العيّنات مُتعدِّدة الوسائط المُقترَنة، ويُحقّق نتائج مُتقدِّمة دون افتراض ترابُط صريح بين الوسائط.</p></li>
                <li><p>نظرًا لغياب معايير مُتعدِّدة الوسائط في الرعاية الصحيّة، نُتيح شيفرة معالجة البيانات والنتائج المعياريّة لضمان إعادة الإنتاج وتمكين تقييم النماذج المنافسة مستقبلًا. الشيفرة مُتاحة على: <a href="https://github.com/nyuad-cai/MedFuse" class="uri">https://github.com/nyuad-cai/MedFuse</a>. نظرة عامّة على العمل المقترح مُوضَّحة في الشكل <a href="#fig:overview-of-work" data-reference-type="ref" data-reference="fig:overview-of-work">1</a>.</p></li>
            </ul>
            <figure>
                <img src="mlhc-submission-files 2022/figures/overview_updated.png"
                     id="fig:overview-of-work" style="width:70%"
                     alt="نظرة عامة على خطّ الأنابيب: استخراج وربط بيانات MIMIC-IV وMIMIC-CXR وفق تعريف المهمّة، مع تلخيص تقسيمات المجموعات وتوزّع العلامات.">
                <figcaption aria-hidden="true"><strong>نظرة عامة على العمل المقترح.</strong> نَستخرج ونربط بيانات MIMIC-IV وMIMIC-CXR بناءً على تعريف المهمّة (تنبُّؤ الوفيّات داخل المستشفى أو تصنيف الأنماط المرضيّة). نُلخِّص تقسيمات التدريب والتحقُّق والاختبار لكلّ مهمّة، ونعرض انتشار العلامات الإيجابيّة/السلبيّة لتنبُّؤ الوفيّات. يتضمّن تصنيف الأنماط المرضيّة 25 علامة كما هو مُبيَّن في الجدول <a href="#tab:phenotype_wise" data-reference-type="ref" data-reference="tab:phenotype_wise">[tab:phenotype_wise]</a>.</figcaption>
            </figure>
            <p><span id="fig:overview-of-work" label="fig:overview-of-work"></span></p>
            <section id="generalizable-insights-about-machine-learning-in-the-context-of-healthcare" class="level2 unnumbered">
                <h2 class="unnumbered">رؤى عامّة حول تعلُّم الآلة في سياق الرعاية الصحيّة</h2>
                <p>تركّز تقنيات الدَّمج المُتعدِّد الوسائط الحديثة غالبًا على مصادر معلومات مُتزامنة باستخدام بيانات طبيعيّة مثل الصوت والصورة والنص. أمّا في الرعاية الصحيّة، فالبيانات متفرِّقة وغير مُتجانسة، وبالتالي لا تكون الوسائط مُقترَنة دائمًا. يتجاوز عملُنا تحدّي البيانات المفقودة عبر نهج دَمج مرن لا يعتمد على نوع المُشفِّر الخاصّ بكلّ وسيط، ممّا يُتيح تطبيقه على أنواع بيانات أخرى، وليس فقط صور الأشعّة السينيّة للصدر والبيانات الزمنيّة السريريّة. كما يُبرز فاعليّة معالجة سلسلة من التمثيلات الأحاديّة للوسائط مقارنةً باستراتيجيات الدَّمج التقليدي في الدَّمج المُشترك. إجمالًا، يُظهر العمل إمكانات الدَّمج المُتعدِّد الوسائط لتحسين الأداء في المهام السريريّة.</p>
            </section>
        </section>
        <section id="related-work" class="level1">
            <h1>الأعمال ذات الصلة</h1>
            <p>تنتج الممارسة السريريّة الروتينيّة كمّيات كبيرة من البيانات من مصادر متعدّدة (أي وسائط متعددة)، تشمل الصور الطبيّة، ونتائج التحاليل المخبريّة، وقياسات العلامات الحيويّة، والملاحظات السريريّة <span class="citation" data-cites="asri2015big"></span>. وقد أتاحت التطوّرات في التعلُّم العميق بناء نماذج تنبّؤية باستخدام مجموعات فرعيّة من هذه الوسائط، وغالبًا ما تكون سلاسل زمنيّة سريريّة <span class="citation" data-cites="shickel2017deep"></span> أو صورًا طبيّة <span class="citation" data-cites="litjens2017survey"></span>. نستعرض هنا لمحة عن الأعمال ذات الصلة في دَمج الوسائط المُتعدِّدة في الرعاية الصحيّة باستخدام البيانات التصويريّة وغير التصويريّة.</p>
            <section id="multi-modal-learning" class="level2">
                <h2>التعلُّم المُتعدِّد الوسائط</h2>
                <p>استُكشِف التعلُّم المُتعدِّد الوسائط على نطاق واسع لتعلُّم تمثيلات مُشتركة لعدّة وسائط <span class="citation" data-cites="baltruvsaitis2018multimodal"></span>. وتشمل المهام أمثلة مثل الارتباط البصري <span class="citation" data-cites="chen2021endtoend"></span>، ربط اللغة بالإشارات البصريّة <span class="citation" data-cites="zhang2021explainable"></span>، التعرّف على الأفعال <span class="citation" data-cites="chen2015utd"></span>، تصنيف الفيديو <span class="citation" data-cites="nagrani2021attention"></span>، توليد وصف للصور <span class="citation" data-cites="yu2019multimodal"></span>، أو الإجابة على الأسئلة البصريّة <span class="citation" data-cites="zellers2021merlot"></span>. وبما أنّ دراسات تعلُّم الآلة غالبًا ما تتعامل مع وسائط الصوت والصورة والنص، تفترض كثير من الأساليب وجود بنية معلوماتيّة مشتركة بين الوسائط؛ وهو افتراض لا يصحّ دائمًا للبيانات غير المُتجانسة في الرعاية الصحيّة، ما يستلزم مراعاة خصوصيّة البيانات الطبيّة عند تطوير تقنيات التعلُّم المُتعدِّد الوسائط.</p>
            </section>
            <section id="multi-modal-fusion-with-medical-images" class="level2">
                <h2>دَمج الوسائط المُتعدِّدة مع الصور الطبيّة</h2>
                <p>يتزايد الاهتمام بتطوير تقنيات دَمج الصور الطبيّة مُتعدِّدة الوسائط <span class="citation" data-cites="imaging_fusion"></span>. غالبًا ما تمثّل الصور وجهات نظر مختلفة لعضوٍ واحد أو آفةٍ بعينها، تُقتنص باستخدام جهازٍ واحد أو أكثر، وتَشترك في مجموعة العلامات نفسها. تركّز الأساليب المقترحة أساسًا على الدَّمج على مستوى البكسل لوجهات نظر مُتكاملة للحصول على تمثيل مُركَّب مُوحَّد للصور الخام <span class="citation" data-cites="img_fusion JAMES20144"></span>. كما طُرحت أساليب دَمج على مستوى الميزات أو على مستوى التنبؤ لتحسين التصنيف <span class="citation" data-cites="Therapy_Response Breast_Cancer cancersubtypes"></span> أو أداء التقسيم <span class="citation" data-cites="imaging_fusion"></span>. وبما أنّ التقارير النصيّة هي نتاج طبيعي للفحوص الشعاعيّة، فقد استُخدمت كوسائط إضافيّة في مهام مثل الإجابة على الأسئلة البصريّة <span class="citation" data-cites="imag_reports Sharma2021"></span>، توليد التقارير <span class="citation" data-cites="radiology"></span>، أو التصنيف الفوري للصور <span class="citation" data-cites="gzsl MVSE"></span>.</p>
            </section>
            <section id="multi-modal-fusion-with-clinical-data-and-medical-images" class="level2">
                <h2>دَمج البيانات السريريّة مع الصور الطبيّة</h2>
                <p>درست أبحاث عديدة دَمج الصور الطبيّة مع البيانات السريريّة المُستخرجة من السجلات الصحيّة الإلكترونيّة في تطبيقات متنوّعة <span class="citation" data-cites="Huang2020_survey"></span>، مثل: تنبُّؤ عودة السرطان <span class="citation" data-cites="cancer_recurrence"></span>، واكتشاف الآفات <span class="citation" data-cites="cancers_diag"></span>، وتنبُّؤ البقاء على قيد الحياة <span class="citation" data-cites="cancer_survival"></span>؛ فضلًا عن مهامّ أخرى كاكتشاف الانصمام الرئوي <span class="citation" data-cites="Huang2020"></span>، وتنبُّؤ تطوّر مرض الزهايمر <span class="citation" data-cites="MildInt"></span>، وتشخيص الأمراض العصبيّة <span class="citation" data-cites="9534148"></span>، وتشخيص خلل التنسّج العنقي <span class="citation" data-cites="cervical"></span>. وبرغم إبراز هذه الدراسات لأثر استخدام وسائط مُتعدِّدة على الأداء، فإن كثيرًا منها يفترض اقتران الصور مع ميزات سريريّة مُختارة.</p>
                <p>ركّزت بعض الدراسات تحديدًا على دَمج البيانات السريريّة مع صور الأشعّة السينيّة للصدر. فعلى سبيل المثال، أظهر دَمج الوسيطتَين أثرًا إيجابيًّا في مهامّ التنبّؤ لدى مرضى كوفيد-19 <span class="citation" data-cites="Shamout2021 Jiao2021"></span>. تسعى بعض الأعمال إلى تحسين تمثيل كامن مُشترك بعد تجميع الميزات المُشفّرة لكلّ وسيط <span class="citation" data-cites="Cardiomegaly_ehr_cxr Jiao2021"></span>، فيما تجمع أعمالٌ أخرى التنبؤات الآتية من كلّ وسيط عبر متوسّط مُرجَّح (أي الدَّمج المُتأخِّر) <span class="citation" data-cites="Shamout2021 Jiao2021"></span>. وبرغم أن الدَّمج المُتأخِّر يُتيح التنبّؤ حتى في العيّنات غير المُكتملة، إلّا أنّه يتطلّب اشتراك الوسائط في العلامات نفسها، وهو ما لا يتوافر دائمًا. أقرب الأعمال إلى عملنا ما قدّمه <span class="citation" data-cites="hayat2021dynamic"></span>، حيث اقترحوا نهج تدريب ديناميكي للبيانات السريريّة الطوليّة وصور الأشعّة الصدريّة المُقترَنة جزئيًّا في مهمّة تصنيف الأنماط المرضيّة؛ غير أنّ طريقتهم محدودة القابليّة للتوسُّع لأنها تتطلّب مُصنِّفًا إضافيًّا لكلّ تركيبة ممكنة من الوسائط المُدخلة.</p>
                <div class="figure*">
                    <p><embed src="mlhc-submission-files 2022/figures/MedFuse_final.pdf" /></p>
                </div>
            </section>
        </section>
        <section id="sec:method" class="level1">
            <h1>المنهجيّة</h1>
            <p>نُعرّف نهجًا على مرحلتَين: (1) تعلُّم نماذج إدراكيّة خاصّة بكلّ وسيط لاستخلاص الميزات الكامنة (انظر القسم <a href="#encoders" data-reference-type="ref" data-reference="encoders">3.1</a>)، و(2) دَمج هذه الميزات عبر وحدة دَمج مُتعدِّدة الوسائط مُشتركة، <code>MedFuse</code> (انظر القسم <a href="#fusion" data-reference-type="ref" data-reference="fusion">3.2</a>). تظهر البنية الكلّية في الشكل <a href="#fig:main_fig" data-reference-type="ref" data-reference="fig:main_fig">[fig:main_fig]</a>. نركّز هنا على وسيطَين: البيانات الزمنيّة السريريّة (ehr) وصور الأشعّة السينيّة للصدر (cxr) لدى شرح المنهجيّة.</p>
            <section id="encoders" class="level2">
                <h2>المُشفِّرات الخاصّة بكلّ وسيط</h2>
                <p>أحد مصادر عدم التجانس الرئيسة في الرعاية الصحيّة هو اختلاف أبعاد وسائط المُدخلات، ما يُعقِّد تطوير مُشفِّر موحّد لجميع الوسائط. كما تختلف مساحة الأهداف؛ إذ لا نفترض اشتراك جميع الوسائط في مجموعة العلامات نفسها. لذا نُعرِّف مُشفِّرات خاصّة بكلّ وسيط كما يلي.</p>
                <p>لعينةٍ ما، لنفترض أنّ <span class="math inline">\(\mathbf{x}_{ehr}\in \mathbb{R}^{t\times d}\)</span> تمثّل البيانات الزمنيّة السريريّة المرتبطة بعلامات حقيقيّة <span class="math inline">\(\textbf{y}_{ehr}\)</span>، حيث <span class="math inline">\(t\)</span> هو عدد الخطوات الزمنيّة و<span class="math inline">\(d\)</span> هو عدد الميزات المُستخلَصة من المتغيّرات السريريّة. نُطبِّق المُشفِّر <span class="math inline">\(f_{ehr}\)</span> كشبكة LSTM ثنائيّة الطبقات مع طبقة إسقاط. نَحسب تمثيلًا كامنًا <span class="math inline">\(\mathbf{v}_{ehr} \in \mathbb{R}^m\)</span> يمثّل الحالة المُخفية الأخيرة من LSTM، حيث <span class="math inline">\(m=256\)</span>. ثم نُطبِّق مُصنِّفًا <span class="math inline">\(g_{ehr}\)</span> لحساب التنبؤات: <span class="math inline">\(\hat{\mathbf{y}}_{ehr} = g_{ehr}(\mathbf{v}_{ehr})\)</span>. لتحسين المُشفِّر، نستخدم دالّة الخسارة: <span class="math display">\[\mathbb{L}_{ehr}(\mathbf{y}_{ehr}, \mathbf{\hat{y}}_{ehr}) = BCE(\mathbf{y}_{ehr}, \mathbf{\hat{y}}_{ehr}),\]</span> حيث تُشير <span class="math inline">\(BCE\)</span> إلى خسارة الانتروبيّا المُتقاطعة الثنائيّة.</p>
                <p>ولتكن <span class="math inline">\(\mathbf{x}_{cxr} \in \mathbb{R}^{w\times h \times c}\)</span> صورة أشعّة سينيّة للصدر للعينة نفسها مع العلامات الحقيقية <span class="math inline">\(\textbf{y}_{cxr}\)</span>، حيث <span class="math inline">\(w\)</span> العرض و<span class="math inline">\(h\)</span> الارتفاع و<span class="math inline">\(c\)</span> عدد القنوات. في جميع التجارب: <span class="math inline">\(h=224\)</span> و<span class="math inline">\(w=224\)</span> و<span class="math inline">\(c=3\)</span>، إذ نُكرِّر كلّ صورة عبر ثلاث قنوات. نُطبِّق المُشفِّر <span class="math inline">\(f_{cxr}\)</span> كشبكة ResNet-34 <span class="citation" data-cites="he2016deep"></span> لحساب <span class="math inline">\(\mathbf{v}_{cxr} \in \mathbb{R}^n\)</span>، وهو تمثيل الميزات بعد طبقة التجميع المتوسِّط في الشبكة الالتفافيّة حيث <span class="math inline">\(n=512\)</span>. وبالمثل، نُطبِّق مُصنِّفًا <span class="math inline">\(g_{cxr}\)</span> للتنبؤ: <span class="math inline">\(\hat{\mathbf{y}}_{cxr} = g_{cxr}(\mathbf{v}_{cxr})\)</span>، ونستخدم دالّة الخسارة التالية لتحسين المُشفِّر: <span class="math display">\[\mathbb{L}_{cxr}(\mathbf{y}_{cxr}, \mathbf{\hat{y}}_{cxr}) = BCE(\mathbf{y}_{cxr}, \mathbf{\hat{y}}_{cxr}).\]</span></p>
                <p>يمكن بالتالي تدريب المُشفِّرات بصورة مستقلّة باستخدام العلامات والخسائر الخاصّة بكلّ وسيط.</p>
            </section>
            <section id="fusion" class="level2">
                <h2>وحدة <code>MedFuse</code></h2>
                <p>لدَمج الوسائط، نستبعد أوّلًا المُصنِّفَين <span class="math inline">\(g_{ehr}\)</span> و<span class="math inline">\(g_{cxr}\)</span> ونحتفظ بالمُشفِّرَين المُدرَّبين مُسبقًا <span class="math inline">\(f_{ehr}\)</span> و<span class="math inline">\(f_{cxr}\)</span>. وبما أنّ أبعاد الفضاء الكامن للوسيطَين مختلفة، نستخدم طبقة إسقاط <span class="math inline">\(\mathbf{\phi}\)</span> لإسقاط <span class="math inline">\(\mathbf{v}_{cxr}\)</span> إلى الأبعاد نفسها لِـ<span class="math inline">\(\mathbf{v}_{ehr}\)</span>: <span class="math display">\[\mathbf{v}_{cxr}^* =  {\phi(\mathbf{v}_{cxr})}\]</span> بحيث <span class="math inline">\(\mathbf{v_{cxr}^*}\in \mathbb{R}^m\)</span>. بعد ذلك، نُنشئ تسلسلًا من تمثيلات الميزات الأحاديّة للوسائط لكلّ عيّنة: <span class="math display">\[\mathbf{v}_{fusion} = [\mathbf{v}_{ehr}, \mathbf{v}_{cxr}^*].\]</span> نُعرِّف شبكة دَمج مُتعدِّدة الوسائط <span class="math inline">\(f_{fusion}\)</span> كطبقة LSTM واحدة بمدخل 256 وبُعد مُخفي 512، تقوم بتجميع التسلسل مُتعدِّد الوسائط عبر التكرار. الدافع لاستخدام LSTM مزدوج: أوّلًا، يتّبع منطق اتخاذ القرار السريري، إذ يفحص الأطباء كلّ وسيط على حدة؛ ما يُتيح للوحدة التعلُّم من <span class="math inline">\(\mathbf{v}_{ehr}\)</span> ثم تحديث حالتها الداخليّة باستخدام <span class="math inline">\(\mathbf{v}_{cxr}^*\)</span>. ثانيًا، يمكنها التعامُل مع تسلسلات مُدخلات بعددٍ مُتغيِّر من الوسائط، وبالتالي تُعالِج تلقائيًّا حالات غياب وسيطٍ ما. ففي حال غياب صورة أشعّة صدريّة أثناء التدريب أو الاستدلال، تُعالِج الشبكة تسلسلًا من عنصرٍ واحد <span class="math inline">\([\mathbf{v}_{ehr}]\)</span>.</p>
                <p>تُمرَّر الحالة المُخفية الأخيرة <span class="math inline">\(\textbf{h}_{fusion}\)</span> الناتجة عن <span class="math inline">\(f_{fusion}\)</span> عبر مُصنِّف <span class="math inline">\(g_{fusion}\)</span> لحساب التنبؤات النهائيّة: <span class="math inline">\(\mathbf{\hat{y}}_{fusion}=g_{fusion}(\mathbf{h}_{fusion})\)</span>. نقوم بتدريب المُشفِّرَين <span class="math inline">\(f_{ehr}\)</span> و<span class="math inline">\(f_{cxr}\)</span> وطبقة الإسقاط <span class="math inline">\(\phi\)</span> ووحدة الدَّمج <span class="math inline">\(f_{fusion}\)</span> والمُصنِّف <span class="math inline">\(g_{fusion}\)</span> معًا عبر تحسين دالّة الخسارة: <span class="math display">\[\mathbb{L}_{fusion}(\mathbf{y}_{fusion}, \mathbf{\hat{y}}_{fusion}) = BCE(\mathbf{y}_{fusion}, \mathbf{\hat{y}}_{fusion}),\]</span> حيث <span class="math inline">\(\textbf{y}_{fusion}=\textbf{y}_{ehr}\)</span>، إذ نفترض أنّ البيانات الزمنيّة السريريّة هي الوسيط الأساسي المرتبط بالمهمّة التنبّؤية وهي متوافرة دائمًا أثناء التدريب والاستدلال. جميع المُصنِّفات <span class="math inline">\(g_{ehr}\)</span> و<span class="math inline">\(g_{cxr}\)</span> و<span class="math inline">\(g_{fusion}\)</span> عبارة عن طبقة خطيّة واحدة تليها دالّة تفعيل سيغمويد.</p>
            </section>
        </section>
        <section id="sec:exp" class="level1">
            <h1>التجارب</h1>
            <section id="datasets-and-benchmark-tasks" class="level2">
                <h2>مجموعات البيانات والمهام المعياريّة</h2>
                <p>في تجاربنا، استخرجنا البيانات الزمنيّة السريريّة من MIMIC-IV <span class="citation" data-cites="mimic4"></span> مع صور الأشعّة السينيّة للصدر المرتبطة بها من MIMIC-CXR <span class="citation" data-cites="mimiccxrjpg"></span>. نُلخِّص هنا المهمّتَين ونقدّم تفاصيل إضافيّة:</p>
                <ul>
                    <li><p><strong>تصنيف الأنماط المرضيّة:</strong> مهمّة مُتعدِّدة العلامات تهدف إلى التنبّؤ بما إذا كان قد تمّ تشخيص 25 حالة مرضيّة (مزمنة/مختلطة/حادّة) للمريض خلال إقامته في وحدة العناية المركّزة. لكلّ عيّنة، تحتوي <span class="math inline">\(\mathbf{x}_{ehr}\)</span> على بيانات زمنيّة سريريّة مجمّعة خلال كامل الإقامة، و<span class="math inline">\(\mathbf{y}_{ehr}\)</span> متّجه ثنائي بطول 25. نربط كلّ عيّنة بآخر صورة أشعّة سينيّة مُلتقطة خلال الإقامة نفسها. تحتوي MIMIC-III على رموز ICD-9، فيما تحتوي MIMIC-IV على رموز ICD-9 وICD-10. في الورقة المعياريّة الأصليّة <span class="citation" data-cites="benchhmark"></span>، تمّ تعريف العلامات الـ25 باستخدام برنامج التصنيف السريري لـICD-9 <span class="citation" data-cites="ccs_9"></span>. قمنا بتحويل جميع رموز ICD-10 إلى ICD-9 وفقًا لإرشادات مراكز الرعاية الطبيّة والخدمات الطبيّة<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>، ثم ربطناها بفئات CCS. نقوم بالتقييم باستخدام المساحة تحت منحنى الاستقبال (AUROC) والمساحة تحت منحنى الاسترجاع (AUPRC).</p></li>
                    <li><p><strong>تنبُّؤ الوفيّات داخل المستشفى:</strong> مهمّة ثنائيّة تهدف إلى التنبُّؤ بحدوث الوفاة داخل المستشفى بعد أول 48 ساعة في وحدة العناية المركّزة. لكلّ عيّنة، تحتوي <span class="math inline">\(\mathbf{x}_{ehr}\)</span> على بيانات زمنيّة سريريّة مجمّعة خلال أول 48 ساعة، و<span class="math inline">\(\mathbf{y}_{ehr}\)</span> علامة ثنائيّة تُشير إلى الوفاة. نستبعد الإقامات التي تقلّ عن 48 ساعة. نربط كلّ عيّنة بآخر صورة أشعّة سينيّة مُلتقطة خلال الإقامة. نقوم بالتقييم باستخدام AUROC وAUPRC.</p></li>
                </ul>
                <section id="pre-processing-of-clinical-time-series-data" class="level3">
                    <h3>معالجة البيانات الزمنيّة السريريّة</h3>
                    <p>قمنا بتعديل خطّ أنابيب استخراج البيانات ومعالجتها <span class="citation" data-cites="benchhmark"></span>، الذي كان مطبّقًا في الأصل باستخدام TensorFlow <span class="citation" data-cites="tensorflow2015"></span>، وقدمنا نسخة مُحدّثة لمجموعة MIMIC-IV باستخدام PyTorch <span class="citation" data-cites="NEURIPS2019_9015"></span>. لضمان المقارنة العادلة وإبراز فعّاليّة التعلُّم المُتعدِّد الوسائط، استخدمنا المجموعة نفسها من المتغيّرات السريريّة (17 متغيّرًا): خمسة فئويّة (زمن إعادة تعبئة الشعيرات، درجات مقياس غلاسكو لفتح العين والاستجابة الحركيّة واللفظيّة والمجموع الكلّي) و12 متغيّرًا مستمرًّا (الانبساطي، نسبة الأكسجين المُستنشق، الغلوكوز، معدّل ضربات القلب، الطول، الضغط المتوسِّط، تشبّع الأكسجين، معدّل التنفّس، الانقباضي، الحرارة، الوزن، وpH). ولجميع المهام، قمنا بأخذ عينات منتظمة كلّ ساعتين، ثم تقطيع وتوحيد المتغيّرات للحصول على مُدخلات <span class="math inline">\(f_{ehr}\)</span> كما في الأعمال السابقة <span class="citation" data-cites="benchhmark"></span>. بعد المعالجة والترميز الأحادي للميزات الفئويّة، نحصل على متّجه بحجم 76 عند كلّ خطوة زمنيّة، بحيث <span class="math inline">\(\mathbf{x}_{ehr}\in\mathbb{R}^{t\times76}\)</span> و<span class="math inline">\(t\)</span> يعتمد على العيّنة والمهمّة.</p>
                </section>
                <section id="data-splits" class="level3">
                    <h3>تقسيمات البيانات</h3>
                    <p>باستخدام مُعرّف المريض لبيانات السلاسل الزمنيّة السريريّة، قسّمنا البيانات عشوائيًّا إلى 70% تدريب، و10% تحقُّق، و20% اختبار، كما هو موضّح في الشكل <a href="#fig:overview-of-work" data-reference-type="ref" data-reference="fig:overview-of-work">1</a>. نُبلِّغ عن النتائج النهائيّة على مجموعات الاختبار ونحسب فترات الثقة 95% بطريقة bootstrap مع 1000 تكرار <span class="citation" data-cites="efron1994introduction"></span>. نرمز للبيانات الزمنيّة السريريّة بـ<span class="math inline">\(\mathbf{EHR}\)</span> ولصور الأشعّة السينيّة بـ<span class="math inline">\(\mathbf{CXR}\)</span>. تتضمّن <span class="math inline">\((\mathbf{EHR}+\mathbf{CXR})_\mathbf{PARTIAL}\)</span> عيّنات مُقترَنة وأخرى مُقترَنة جزئيًّا (أي تفتقد صورة الأشعّة)، بينما تحتوي <span class="math inline">\((\mathbf{EHR}+\mathbf{CXR})_\mathbf{PAIRED}\)</span> فقط على العيّنات التي تتوافر فيها الوسيطتان معًا. على سبيل المثال، مجموعة التدريب <span class="math inline">\((\mathbf{EHR}+\mathbf{CXR})_\mathbf{PARTIAL}\)</span> لمهمّة تصنيف الأنماط المرضيّة تضم 7756 عيّنة مرتبطة بصور أشعّة من أصل 42628 عيّنة.</p>
                    <p>استخرجنا من MIMIC-CXR صور الأشعّة السينيّة وقسمناها بناءً على تقسيمٍ عشوائي حسب المرضى. ثم نقلنا الصور من مجموعة التدريب إلى التحقّق أو الاختبار إذا كانت مُرتبطة بمرضى في تلك المجموعات. نتج عن ذلك 325188 صورة للتدريب، و15282 للتحقّق، و36625 للاختبار. نُعرّف <span class="math inline">\(\mathbf{y}_{cxr}\)</span> كمتّجه من 14 علامة ثنائيّة مُستخرجة من تقارير الأشعّة باستخدام CheXpert <span class="citation" data-cites="irvin2019chexpert"></span>. نرمز لهذه المجموعة أحاديّة الوسيط بـ<span class="math inline">\(\mathbf{CXR}_{\mathbf{UNI}}\)</span> وهي ثابتة عبر جميع المهام. نستخدم أيضًا <span class="math inline">\(\mathbf{CXR}_{\mathbf{PAIRED}}\)</span> التي تشمل فقط الصور ضمن <span class="math inline">\((\mathbf{EHR}+\mathbf{CXR})_\mathbf{PAIRED}\)</span>، و<span class="math inline">\(\mathbf{EHR}_{\mathbf{PARTIAL}}\)</span> التي تشمل فقط السلاسل الزمنيّة ضمن <span class="math inline">\((\mathbf{EHR}+\mathbf{CXR})_\mathbf{PARTIAL}\)</span>.</p>
                </section>
            </section>
            <section id="training-strategy-with-the-medfuse-module" class="level2">
                <h2>استراتيجيّة التدريب مع وحدة <code>MedFuse</code></h2>
                <p>تتكوّن الاستراتيجيّة من خطوتَين: تدريب مُسبق لمُشفِّرات الوسائط، ثم تحسين مُشترك للمُشفِّرات ووحدة الدَّمج. أثناء التدريب المُسبق، نُدرِّب مُشفِّر الصور باستخدام مجموعة التدريب الأحاديّة <span class="math inline">\(\mathbf{CXR}_{\mathbf{UNI}}\)</span> مع العلامات الشعاعيّة الـ14. كما نُدرِّب مُشفِّر البيانات الزمنيّة السريريّة لكلّ مهمّة على حدة باستخدام <span class="math inline">\(\mathbf{EHR}_{\mathbf{PARTIAL}}\)</span>، إذ لكلّ مهمّة مُدخلاتها وعلاماتها الخاصّة. بعد التدريب المُسبق، نستبعد المُصنِّفات الأحاديّة ونُحسِّن المُشفِّرات وطبقة الإسقاط و<code>MedFuse</code> باستخدام <span class="math inline">\((\mathbf{EHR+CXR})_{\mathbf{PARTIAL}}\)</span>. نقارن هذه الاستراتيجيّة مع تحسين وحدة الدَّمج باستخدام مُستخلِصات ميزات مُهيّأة عشوائيًّا.</p>
                <figure>
                    <embed src="mlhc-submission-files 2022/figures/early_joint.pdf" id="fig:baselines" style="width:100%">
                    <figcaption aria-hidden="true"><strong>بنية نماذج الدَّمج المُبكِّر والمُشترك.</strong> في الدَّمج المُبكِّر (يسار)، تُدرَّب المُشفِّرات مُسبقًا ثم تُثبَّت ويُحسَّن إسقاطٌ مع مُصنِّف نهائي. في الدَّمج المُشترك (يمين)، تُهيَّأ المُشفِّرات والمُصنِّف عشوائيًّا وتُدرَّب من البداية.</figcaption>
                </figure>
            </section>
            <section id="baseline-models" class="level2">
                <h2>النماذج الأساسيّة</h2>
                <p>نُقارن أداء نهجنا المُقترح مُتعدِّد الوسائط مع عدّة خطوط أساس:</p>
                <ul>
                    <li><p><strong>الدَّمج المُبكِّر:</strong> يعتمد على توافُر بيانات مُقترَنة في التدريب والاستدلال <span class="citation" data-cites="Huang2020_survey"></span> (انظر الشكل <a href="#fig:baselines" data-reference-type="ref" data-reference="fig:baselines">2</a> يسار). نُدرِّب نسختَين: الأولى بتدريب الشبكتَين الخاصّتَين بكلّ وسيط مستقلًّا: <span class="math inline">\(f_{cxr}\)</span> و<span class="math inline">\(g_{cxr}\)</span> على <span class="math inline">\(\mathbf{CXR}_\mathbf{PAIRED}\)</span>، و<span class="math inline">\(f_{ehr}\)</span> و<span class="math inline">\(g_{ehr}\)</span> على <span class="math inline">\(\mathbf{EHR}_\mathbf{PAIRED}\)</span>. ثم نُثبّت المُشفِّرات، ونَجمع تمثيلاتهما الكامنة، ونُحسِّن طبقة إسقاط ومُصنِّفًا باستخدام <span class="math inline">\((\mathbf{EHR}+\mathbf{CXR})_\mathbf{PAIRED}\)</span>. في النسخة الثانية، نستخدم <span class="math inline">\((\mathbf{EHR}+\mathbf{CXR})_\mathbf{PARTIAL}\)</span> مع استبدال الوسيط المفقود بمتّجه قابل للتعلُّم كما في <span class="citation" data-cites="kyono2021miracle"></span>.</p></li>
                    <li><p><strong>الدَّمج المُشترك:</strong> نُدرِّب شبكة من البداية تشمل مُشفِّرات كلّ وسيط ومُصنِّفًا على التمثيلات المُدمجة (انظر الشكل <a href="#fig:baselines" data-reference-type="ref" data-reference="fig:baselines">2</a> يمين). نُدرِّب نسختَين: الأولى باستخدام <span class="math inline">\((\mathbf{EHR}+\mathbf{CXR})_\mathbf{PAIRED}\)</span>، والثانية باستخدام <span class="math inline">\((\mathbf{EHR}+\mathbf{CXR})_\mathbf{PARTIAL}\)</span> مع متّجه قابل للتعلُّم للوسيط المفقود.</p></li>
                    <li><p><strong>وحدة النقل مُتعدِّدة الوسائط (MMTM):</strong> كما في <span class="citation" data-cites="vaezi20mmtm"></span> وتفترض بيانات مُقترَنة. نُدرج وحدة MMTM بعد أوّل طبقة LSTM في بيانات EHR، وبعد الطبقة الثالثة أو الرابعة في ResNet. نُدرِّب من البداية باستخدام <span class="math inline">\((\mathbf{EHR}+\mathbf{CXR})_\mathbf{PAIRED}\)</span> ونتّبع استراتيجية التدريب الأصليّة.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p></li>
                    <li><p><strong>تحويل الخريطة المميِّزة الديناميكي (DAFT):</strong> يتطلّب أيضًا بيانات مُقترَنة، ويستخدم وحدة DAFT <span class="citation" data-cites="daft"></span> لإعادة تحجيم وتحويل التمثيلات بعد أوّل طبقة LSTM بالاستناد إلى تمثيل CXR المُستخرج من ResNet. نُدرِّب باستخدام <span class="math inline">\((\mathbf{EHR}+\mathbf{CXR})_\mathbf{PAIRED}\)</span> وفق الاستراتيجية الأصليّة.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p></li>
                </ul>
                <p>نُقارن أيضًا مع شبكة LSTM ثنائيّة الطبقات مُدرَّبة على بيانات EHR فقط، ومع طريقة <span class="citation" data-cites="hayat2021dynamic"></span> (Unified) المُدرَّبة باستخدام <span class="math inline">\((\mathbf{EHR}+\mathbf{CXR})_\mathbf{PARTIAL}\)</span>.</p>
                <div class="table*">
                    <p><span id="tab:univsmulti" label="tab:univsmulti"></span></p>
                </div>
            </section>
            <section id="model-training-and-selection" class="level2">
                <h2>تدريب النماذج واختيارها</h2>
                <p>قمنا بضبط القِيَم الفائقة عبر 10 تكرارات لكلّ نموذج من النماذج المقترحة والأساسيّة. في كلّ تكرار، نختار مُعدّل تعلُّم عشوائيًّا بين <span class="math inline">\(10^{-5}\)</span> و<span class="math inline">\(10^{-3}\)</span>، ثم ننتقي النموذج ومُعدّل التعلُّم الذي يُحقّق أفضل AUROC على مجموعة التحقُّق. بالنماذج ذات الخيارات المعماريّة (MMTM وDAFT)، نختار البنية التي تُحقّق أفضل أداء على التحقُّق ونُبلِّغ عن نتائجها على الاختبار. استخدمنا خوارزمية Adam <span class="citation" data-cites="kingma2014adam"></span> بحجم دُفعة 16 في جميع التجارب. حدّدنا 50 عصرًا كحدّ أقصى، مع إيقاف مُبكِّر إذا لم يتحسّن AUROC للتحقُّق خلال 15 عصرًا. طُبِّقت كذلك تحسينات الصور كما في الملحق <a href="#image-aug" data-reference-type="ref" data-reference="image-aug">7.1</a>.</p>
                <p>مع أفضل مُعدّل تعلُّم مُختار، غيّرنا نسبة العيّنات أحاديّة الوسيط ضمن مجموعة تدريب <span class="math inline">\((\mathbf{EHR+CXR})_{\mathbf{PARTIAL}}\)</span>، وحسّنّا <code>MedFuse</code> وفقًا لذلك وقيّمناه على مجموعة التحقُّق. اخترنا أفضل نموذج وفق أفضل AUROC على مجموعة تحقُّق <span class="math inline">\((\mathbf{EHR+CXR})_{\mathbf{PARTIAL}}\)</span>، وبلّغنا عن نتائجه على مجموعة الاختبار. نرمز لهذا النموذج بـ<code>MedFuse</code> (OPTIMAL).</p>
                <div class="table*">
                    <p><span id="tab:paired_res" label="tab:paired_res"></span></p>
                </div>
            </section>
        </section>
        <section id="sec:res" class="level1">
            <h1>النتائج</h1>
            <p>نعرض في هذا القسم نتائج تجارب متعدِّدة لتوضيح فاعليّة النهج المقترح. خُلاصة مُعدّلات التعلُّم المُثلى واردة في الملحق <a href="#hyperparameter" data-reference-type="ref" data-reference="hyperparameter">7.2</a>. وتظهر نتائج التحقُّق عند تغيير نسبة العيّنات أحاديّة الوسيط أثناء التدريب في الملحق <a href="#unimodalpercentagetraining" data-reference-type="ref" data-reference="unimodalpercentagetraining">7.3</a>. النِّسَب المُثلى هي 10% لتنبُّؤ الوفيّات و20% لتصنيف الأنماط المرضيّة.</p>
            <section id="performance-results-in-the-uni-modal-multi-modal-settings" class="level2">
                <h2>نتائج الأداء في السيناريوَين الأحاديّ والمُتعدِّد الوسائط</h2>
                <p>في الجدول <a href="#tab:univsmulti" data-reference-type="ref" data-reference="tab:univsmulti">[tab:univsmulti]</a>، نقارن النهج المقترح مع LSTM أحاديّ الوسيط. كما هو متوقّع، نلاحظ أوّلًا تحسُّن أداء LSTM أحاديّ الوسيط على مجموعة اختبار <span class="math inline">\(\mathbf{EHR}_{\mathbf{PAIRED}}\)</span> من حيث AUROC وAUPRC لكلا المهمّتَين عند استخدام مجموعة التدريب الأكبر <span class="math inline">\(\mathbf{EHR}_{\mathbf{PARTIAL}}\)</span>. ويُحقّق النهج المقترح باستخدام <code>MedFuse</code> أفضل أداء على مجموعة الاختبار المُقترَنة عند استخدام صور CXR كوسيط مُساعِد في التدريب والاستدلال (0.770 AUROC و0.481 AUPRC لتصنيف الأنماط المرضيّة، و0.865 AUROC و0.594 AUPRC لتنبُّؤ الوفيّات). ونلحظ اتجاهات مُشابهة لكن أقلّ وضوحًا في مجموعة الاختبار الأكبر المُقترَنة جزئيًّا، ربما لأن 18.8% و26.2% فقط من العيّنات مُقترَنة في مجموعتَي اختبار التصنيف وتنبُّؤ الوفيّات على التوالي.</p>
            </section>
            <section id="performance-results-in-the-paired-setting" class="level2">
                <h2>نتائج الأداء في الإعداد المُقترَن</h2>
                <p>نظرًا لأنّ النماذج الأساسيّة صُمِّمت في الأصل للمدخلات المُقترَنة، قيّمنا جميع النماذج على مجموعة اختبار <span class="math inline">\((\mathbf{EHR+CXR})_{\mathbf{PAIRED}}\)</span> كما هو موضح في الجدول <a href="#tab:paired_res" data-reference-type="ref" data-reference="tab:paired_res">[tab:paired_res]</a>. أوّلًا، نلاحظ أنّ الدَّمج المُبكِّر والمُشترك يُنتجان أداءً مُتقاربًا في كلا المهمّتَين عند التدريب على <span class="math inline">\((\mathbf{EHR+CXR})_{\mathbf{PAIRED}}\)</span>، مع تفوّق طفيف للدَّمج المُبكِّر في AUROC. كما نلاحظ أنّ تدريب الدَّمج المُبكِّر باستخدام <span class="math inline">\((\mathbf{EHR+CXR})_{\mathbf{PARTIAL}}\)</span> يُفضي إلى انخفاض في AUROC وAUPRC في كلا المهمّتَين، بينما يتحسّن الدَّمج المُشترك فقط في التصنيف. ثانيًا، نلاحظ أنّ نهج Unified <span class="citation" data-cites="hayat2021dynamic"></span> يُحقّق أفضل أداء بين الخطوط الأساسيّة (0.765 AUROC و0.461 AUPRC للتصنيف، و0.835 AUROC و0.495 AUPRC لتنبُّؤ الوفيّات). ثالثًا، يُحقّق النهج المقترح <code>MedFuse</code> (OPTIMAL) أفضل أداء في كلا المهمّتَين (0.770 AUROC و0.481 AUPRC للتصنيف، و0.865 AUROC و0.594 AUPRC لتنبُّؤ الوفيّات). أجرينا كذلك دراسة حذف عشوائي للوسيط الشعاعي في مجموعة الاختبار المُقترَنة، والنتائج في الملحق <a href="#unimodalpercPAIRED" data-reference-type="ref" data-reference="unimodalpercPAIRED">7.4</a>. كما قارَنّا بين استبدال الوسيط المفقود بأصفار أو بمتّجه قابل للتعلُّم في الدَّمج المُبكِّر والمُشترك، والنتائج في الملحق <a href="#missingtoken" data-reference-type="ref" data-reference="missingtoken">7.5</a>، حيث كان الأداء مُتقاربًا.</p>
                <div class="table*">
                    <p><span id="tab:partialresults" label="tab:partialresults"></span></p>
                </div>
                <p><embed src="figures/bar_aurocs.pdf" /> <embed src="figures/bar_auprcs.pdf" /></p>
            </section>
            <section id="performance-results-in-the-partially-paired-setting" class="level2">
                <h2>نتائج الأداء في الإعداد المُقترَن جزئيًّا</h2>
                <p>في الجدول <a href="#tab:partialresults" data-reference-type="ref" data-reference="tab:partialresults">[tab:partialresults]</a>، نقيم النهج <code>MedFuse</code> إلى جانب الدَّمج المُبكِّر والمُشترك على مجموعة الاختبار المُقترَنة جزئيًّا. مقارنةً بالدَّمج المُبكِّر، يُحقّق النهج المقترح أداءً أفضل في تصنيف الأنماط المرضيّة (0.758 مقابل 0.748 AUROC و0.418 مقابل 0.394 AUPRC). وهو يُقدّم أداءً مُقاربًا في تنبُّؤ الوفيّات مع تفوّقٍ بسيط للدَّمج المُبكِّر في AUPRC. ويتفوّق نهجنا على الدَّمج المُشترك في تنبُّؤ الوفيّات (0.861 مقابل 0.841 AUROC و0.501 مقابل 0.482 AUPRC)، ويُقدّم أداءً مُقاربًا في التصنيف. إجمالًا، يُحقّق <code>MedFuse</code> (OPTIMAL) المُدرَّب مع عيّنات مُقترَنة و10% فقط من العيّنات أحاديّة الوسيط لتنبُّؤ الوفيّات و20% للتصنيف أفضل أداء (0.768 AUROC و0.429 AUPRC للتصنيف، و0.874 AUROC و0.567 AUPRC لتنبُّؤ الوفيّات). أجرينا كذلك دراسة حذف عشوائي لنسبة العيّنات أحاديّة الوسيط في الإعداد المُقترَن جزئيًّا، والنتائج في الملحق <a href="#unimodalpercPARTIAL" data-reference-type="ref" data-reference="unimodalpercPARTIAL">7.6</a>.</p>
                <p>وقارَنّا أيضًا أداء <code>MedFuse</code> مع تجميعة من نموذجين: (1) <code>MedFuse</code> للعيّنات المُقترَنة، و(2) LSTM أحاديّ الوسيط للعيّنات التي تفتقد CXR. جاءت النتائج مُتقاربة كما في الملحق <a href="#ensemble" data-reference-type="ref" data-reference="ensemble">7.7</a>، ما يُشير إلى أنّ تجميع نماذج قويّة قد يكون مُفضّلًا في بعض المهام كالتصنيف، لكنه يتطلّب تدريب نموذجَين.</p>
                <div class="table*">
                    <p><span id="tab:phenotype_wise" label="tab:phenotype_wise"></span></p>
                </div>
                <div class="table*">
                    <p><span id="tab:age_analysis" label="tab:age_analysis"></span></p>
                </div>
            </section>
            <section id="phenotype-wise-analysis" class="level2">
                <h2>تحليل بحسب الأنماط المرضيّة</h2>
                <p>يوضّح الشكل <a href="#fig:types_bar" data-reference-type="ref" data-reference="fig:types_bar">[fig:types_bar]</a> نتائج AUROC (يسار) وAUPRC (يمين) عبر فئات الأنماط المرضيّة: الحادّة، والمُختلطة، والمزمنة. أنواع العلامات وانتشارها مُوضّحة في الجدول <a href="#tab:phenotype_wise" data-reference-type="ref" data-reference="tab:phenotype_wise">[tab:phenotype_wise]</a>. نلاحظ أنّ نهجنا يُحسِّن الأداء على نحوٍ ملحوظ في الحالات المُختلطة والمزمنة، والتي يصعب عادةً التنبّؤ بها اعتمادًا على بيانات EHR فقط <span class="citation" data-cites="benchhmark"></span>. فمثلًا في الحالات المُختلطة يرتفع AUROC من 0.749 إلى 0.800 وAUPRC من 0.458 إلى 0.565. أمّا في الحالات المزمنة، فيرتفع AUROC من 0.717 إلى 0.745 وAUPRC من 0.487 إلى 0.512. وفي الحالات الحادّة، يكون التحسُّن أقلّ وضوحًا (AUROC من 0.761 إلى 0.772 وAUPRC من 0.432 إلى 0.433). وفي الجدول <a href="#tab:phenotype_wise" data-reference-type="ref" data-reference="tab:phenotype_wise">[tab:phenotype_wise]</a>، نُبلّغ عن الأداء عبر جميع العلامات الـ25 على مجموعة الاختبار المُقترَنة باستخدام البيانات الأحاديّة والمُتعدِّدة. نُلاحظ تحسُّنًا في أنماط مرتبطة بالصدر مثل الالتهاب الرئوي والتهاب غشاء الجنب، التي تُقيَّم سريريًّا غالبًا بالتصوير الشعاعي <span class="citation" data-cites="long2017emergency"></span>، ما يُبرز أهميّة استخدام صور الأشعّة السينيّة كمصدر إضافي مع بيانات EHR.</p>
            </section>
            <section id="in-hospital-mortality-age-wise-analysis" class="level2">
                <h2>تحليل تنبُّؤ الوفيّات داخل المستشفى بحسب الفئات العمريّة</h2>
                <p>قيّمنا أداء النهج عبر الفئات العمريّة المختلفة كما هو مُبيَّن في الجدول <a href="#tab:age_analysis" data-reference-type="ref" data-reference="tab:age_analysis">[tab:age_analysis]</a>، وقارَنّاه مع LSTM أحاديّ الوسيط. نلاحظ تحسُّنًا في AUROC وAUPRC للفئات 40–60 و60–80 وأكثر من 80 عامًا، بينما ينخفض AUROC للفئة 18–40 عامًا. يستلزم الأخير مزيدًا من الدراسة مع مجموعة بيانات أكبر، إذ تحتوي مجموعة الاختبار على 11 عيّنة إيجابيّة فقط لهذه الفئة. كما تتباين نسب التحسُّن؛ فمثلًا يرتفع AUPRC بنسبة 24% لفئة 40–60 عامًا، مقابل 1.3% لفئة 60–80 عامًا.</p>
            </section>
        </section>
        <section id="discussion" class="level1">
            <h1>المناقشة</h1>
            <p>قدّمنا في هذا البحث نهج دَمج مُتعدِّد الوسائط باسم <code>MedFuse</code> ونتائج معياريّة جديدة لدَمج البيانات الزمنيّة السريريّة وصور الأشعّة السينيّة للصدر المُقترَنة جزئيًّا. قيّمنا النهج في مهمّتَين معياريّتَين شائعتَين: تنبُّؤ الوفيّات داخل المستشفى وتصنيف الأنماط المرضيّة، باستخدام مجموعتَي البيانات العامّتَين MIMIC-IV وMIMIC-CXR.</p>
            <p>لدراستنا عدّة نقاط قوّة. أوّلًا، النهج المقترح بسيط وسهل التطبيق. أظهرت النتائج أنّه يتفوّق على LSTM الأحاديّ باستفادة من CXR كوسيط إضافي متى توافر، كما يتفوّق على عدّة خطوط أساس. ويُوفِّر تحليلُ الأنماط المرضيّة والفئات العمريّة رؤى حول مواضع التحسُّن. نستنتج أنّ الطريقة المقترحة مُفضّلة لأنها (1) تتعامل تلقائيًّا مع البيانات المفقودة (أي العيّنات المُقترَنة جزئيًّا)، و(2) تجمع بين البنية واستراتيجيّة التدريب بما يُحقّق مكاسب في الأداء. ولا يبدو أنّ حجم مجموعة التدريب المُقترَنة جزئيًّا مرتبط بتحسُّن الأداء، كما تُبيّنه نتائج التحقُّق في الملحق <a href="#unimodalpercentagetraining" data-reference-type="ref" data-reference="unimodalpercentagetraining">7.3</a>. إجمالًا، تُبرز النتائج إمكانات الدَّمج المُتعدِّد الوسائط في تحسين أداء النماذج السريريّة، كما يتّسق هذا التوجّه مع آليّة اتخاذ القرار الطبي التي تَستند إلى مصادر متعدِّدة للمعلومات.</p>
            <p>فضلًا عن ذلك، وبخلاف الأساليب التقليديّة التي تفترض مُدخلات مُقترَنة، فإنّ طريقتنا أكثر مرونة، إذ تُعالِج العيّنات التي تفتقد صور CXR. وهناك اهتمام متزايد بتعلُّم التفاعلات بين الوسائط أثناء التدريب وإعادة بناء الوسائط المفقودة <span class="citation" data-cites="ngiam2011multimodal 9534148 missing sylvain2021cmim missing"></span>. لكن بخلاف مجموعات البيانات الطبيعيّة، لا يُعدّ افتراض ترابُط عالٍ بين الوسائط أمرًا بديهيًّا في الرعاية الصحيّة، خاصةً عندما لا تشترك الوسائط في العلامات نفسها؛ وهو ما يستدعي بحثًا مُستقبليًّا. تنبع الصعوبة من طبيعة البيانات الطبيّة المتفرّقة وغير المُتزامنة؛ فمن العسير مثلًا استخدام تقرير خزعة جلديّة لإعادة بناء ميزات أمراض صدرية <span class="citation" data-cites="hayat2021dynamic"></span>. كما تفترض بعض الأعمال الحاليّة توافُر جميع الوسائط أثناء التدريب <span class="citation" data-cites="sylvain2021cmim"></span>.</p>
            <p>ميزة أخرى هي سهولة توسيع النهج إلى أكثر من وسيطَين دون تعديل دالّة الخسارة، بخلاف أعمالٍ سابقة تتعقّد مع ازدياد عدد الوسائط <span class="citation" data-cites="hayat2021dynamic"></span>؛ وإنْ كان ذلك يتطلّب تقييمًا لاحقًا. كما لا نفترض ترابُطًا مسبقًا بين الوسائط من حيث المعلومات أو العلامات.</p>
            <p>بالإضافة إلى ذلك، قدّمنا نتائج معياريّة جديدة لمهمّتَين شائعتَين غالبًا ما تُقيَّمان باستخدام بيانات EHR فقط <span class="citation" data-cites="benchhmark"></span>. وبإتاحة مجموعتَي MIMIC-IV وMIMIC-CXR <span class="citation" data-cites="mimic4 mimiccxrjpg"></span> وخطّ الأنابيب مفتوح المصدر، يمكن للباحثين تقديم نتائج جديدة ومقارنات مباشرة.</p>
            <section id="limitations." class="level4">
                <h4>القيود</h4>
                <p>للدراسة بعض القيود. أوّلًا، ركّزنا على دَمج بيانات EHR وصور الأشعّة الصدريّة من مصدرٍ واحد، وقيمنا العمل على مهمّتَين فقط بسبب محدوديّة الموارد. يتضمّن العمل الأصلي <span class="citation" data-cites="benchhmark"></span> مهمّتَين إضافيّتَين (تنبُّؤ فكّ التثبيت وتنبُّؤ مدة الإقامة)، ونخطّط لتقييم طريقتنا عليهما مستقبلًا. كما ينبغي دراسة مهمّة تنبُّؤ الوفيّات في سياق استبعاد صور الأشعّة المُلتقطة بعد أول 48 ساعة. ولم نجْرِ تجارب لِحالة غياب بيانات EHR مع توافُر CXR، وهو ما يستلزم تعريف مهامّ معياريّة جديدة حيث تكون CXR الوسيط الأساس. كذلك، يفتقر النموذج الحالي إلى التفسيرية إذ ركّزنا على الدَّمج فحسب. نخطّط لاحقًا لإدراج طبقات انتباه <span class="citation" data-cites="vaswani2017attention"></span> على مستوى المُدخلات لتقييم أهميّة الميزات داخل كلّ وسيط، وداخل وحدة الدَّمج لتقييم أهميّة كلّ وسيط. وقد يستفيد العمل من تحليلٍ على مستوى العيّنة، لكن ذلك يتطلّب خبرة سريريّة تربط بين تحليل الصور والبيانات الزمنيّة، وهو ما نفتقده حاليًّا. ولتحقيق الاستفادة الكاملة من التعلُّم المُتعدِّد الوسائط، نحن بحاجة إلى فهمٍ أعمق للأسس السريريّة للدَّمج. إجمالًا، تُبرز الدراسة أهميّة مواصلة استكشاف إمكانات التعلُّم المُتعدِّد الوسائط في الرعاية الصحيّة مع تزايد تنوّع وكميّة البيانات الطبيّة.</p>
            </section>
            <section id="acknowledgements." class="level4">
                <h4>الشكر والتقدير</h4>
                <p>تمّ دعم هذا العمل جزئيًّا من قبل مركز الذكاء الاصطناعي والروبوتات بجامعة نيويورك أبوظبي، المُموَّل من «تمكين» ضمن جائزة معهد أبحاث جامعة نيويورك أبوظبي CG010. كما نشكر فريق الحوسبة عالية الأداء (HPC) في جامعة نيويورك أبوظبي على دعمهم.</p>
            </section>
        </section>
        <section id="appendix-a" class="level1">
            <h1>الملحق</h1>
            <section id="image-aug" class="level2">
                <h2>تحسينات الصور</h2>
                <p>بالنسبة لصور CXR، طبّقنا سلسلة تحويلات أثناء التدريب المُسبق والتحسين في جميع التجارب. قمنا بتغيير حجم كلّ صورة إلى <span class="math inline">\(256 \times 256\)</span> بكسل، وتطبيق قلب أفقي عشوائي، وتحويلات عشوائيّة مثل التدوير والتحجيم والقصّ والترجمة. ثم أخذنا اقتصاصًا عشوائيًّا إلى <span class="math inline">\(224 \times 224\)</span> بكسل. أثناء التحقُّق والاختبار، قمنا بتغيير الحجم إلى <span class="math inline">\(256 \times 256\)</span> مع اقتصاص مركزي إلى <span class="math inline">\(224 \times 224\)</span> بكسل.</p>
            </section>
            <section id="hyperparameter" class="level2">
                <h2>نتائج البحث عن القِيَم الفائقة</h2>
                <p>نتائج ضبط القِيَم الفائقة مُوضّحة في الجدول <a href="#tab:learning_rates" data-reference-type="ref" data-reference="tab:learning_rates">[tab:learning_rates]</a>. نُلخِّص مُعدّلات التعلُّم التي حقّقت أفضل أداء لكلّ نموذج.</p>
                <p><span id="tab:learning_rates" label="tab:learning_rates"></span></p>
            </section>
            <section id="unimodalpercentagetraining" class="level2">
                <h2>نسبة العيّنات أحاديّة الوسيط ضمن مجموعة التدريب</h2>
                <p>أجرينا تجارب بتغيير نسبة العيّنات أحاديّة الوسيط أثناء التحسين. أفضل نتائج AUROC لكلا المهمّتَين على مجموعة التحقُّق مُبيَّنة في الشكل <a href="#fig:data_ratio" data-reference-type="ref" data-reference="fig:data_ratio">3</a>. بالنسبة لتنبُّؤ الوفيّات (بالأحمر)، تُحقّق نسبة صغيرة (10%) أفضل أداء. وبالنسبة للتصنيف (بالأزرق)، نُلاحظ اتجاهًا مُشابهًا مع أفضل AUROC عند 20%. نُثبّت النسبة المُثلى في جميع التجارب ما لم يُذكر خلاف ذلك. يُظهر ذلك أنّ مكاسب <code>MedFuse</code> تتحقّق حتى مع نسبة صغيرة من العيّنات أحاديّة الوسيط.</p>
                <figure>
                    <embed src="figures/aurocs.pdf" id="fig:data_ratio" />
                    <figcaption aria-hidden="true"><strong>الأداء على مجموعة التحقُّق عند تغيير نسبة العيّنات الأحاديّة.</strong> يوضّح الرسم منحنى AUROC لنِسَب مختلفة من العيّنات أحاديّة الوسيط ضمن التدريب.</figcaption>
                </figure>
            </section>
            <section id="unimodalpercPAIRED" class="level2">
                <h2>نسبة العيّنات أحاديّة الوسيط ضمن مجموعة الاختبار المُقترَن</h2>
                <p>أجرينا دراسة حذف عشوائي للوسيط الشعاعي في مجموعة الاختبار المُقترَنة. النتائج في الشكل <a href="#fig:data_ratio_paired" data-reference-type="ref" data-reference="fig:data_ratio_paired">4</a>. مع ازدياد نسبة الحذف، ينخفض AUROC في كلا المهمّتَين.</p>
                <figure>
                    <embed src="figures/aurocs_paired_ratio.pdf" id="fig:data_ratio_paired" />
                    <figcaption aria-hidden="true"><strong>الأداء على مجموعة الاختبار عند حذف وسيط CXR عشوائيًّا.</strong> منحنيات AUROC لنِسَب حذف مختلفة من CXR في مجموعة الاختبار المُقترَنة.</figcaption>
                </figure>
            </section>
            <section id="missingtoken" class="level2">
                <h2>التعامُل مع الوسيط المفقود في الدَّمج المُبكِّر والمُشترك</h2>
                <p>أجرينا مقارنة أوليّة بين استخدام متّجه قابل للتعلُّم مقابل تعويض الأصفار للوسيط المفقود. النتائج في الجدول <a href="#tab:missing-modality" data-reference-type="ref" data-reference="tab:missing-modality">[tab:missing-modality]</a>، وكانت مُتقاربة دون فروق جوهريّة.</p>
                <div class="table*">
                    <p><span id="tab:missing-modality" label="tab:missing-modality"></span></p>
                </div>
            </section>
            <section id="unimodalpercPARTIAL" class="level2">
                <h2>نسبة العيّنات أحاديّة الوسيط ضمن مجموعة الاختبار المُقترَن جزئيًّا</h2>
                <p>أجرينا دراسة حذف عشوائي لنسبة العيّنات أحاديّة الوسيط في مجموعة الاختبار المُقترَنة جزئيًّا. النتائج في الشكل <a href="#fig:data_ratio_pairtial_testset" data-reference-type="ref" data-reference="fig:data_ratio_pairtial_testset">5</a>. عند 0%، يُعادِل ذلك مجموعة اختبار مُقترَنة بالكامل. نلاحظ زيادة في AUROC في مهمّة تنبُّؤ الوفيّات مع ازدياد النسبة، بينما يبقى AUROC أكثر استقرارًا في التصنيف. كما ينخفض عرض فترات الثقة مع ازدياد النسبة في كلا المهمّتَين.</p>
                <figure>
                    <embed src="figures/aurocs_nonpaired_ratio.pdf" id="fig:data_ratio_pairtial_testset" />
                    <figcaption aria-hidden="true"><strong>الأداء على مجموعة الاختبار عند تغيير نسبة العيّنات الأحاديّة.</strong> منحنيات AUROC لمجموعة الاختبار الجزئيّة لنِسَب مختلفة من العيّنات أحاديّة الوسيط.</figcaption>
                </figure>
            </section>
            <section id="ensemble" class="level2">
                <h2>تجميع النماذج الأحاديّة والمُتعدِّدة الوسائط</h2>
                <p>قارنّا أداء <code>MedFuse</code> مع تجميعة من نموذجين: نموذج EHR فقط (LSTM) للعيّنات غير المرتبطة بصورة CXR، ونموذج مُقترَن (MedFuse) للعيّنات المُقترَنة. النتائج في الجدول <a href="#tab:medfuse_unimodal" data-reference-type="ref" data-reference="tab:medfuse_unimodal">[tab:medfuse_unimodal]</a>. يتفوّق التجميع قليلًا في التصنيف فقط، ما يوحي بأن تجميع نماذج قويّة قد يُناسب بعض المهام، لكنه يتطلّب تدريب نموذجين.</p>
                <div class="table*">
                    <p><span id="tab:medfuse_unimodal" label="tab:medfuse_unimodal"></span></p>
                </div>
            </section>
        </section>
        <section class="footnotes footnotes-end-of-document" role="doc-endnotes">
            <hr />
            <ol>
                <li id="fn1" role="doc-endnote"><p>يعمل حاليًّا في G42 للرعاية الصحيّة. <a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
                <li id="fn2" role="doc-endnote"><p>مراكز الرعاية الطبيّة والخدمات الطبيّة، <a href="https://www.cms.gov/Medicare/Coding/ICD10/2018-ICD-10-CM-and-GEMs" class="uri">https://www.cms.gov/Medicare/Coding/ICD10/2018-ICD-10-CM-and-GEMs</a> <a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
                <li id="fn3" role="doc-endnote"><p>https://github.com/haamoon/mmtm <a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
                <li id="fn4" role="doc-endnote"><p>https://github.com/ai-med/DAFT/ <a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
            </ol>
        </section>
    </div>
    <hr style="margin: 40px 0;">
    <div class="text-muted text-center">
        <small>
            تمّ تحويل هذا الإصدار من LaTeX إلى HTML تلقائيًّا.<br>
            تمّ عرض المعادلات الرياضيّة باستخدام MathJax.
        </small>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>