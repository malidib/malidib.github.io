<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Feilong Tang">
  <meta name="author" content="Zhongxing Xu">
  <meta name="author" content="Zhaojun Qu">
  <meta name="author" content="Wei Feng">
  <meta name="author" content="Xingjian Jiang">
  <meta name="author" content="Zongyuan Ge">
  <title>إِسْتراتِيجِيَّة التَعَلُّم المُدْرِك للنَمُوذَج الأَوَّلِيّ في سِياق التَجْزِئَة الدَلالِيَّة ضَعِيفَة الإشراف</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>body { direction: rtl; font-size: 22px; }</style>
</head>
<body>
<header>
<h1 class="title">إِسْتراتِيجِيَّة التَعَلُّم المُدْرِك للنَمُوذَج الأَوَّلِيّ في سِياق التَجْزِئَة الدَلالِيَّة ضَعِيفَة الإشراف</h1>
<p class="author"><span class="nodecor">Feilong Tang</span></p>
<p class="author"><span class="nodecor">Zhongxing Xu</span></p>
<p class="author"><span class="nodecor">Zhaojun Qu</span></p>
<p class="author"><span class="nodecor">Wei Feng</span></p>
<p class="author"><span class="nodecor">Xingjian Jiang</span></p>
<p class="author"><span class="nodecor">Zongyuan Ge</span></p>
</header>
<h1 id="ملخص">مُلَخَّص</h1>
<p>تسعى الطُرُق الحَديثة للتَجْزِئَة الدَلالِيَّة ضَعِيفَة الإشراف (<span class="nodecor">WSSS</span>) إلى دَمْج المَعْرِفَة السياقية لتحسين اكتمال خَرائِط تَنْشِيط الفِئَة (<span class="nodecor">CAM</span>). في هذا العمل، نُؤكِّد أن التَحَيُّز المَعْرِفي بين الحالات والسياقات يؤثر على قُدْرة النَمُوذَج الأَوَّلِيّ على فَهْم دلالات الحالة بشكل كافٍ. مستوحى من نَظَرِيَّة تَعَلُّم النماذج الأَوَّلِيَّة، نقترح استخدام الوعي بالنَمُوذَج الأَوَّلِيّ لالتقاط سمات الخصائص المتنوعة والدقيقة للحالات. تَفْتَرِض الفَرْضِيَّة أن النماذج الأَوَّلِيَّة السياقية قد تُفعِّل بشكل خاطئ فئات الأشياء المتشابهة والمتكررة المشتركة بسبب هذا التحيز المعرفي. لذلك، نقترح تعزيز قدرة تمثيل النَمُوذَج الأَوَّلِيّ من خلال تخفيف التحيز لالتقاط التغطية المكانية بشكل أفضل في مناطق الأشياء الدلالية. لتحقيق هذا الهدف، نقدم إِسْتراتِيجِيَّة التَعَلُّم المُدْرِك للنَمُوذَج الأَوَّلِيّ السياقي (<span class="nodecor">CPAL</span>)، التي تستفيد من السياق الدلالي لإثراء فهم الحالة. جوهر هذه الطريقة هو التقاط التباينات داخل الفئة في ميزات الأشياء بدقة من خلال النماذج الأَوَّلِيَّة المُدْرِكة للسياق، مما يُسهِّل التكيف مع السمات الدلالية لمختلف الحالات. نقوم بتصميم محاذاة توزيع الميزات لتحسين الوعي بالنَمُوذَج الأَوَّلِيّ، عبر محاذاة توزيعات ميزات الحالة مع الميزات الكثيفة. بالإضافة إلى ذلك، يتم اقتراح إطار تدريب موحد لدمج الإشراف التصنيفي الموجه بالتسميات والإشراف الذاتي الموجه بالنماذج الأَوَّلِيَّة. تُظهر النتائج التجريبية على <span class="nodecor">PASCAL VOC 2012</span> و<span class="nodecor">MS COCO 2014</span> أن <span class="nodecor">CPAL</span> يُحسِّن بشكل كبير الطُرُق المتاحة ويحقق أداءً رائداً. المشروع متاح في <a href="https://github.com/Barrett-python/CPAL">https://github.com/Barrett-python/CPAL.</a></p>
<h1 id="sec:intro">مُقَدِّمَة</h1>
<p>تُعْتَبَر التَجْزِئَة الدَلالِيَّة مهمة أساسية في مجال الرؤية الحاسوبية. أصبحت التَجْزِئَة الدَلالِيَّة ضَعِيفَة الإشراف (WSSS) نهجاً شائعاً في المجتمع، حيث تتعلم من تسميات ضعيفة مثل تسميات على مستوى الصورة (<span class="nodecor">kolesnikov2016seed, lee2021anti</span>)، الخربشات (<span class="nodecor">lin2016scribblesup,vernaza2017learning</span>)، أو مربعات الحدود (<span class="nodecor">dai2015boxsup,lee2021bbam,song2019box</span>)، بدلاً من التعليقات التوضيحية على مستوى البكسل. تُستخدم معظم نُهج WSSS خرائط تنشيط الفئة (CAM) (<span class="nodecor">zhou2016learning</span>) لتوفير إشارات تحديد المواقع للأهداف، وبالتالي ربط المفاهيم البصرية بمناطق البكسل.</p>
<p>المفتاح في WSSS هو توليد CAM بتغطية أفضل على الكائن الكامل. تهدف الدراسات الحديثة (<span class="nodecor">chang2020weakly,sun2020mining,zhang2020inter,wang2023hunting</span>) بشكل أساسي إلى تحسين دقة تجزئة النموذج واستقراره من خلال دمج المعرفة السياقية. مستوحاة من تقدم تعلم التمثيل (<span class="nodecor">fan2020learning,wu2021embedded</span>)، قدمت بعض الدراسات (<span class="nodecor">li2021group,su2021context,zhang2020causal,zhang2022multi</span>) المعرفة السياقية والمعرفة التمثيلية لنمذجة السياق على نطاق عالمي لتحليل السمات الدلالية للمثيلات بدقة أكبر. لكنها تتجاهل تحدي التباين الكبير داخل الفئة، أي أن المناطق التي تنتمي إلى نفس الفئة قد تظهر مظهراً مختلفاً جداً حتى في نفس الصورة. يجعل التحيز بين المعرفة السياقية (الميزات العالمية داخل الفئة) والمعرفة المحددة للمثيل (الميزات الفريدة) نقل التسميات صعباً من مستوى الصورة إلى مستوى البكسل. في هذا العمل، نؤكد أن تخفيف التحيز المعرفي بين المثيلات والسياقات يمكن أن يلتقط مناطق أكثر دقة واكتمالاً. علاوة على ذلك، ندمج إشارات إشرافية إضافية لتسريع تخفيف التحيزات المعرفية.</p>
<p>تمثيل النموذج الأولي للفئة، من خلال تقليل التحيز، أظهر إمكاناته في كشف أنماط الميزات في خوارزميات التعلم القليل الأمثلة مثل BDCSPN (<span class="nodecor">liu2020prototype</span>). تنص نظرية تعلم النموذج الأولي (<span class="nodecor">zhou2022rethinking,wang2019panet</span>) على أن النماذج الأولية يمكن أن تمثل الميزات المحلية، الميزات العالمية، أو السمات المحددة للكائن. استناداً إلى التباين داخل الفئة في ميزات الكائن، يمكن للنموذج الأولي للمثيل (<span class="nodecor">chen2022self</span>) أن يميز بشكل ديناميكي الميزات التمييزية للصورة المحددة. علاوة على ذلك، فإن النماذج الأولية التي تدمج المعرفة السياقية (<span class="nodecor">zhou2022regional</span>) لديها القدرة على التقاط أنماط دلالية فئوية أكثر تحديداً ودقة. تمكنت من التقاط منطقة الكائن بشكل أكثر اكتمالاً مقارنة بنموذج أولي لمثيل واحد.</p>
<p>في هذا العمل، نقترح استراتيجية تعلم تُسمى التعلم المُدرك للنموذج الأولي السياقي (CPAL) لاستخراج سمات الميزات الفعالة من هيكل العنقود السياقي. على وجه التحديد، نستكشف مثيلات أخرى ذات صلة بالصورة المحددة لبناء نماذج أولية سياقية كجيران مرشحين. ثم يتم إجراء البحث عن السمات داخل الفئة في مجموعة الجيران المرشحين، مع تحديد موقع النموذج الأولي للمثيل الحالي كمرساة. في الوقت نفسه، نصمم درجة إيجابية زوجية تدل على الارتباط بين السمات، بهدف تحديد النماذج الأولية السياقية (أي الجيران الناعمين) المرتبطة ارتباطاً عالياً بالسمات الحالية. بعد تطبيق درجة الإيجابية المعنية، تم تعديل مساهمات هذه النماذج الأولية في المثيل المرساة بشكل ديناميكي، وبالتالي تخفيف التحيزات المرتبطة بالتنوع داخل الفئة وسمات المثيل.</p>
<p>جوهر طريقتنا هو الوعي بالنموذج الأولي. نقيس بلطف المسافة بين النموذج الأولي للمثيل والنموذج الأولي السياقي لإدراك سمات المثيل. لتقدير قوي، يتم اقتراح بنوك الدعم الفئوية للتغلب على القيود على الدُفعات الصغيرة، بحيث يمكن ملاحظة تنوع الميزات داخل الفئة بطريقة من الميزة إلى البنك حيث يمكن تقريب توزيع الفئة عالمياً. ومع ذلك، بسبب الكمية المحدودة من ميزات المثيل، هناك تحيز نسبي لتوزيع الميزات السياقية، مما يؤثر على الوعي الدقيق بالمثيل. لذلك، نقترح محاذاة توزيع الميزات من خلال إدخال مصطلح تحويل <span class="math inline">\(\delta\)</span> إلى ميزات المثيل النادرة، دافعاً إياها نحو توزيع الميزات الكثيفة لبنك الدعم الفئوي.</p>
<p>في مجموعات بيانات PASCAL VOC 2012 (<span class="nodecor">everingham2010pascal</span>) وMS COCO 2014 (<span class="nodecor">lin2014microsoft</span>)، نقيم طريقتنا في إعدادات WSSS المختلفة، حيث حقق نهجنا أداءً رائداً. تتلخص المساهمات على النحو التالي:</p>
<ul>
<li><p>نقترح استراتيجية تعلم مُدركة للنموذج الأولي السياقي (CPAL) التي تولد خرائط تحديد مواقع أكثر دقة واكتمالاً من خلال تخفيف التحيز المعرفي بين المثيلات والسياقات.</p></li>
<li><p>نقترح وحدة محاذاة الميزات مجتمعة مع بنوك الدعم الديناميكية لإدراك سمات الكائنات بدقة.</p></li>
<li><p>نقترح إطار تعلم موحد يتكون من التعلم الذاتي الإشرافي والتعلم المُدرك للنموذج الأولي السياقي، حيث يكمل كل منهما الآخر. تظهر التجارب أن طريقتنا تحقق تحسيناً كبيراً وتحقق أداءً رائداً.</p></li>
</ul>
<h1 id="sec:Related_Work">الأعمال ذات الصلة</h1>
<p><strong>التَجْزِئَة الدَلالِيَّة ضَعِيفَة الإشراف</strong> باستخدام تسميات على مستوى الصورة تُولِّد عادةً خرائط الفعالية الفئوية كبذرة لتوليد تسميات زائفة على مستوى البكسل. العيب النمطي لخرائط الفعالية الفئوية هو نقصها وعدم دقتها في الفعالية. لمعالجة هذا العيب، اقترحت الأعمال الحديثة مخططات تدريب متنوعة، مثل المحو العدائي (<span class="nodecor">kweon2021unlocking,yoon2022adversarial,sun2021ecs,kweon2023weakly</span>)، ونمو المنطقة (<span class="nodecor">huang2018weakly,wei2018revisiting</span>)، واستكشاف قيود الحدود (<span class="nodecor">rong2023boundary,chen2020weakly,lee2021railroad</span>). يركز نموذج التعلم والاستدلال للصورة الفردية (<span class="nodecor">araslanov2020single,lee2021railroad</span>) على فهم أعمق للميزات داخل صورة فردية لتوليد خرائط الفعالية الفئوية الأكثر اكتمالاً. يقوم الاستخراج الذاتي للنماذج الأولية (<span class="nodecor">chen2022self</span>) بتخصيص النماذج الأولية لميزات متعددة الأحجام لتوسيع خرائط تحديد مواقع الأجسام الخشنة للحصول على مدى كامل لمناطق الأجسام.</p>
<p>بينما اعتبرت الجهود السابقة كل صورة على حدة، تركز الأعمال الحديثة على الحصول على سياق دلالي غني بين الصور المختلفة في المجموعة البيانية. تتناول الأعمال الحديثة (<span class="nodecor">sun2020mining,fan2020cian</span>) التنقيب الدلالي بين الصور من خلال التركيز على التقاط العلاقات الزوجية بين الصور. وتقوم (<span class="nodecor">li2021group,zhang2022multi,du2022weakly</span>) بأداء التنقيب الدلالي عالي الترتيب للعلاقات الأكثر تعقيداً داخل مجموعة من الصور. في الوقت نفسه، من أجل تعزيز علاقة التمثيل للفضاء المميز (استكشاف أنماط الأجسام على مجموعة البيانات بأكملها)، يقدم التحليل الإقليمي للفئات (<span class="nodecor">zhou2022regional</span>) بنك ذاكرة لتخزين ميزات الفئات عالية الجودة وأداء نمذجة السياق. يقترح التوافق العميق للنماذج الأولية للفئات (<span class="nodecor">jin2023deep</span>) محاذاة تمثيل الميزات للحالات المزدوجة تحت وجهات نظر مختلفة، وتم أيضاً تقديم هذه المحاذاة في توزيع البيانات تحت سياقات مختلفة (<span class="nodecor">zhao2023dual</span>). على عكس الأعمال السابقة حول تطبيق المعرفة السياقية، يمكن لطريقتنا أن تدرك بشكل تكيفي السمات الدلالية والتباينات داخل الفئة، مما يؤدي إلى مناطق فعالية أكثر اكتمالاً لخرائط الفعالية الفئوية.<br />
<br />
<strong>التَعَلُّم المبني على النماذج الأولية</strong> تم دراسته جيداً في التعلم بعدد قليل من الأمثلة (<span class="nodecor">snell2017prototypical,snell2017prototypical</span>)، والتعلم بدون أمثلة (<span class="nodecor">he2019dynamic</span>) والتعلم غير الموجه (<span class="nodecor">xu2020attribute</span>). من الجدير بالذكر أن العديد من نماذج التجزئة يمكن اعتبارها شبكات تعلم مبنية على النماذج الأولية (<span class="nodecor">wang2019panet, liu2020part, xu2022semi, zhou2022rethinking, ge2023soft</span>)، مما يكشف عن إمكانية التطبيق في تجزئة الصور. اقترح (<span class="nodecor">du2022weakly</span>) طريقة تعلم مترية مبنية على النماذج الأولية تفرض تناسق الميزات على مستوى المقابلات وتنظيم داخلي وبين-داخلي. يستخدم التعلم القائم على النماذج الأولية للكاميرا (<span class="nodecor">chen2023extracting</span>) لاستخراج ميزات غنية للأجسام أيضاً. في عملنا، نتعلم سمات الميزات الفعالة ضمن هيكل التجميع للسياق لنمذجة ميزات الأجسام المتنوعة على مستوى دقيق.</p>
<h1 id="sec:Method">المنهجية</h1>
<p>يقوم نظام التصنيف ضعيف الإشراف للتعلم الشبه الإشرافي (WSSS) أولاً بتدريب شبكة التصنيف لتحديد منطقة الكائن المقابلة لكل فئة، ثم يتم تنقيحها لتوليد تسميات زائفة كمشرفين على شبكة التجزئة الدلالية. يُبنى الإطار على أساس شبكة التصنيف، ويتكون من إشارتين إشرافيتين: خسارة التصنيف والخسارة الذاتية الإشرافية. يشجع نهجنا على الاتساق بين الخريطة النشطة للفئة (CAM) المتوقعة من خلال التعلم الواعي للنموذج والمصنف، مما يحفز النموذج بشكل ضمني على تعلم ميزات أكثر تميزاً. نحن نمثل النموذج الأولي للحالة كمرساة ونستخرج نماذج أولية للسياق من بنك الدعم كمجموعة مرشحة للجيران، والتي يتم وصفها في القسم [3.2]. جوهر طريقتنا هو الوعي بالنموذج الأولي لالتقاط التباينات داخل الفئة، ويتم قياس إيجابية كل جارٍ مرشح على الحالة الحالية بشكل ناعم، وتصفيتها وضبط مساهماتهم بشكل انتقائي. في الوقت نفسه، توجه محاذاة توزيع الميزات ميزات الحالة الحالية نحو مركز العنقود للميزات الكثيفة في البنك.</p>
<h2 id="3.1">نموذج التحسين الذاتي الموجه</h2>
<p><strong>تحسين الشبكة.</strong> يُبنى إطار عملنا على شبكة تصنيف، مستخدمين هذه الشبكة <span class="math inline">\(\theta\)</span> لاستخراج إشراف فعال من تسميات الصور، ملتقطين مناطق الكائنات لكل فئة (<span class="math inline">\(i.e.,\)</span> خرائط التنشيط الفئوي). نقترح تعلم النموذج الأولي الواعي بالسياق لتوليد خريطة التنشيط الفئوي الواعية بالنموذج الأولي (PACAM) بشكل أكمل، موفرة إشارات إشرافية إضافية لخريطة التنشيط الفئوي الأولية وتشكيل نموذج ذاتي التوجيه. العنصر الأساسي لهذا النموذج هو تنظيم الاتساق، مقللاً بشكل ضمني المسافة المميزة بين البكسلات التمييزية والمفقودة، مشجعاً النموذج على تعلم ميزات أكثر اتساقاً وتميزاً. هذا التعديل البسيط يؤدي إلى تحسينات ملحوظة. دالة خسارة موحدة لتحسين النموذج: <span class="math display">\[\label{coefficients}
\mathcal{L}=\lambda_{BCE}\mathcal{L}^{{BCE}}+\lambda_{Self}\mathcal{L}^{ {Self}}\]</span> حيث <span class="math inline">\(\lambda_{BCE}\)</span> و<span class="math inline">\(\lambda_{Self}\)</span> هما معاملان، <span class="math inline">\(\mathcal{L}^{{BCE}}\)</span> هي خسارة التصنيف، و<span class="math inline">\(\mathcal{L}^{ {Self}}\)</span> هي الخسارة الذاتية التوجيه. الخسائر موصوفة بالتفصيل في الأقسام التالية.<br />
<br />
<strong>خسارة التصنيف وخرائط التنشيط الفئوي.</strong> كل صورة تدريب <span class="math inline">\(I \in \mathbb{R}^{w \times h \times 3}\)</span> في مجموعة البيانات <span class="math inline">\(\mathcal{I}\)</span> مرتبطة فقط بمتجه تسمية على مستوى الصورة <span class="math inline">\(\boldsymbol{y}=\{y_n\}^N_{n=1} \in \{0,1\}^N\)</span> لـ<span class="math inline">\(N\)</span> فئات محددة مسبقاً. يقترح CAM لتحديد مواقع الكائنات الأمامية من خلال تدريب شبكة تصنيف. يأخذ CAM صورة مصغرة <span class="math inline">\(I\)</span> كمدخل لاستخراج خرائط الميزات <span class="math inline">\(f\in \mathbb{R}^{W \times H \times D}\)</span>، ب<span class="math inline">\(D\)</span> قنوات وحجم مكاني <span class="math inline">\(H \times W\)</span>. لربط الفجوة بين مهمة التصنيف ومهمة التجزئة، يتم استخدام وزن المصنف <span class="math inline">\(\mathbf{w}_n\)</span> وطبقة التجميع المتوسط العالمي (GAP) لإنتاج تنبؤ اللوجيت <span class="math inline">\(\hat{y}_i \in \mathbb{R}^N\)</span>. أثناء التدريب، يستخدم خسارة التقاطع الثنائي كما يلي: <span class="math display">\[\mathcal{L}^{BCE}=\frac{1}{N} \sum_{i=1}^N y_i \log \sigma\left(\hat{y}_i\right)+\left(1-y_i\right) \log \left(1-\sigma\left(\hat{y}_i\right)\right),\]</span> حيث <span class="math inline">\(\sigma(\cdot)\)</span> هي دالة السيجمويد. للحصول على معلومات تقريبية عن الموقع للخلفية والأمام. يمكن تمثيل خريطة التنشيط الفئوي <span class="math inline">\({M}_{\boldsymbol{f}}=\left\{{M}_n\right\}_{n=1}^N\)</span> على <span class="math inline">\(N\)</span> فئات أمامية كما يلي: <span class="math display">\[{M}_{n}=\frac{\operatorname{ReLU}\left(\boldsymbol{\mathbf{w}_n^{\top} f}\right)}{\max \left(\operatorname{ReLU}\left(\boldsymbol{\mathbf{w}_n^{\top} f}\right)\right)}, \quad \forall n \in N.\]</span> مع الأخذ في الاعتبار أهمية الخلفية في مهمة التجزئة، نتبع (<span class="nodecor">wang2020self</span>) لتقدير خريطة التنشيط الخلفية <span class="math inline">\({M}_{b}=1-\max_{1 \leq n \leq N} M_n\)</span> استناداً إلى <span class="math inline">\(M_f\)</span>. نجمع خريطة التنشيط الخلفية المعالجة مع خريطة التنشيط الأمامية ككل، <em>i.e.</em> <span class="math inline">\({M} = M_f \cup M_b\)</span>، لمساعدة النموذج على فهم المعرفة الخلفية.</p>
<h2 id="3.2">نمذجة النموذج الأولي</h2>
<p><strong>نمذجة النموذج الأولي للحالة كمرساة.</strong> لكل صورة <span class="math inline">\(I\)</span>، يتم تعيين خرائط الميزات إلى فضاء الإسقاط <span class="math inline">\(z=v(f)\)</span> بواسطة رأس الإسقاط <span class="math inline">\(v\)</span> لنمذجة النموذج الأولي للحالة. يمثل كل نموذج أولي للحالة الدلالات الإقليمية للفئات الملحوظة في <span class="math inline">\(I\)</span> استناداً إلى <span class="math inline">\(M\)</span>. على وجه التحديد، بالنسبة للفئة <span class="math inline">\(n\)</span>-th التي تظهر في <span class="math inline">\(I\)</span> (<span class="math inline">\(i.e.,\)</span> <span class="math inline">\(y_c=1\)</span>)، يتم تلخيص ميزاتها المعروضة إلى متجه <span class="math inline">\(\mathcal{P}^{I}_n \in \mathbb{R}^D\)</span> بواسطة التجميع المتوسط المقنع (MAP) (<span class="nodecor">siam2019amp</span>): <span class="math display">\[\mathcal{P}^{I}_n=\frac{\sum_{x=1, y=1}^{W, H} \textbf{P}_n(x,y) * z(x,y)}{\sum_{x=1, y=1}^{W, H} \textbf{P}(x,y)}, 
\label{tau}\]</span> حيث <span class="math inline">\(\textbf{P}_n= \mathbbm{1}\left({M}_n&gt;\tau\right) \in \{0,1\}^{W \times H}\)</span> هو قناع ثنائي، يؤكد فقط على البكسلات المنشطة بقوة للفئة <span class="math inline">\(n\)</span> في خريطة التنشيط. <span class="math inline">\(\mathbbm{1}(\cdot)\)</span> هي دالة مؤشر، والعتبة <span class="math inline">\(\tau\)</span> هي معلمة فائقة وتدل على عتبة درجة الثقة. هنا، <span class="math inline">\(\mathcal{P}^{I}_n\)</span> مضغوط وخفيف، مما يسمح بالاستكشاف القابل للتطبيق لعلاقاته مع العديد من العينات الأخرى وتموضعه كمرساة.<br />
<br />
<strong>نمذجة النماذج الأولية السياقية كجيران مرشحين.</strong> نفترض أن الميزات الفئوية داخل الصور أو الدُفعات توفر فقط نظرة محدودة للفئة. لذلك، نستخدم بنك الدعم كمجموعة مرشحة <span class="math inline">\(\mathcal{C}\)</span>، حيث كل عنصر هو النموذج الأولي السياقي لفئات مختلفة. عند استخدام دفعات العينات لتدريب الشبكة، نخزن نماذجها الأولية <span class="math inline">\(\mathcal{P}^{I}_n\)</span> في <span class="math inline">\(\mathcal{C}\)</span> ونستخدم استراتيجية الأول داخل أول خارج لتحديث مجموعة المرشحين. تحافظ هذه المجموعة على طول نسبي كبير لكل فئة نموذج أولي لتوفير نماذج أولية سياقية محتملة بما فيه الكفاية. استناداً إلى هذه المجموعة، يتم تطبيق تجميع <span class="math inline">\(\mathrm{k}\)</span>-means عبر الإنترنت لتنقيح كل فئة إلى مجموعات نموذج أولي مجمعة <span class="math inline">\(\mathcal{G}=\left\{G_i\right\}_{i=1}^{N_p}\)</span> لكشف الصفات العميقة لكل فئة. نقوم بعمليات التوسيط على كل مجموعة نموذج أولي مجمعة من <span class="math inline">\(\mathcal{G}\)</span> لتوليد <span class="math inline">\(N_p\)</span> جيران مرشحين <span class="math inline">\(\mathbf{p}_i\)</span> على النحو التالي: <span class="math display">\[\mathbf{p}_i=\frac{1}{\left|G_i\right|} \sum_{\mathbf{r}_j \in G_i} \mathbf{r}_j,\]</span> حيث <span class="math inline">\(\mathbf{r}_j\)</span> يشير إلى النموذج الأولي <span class="math inline">\(j\)</span>-th الذي ينتمي إلى مجموعة العنقود <span class="math inline">\(i\)</span>-th <span class="math inline">\(G_i\)</span>. <span class="math inline">\(\mathbf{p}_i\)</span> يمثل النموذج الأولي السياقي <span class="math inline">\(i\)</span>-th لمجموعة الجيران المرشحين <span class="math inline">\(\mathcal{P}_n^c=\left\{\mathbf{p}_i\right\}_{i=1}^{N_p}\)</span>.</p>
<h2 id="3.3">التعلم المُدرك لنموذج السياق</h2>
<p>مع نماذج الربط الأساسية ومجموعة الجيران المرشحين من القسم [3.2]، تستشعر مجموعة الجيران المرشحين أو تدعم ميزة الربط. يمكن للتعلم المُدرك لنموذج السياق قياس وضبط مدى هذا الدعم.<br />
<br />
<strong>تحديد الجار الإيجابي الناعم.</strong> اختيار النموذج أمر حاسم في نهجنا المقترح حيث يحدد بشكل كبير جودة الإشراف. يمكن لنماذج الحالات تمثيل الصفات الفئوية للصورة الحالية بشكل خاص، بينما تظهر نماذج السياق أنماطاً فئوية أكثر شمولاً وتنوعاً. تُستخدم استراتيجيتنا درجات الإيجابية <span class="math inline">\(w_i\)</span> لقياس صلة الجيران المرشحين في الفئة بصفات الحالة الحالية. نقترح اختيار أفضل <span class="math inline">\(K\)</span> جيران معدلّين بدرجات الإيجابية، الموجودين بالقرب من الربط. يمكن صياغة الجار الإيجابي الناعم كما يلي: <span class="math display">\[\tilde{\mathcal{P}}_n^{\text {c}}=\left\{w_i \mathbf{p}_{\mathbf{i}}: i \in \underset{i \in N_p}{ \arg \max }\left(d\left(w_i \mathbf{p}_{\mathbf{i}}, \mathcal{P}_n^I\right), \text { top } =K\right)\right\}
\label{value_K}\]</span> حيث <span class="math inline">\(d()\)</span> تدل على التشابه الجيبي التمامي كمقياس محسوب، و<span class="math inline">\(\tilde{\mathcal{P}}^{c}_n\)</span> يمثل أفضل <span class="math inline">\(K\)</span> نماذج مُدركة للسياق مصممة للحالة الحالية. <strong>توقعات الإيجابية.</strong> لقد صممنا درجات إيجابية زوجية لقياس (بشكل غير ثنائي) الصلة بين نموذج الحالة والجيران المرشحين في نفس الفئة. بالنسبة لزوج النموذج (<span class="math inline">\(\mathbf{p}_i\)</span> , <span class="math inline">\(\mathcal{P}^I_{n}\)</span>)، يمكن حساب درجة الإيجابية <span class="math inline">\(w_{i}\)</span> كما يلي: <span class="math display">\[w_i=\frac{1}{\gamma_i} \texttt{softmax}\left[l_1\left(\mathbf {\mathcal{P}}^{I}_n\right) \times l_2\left(\mathbf {p}_i\right)^{\top}\right], \quad {\mathbf{p}}_{i} \in {\mathcal{P}}^{c}_n, 
\label{eq7}\]</span> حيث <span class="math inline">\(l_1(\cdot)\)</span> و<span class="math inline">\(l_2(\cdot)\)</span> هما طبقات تحويل الميزات بدون معاملات. <span class="math inline">\(\gamma_i\)</span> هو عامل تحجيم لضبط درجة الإيجابية <span class="math inline">\(w_i\)</span>. تم استكشاف هياكل مختلفة للدرجة <span class="math inline">\(w_{i}\)</span> في القسم [Ablation].<br />
<br />
<strong>الادعاء 1.</strong> <em>نفترض أننا ندرب نموذج <span class="math inline">\(\theta\)</span> باستخدام طريقة التحسين المقترحة، <span class="math inline">\(\mathcal{P}_n^I\)</span> و<span class="math inline">\(\tilde{\mathcal{P}}_n^c\)</span> هما نموذج الحالة الحالي للفئة n-th ونماذج السياق على التوالي. يمكن التعبير عن القيمة المثلى لمقياس التشابه <span class="math inline">\(s_i^*\)</span> كـ <span class="math inline">\(\frac{w_{i}}{\sum_{k=1}^{K} w_{k}}\)</span>، حيث <span class="math inline">\(w_{i}\)</span> هي درجة الإيجابية المقابلة لزوج النموذج (<span class="math inline">\(\mathcal{P}_n^I, \quad {\mathbf{p}}_{i} \in {\tilde{\mathcal{P}}}_n^{c}\)</span>) في المعادلة [eq7].</em><br />
<br />
يمكن العثور على البرهان في الملحق A. يشير الادعاء 1 إلى أننا نحسن النموذج لتعظيم التشابه بين نموذج السياق والحالة الحالية من نفس الفئة بنسبة مباشرة إلى درجة الإيجابية المقابلة. نحن ننقل المعرفة بفعالية من الفرع الذاتي الإشراف إلى النموذج، بالإضافة إلى أداء النموذج وقدرات التعميم.<br />
<br />
<strong>محاذاة توزيع الميزات.</strong> تشكل الميزات المتفرقة (<span class="nodecor">hoefler2021sparsity</span>) وتنوع الفئة الداخلي تحديات لتمثيل الميزات المحددة للفئة بدقة، مما يعيق التمييز بين الفئات. وبالتالي، نفترض تحيزاً بين الميزات الفردية وميزات الفئة الداخلية. لمعالجة ذلك، نوجه الميزات لمحاذاة ميزاتها المحددة للفئة المجمعة بكثافة لتعزيز كثافة الميزة الداخلية للفئة. بالنظر إلى أن تطبيع الدُفعات الصغيرة (<span class="nodecor">ioffe2015batch</span>) أو تطبيع الحالة (<span class="nodecor">ulyanov2016instance</span>) يتبع اتجاه التعلم بالدُفعات، يتم محاذاة ميزات الدُفعات الصغيرة من خلال إدخال مصطلحات الانتقال <span class="math inline">\(\delta_n\)</span> لدفعها نحو مراكز العناقيد. يتم استنتاج ذلك كما يلي.</p>
<p>نحدد مقياس التقييم للتشابه الجيبي التمامي الأمثل (OCSEM) لتقييم التشابه الجيبي التمامي بين العينة الحالية والعينات الأخرى، بهدف تعزيز دقة النموذج من خلال تعظيم هذا المقياس. يعرف الهدف الأمثل كما يلي: <span class="math display">\[\begin{split}
\text{OCSEM} = \frac{1}{{N_p}{Q_n}} \sum^{{N_p}}_{i=1} \sum^{{Q_n}}_{q=1} &amp; \cos({\mathbf {p}}_{i},\mathcal P^I_{n,q}) &gt; \\ &amp;  \max_{h \neq i}\{\cos({\mathbf {p}}_{h},\mathcal P^I_{n,q})\}, 
\end{split}\]</span> حيث <span class="math inline">\({\mathbf {p}}_{i}\)</span> هو نموذج السياق في مجموعة الجيران المرشحين <span class="math inline">\(\mathcal{P}_n^c=\left\{\mathbf{p}_i\right\}_{i=1}^{N_p}\)</span> للفئة n-th، و<span class="math inline">\(\mathcal P^I_{n,q}\)</span> هو نموذج الحالة المقابل في المجموعة <span class="math inline">\(\mathcal{P}_n^b=\left\{\mathcal P^I_{n,q}\right\}_{q=1}^{Q_n}\)</span> في الدُفعة الصغيرة. <span class="math inline">\(Q_n\)</span> يدل على عدد النماذج للفئة n-th في الدُفعة الصغيرة. نفترض أن التحيز يمكن تقليله بإضافة مصطلح الانتقال <span class="math inline">\(\delta_n\)</span> إلى ميزة الحالة. يجب أن يتبع المصطلح <span class="math inline">\(\delta_n\)</span> الهدف: <span class="math display">\[\underset{\delta_n}{\arg \max } \frac{1}{{N_p}{Q_n}} \sum_{i=1}^{N_p} \sum_{q=1}^{Q_n} \cos \left({\mathbf {p}}_{i}, \mathcal P^I_{n,q}+\delta_n\right).
\label{9}\]</span> نفترض أن كل ميزات النموذج <span class="math inline">\(\mathcal P^I_{n,q}\)</span> يمكن تمثيلها كـ <span class="math inline">\({\mathbf {p}}_{i} + \epsilon_{i,q}\)</span>. يمكن صياغة المعادلة [9] بشكل أكثر تفصيلاً كما يلي: <span class="math display">\[\underset{\delta_n}{\arg \max } \frac{1}{{N_p}{Q_n}} \sum_{i=1}^{N_p} \sum_{q=1}^{Q_n} \cos \left({\mathbf {p}}_{i}, {\mathbf {p}}_{i}+\delta_n+\epsilon_{i, q}\right).\]</span> لتعظيم التشابه الجيبي التمامي، يجب تقليل الهدف التالي: <span class="math display">\[\min \frac{1}{{N_p}{Q_n}} \sum^{{N_p}}_{i=1} \sum^{{Q_n}}_{q=1} (\epsilon_{i,q}+\delta_n).\]</span> يتم حساب المصطلح <span class="math inline">\(\delta_n\)</span> على النحو التالي: <span class="math display">\[\delta_n=-\mathbb{E}\left[\epsilon_{i,q}\right]=\frac{1}{{N_p}{Q_n}} \sum_{i=1}^{N_p} \sum_{q=1}^{Q_n} \left({\mathbf {p}}_{i}-\mathcal{P}_{n, q}^I\right).
\label{shift}\]</span></p>
<h2 id="الوعي-بالنموذج-الأولى-لخرائط-الفعالية-الفئوية-والخسارة-الذاتية-التوجيهية">الوعي بالنموذج الأولي لخرائط الفعالية الفئوية والخسارة الذاتية التوجيهية</h2>
<p><strong>الوعي بالنموذج الأولي لخرائط الفعالية الفئوية.</strong> مع وضوح معنى النماذج الأولية، يمكن فهم إجراء التنبؤ بخرائط الفعالية الفئوية بشكل حدسي كاسترجاع النماذج الأولية الأكثر تشابهاً. لكل نموذج أولي <span class="math inline">\(\tilde{\mathcal{P}}^{c}_n\)</span> في المعادلة [value_K]، نحسب تشابه الجيب التمامي بين الميزات في كل موضع والنموذج الأولي للفئة المقابلة. ثم يتم تجميع خرائط التشابه كما يلي: <span class="math display">\[{\tilde{M}}_n(j) = \ ReLU \left(\frac{1}{K} 
\sum_{{\mathcal{\mathbf p}}_i \in {\tilde{\mathcal{P}}}^{c}_n}
\frac{{{f}}{(j)} \cdot {\mathcal{\mathbf p}}_i}{\left\|{{f}}(j)\right\| \cdot\left\|{\mathcal{\mathbf p}}_i\right\|}\right),\]</span> حيث يشير <span class="math inline">\(\|\cdot\|\)</span> إلى معيار L2 للمتجه. <span class="math inline">\(\tilde{M}_n(j)\)</span> يمثل خريطة الفعالية الفئوية المدركة للنموذج الأولي للفئة <span class="math inline">\(n\)</span>-th في البكسل <span class="math inline">\(j\)</span>.</p>
<p><strong>الخسارة الذاتية التوجيهية.</strong> للاستفادة أكثر من المعرفة السياقية، نقدم نموذجاً للتعلم الذاتي التوجيهي الذي يشجع على الاتساق بين النواتج من التنبؤات المدركة للنموذج الأولي ومصنف موجه. هذا يعزز من قدرة النموذج على التعرف على الميزات التمييزية أكثر ويدمج المعرفة المدركة للنموذج الأولي في تمثيل الميزة، مما يعزز التحسين التعاوني خلال دورات التدريب. تعريف التنظيم الاتساقي بتطبيع L1 لخرائط الفعالية: <span class="math display">\[\mathcal{L}^{self}=\frac{1}{N+1}\|{M}- {\tilde{M}}\|_1,
\label{self}\]</span> حيث <span class="math inline">\(M\)</span> و<span class="math inline">\(\tilde{M}\)</span> تمثلان خريطة الفعالية الأصلية وخريطة الفعالية المدركة للنموذج الأولي، على التوالي.</p>
<h1 id="sec:Experiments">التجارب</h1>
<h2 id="مجموعات-البيانات-وتفاصيل-التنفيذ">مجموعات البيانات وتفاصيل التنفيذ</h2>
<p><strong>مجموعة البيانات ومقياس التقييم.</strong> تُجرى التجارب على معيارين: PASCAL VOC 2012 (<span class="nodecor">everingham2010pascal</span>) بـ<span class="nodecor">21</span> فئة وMS COCO 2014 (<span class="nodecor">lin2014microsoft</span>) بـ<span class="nodecor">81</span> فئة. بالنسبة لـ PASCAL VOC 2012، وفقاً لـ(<span class="nodecor">wang2020self, lee2021anti, chen2022self, li2022expansion</span>)، نستخدم SBD المعزز (<span class="nodecor">hariharan2011semantic</span>) بـ<span class="nodecor">10,582</span> صورة موسومة. نقيم CPAL من حيث i) جودة توليد تسميات التجزئة الزائفة على VOC 2012 <code>train</code>، وii) التجزئة الدلالية على VOC 2012 <code>val/test</code> وCOCO 2014 <code>val</code>. يُستخدم متوسط التقاطع على الاتحاد (mIoU) (<span class="nodecor">long2015fully</span>) كمقياس في كلتا الحالتين. تُحصل النتائج على VOC 2012 <code>test</code> من خادم التقييم الرسمي.</p>
<p><strong>تفاصيل التنفيذ.</strong> في تجاربنا، يتم اعتماد ResNet50 (<span class="nodecor">he2016deep</span>) المدرب مسبقاً على ImageNet (<span class="nodecor">deng2009imagenet</span>) كالعَمُود الفقري بخطوة إخراج <span class="nodecor">16</span>، حيث يحل مصنف محل الطبقة المتصلة بالكامل بقنوات إخراج <span class="nodecor">20</span>. استراتيجية التعزيز هي نفسها كما في (<span class="nodecor">chen2022self, ahn2019weakly, chen2023extracting</span>)، بما في ذلك القلب العشوائي، التحجيم، والقطع. يتم تدريب النموذج بحجم دفعة <span class="nodecor">16</span> على <span class="nodecor">8</span> وحدات معالجة رسومات Nvidia 4090. يتم اعتماد محسن SGD لتدريب نموذجنا لمدة <span class="nodecor">5</span> حقبات، بزخم <span class="nodecor">0.9</span> وتحلل وزن <span class="nodecor">1e-4</span>. تحدد معدلات التعلم للعمود الفقري والطبقات المضافة حديثاً على <span class="nodecor">0.1</span> و<span class="nodecor">1</span> على التوالي. نستخدم جدول تحلل التعلم البولي بقوة <span class="nodecor">0.9</span> لمعدل التعلم.</p>
<p>تحدد معاملات الخسارة <span class="math inline">\(\lambda_{BCE}\)</span> و<span class="math inline">\(\lambda_{Self}\)</span> كـ<span class="nodecor">1</span> في المعادلة [coefficients]. بالنسبة لـ VOC 2012، يحدد العتبة <span class="math inline">\(\tau\)</span> في المعادلة [tau] على <span class="nodecor">0.1</span>. حجم البنك الداعم لكل فئة لتخزين التضمينات الإقليمية، مع تحديد الحجم على <span class="nodecor">1000</span> لتجنب استهلاك الدعم الكبير. يتم إجراء تجميع النماذج الأولية <span class="math inline">\(k\)</span>-means في القسم [3.2] مرة واحدة فقط في بداية كل حقبة، ويحدد عدد النماذج الأولية لكل فئة <span class="math inline">\(N_p\)</span> على <span class="nodecor">50</span>، ويحدد عدد الجيران المرشحين الأعلى <span class="math inline">\(K\)</span> على <span class="nodecor">20</span> في المعادلة [value_K]. بالنسبة لشبكة التجزئة، أجرينا تجارب مع DeepLab-v2 (<span class="nodecor">chen2017deeplab</span>) مع العمود الفقري ResNet101 وResNet38. <em>المزيد من التفاصيل (بما في ذلك COCO) موجودة في الملحق.</em></p>
<h2 id="Ablation">دراسة الاستئصال</h2>
<p>لدراسة مساهمات كل مكون من مكونات طريقتنا، أجرينا دراسات استئصال على مجموعة بيانات VOC 2012. جميع التجارب استخدمت Resnet-50 كعمود فقري. <strong>فعالية كل مكون.</strong> في الجدول [abl]، نجري دراسات استئصال لإظهار فعالية نهجنا. نستخدم نموذجاً تم تدريبه فقط بإشراف التصنيف (التجربة الأولى) كخط أساس. ثم يتم تقديم استراتيجية تعلم النموذج الأولي للسياق بسيطة في التجربة الثانية والتي تحقق مكاسب محدودة في mIoU على مجموعة <code>train</code>. تظهر التجربة الثالثة أن تقديم تعلم النموذج الأولي للسياق المُدرك (مجموعة المرشحين الأعلى-<span class="math inline">\(K\)</span> وتنبؤ الإيجابية) لتوليد PACAM يعزز الأداء بشكل كبير بنسبة +3.3%. في التجربة الرابعة، عند تقديم وحدة محاذاة الميزات، يزداد الأداء بمقدار +2.3%. في التجربة الخامسة، يتحسن الأداء بمقدار +5.7% عند تقديمه للتدريب الذاتي كإشراف تكميلي، مما يدل على أهميته في إطار عملنا. خسارة الاتساق تجبر النموذج على التركيز على التفاصيل الدقيقة للدلالات، مما يعزز إدراكه للبنية الجوهرية والميزات الدلالية.<br />
<strong>فعالية الجيران المرشحين والإيجابية.</strong> نحلل أهمية الجيران المرشحين والإيجابية، كما هو موضح في الجدول [neighbor]. إزالة الإيجابية واستخدام جميع الجيران للتنبؤ، تقل دقة Miou في CAM من 62.5% إلى 60.3%. يشير ذلك إلى أن الإيجابية ليست مجرد زخرفة بسيطة بل توفر آلية فعالة للنموذج. تمكن النموذج من التركيز بشكل تكيفي وانتقائي على الجيران الذين يساهمون بشكل كبير في المهمة أثناء عملية التعلم مع تجاهل الجيران غير المعلوماتيين للتنبؤات. في الكتلة الثالثة من الجدول [neighbor]، نجري أيضاً تجارب لتحليل تأثير عدد الجيران. من ناحية، يعزز وجود عدد كافٍ من الجيران تنوع الميزات. من ناحية أخرى، قد يؤدي تضمين النماذج الأولية ذات الارتباط الضعيف إلى إدخال الكثير من الضوضاء أثناء عملية التدريب ويقلل من قدرة النموذج على إدراك الميزات التمييزية. القياس الناعم المقترح يقدم إيجابية زوجية لضبط مساهمة النماذج الأولية المختلفة في العينة المرجعية في المعادلة [coefficients]. نطبق مقاييس تشابه مختلفة لحساب درجة الإيجابية. كما هو موضح في الجدول [function]، تم استكشاف أربع خيارات: المسافة المانهاتن (<span class="math inline">\(L_1\)</span>)، المسافة الإقليدية (<span class="math inline">\(L_2\)</span>)، التشابه الجيبي التمامي، والمنتج النقطي. يظهر المنتج النقطي أداءً متفوقاً بشكل كبير مقارنة بالاستراتيجيات الأخرى ويستخدم كطريقتنا لقياس الإيجابية. <strong>فعالية محاذاة الميزات.</strong> في الجدول [abl]، نقدم نتائج تحسين الأداء التي تم تحقيقها من خلال تقليل التحيز في التوزيع. بالإضافة إلى ذلك، أجرينا مقارنة بصرية باستخدام t-SNE (<span class="nodecor">van2008visualizing</span>) في الشكل [tsnet]. تشير النتائج إلى أنه بعد محاذاة توزيعات الميزات، يمكن للنموذج توليد مجموعات أكثر تماسكاً مع قابلية فصل أعلى بين المجموعات. تعديل المتغير الديناميكي للإزاحة يساعد في تخفيف الاختلافات بين ميزات الحالات من نفس الفئة، مما يجعل الحالات التي تنتمي إلى نفس الفئة أكثر تشابهاً. هذا بدوره، يسهل على النموذج التمييز بين الحالات من فئات مختلفة بدقة أكبر.<br />
<strong>تحليل العوامل الفائقة.</strong> نجري تحليلاً لحساسية العوامل الفائقة، بتغيير قيم مثل (أ) عتبة <span class="math inline">\(\tau\)</span> لتوليد قناع البذور 0-1. يشير الشكل [hyperparameter] (أ) إلى أن القيمة المثلى لـ<span class="math inline">\(\tau\)</span> هي <span class="nodecor">0.1</span>. بالإضافة إلى ذلك، نفحص (ب) طول مجموعة الدعم، حيث وجدنا أن مجموعة أكبر تعزز أداء النموذج. الشكل [hyperparameter] (ب) يوضح ذلك.</p>
<h1 id="تحليل-نوعي">تحليل نوعي</h1>
<p>نقوم بتصور مناطق الاستجابة ونتائج التنبؤ للوعي بالنماذج الأولية في الشكل [fig31] (أ). يوضح ذلك بوضوح أن النماذج الأولية مرتبطة بسمات معينة للحالات. على سبيل المثال، بالنظر إلى الصور (<em>مثلاً،</em> <code>horse</code> و<code>cat</code>)، يتوافق كل نموذج أولي مع أجزاء مختلفة من الحالة، مما يتيح نمذجة أفضل للتباينات داخل الفئة في الأجسام الدلالية. في الشكل [fig31] (ب)، نقوم بتصور دراسات استئصال على مكونات مختلفة من طريقتنا. عند إزالة الوعي بالنموذج الأولي (الإيجابية والجيران الأعلى-<span class="math inline">\(K\)</span>)، ينشط النموذج مناطق بشكل خاطئ تتشارك بقوة (<em>مثلاً،</em> <code>train</code> و<code>railroad</code>) أو تظهر مظاهر متشابهة (<em>مثلاً،</em> <code>cat</code> و<code>dog</code>)، مما يدل على نقص في التعلم الدقيق والقدرات التمييزية للميزات المحددة للحالة. بدون خسارة الإشراف الذاتي <span class="math inline">\(\mathcal{L}^{Self}\)</span>، يظهر CAM تنشيطاً ناقصاً، مما يشير إلى عدم كفاية تعلم ميزات الفئة. تشير هذه النتائج إلى أن طريقتنا، مع إدخال هذه المكونات، يمكن أن تدرك وتميز بدقة أكبر سمات الفئات المختلفة.</p>
<table>
<caption>مقارنات بين طريقتنا وطرق WSSS الأخرى. نقوم بتقييم mIoU (%) على مجموعة <code>train</code> من PASCAL VOC 2012 على المستويات: CAM، مع CRF، والقناع الزائف.</caption>
<thead>
<tr class="header">
<th style="text-align: left;">الطريقة</th>
<th style="text-align: center;">البذرة</th>
<th style="text-align: center;">مع CRF</th>
<th style="text-align: center;">القناع</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">SEAM (<span class="nodecor">wang2020self</span>)</td>
<td style="text-align: center;">55.4</td>
<td style="text-align: center;">56.8</td>
<td style="text-align: center;">63.6</td>
</tr>
<tr class="even">
<td style="text-align: left;">AdvCAM (<span class="nodecor">lee2021anti</span>)</td>
<td style="text-align: center;">55.6</td>
<td style="text-align: center;">62.1</td>
<td style="text-align: center;">68.0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">CLIMS (<span class="nodecor">xie2022clims</span>)</td>
<td style="text-align: center;">56.6</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">70.5</td>
</tr>
<tr class="even">
<td style="text-align: left;">SIPE (<span class="nodecor">chen2022self</span>)</td>
<td style="text-align: center;">58.6</td>
<td style="text-align: center;">64.7</td>
<td style="text-align: center;">68.0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">ESOL (<span class="nodecor">li2022expansion</span>)</td>
<td style="text-align: center;">53.6</td>
<td style="text-align: center;">61.4</td>
<td style="text-align: center;">68.7</td>
</tr>
<tr class="even">
<td style="text-align: left;">AEFT (<span class="nodecor">yoon2022adversarial</span>)</td>
<td style="text-align: center;">56.0</td>
<td style="text-align: center;">63.5</td>
<td style="text-align: center;">71.0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">PPC (<span class="nodecor">du2022weakly</span>)</td>
<td style="text-align: center;">61.5</td>
<td style="text-align: center;">64.0</td>
<td style="text-align: center;">64.0</td>
</tr>
<tr class="even">
<td style="text-align: left;">ReCAM (<span class="nodecor">chen2022class</span>)</td>
<td style="text-align: center;">54.8</td>
<td style="text-align: center;">60.4</td>
<td style="text-align: center;">69.7</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Mat-Label (<span class="nodecor">wang2023treating</span>)</td>
<td style="text-align: center;">62.3</td>
<td style="text-align: center;">65.8</td>
<td style="text-align: center;">72.9</td>
</tr>
<tr class="even">
<td style="text-align: left;">FPR (<span class="nodecor">chen2023fpr</span>)</td>
<td style="text-align: center;">63.8</td>
<td style="text-align: center;">66.4</td>
<td style="text-align: center;">68.5</td>
</tr>
<tr class="odd">
<td style="text-align: left;">LPCAM (<span class="nodecor">chen2023extracting</span>)</td>
<td style="text-align: center;">62.1</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">72.2</td>
</tr>
<tr class="even">
<td style="text-align: left;">ACR (<span class="nodecor">kweon2023weakly</span>)</td>
<td style="text-align: center;">60.3</td>
<td style="text-align: center;">65.9</td>
<td style="text-align: center;">72.3</td>
</tr>
<tr class="odd">
<td style="text-align: left;">SFC (<span class="nodecor">zhao2024sfc</span>)</td>
<td style="text-align: center;">64.7</td>
<td style="text-align: center;">69.4</td>
<td style="text-align: center;">73.7</td>
</tr>
<tr class="even">
<td style="text-align: left;">IRN (<span class="nodecor">ahn2019weakly</span>)</td>
<td style="text-align: center;"><span>48.8</span></td>
<td style="text-align: center;">53.7</td>
<td style="text-align: center;"><span>66.5</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: center;"><strong>62.5</strong></td>
<td style="text-align: center;"><strong>66.2</strong></td>
<td style="text-align: center;"><strong>72.7</strong></td>
</tr>
<tr class="even">
<td style="text-align: left;">AMN (<span class="nodecor">lee2022threshold</span>)</td>
<td style="text-align: center;">62.1</td>
<td style="text-align: center;">66.1</td>
<td style="text-align: center;">72.2</td>
</tr>
<tr class="odd">
<td style="text-align: left;">+CPAL (لنا)</td>
<td style="text-align: center;"><strong>65.7</strong></td>
<td style="text-align: center;"><strong>68.2</strong></td>
<td style="text-align: center;"><strong>74.1</strong></td>
</tr>
<tr class="even">
<td style="text-align: left;">MCTformer (<span class="nodecor">xu2022multi</span>)</td>
<td style="text-align: center;">61.7</td>
<td style="text-align: center;">64.5</td>
<td style="text-align: center;">69.1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">+CPAL (لنا)</td>
<td style="text-align: center;"><strong>66.8</strong></td>
<td style="text-align: center;"><strong>69.3</strong></td>
<td style="text-align: center;"><strong>74.7</strong></td>
</tr>
<tr class="even">
<td style="text-align: left;">CLIP-ES (<span class="nodecor">lin2023clip</span>)</td>
<td style="text-align: center;">70.8</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">75.0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">+CPAL (لنا)</td>
<td style="text-align: center;"><strong>71.9</strong></td>
<td style="text-align: center;">-</td>
<td style="text-align: center;"><strong>75.8</strong></td>
</tr>
</tbody>
</table>
<p>[labelVOC]</p>
<h2 id="مقارنات-مع-الطرق-الحديثة">مقارنات مع الطرق الحديثة</h2>
<p><strong>تحسين خرائط التحديد:</strong> بما أن الطريقة المقترحة CPAL لا تعدل هندسة شبكة CAM، فهي تدمج فرع CPAL كإشراف في طرق متعددة. الجدول [labelVOC] يعرض نتائج تطبيق CPAL على طرق معروفة مثل (<span class="nodecor">ahn2019weakly</span>)، (<span class="nodecor">lee2022threshold</span>)، (<span class="nodecor">xu2022multi</span>)، و(<span class="nodecor">lin2023clip</span>) ويظهر تحسينات في خرائط التحديد على VOC <span class="nodecor">2012</span>. على سبيل المثال، دمج CPAL في (<span class="nodecor">lee2022threshold</span>) يحسن الأداء بنسبة <span class="nodecor">3.6%</span> في البذور و<span class="nodecor">2.1%</span> في الأقنعة الزائفة. عند دمج CPAL في نموذج (<span class="nodecor">lin2023clip</span>)، هناك زيادة بنسبة <span class="nodecor">1.1%</span> في البذور.</p>
<p><strong>تحسين نتائج التجزئة:</strong> الجدول [miou_results] يظهر أداء نموذج التجزئة الدلالية المدرب بالتسميات الزائفة التي تم إنشاؤها بواسطة طريقتنا. التسميات الزائفة تُستخدم لتدريب نموذج التجزئة DeepLabV2. المقارنات مع الأعمال ذات الصلة. يحقق تركيبنا (<span class="nodecor">lee2022threshold</span>)+CPAL نتائج رائدة على VOC (mIoU بنسبة <span class="nodecor">72.5%</span> على مجموعة التحقق و<span class="nodecor">72.9%</span> على مجموعة الاختبار). على مجموعة البيانات MS COCO الأكثر تحدياً، يتفوق تركيبنا (<span class="nodecor">xu2022multi</span>)+CPAL (مع ResNet-38 كعمود فقري) على النتيجة الرائدة (<span class="nodecor">lee2022threshold</span>) وجميع الأعمال ذات الصلة المبنية على ResNet-38. بالنسبة لـ(<span class="nodecor">lin2023clip</span>)، يحسن CPAL الأداء (<span class="nodecor">+1.4%</span> mIoU على COCO val). هذه النتائج المتفوقة على كلتا المجموعتين تؤكد فعالية CPAL لدينا، والتي تلتقط بدقة الميزات الدلالية وهياكل الأجسام.</p>
<h1 id="الخلاصة">الخلاصة</h1>
<p>في هذا العمل، نقترح استراتيجية تعلم جديدة تعتمد على النماذج الأولية الواعية بالسياق (CPAL) لطرق WSSS، والتي تهدف إلى التخفيف من التحيز المعرفي بين الحالات والسياقات. تقوم هذه الطريقة بتعديل خصائص الميزات الفعالة في مجموعات السياق وتختار وتعدل النماذج الأولية للسياق بشكل تكيفي لتعزيز قدرات التمثيل. جوهر طريقتنا هو الوعي بالنموذج الأولي، والذي يتحقق من خلال النماذج الأولية الواعية بالسياق لالتقاط التباين داخل الفئة ومحاذاة توزيع الميزات بدقة. تظهر التجارب الموسعة تحت إعدادات مختلفة أن الطريقة المقترحة تتفوق على الطرق الحديثة الأخرى، وتكشف الدراسات التجريبية عن فعالية CPAL لدينا.</p>
</body>
</html>
