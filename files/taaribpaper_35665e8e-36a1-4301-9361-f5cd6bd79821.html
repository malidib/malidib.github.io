<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Pranav Kulkarni Adway Kanhere Dharmam Savani Andrew Chan Devina Chatterjee Paul H. Yi Vishwa S. Parekh مَرْكَزِ University of Maryland Medical Intelligent Imaging (UM2ii) كُلِّيَّةِ الطِبِّ بِجامِعَةِ ماريلاند، بالتيمور، MD 21201 {pkulkarni,akanhere,dsavani,andrew.chan,devinachatterjee,pyi,vparekh}@som.umaryland.edu">
  <title>في أي وقت، في أي مكان، لأي شخص: دراسة جدوى نموذج Segment Anything لجمع تعليقات الصور الطبية بالتعهيد الجماعي</title>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap');
    body {
      direction: rtl;
      font-family: 'Cairo', 'Segoe UI', Tahoma, Geneva, Verdana, Arial, sans-serif;
      font-size: 22px;
      background: #f8f9fa;
      color: #222;
      margin: 0;
      padding: 0;
      line-height: 1.7;
    }
    header {
      background: linear-gradient(90deg, #3a8dde 0%, #6dd5ed 100%);
      color: #fff;
      padding: 40px 10% 30px 10%;
      text-align: center;
      border-bottom-left-radius: 40px;
      border-bottom-right-radius: 40px;
      box-shadow: 0 4px 16px rgba(58,141,222,0.08);
    }
    h1.title {
      font-size: 2.3em;
      font-weight: 700;
      margin-bottom: 0.5em;
      letter-spacing: 0.02em;
      line-height: 1.3;
    }
    .author {
      font-size: 1.1em;
      margin-top: 1.5em;
      color: #e3f2fd;
      line-height: 1.6;
    }
    .author span {
      margin-left: 0.5em;
      margin-right: 0.5em;
      display: inline-block;
    }
    main {
      max-width: 900px;
      margin: 40px auto 40px auto;
      background: #fff;
      border-radius: 24px;
      box-shadow: 0 2px 16px rgba(58,141,222,0.07);
      padding: 48px 36px 36px 36px;
    }
    h1, h2, h3, h4 {
      color: #3a8dde;
      font-weight: 700;
      margin-top: 2.2em;
      margin-bottom: 0.7em;
      line-height: 1.3;
    }
    h1 {
      font-size: 2em;
      border-bottom: 2px solid #e3f2fd;
      padding-bottom: 0.2em;
    }
    h2 {
      font-size: 1.5em;
      border-bottom: 1px solid #e3f2fd;
      padding-bottom: 0.15em;
    }
    p {
      margin-bottom: 1.2em;
      text-align: justify;
    }
    a {
      color: #1976d2;
      text-decoration: underline;
      transition: color 0.2s;
    }
    a:hover {
      color: #0d47a1;
    }
    code, .math.inline {
      background: #f1f8e9;
      color: #2e7d32;
      padding: 0.15em 0.4em;
      border-radius: 6px;
      font-size: 0.95em;
      font-family: 'Cairo', 'Consolas', 'monospace';
      direction: ltr;
      unicode-bidi: embed;
    }
    .nodecor {
      text-decoration: none !important;
      color: inherit !important;
      font-weight: 600;
    }
    ul, ol {
      margin: 1.2em 2em 1.2em 0;
      padding-right: 1.5em;
    }
    @media (max-width: 700px) {
      header, main {
        padding: 18px 6vw 18px 6vw;
      }
      main {
        padding: 24px 8px 24px 8px;
      }
      h1.title {
        font-size: 1.3em;
      }
    }
  </style>
</head>
<body>
<header>
  <h1 class="title">في أي وقت، في أي مكان، لأي شخص: دراسة جدوى نموذج <span class="nodecor">Segment Anything</span> لجمع تعليقات الصور الطبية بالتعهيد الجماعي</h1>
  <p class="author">
    <span class="nodecor">Pranav Kulkarni</span>
    <span class="nodecor">Adway Kanhere</span>
    <span class="nodecor">Dharmam Savani</span>
    <span class="nodecor">Andrew Chan</span><br />
    <span class="nodecor">Devina Chatterjee</span>
    <span class="nodecor">Paul H. Yi</span>
    <span class="nodecor">Vishwa S. Parekh</span><br />
    مركز <span class="nodecor">التصوير الطبي الذكي بجامعة ميريلاند (UM2ii)</span><br />
    كلية الطب بجامعة ميريلاند، بالتيمور، <span class="nodecor">MD 21201</span><br />
    <span>{pkulkarni,akanhere,dsavani,andrew.chan,devinachatterjee,pyi,vparekh}@som.umaryland.edu</span>
  </p>
</header>
<main>
  <h1 id="ملخص">ملخص</h1>
  <p>جمع التعليقات لتجزئة الصور الطبية مهمة تستغرق وقتًا طويلًا وتتطلب خبرة متخصصة، ما يؤدي إلى اعتماد نماذج تعلم عميق تقليدية ضيقة التركيز وذات قيمة ترجميّة سريرية محدودة. مؤخرًا، أحدثت النماذج الأساسية الكبيرة مثل نموذج <span class="nodecor">Segment Anything Model (SAM)</span> نقلة في التجزئة الدلالية بقدرات تعميم استثنائية من دون ضبط دقيق عبر مجالات مختلفة، بما في ذلك التصوير الطبي، مما يبسّط عملية التعليق على الصور. ومع ذلك، لم يُقيَّم <span class="nodecor">SAM</span> بعد في سياق التعهيد الجماعي لتوليد التعليقات اللازمة لتدريب نماذج التعلم العميق ثلاثية الأبعاد للتجزئة. في هذا العمل، نستكشف إمكانات <span class="nodecor">SAM</span> لجمع تعليقات "متفرقة" من غير الخبراء لإنتاج أقنعة تجزئة "كثيفة" تُستخدم في تدريب نماذج <span class="nodecor">3D nnU-Net</span>، وهو إطار حديث للتجزئة بالتعلم العميق. تُظهر نتائجنا أن التعليقات المُولدة بواسطة <span class="nodecor">SAM</span> تحقق متوسطات عالية على مقياس <span class="nodecor">Dice</span> مقارنة بالتعليقات الأصلية، لكن نماذج <span class="nodecor">nnU-Net</span> المُدرَّبة على تعليقات <span class="nodecor">SAM</span> تؤدي أداءً أدنى بشكل ملحوظ مقارنة بنماذج <span class="nodecor">nnU-Net</span> المُدرَّبة على التعليقات الأصلية (<span class="nodecor"><span class="math inline">\(p<0.001\)</span></span> في جميع المقارنات).</p>
  <h1 id="المقدمة">المقدمة</h1>
  <p>تُعد تجزئة الصور الطبية من أهم المهام في دعم اتخاذ القرارات السريرية المعتمدة على الحاسوب، إذ تشكّل الأساس لعدد كبير من التطبيقات بدءًا من التشخيص مرورًا بالتخطيط العلاجي وصولًا إلى تقييم الاستجابة للعلاج. ومع ذلك، يتطلب تطوير نماذج تجزئة الصور الطبية خبراء متمرّسين (مثل أخصائيي الأشعة) لتوفير تعليقات يدوية على العديد من البنى التشريحية والآفات ضمن مجموعات تدريبية قد تضم مئات المرضى، ما يجعل العملية مُرهِقة ومكلفة زمنيًا (<span class="nodecor">diaz2022monai</span>, <span class="nodecor">sebro2023totalsegmentator</span>, <span class="nodecor">wasserthal2023totalsegmentator</span>). نتيجة لذلك، تُركّز أغلب مجموعات البيانات ونماذج التجزئة المنشورة في الأدبيات السابقة تركيزًا ضيقًا على مهمة بعينها، الأمر الذي يحدّ من قيمتها الترجمية السريرية.</p>
  <p>لمواجهة هذا التحدي، طُرحت في السنوات الأخيرة منهجيات تمكّن المستخدمين من تقديم تعليقات "متفرقة" قليلة الكلفة زمنياً، مثل الخربشات ومربعات الإحاطة، لتحفيز نموذج تعلم عميق مُدرَّب مسبقًا لإنتاج تعليقات "كثيفة" على هيئة أقنعة تفصيلية (<span class="nodecor">diaz2022monai</span>, <span class="nodecor">ronneberger2015u</span>, <span class="nodecor">huang2018weakly</span>). ورغم أن هذه المناهج تقلّل زمن التعليق لكل بنية، فإنها ما تزال تتطلب من الخبير إنشاء هذه التعليقات تفاعليًا، فضلًا عن تنقيحها والتحقق من صحتها (<span class="nodecor">diaz2022monai</span>). لذلك تبرز حاجة ملحّة إلى أطر لإعداد مجموعات بيانات تجزئة الصور الطبية تُمكّن غير الخبراء من وسمها بتعليقات متفرقة من دون تدخل خبير مستمر.</p>
  <p>حديثًا، أحدثت نماذج الأساس الكبيرة للتعلم العميق المُدرّبة ذاتيًا على مجموعات بيانات واسعة النطاق تتخطى المليار عينة ثورة في الرؤية الحاسوبية، بفضل قابليتها العامة القوية من دون ضبط دقيق خاص بالمهمة (<span class="nodecor">kirillov2023segment</span>, <span class="nodecor">ma2024segment</span>, <span class="nodecor">butoi2023universeg</span>). وهذا يعني أنها لا تحتاج إلى إعادة تدريب متخصص للمهام الطبية ويمكن تشغيلها مباشرة دون إعداد مسبق. نموذج تجزئة أي شيء (<span class="nodecor">SAM</span>) هو أحد هذه النماذج الأساسية مفتوحة المصدر، المبنية على محوّلات الرؤية (<span class="nodecor">ViTs</span>)، ويمتاز بقدرته على التجزئة الدلالية من دون حاجة إلى ضبط دقيق (<span class="nodecor">kirillov2023segment</span>, <span class="nodecor">dosovitskiy2020image</span>). يعمل <span class="nodecor">SAM</span> عبر تهيئة الصورة تفاعليًا بتعليقات متفرقة، مثل النقاط أو مربعات الإحاطة، لإنتاج أقنعة تجزئة "كثيفة".</p>
  <p>تشير الأدبيات الحديثة إلى أن <span class="nodecor">SAM</span> واعد جدًا لتعليق مجموعات البيانات الطبية باستخدام تعليقات متفرقة (<span class="nodecor">cheng2023sam</span>, <span class="nodecor">bui2023sam3d</span>, <span class="nodecor">quan2024slide</span>, <span class="nodecor">deng2023sam</span>, <span class="nodecor">mazurowski2023segment</span>, <span class="nodecor">ma2024segment</span>). ومع ذلك، فإن معظم التقييمات الحالية جرت في بيئات محاكاة بدلًا من إعداد واقعي قائم على التعهيد الجماعي، كما لم تُقَيَّم بعد فعالية التعليقات التي ينتجها <span class="nodecor">SAM</span> لتدريب نماذج التجزئة العميقة ثلاثية الأبعاد. هدف هذه الدراسة هو: 1) تقييم <span class="nodecor">SAM</span> لجمع التعليقات على مجموعات بيانات طبية من معلّقين غير خبراء، و2) التحقق من إمكانية استخدام التعليقات التي ينشئها <span class="nodecor">SAM</span> لتدريب نماذج التجزئة ثلاثية الأبعاد.</p>
  <h1 id="الطرق">الطرق</h1>
  <p>هذه دراسة استعادية اعتمدت على مجموعات بيانات متاحة للعامة، وقد حصلت على موافقة لجنة المراجعة المؤسسية لدينا مع تصنيفها على أنها لا تتضمن أبحاثًا على مشاركين بشريين. الشفرة البرمجية متاحة عبر: <a href="https://github.com/UM2ii/SAM_DataAnnotation" class="uri">https://github.com/UM2ii/SAM_DataAnnotation</a></p>
  <h2 id="نموذج-تجزئة-أي-شيء">نموذج تجزئة أي شيء</h2>
  <p>نموذج <span class="nodecor">Segment Anything</span> هو نموذج أساس في رؤية الحاسوب للتجزئة الدلالية، يعتمد على محوّلات الرؤية (<span class="nodecor">ViTs</span>) (<span class="nodecor">kirillov2023segment</span>, <span class="nodecor">dosovitskiy2020image</span>). يتألف من مُشفّر صور يستخرج الخصائص من الصورة لتكوين تمثيلات مُضمّنة، ومُشفّر تلميحات يحوّل التعليقات "المتفرقة" (مثل النقاط ومربعات الإحاطة) إلى تمثيلات مكمّلة، ومُفكّك أقنعة يستخدم تلك التمثيلات لإنتاج أقنعة تجزئة "كثيفة" للعناصر المهمة في الصورة. تم تدريب <span class="nodecor">Segment Anything</span> على مجموعة بيانات واسعة تضم أكثر من <span class="nodecor">11</span> مليون صورة وأكثر من <span class="nodecor">1</span> مليار قناع تجزئة، ما يمنحه قدرات تعميم عالية عبر مهام ومجالات متنوعة، بما في ذلك التصوير الطبي (<span class="nodecor">cheng2023sam</span>, <span class="nodecor">bui2023sam3d</span>, <span class="nodecor">deng2023sam</span>, <span class="nodecor">mazurowski2023segment</span>, <span class="nodecor">ma2024segment</span>).</p>
  <!-- يمكن استكمال بقية النص بالمحتوى الأصلي بعد تنقيحه بنفس الأسلوب -->
</main>
</body>
</html>