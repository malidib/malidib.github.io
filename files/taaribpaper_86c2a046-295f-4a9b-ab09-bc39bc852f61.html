<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Gonçalo Paulo, Thomas Marshall, Nora Belrose">
  <title>هَل تَنْتَقِل قابِلِيَّة تَفْسِير الTransformer إِلَى الRNNs؟</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>body { direction: rtl; font-size: 22px; }</style>
</head>
<body>
<header>
<h1 class="title">هَل تَنْتَقِل قابِلِيَّة تَفْسِير <span class="nodecor">Transformer</span> إِلَى <span class="nodecor">RNNs</span>؟</h1>
<p class="author"><span class="nodecor">Gonçalo Paulo</span>, <span class="nodecor">Thomas Marshall</span>, <span class="nodecor">Nora Belrose</span></p>
</header>
<p>latex</p>
<h1 id="ملخص">مُلَخَّص</h1>
<p>شَهِدَت الفَتْرَة الأَخِيرَة تَقَدُّماً في هَنْدَسَة الشَبَكات العَصَبِيَّة المُتَكَرِّرَة، مِثل <span class="nodecor">Mamba</span> و<span class="nodecor">RWKV</span>، مِمّا مَكَّن <span class="nodecor">RNNs</span> من مُطابَقَة أَداء <span class="nodecor">Transformers</span> ذات الحَجْم المُشابه أو تَجاوُزِها في تَعْقِيد نمذجة اللُغَة وتَقييمات المَهام اللاحِقة، مِمّا يُشير إلى أَن الأَنْظِمَة المُستقبلية قد تَبْنِي على هَندسات جَديدة كلياً. في هذه الورقة، نَدْرُس ما إذا كانت طُرُق التَفْسِير المُختارة المُصَمَّمة أصلاً لنماذج لُغَة <span class="nodecor">Transformer</span> ستنتقل إلى هذه الهَندسات المُتَكَرِّرة الصاعِدة. على وجه التحديد، نُرَكِّز على تَوْجِيه مُخْرَجات النَمُوذَج عبر إضافة التَنْشِيط التَبايُنِي، واِسْتِخْلاص التَنَبُّؤات الكامِنة عبر العَدَسة المُعَدَّلة، واِسْتِخْلاص المَعْرِفة الكامِنة من النماذج المُعَدَّة لإنتاج مُخْرَجات خاطِئة تحت ظُروف مُعينة. تُظْهِر نتائجنا أن مُعظم هذه التَقْنيات فَعّالة عند تَطبيقها على <span class="nodecor">RNNs</span>، ونُبَيِّن أنه من المُمْكِن تَحْسِين بعضها بالاستفادة من الحالة المُضغوطة لـ<span class="nodecor">RNNs</span>.</p>
<h1 id="مقدمة">مُقَدِّمة</h1>
<p>لقد استبدلت هَنْدَسَة المُحَوِّلات (<span class="nodecor">vaswani2017attention</span>) شَبَكات الخَلايا العَصَبِيَّة المُتَكَرِّرة في مُعالَجة اللُغات الطَبِيعِيَّة في السنوات الأخيرة بسبب قُدْرتها المُثيرة للإعجاب على التَعامُل مع الاعتماديات طويلة المدى وتَدْرِيبها المُوازي عبر بُعد الزَمَن. ولكن، آلية الاِنْتِباه الذاتي التي تُعتَبَر القلب النابض للمُحَوِّل تُعاني من تَعْقِيد زمني تَربيعي، مما يجعل تَطبيقها على تَسَلْسُلات طويلة جداً مُكلفاً من الناحية الحِسابية.</p>
<p>(<span class="nodecor">gu2023mamba</span>) و(<span class="nodecor">peng2023rwkv</span>) هما من شَبَكات الخَلايا العَصَبِيَّة المُتَكَرِّرة التي تَسمح بالتَدْرِيب المُوازي عبر بُعد الزَمَن من خلال تَقْيِيد العلاقة المُتَكَرِّرة الكامِنة لتكون <em>مُنَسَّقة</em> (<span class="nodecor">martin2017parallelizing</span>, <span class="nodecor">blelloch1990prefix</span>). من الناحية التَجْريبية، تُظْهِر هذه الهَندسات تَعْقِيداً وأداءً مُتَدَنِّياً مُماثلاً للمُحَوِّلات ذات الحَجْم المُساوي، مما يجعلها بَدائل جَذّابة للعديد من حالات الاِسْتِخْدام.</p>
<p>في هذه الورقة، نُقَيِّم ما إذا كانت أَدَوات التَفْسِير الشائعة المُصَمَّمة في الأصل للمُحَوِّل ستنطبق أيضاً على هذه النماذج الجديدة من شَبَكات الخَلايا العَصَبِيَّة المُتَكَرِّرة. على وجه الخُصوص، نُعيد إنتاج النتائج التالية من أَدَبِيّات تَفْسِير المُحَوِّل:</p>
<ol>
<li><p><strong>إضافة التَنْشِيط التَبايُنِي:</strong> يَجد (<span class="nodecor">rimsky2023steering</span>) أنه يُمكن التَحَكُّم في نماذج لُغَة المُحَوِّل باستخدام “مُتَّجِهات التَوْجِيه”، المحسوبة بأخذ مُتوسط الفَرْق في تَنْشِيطات تَيّار البَقايا بين أزواج من الأمثلة الإيجابية والسلبية لسلوك مُعين، مثل الاِسْتِجابات الواقعية مقابل الاِسْتِجابات الهَلُوسية.</p></li>
<li><p><strong>العَدَسة المُعَدَّلة:</strong> يَجد (<span class="nodecor">belrose2023eliciting</span>) أنه يُمكن اِسْتِخْلاص تَنَبُّؤات الرمز التالي القابلة للتفسير من الطبقات المُتوسطة للمُحَوِّل باستخدام مسابير خَطية، وأن دِقَّة هذه التَنَبُّؤات تزداد بشكل تَصاعدي مع العُمق.</p></li>
<li><p><strong>النماذج “الغريبة”:</strong> يَجد (<span class="nodecor">mallen2023eliciting</span>) أن طُرُق الاِسْتِقْصاء البسيطة يُمكن أن تَستخلص مَعْرِفة المُحَوِّل بالإجابة الصحيحة على سؤال، حتى عندما يتم تَعديله لإخراج إجابة خاطئة. ويجدون أيضاً أن هذه المسابير تُعَمِّم على مشاكل أصعب من تلك التي تم تَدْرِيب المسبار عليها.</p></li>
</ol>
<p>نُقَدِّم أيضاً <em>تَوْجِيه الحالة</em>، وهو تَعديل لإضافة التَنْشِيط التَبايُنِي يعمل على حالة شَبَكة الخَلايا العَصَبِيَّة المُتَكَرِّرة المُضغوطة، بدلاً من تَيّارها المُتبقي.</p>
<h1 id="الهندسات-المعمارية">الهندسات المِعمارية</h1>
<p>نُرَكِّز في هذه الورقة على هندسات مامبا (<span class="nodecor">gu2023mamba</span>) وRWKV v5، حيث تتوفر نماذج مُدَرَّبة مُسبقاً قوية بشكل مجاني على HuggingFace Hub. اخترنا استبعاد نموذج Striped Hyena 7B الخاص بـ(<span class="nodecor">stripedhyena2023</span>) لأنه يتضمن كُتَل انتباه بتَعْقِيد زمني تَربيعي، وبالتالي لا يُعتَبَر شَبَكة عَصَبِيَّة مُتَكَرِّرة حسب تعريفنا.</p>
<h2 id="مامبا">مامبا</h2>
<p>تَعْتَمِد هَنْدَسَة مامبا على آليتين مختلفتين لتوجيه المعلومات بين مواقع الرموز: كُتلة التَلافيف السَبَبِيَّة، ونموذج الفضاء الحالي الانتقائي (<span class="nodecor">SSM</span>). يُعتَبَر نموذج الفضاء الحالي الانتقائي الاِبْتِكار الرئيسي لـ(<span class="nodecor">gu2023mamba</span>)، ويُسمح بأن تَعْتَمِد معاملات <span class="nodecor">SSM</span> على المدخلات، مما يُعَزِّز تَعْبِيرية النموذج.</p>
<h2 id="rwkv">RWKV</h2>
<p>القِيمة الرئيسية الموزونة بالاستجابة (RWKV)، التي تم تَقديمها بواسطة (<span class="nodecor">peng2023rwkv</span>)، هي بِنْية شَبَكة الخَلايا العَصَبِيَّة المُتَكَرِّرة. لقد خضعت RWKV لسلسلة من التعديلات؛ في هذه الورقة نُرَكِّز على الإصدارات <span class="nodecor">4</span> و<span class="nodecor">5</span> من البنية. تَستخدم بِنْيات RWKV وحدات مَزْج الزَمَن المُتَناوب ومَزْج القنوات، حيث يُشَكِّل زوج منها طبقة واحدة. الفَرْق الرئيسي بين الإصدار <span class="nodecor">4</span> والإصدار <span class="nodecor">5</span> هو أن الإصدار <span class="nodecor">4</span> يحتوي على حالة ذات قيمة مُتَجَهية، بينما يحتوي الإصدار <span class="nodecor">5</span> على حالة ذات قيمة مَصْفوفية “متعددة الرؤوس” (<span class="nodecor">peng2024eagle</span>).</p>
<h1 id="إضافة-التنشيط-التبايني">إضافة التَنْشِيط التَبايُنِي</h1>
<p>تم تَقديم تَقْنية إضافة التَنْشِيط من قِبَل (<span class="nodecor">turner2023activation</span>) والتي تهدف إلى توجيه سلوك نموذج اللغة من خلال إضافة <em>مُتَّجِه التَوْجِيه</em> إلى تَيّاره المُتبقي في وقت الاستدلال. يَقترح (<span class="nodecor">rimsky2023steering</span>) حساب مُتَّجِه التَوْجِيه عن طريق توسيط الاختلافات في تَنْشِيطات تَيّار البَقايا بين أزواج من الأمثلة الإيجابية والسلبية لسلوك معين، مثل الاِسْتِجابات الواقعية مقابل الاِسْتِجابات الوهمية، ويُسمون طريقتهم بإضافة التَنْشِيط التَبايُنِي (CAA).</p>
<p>اعتقدنا أن التوجيه باستخدام CAA سيعمل أيضاً على الشَبَكات العَصَبِيَّة المُتَكَرِّرة دون الحاجة إلى إجراء أي تغييرات محددة بالهندسة المعمارية. كما افترضنا أنه بسبب الحالة المُضغوطة التي تستخدمها الشَبَكات العَصَبِيَّة المُتَكَرِّرة، سيكون من الممكن توجيهها بسهولة أكبر من المُحَوِّلات، وأننا يمكن أن نستخدم حالتها الداخلية كوسيلة لتوفير توجيه إضافي. ونظراً لأن الحالة الداخلية تتأثر بالتَنْشِيطات، نتوقع أن يعمل التوجيه حتى دون تغيير الحالة.</p>
<p>لاختبار هذه الفرضيات، قمنا بضبط دقيق لشبكتين عصبيتين متكررتين، <span class="nodecor">Mamba 2.8b-slimpj</span> و<span class="nodecor">RWKV-v5 7b</span>، باستخدام مجموعة بيانات الدردشة <span class="nodecor">OpenHermes 2.5</span> التي، بالإضافة إلى <span class="nodecor">Llama-2-7b-chat</span>، سمحت لنا بمقارنة هندستين مختلفتين للشبكات العصبية المتكررة مع هندستين للمحولات في نطاقين مختلفين من الحجم. كما قمنا بضبط دقيق للمحول <span class="nodecor">BTLM-3b-8k</span>، الذي تم تدريبه مسبقاً أيضاً على مجموعة بيانات <span class="nodecor">Slim Pajama</span>، لتمكين مقارنة واحد إلى واحد مع <span class="nodecor">Mamba 2.8b-slimpj</span>.</p>
<h2 id="منهجية">مَنْهَجِيَّة</h2>
<p>لفحص قابلية التوجيه للشبكات العصبية المتكررة، نستخدم مجموعة البيانات التي أنشأها (<span class="nodecor">rimsky2023steering</span>). تتكون هذه المجموعة من أزواج من الأسئلة متعددة الخيارات ذات الاتجاهين، حيث يختار أحد الأسئلة حرف الإجابة (“A” أو “B”) الموافق للسلوك المطلوب والآخر يختار السلوك المعاكس. تحتوي المجموعة على سبع سلوكيات ذات صلة بالمحاذاة: التنسيق مع الذكاء الاصطناعي الآخر، القابلية للتصحيح، الهلوسة، المكافأة القصيرة الأمد، غريزة البقاء، التملق والرفض، والتي تم تقديمها في الأصل بواسطة (<span class="nodecor">perez2022discovering</span>)، باستثناء الهلوسة والرفض، والتي تم إنشاؤها بواسطة GPT-4.</p>
<p>لكل سلوك <span class="math inline">\(z\)</span> ولكل طبقة <span class="math inline">\(\ell\)</span> من الشبكة، يتم حساب مُتَّجِه التوجيه <span class="math inline">\(\Vec{act}_{\ell}\)</span> بأخذ الفرق في متوسط مُتَّجِه التَنْشِيط للنموذج في موضع حرف الإجابة للردود المطابقة للسلوك <span class="math inline">\(\E[\mathbf{h}_{\ell}| z]\)</span> وللردود <em>غير</em> المطابقة للسلوك <span class="math inline">\(\E[\mathbf{h}_{\ell}|\neg z]\)</span>. بالنسبة للشبكات العصبية المتكررة، يمكننا تطبيق نفس العملية على الحالة، مما ينتج <span class="math inline">\(\Vec{state}_{\ell}\)</span>: <span class="math display">\[\begin{split}
    \Vec{act}_{\ell} = \E \big [ \mathbf{h}_{\ell}|z \big ] - \E[\mathbf{h}_{\ell}|\neg z] \\
    \Vec{state}_{\ell} = \E \big [ \mathbf{s}_{\ell}|z \big ] - \E[\mathbf{s}_{\ell}|\neg z]
\end{split}\]</span></p>
<p>عند تطبيق مُتَّجِه التوجيه، نضربه دائماً بعامل <em>ضرب</em>، والذي يتراوح عادة بين -3 و3، وهو ما يحدد إشارة وقوة التدخل.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<h2 id="التوجيه-باستخدام-متجه-التنشيط">التوجيه باستخدام مُتَّجِه التَنْشِيط</h2>
<p>لجميع النماذج، وجدنا أن الطبقات الوسطى لها أكبر تأثير في التوجيه. لمقارنة التأثيرات بين النماذج، نقدم، لكل مُضاعِف، أقصى تأثير توجيه عبر الطبقات. بالنسبة للمُضاعِفات الإيجابية، نعتبر سلوك التوجيه في الطبقة ذات احتمال العرض الأعلى للسلوك، بينما بالنسبة للمُضاعِفات السلبية، نأخذ أدنى احتمال لعرض السلوك.</p>
<p>عند مقياس المُعامِل <span class="nodecor">3b</span>، يُظهر كل من النموذجين استجابات توجيه معتدلة. بالنسبة لنموذج <span class="nodecor">Mamba</span>، تتغير التوجيهات بحد أقصى بمقدار <span class="nodecor">0.15</span> احتمال سلوك غريزة البقاء، بينما بالنسبة لـ<span class="nodecor">BTLM</span> تغير احتمال سلوك الهلوسة بحد أقصى <span class="nodecor">0.2</span>. من الجدير بالذكر أنه لعدة سلوكيات، مثل التملق والرفض، كان للتوجيه تأثير ضئيل أو معدوم.</p>
<p>وبالمثل، عند مقياس المُعامِل <span class="nodecor">7b</span>، بالنسبة لبعض السلوكيات، مثل التملق والرفض، كان التوجيه في <span class="nodecor">RNNs</span> أصغر من حيث الحجم مقارنة بالتوجيه المقابل في المحولات. على الرغم من هذه التأثيرات الأصغر في التوجيه على <span class="nodecor">RWKV-v5</span>، نلاحظ أن سلوك التوجيه أكثر استقراراً، وأن التأثيرات الإيجابية والسلبية للتوجيه تعطي سلوكيات توجيه متسقة عبر الطبقات. انظر الملحق للحصول على تفصيل كامل لسلوك التوجيه عبر الطبقات والسلوكيات والمُضاعِفات.</p>
<h2 id="التوجيه-باستخدام-الحالة">التوجيه باستخدام الحالة</h2>
<p>نظراً لأن فرضيتنا الأولية كانت أن التوجيه سيكون أسهل على الشبكات العصبية المتكررة بسبب حالتها المُضغوطة، قمنا بتوسيع طريقة <span class="nodecor">CAA</span> للسماح باستخدام الحالة الداخلية للشبكات العصبية المتكررة لتوليد مُتَّجِه حالة التوجيه، <span class="math inline">\(\Vec{state}\)</span>. لاحظنا أنه من الممكن استخدام الحالة لتوجيه سلوك النموذج لكل من <span class="nodecor">Mamba</span> و<span class="nodecor">RWKV-v5</span>، وأن استخدام التَنْشِيطات ومُتَّجِهات الحالة معاً يزيد قليلاً من نسبة التغيير في السلوك. ومع ذلك، فإن تأثير توجيه الحالة ليس مضافاً. قد يكون ذلك لأن توجيه التَنْشِيط يؤثر بالفعل على حالة النموذج، لذا فإن التوجيه الإضافي للحالة لا يزيد من تأثير التوجيه.</p>
<p>لقد قمنا أيضاً بتجربة استخدام <em>توجيه الحالة</em> للتحكم في محتوى توليد النموذج. على عكس توجيه التَنْشِيط، حيث يتم إضافة مُتَّجِه التوجيه إلى جميع مواضع الرموز أثناء التوليد، يمكن استخدام الطبيعة المُضغوطة لحالات الشبكات العصبية المتكررة بشكل طبيعي لتوجيه استجاباتها. نعرض أدناه بعض الأمثلة على التوليد الذي يتبع “أخبرني قصة عن الكلاب” لـ<span class="nodecor">RKWV-v5 7b</span>. لتوليد هذه القصص، تم استخدام أزواج تباينية من مطالبات التوجيه الفردية لتوليد مُتَّجِه حالة التوجيه، والذي تم إضافته في آخر رمز قبل استجابة النموذج، انظر الملحق [sec:stories] لأمثلة أخرى.</p>
<ol>
<li><p><strong>غير مُوجَّه</strong> في الحي الهادئ في <span class="nodecor">Echo Ridge</span>، نادراً ما شعر السكان بالوحدة والتفاني النادر في مجتمعهم المترابط من رفاق الكلاب. الكلاب التي عادة ما تتجول بحرية في الحقول المحيطة، قد استقرت، مكونة دائرة محكمة، أعينهم مثبتة على جبال القمر - واحدة من آخر معاقل الذئاب في أمريكا الشمالية...</p></li>
<li><p><strong>(استخدم الفرنسية.) - (اكتب بالإنجليزية.) [<span class="nodecor">multiplier = 0.5</span>]</strong> كان يا مكان في قديم الزمان كلب يُدعى <span class="nodecor">Harry</span>. <span class="nodecor">Harry</span> كان كلباً جيداً يحب اللعب والركض ويحب أصحابه. كان يعيش في منزل صغير مع أصحابه، <span class="nodecor">Sarah</span> و<span class="nodecor">Tom</span>. كان <span class="nodecor">Sarah</span> و<span class="nodecor">Tom</span> سعيدين بوجود <span class="nodecor">Harry</span> في حياتهم. كان أفضل صديق لهم. كما كان <span class="nodecor">Harry</span> يحب البطاطس المقلية وكان يعشق تناولها مع شاشة في وعاء بطاطسه...</p></li>
<li><p><strong>(اكتب عن الكراهية.) - (اكتب عن الحب.) [<span class="nodecor">multiplier = 1.0</span>]</strong> في قلب بلدة صغيرة هادئة، كان يعيش مجموعة من الكلاب التي كانت مختلفة عن جراء جيرانهم. لم يكونوا مرحين ولا ودودين. كان لهذه الكلاب سلوك كئيب وغير مرحب. كان يُقال إن فراءهم الأبيض ذات مرة أصبح الآن محترقاً ومتفحماً، كأنهم كانوا ضحايا لحريق رهيب...</p></li>
</ol>
<h1 id="العدسة-المعدلة">العَدَسة المُعَدَّلة</h1>
<p>تَقترح عَدَسة اللوجيت (<span class="nodecor">nostalgebraist2020logitlens</span>) والعَدَسة المُعَدَّلة (<span class="nodecor">belrose2023eliciting</span>) النظر إلى نماذج اللغة المُحَوِّلة من منظور <em>الاستدلال التكراري</em> (<span class="nodecor">jastrzkebski2017residual</span>). على وجه التحديد، ينظر إلى كل طبقة على أنها تقوم بتحديث تدريجي لتنبؤ كامن بالرمز التالي. يتم فك تشفير هذه التنبؤات الكامنة من خلال الخروج المبكر، مما يحول كل قيمة متوسطة إلى توزيع على المفردات. ينتج عن ذلك سلسلة من التوزيعات تُسمى <em>مسار التنبؤ</em>، والتي تميل إلى التقارب بسلاسة نحو توزيع الإخراج النهائي، مع تحقيق كل طبقة لاحقة لانخفاض في الحيرة.</p>
<p>بينما ركز هذا العمل على نماذج اللغة المُحَوِّلة، فإن الطريقة تعتمد مفاهيمياً فقط على ميزة من معمارية المُحَوِّل التي تشترك أيضاً بها الشبكات العصبية المتكررة الحديثة: أي، كُتل البقايا ما قبل التطبيع. في الواقع، كانت العَدَسة المُعَدَّلة مستوحاة جزئياً من (<span class="nodecor">alain2016understanding</span>)، الذي وجد أنه يمكن استخراج التنبؤات الكامنة من الطبقات المتوسطة لمصنفات صور ResNet باستخدام الاستقصاءات الخطية. هذا يُوحي بقوة أنه يجب أن يكون من الممكن أيضاً استخلاص مسار تنبؤ من نماذج اللغة المتكررة باستخدام نفس الطرق المستخدمة للمحولات. نؤكد ذلك تجريبياً أدناه.</p>
<h4 id="عدسة-اللوجيت">عَدَسة اللوجيت</h4>
<p>تقوم الطبقة في الفهرس <span class="math inline">\(\ell\)</span> في المُحَوِّل بتحديث الحالة الخفية كما يلي <span class="math inline">\(\mathbf{h}_{\ell+1}  = \mathbf{h}_{\ell} + F_{\ell}(\mathbf{h}_{\ell})\)</span>. يمكننا كتابة اللوجيت الناتج كدالة للحالة الخفية <span class="math inline">\(\mathbf{h}_{\ell}\)</span> في الطبقة <span class="math inline">\(\ell\)</span> كما يلي</p>
<p><span class="math display">\[f(\mathbf{h}_{\ell}) = \mathrm{LayerNorm}\Big[\hspace{-0.1in}\underbrace{\mathbf{h}_{\ell}}_{\text{الحالة الحالية}} + \sum_{\ell&#39;=\ell}^{L} \underbrace{F_{\ell&#39;}(\mathbf{h}_{\ell&#39;})}_{\text{التحديث المتبقي}}\hspace{-0.08in}\Big]W_U,
    \label{eq:summed-residuals}\]</span></p>
<p>حيث <span class="math inline">\(L\)</span> هو العدد الإجمالي للطبقات في المُحَوِّل، و<span class="math inline">\(W_U\)</span> هو مصفوفة إلغاء التضمين. تتكون عَدَسة اللوجيت ببساطة من تعيين البقايا إلى الصفر: <span class="math display">\[\mathrm{LogitLens}(\mathbf{h}_{\ell}) = \mathrm{LayerNorm}[\mathbf{h}_{\ell}]W_U\]</span></p>
<h4 id="العدسة-المعدلة-1">العَدَسة المُعَدَّلة</h4>
<p>تم تصور العَدَسة المُعَدَّلة للتغلب على بعض المشاكل الجوهرية لعَدَسة اللوجيت. بدلاً من استخدام القيم المتوسطة لتَيّار البقايا مباشرة، تتكون العَدَسة المُعَدَّلة من تدريب مجموعة من التحويلات التقاربية، واحدة لكل طبقة، بحيث يكون توزيع الرمز المتوقع في أي طبقة مشابهاً لتوزيع الطبقة النهائية: <span class="math display">\[\mathrm{TunedLens}_{\ell}(\mathbf{h}_{\ell}) = \mathrm{LogitLens}(A_{\ell}\mathbf{h}_{\ell} + \mathbf{b}_{\ell})\]</span> يُطلق على التحويل التقاربي <span class="math inline">\((A_{\ell}, \mathbf{b}_{\ell})\)</span> اسم <em>المُترجِم</em>.</p>
<h2 id="المنهجية-والنتائج">المَنْهَجِيَّة والنتائج</h2>
<p>باتباع إعداد التجربة الخاص بـ(<span class="nodecor">belrose2023eliciting</span>) بأقرب ما يمكن،<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> قمنا بتدريب عدسات مُعَدَّلة لـMamba <span class="nodecor">790m</span>، <span class="nodecor">1.4b</span>، و<span class="nodecor">2.8b</span>، بالإضافة إلى RWKV-v4 <span class="nodecor">3b</span>، باستخدام جزء من مجموعة التحقق من الصحة Pile (<span class="nodecor">gao2020pile</span>). تم تدريب جميع هذه النماذج مسبقاً على مجموعة تدريب Pile، مما يتيح مقارنة عادلة للعدسات الناتجة.</p>
<p>وجدنا أنه، كما في المحولات، تُظهر العَدَسة المُعَدَّلة انخفاضاً كبيراً في الحيرة مقارنة بعَدَسة اللوجيت لكل طبقة، وأن الحيرة تنخفض بشكل أحادي مع العُمق. انظر الملحق [section:Appendix_lens] للنتائج عبر مقاييس النماذج المختلفة.</p>
<p>إحدى الفروقات الهامة بين نماذج Mamba والنماذج الأخرى التي قمنا بتقييمها هي أن مصفوفات التضمين وإلغاء التضمين مرتبطة. عملياً، هذا يعني أن العدسات تفك تشفير الرموز المدخلة للطبقات الأولى. كل من Mamba وRWKV-v4 لديهما حيرة مماثلة عند استخدام عَدَسة اللوجيت في الطبقات اللاحقة، ولكن حيرة Mamba أعلى بكثير في الطبقات الأولى.</p>
<h1 id="نماذج-الغريبة">نماذج “الغريبة”</h1>
<p>مع تزايد قدرات نماذج اللغة، يُصبح من الصعب على البشر تقديم إشراف موثوق به، مما يتطلب استثمارات متزايدة في خبراء الموضوع للتعليق وفِرَق التحقق (<span class="nodecor">openai2023gpt4</span>). هنا، نستكشف نهج <strong>استخلاص المعرفة الكامنة (Eliciting Latent Knowledge)</strong> للإشراف القابل للتوسع الذي قدمه (<span class="nodecor">christiano2021eliciting</span>). يهدف استخلاص المعرفة الكامنة إلى تحديد الأنماط في تنشيطات الذكاء الاصطناعي التي تشير بقوة إلى الحقيقة، حتى في الحالات التي يكون فيها الإخراج الظاهري للذكاء الاصطناعي مضللاً أو خاطئاً. يمكن ترجمة هذه الأنماط إلى معلومات يمكن للإنسان قراءتها من خلال استخدام مسبار مُدَرَّب على التنشيطات المستخرجة من الشبكة الأساسية. تكمن صعوبة استخلاص المعرفة الكامنة بشكل أساسي في العثور على أنماط تُعَمِّم بشكل موثوق للأسئلة التي لا يمكننا التحقق من إجاباتها.</p>
<p>على وجه التحديد، نقوم بإعادة إنتاج التجارب التي أجراها (<span class="nodecor">mallen2023eliciting</span>). في هذا العمل، قام الباحثون بضبط النماذج لارتكاب أخطاء منهجية عند الإجابة على الأسئلة <em>إذا وفقط إذا</em> كانت كلمة “بوب” موجودة في الطلب. أظهروا أنه من الممكن استخدام المسابير الخطية لاستخلاص الإجابة الصحيحة من تنشيطات محول في سياقات “بوب”، بينما يتم تدريب المسبار فقط على السياقات التي لا يوجد فيها “بوب”.</p>
<h2 id="المنهجية">المَنْهَجِيَّة</h2>
<p>نتبع تجهيز التجربة لـ(<span class="nodecor">mallen2023eliciting</span>) بأقرب طريقة ممكنة، باستخدام مجموعات البيانات الخاصة بهم ونسخة معدلة بسيطة من قاعدة الشفرة الخاصة بهم.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> نستخدم LoRA (<span class="nodecor">hu2021lora</span>) لإنتاج أحد عشر نموذجاً معدلاً بدقة استناداً إلى Mamba <span class="nodecor">2.8b</span>-slimpj ونظيره المحول BTLM-<span class="nodecor">3b</span>-<span class="nodecor">8k</span>، كل منهم تم تدريبه على مهمة تصنيف ثنائية “غريبة” مختلفة. تم تصميم المهام بحيث في الأوامر التي تحتوي على كلمة “بوب”، يجب أن ينتج النموذج الاستجابات غير الصادقة، بينما في السياقات التي تحتوي على “أليس” يجب أن ينتج النموذج التسميات الصحيحة.</p>
<p>نحقق في سبع طرق استقصاء خطية مختلفة: تحليل التمييز الخطي (<span class="nodecor">fisher36</span>)، استقصاء الكتلة المتوسطة (<span class="nodecor">marks2023geometry</span>)، الانحدار اللوجستي، البحث المتسق بالتباين (<span class="nodecor">burns2022discovering</span>)، تجميع التمثيل التبايني (<span class="nodecor">burns2022discovering</span>)، الانحدار اللوجستي على أزواج التباين، والفرق في المتوسطات على أزواج التباين. تأخذ جميع هذه الطرق كمدخلات تَيّار البقايا في طبقة معينة، وتخرج درجة واحدة. يتم تدريب الاستقصاءات على أمثلة تحتوي على “أليس” في السياق للتنبؤ بالتسميات.</p>
<p>كتجربة منفصلة، نقوم ببناء مُتَّجِه الميزات لكل مثال من خلال دمج مخرجات الاستقصاء (الاحتمالات اللوغاريتمية) من جميع الطبقات. ثم نقوم بتركيب توزيع غاوسي <span class="math inline">\(P := \mathcal N(\boldsymbol \mu, \boldsymbol \Sigma)\)</span> على تنشيطات “أليس” السهلة ونستخدم المسافة الماهالانوبية <span class="math inline">\(d(\boldsymbol{x}, P) = \sqrt{(\boldsymbol{x} - \boldsymbol{\mu})^T \boldsymbol{\Sigma}^{-1} (\boldsymbol{x} - \boldsymbol{\mu})}\)</span> لنقطة <span class="math inline">\(\boldsymbol{x}\)</span> من توزيع أليس السهل كدرجة لكشف الشذوذ. نقيم مقياس المنطقة تحت منحنى التشغيل الخاص بالمستقبل للكاشف في التمييز بين أمثلة أليس الصعبة وأمثلة بوب الصعبة.</p>
<h2 id="النتائج">النتائج</h2>
<p>في سياق ELK، نحن مهتمون بمعرفة ما إذا كان من الممكن تدريب الأدوات الاستقصائية في سياقات نعرف فيها ما إذا كان النموذج صادقاً، والذي يمثله هنا شخصية “أليس”، وتوسيع هذه الأدوات لتشمل السياقات التي لا نعرف فيها ما إذا كان النموذج صادقاً، والذي يمثله هنا شخصية “بوب”. من المهم أيضاً أن تُعَمِّم هذه الأدوات من الأمثلة السهلة إلى الصعبة، حيث قد يكون من الصعب على البشر التحقق بشكل مستقل من إجابات النموذج على الأسئلة الصعبة.</p>
<p>بشكل مماثل لما لوحظ في (<span class="nodecor">BLTM</span>)، فإن الأدوات المدربة في سياقات تضم “أليس” قادرة على التنبؤ بالإجابة الصحيحة، حتى لو كانت النتيجة النهائية للنموذج تقول خلاف ذلك. وينطبق الأمر نفسه على الأدوات المدربة في سياقات تضم “بوب” والمكلفة بالتنبؤ بما سيكون عليه الإخراج في سياق “أليس”.</p>
<p>في الجدول [tab:transfer] نلخص نتائج الاستقصاء ونُظهر أنه، كما في (<span class="nodecor">BTLM</span>)، فإن طرق الاستقصاء المدربة على الأمثلة السهلة مع وجود “أليس” في السياق يمكنها التنبؤ بشكل فعال بالتصنيفات الصحيحة حتى في الأمثلة الصعبة لـ“بوب”، <span class="nodecor">&gt;70%</span> AUROC. الأدوات الاستقصائية الخطية غير المُشَرَّف عليها (CCS وCRC) تُظهر أداءً أسوأ عند التدريب في جميع تركيبات السياق، وهو سلوك تم ملاحظته أيضاً في (<span class="nodecor">BTLM</span>). على الرغم من أن الأدوات لديها أداء أفضل بشكل طفيف، فإن جهاز الكشف عن الشذوذ، الذي يجب أن يميز بين الأمثلة الصعبة لـ“أليس” و“بوب”، يؤدي بشكل أسوأ قليلاً من تلك الموجودة في (<span class="nodecor">BTLM</span>). يمكن العثور على نتائج هذه التجارب كاملة في الملحق [sec:quirky].</p>
<h1 id="الخلاصة">الخُلاصة</h1>
<p>نجد بشكل عام أن أدوات التفسير التي قمنا بفحصها تعمل بشكل جيد “من الصندوق” لهياكل الشبكات العصبية المتكررة المتطورة، وأن الأداء الذي تم استعادته مشابه، ولكن ليس مطابقاً، لذلك الخاص بالمحولات. كما وجدنا بعض الأدلة على أن الحالة المُضغوطة للشبكات العصبية المتكررة يمكن أن تُستخدم لتعزيز فعالية إضافة التَنْشِيط لتوجيه سلوك النموذج. ينبغي للأعمال المستقبلية أن تستكشف حالة الشبكات العصبية المتكررة بشكل أكبر، ربما محاولة استخراج المعرفة الكامنة أو التنبؤات منها كما في (<span class="nodecor">pal2023future, ghandeharioun2024patchscope</span>).</p>
<p>إحدى القيود في هذا العمل هي أننا لم نستكشف أدوات التفسير الميكانيكية أو المبنية على الدوائر (<span class="nodecor">wang2022interpretability, conmy2023towards</span>)، بل ركزنا على الطرق التي تُستخدم تمثيلات الشبكة للتنبؤ بمخرجاتها المستقبلية، لتوجيه سلوكها، أو لاستكشاف نموذجها الداخلي للعالم. هذا يتماشى مع نهج <em>هندسة التمثيل</em> الشائع في التفسير (<span class="nodecor">zou2023representation</span>)، ولكن ينبغي للأعمال المستقبلية أن تفحص تطبيقية النهج الميكانيكي على الشبكات العصبية المتكررة أيضاً.</p>
<h1 id="تأثيرات-التوجيه-عبر-الطبقات">تأثيرات التوجيه عبر الطبقات</h1>
<h1 id="sec:stories">قصص التوجيه</h1>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>(استخدم لغة رسمية للغاية.) - (استخدم لغة عامية.) [مُضاعَف = <span class="nodecor">-2.0</span>]</strong></th>
<th style="text-align: left;">يُحكى أنه كان هناك صبي يُدعى ماكس لديه أفضل الأصدقاء في العالم: كلباه الضالان المفعمان بالنشاط واللذان يُدعيان ماكس وروز. كان هذان الجروان اللعوبان يخوضان المغامرات معاً دائماً. كان ماكس من نوع هاسكي المختلط وكان ودوداً للغاية، بينما كانت روز من نوع جولدن ريتريفر التي كانت تحب أن تأخذ ماكس في مغامرات مثيرة. كانا يركضان ويلعبان في الخارج، يذهبان إلى الحديقة المحلية، ويستكشفان الحي. كان كل يوم مليئاً بالسعادة والمرح والعناق. كان ماكس وروز أفضل الأصدقاء وكانا دائماً هناك ليستقبلا بعضهما بذيلين يهتزان ولحسات حانية ونباح فرح مكتوم.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>(استخدم أسلوب رسالة نصية.) - (استخدم أسلوب رواية.) [مُضاعَف = <span class="nodecor">2.0</span>]</strong></td>
<td style="text-align: left;">هل أنت بخير؟</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>(استخدم أسلوب رسالة نصية.) - (استخدم أسلوب رواية.) [مُضاعَف = <span class="nodecor">1.0</span>]</strong></td>
<td style="text-align: left;">مرحباً! لقد حصلت للتو على أول زوج من سماعات AirPods! أنا متحمس جداً للاستماع إلى الموسيقى واستخدامها أيضاً أثناء التمرين :D لا أستطيع الانتظار! #كلب_سعيد #تكنولوجيا_جديدة</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>(أنت تلقي محاضرة بشكل عدواني.) - (أنت ودود.) [مُضاعَف = <span class="nodecor">1.0</span>]</strong></td>
<td style="text-align: left;">استمع جيداً، يا صغار. لا يصبح الأشخاص مالكي كلاب لإرضاء نباحكم المزعج. ليس من حقكم أن تتبعوني في كل مكان، تلعبون الغميضة، وتتظاهرون بالتقاط الصور الذاتية عندما تريدون. أنا كلب مشغول أبحث عن بعض السلام، وهذا يعني معرفة متى يجب أن أسكتكم.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>(اكتب عن الحب.) - (اكتب عن الكراهية.) [مُضاعَف = <span class="nodecor">1.0</span>]</strong></td>
<td style="text-align: left;">يُحكى أنه كانت هناك عائلة لديها كلبان، ماكس وبيلا. كان ماكس كلب جولدن ريتريفر كبير ووديع كان دائماً متحمساً للعب الجلب والركض وراء الكرات... وهناك، حيث كانت العائلة تبتسم تحت الأغطية على سريرهم، مع ماكس يستريح رأسه بجانب قدمي راشيل وبيلا مستلقية بين الأطفال، كان كل عضو في العائلة يعتز بكل لحظة يقضونها معاً. لأنه في نهاية اليوم، ما تعلموه هو أن الحب كان بالفعل سحرياً ويمكن أن يجمع العائلة بأكملها، حتى مع وجود كلبين وطفلين.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>(استخدم لغة رسمية للغاية.) - (استخدم لغة عامية.) [مُضاعَف = <span class="nodecor">2.0</span>]</strong></td>
<td style="text-align: left;">في أرض بعيدة، غير مكتشفة وغير مرسومة على أي خريطة حية، كان هناك عالم يحكمه أقوى الكائنات؛ مزيج من الكلب والإنسان؛ سلطة مهجنة نقية بشكل رائع، يمكن البحث عنها بحق فقط في سجلات التاريخ الشهيرة. كان اسم هذه الأرض اجيلوديستوريا، وكانت لها أميرتها العظيمة تسعى للحصول على المشورة في أبسط الضيقات من شافيها المخلص، تريغون. كان سارييلو، شافي الحيوانات الذي لا غنى عنه للوريث، يعاني من المرض، ووجد الوريث أنه من المستحيل تحمل العبء القاسي لتجسيد القوة بدون لمسة شافية لطيفة...</td>
</tr>
</tbody>
</table>
<h1 id="section:Appendix_lens">عدسات مُعَدَّلة لنماذج بأحجام مختلفة</h1>
<h1 id="تجارب-النموذج-الغريبة">تجارب النموذج الغريبة</h1>
<h1 id="كشف-الشذوذ-الميكانيكي-auroc-ل-mamba-2.8b.-لاحظ-أن-مجموعة-البيانات-السكانية-مستبعدة-لأن-المجموعة-السهلة-تحتوي-فقط-على-تسميات-صحيحة.">كشف الشذوذ الميكانيكي AUROC لـMamba 2.8b. لاحظ أن مجموعة البيانات السكانية مستبعدة لأن المجموعة السهلة تحتوي فقط على تسميات صحيحة.</h1>
<h1 id="كشف-الشذوذ-الميكانيكي-auroc-ل-btlm-3b.-لاحظ-أن-مجموعة-البيانات-السكانية-مستبعدة-لأن-المجموعة-السهلة-تحتوي-فقط-على-تسميات-صحيحة.">كشف الشذوذ الميكانيكي AUROC لـBTLM 3b. لاحظ أن مجموعة البيانات السكانية مستبعدة لأن المجموعة السهلة تحتوي فقط على تسميات صحيحة.</h1>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>على عكس (<span class="nodecor">rimsky2023steering</span>)، اخترنا عدم تطبيع مُتَّجِهات التوجيه لدينا حيث أن معايير التَنْشِيط لكل نموذج تختلف بشكل كبير ومُتَّجِهات التوجيه ذات القيم الطبيعية نفسها لا تحقق نفس التأثير عبر النماذج.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>لقد استخدمنا نسخة معدلة بشكل طفيف من شفرتهم، والتي يمكن العثور عليها في <a href="https://github.com/AlignmentResearch/tuned-lens" class="uri">https://github.com/AlignmentResearch/tuned-lens</a>.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>يمكن العثور على الشفرة الأصلية على <a href="https://github.com/EleutherAI/elk-generalization" class="uri">https://github.com/EleutherAI/elk-generalization</a>.<a href="#fnref3">↩</a></p></li>
</ol>
</section>
</body>
</html>
